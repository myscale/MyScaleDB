From d665f98f34c7fec97e7e047a030c552c1253d402 Mon Sep 17 00:00:00 2001
From: Libao Yang <libaoy@moqi.ai>
Date: Fri, 6 Jan 2023 12:07:08 +0000
Subject: [PATCH 10/85] Fix index building blocks dropping table and ignores
 dropping index issue

---
 src/Core/Settings.h                           |  3 +-
 src/Interpreters/InterpreterDropQuery.cpp     |  6 ++
 .../MergeTreeVectorIndexBuilderUpdater.cpp    | 95 +++++++++++++++----
 src/Storages/StorageMergeTree.cpp             | 19 ++--
 ...drop_vector_index_and_drop_table.reference |  5 +
 ...0_mqvs_drop_vector_index_and_drop_table.sh | 44 +++++++++
 6 files changed, 141 insertions(+), 31 deletions(-)
 create mode 100644 tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.reference
 create mode 100755 tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.sh

diff --git a/src/Core/Settings.h b/src/Core/Settings.h
index c2278dff20..c31878b241 100644
--- a/src/Core/Settings.h
+++ b/src/Core/Settings.h
@@ -170,7 +170,8 @@ class IColumn;
     M(Float, incremental_build_index_ratio, 0.1, "the ratio which data in a datapart is being added to vector index, also is the ratio of data being used for training index", 0)   \
     M(UInt64, max_build_index_block, 100000, "number of rows to build index in one round", 0)     \
     M(UInt64, max_build_index_block_size_rows, 160000, "number of rows to build index in one round", 0) \
-    M(UInt64, max_build_index_block_size_bytes, 512 * 1024 * 1024, "bytes to build index in one round", 0) \
+    M(UInt64, min_build_index_train_block_size, 100 * 1024 * 1024, "Minimum block size in bytes for training in build index", 0) \
+    M(UInt64, max_build_index_add_block_size, 10 * 1024 * 1024, "Maximum block size in bytes for adding vectors in one round of build index", 0) \
     M(UInt64, serialized_index_segment_max_byte, 1000000000,"the number of bytes each segment of a vector index can occupy. lower value generate more segments, resulting in longer build index time but smaller memory consumption.",0)        \
     M(UInt64, background_schedule_pool_size, 128, "Number of threads performing background tasks for replicated tables, dns cache updates. Only has meaning at server startup.", 0) \
     M(UInt64, background_message_broker_schedule_pool_size, 16, "Number of threads performing background tasks for message streaming. Only has meaning at server startup.", 0) \
diff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp
index b04342b37f..2ad3b0d380 100644
--- a/src/Interpreters/InterpreterDropQuery.cpp
+++ b/src/Interpreters/InterpreterDropQuery.cpp
@@ -232,6 +232,12 @@ BlockIO InterpreterDropQuery::executeToTableImpl(ContextPtr context_, ASTDropQue
             else
                 table->checkTableCanBeDropped();
 
+            if(!table->getInMemoryMetadata().vec_indices.empty())
+            {
+                StorageInMemoryMetadata metadata_table = table->getInMemoryMetadata();
+                metadata_table.vec_indices.clear();
+                table->setInMemoryMetadata(metadata_table);
+            }
             table->flushAndShutdown();
 
             TableExclusiveLockHolder table_lock;
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
index 47bf89cb2a..02d0f94a44 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
@@ -325,14 +325,6 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(
 BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOnePart(
     const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part, bool tune, bool slow_mode)
 {
-    MergeTreeReaderSettings reader_settings;
-
-    /// float incremental_ratio = data.getContext()->getSettingsRef().incremental_build_index_ratio;
-    /// size_t max_build_index_block_size_rows = data.getContext()->getSettingsRef().max_build_index_block_size_rows;
-
-    /// try to control memory usage only use max_build_index_block_size_bytes
-    size_t max_build_index_block_size_bytes = data.getContext()->getSettingsRef().max_build_index_block_size_bytes;
-
     LOG_INFO(log, "[buildVectorIndex] part:{}, start checking for build index", part->name);
     for (auto & vec_index_desc : metadata_snapshot->vec_indices)
     {
@@ -488,6 +480,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
             }
         }
 
+        MergeTreeReaderSettings reader_settings;
         auto reader = part->getReader(
             cols,
             metadata_snapshot,
@@ -500,9 +493,21 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
         /// max read block rows for each round
         /// size_t read_block_rows_num = std::max(max_build_index_block_size_rows, static_cast<size_t>(part->rows_count * incremental_ratio));
 
+        /// try to control memory usage only use max_build_index_add_block_size and min_build_index_train_block_size
+        size_t max_build_index_add_block_size = data.getContext()->getSettingsRef().max_build_index_add_block_size;
+        size_t min_build_index_train_block_size = data.getContext()->getSettingsRef().min_build_index_train_block_size;
+        if (min_build_index_train_block_size < max_build_index_add_block_size)
+        {
+            LOG_INFO(log, "[buildVectorIndex] min_build_index_train_block_size {} is smaller than max_build_index_add_block_size {}, will be updated",
+                          min_build_index_train_block_size, max_build_index_add_block_size);
+            min_build_index_train_block_size = max_build_index_add_block_size;
+        }
+
         /// never divide a zero
-        size_t read_block_rows_num = max_build_index_block_size_bytes / 4 / std::max(1, dim);
-        LOG_INFO(log, "[buildVectorIndex] set read_block_rows_num to {}", read_block_rows_num);
+        size_t read_block_rows_num = max_build_index_add_block_size / 4 / std::max(1, dim);
+        size_t train_block_rows_num = min_build_index_train_block_size / 4 / std::max(1, dim);
+        LOG_INFO(log, "[buildVectorIndex] set read_block_rows_num to {}, train_block_rows_num to {}", read_block_rows_num, train_block_rows_num);
+
         bool continue_read = false;
         bool training = true;
 
@@ -516,6 +521,10 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
 
         auto & index_granularity = part->index_granularity;
 
+        size_t num_rows_train = 0;
+        int32_t dataset_offsets_size_train = 0;
+        std::vector<float> vector_raw_data_train;
+
         /// process data block by block
         while (num_rows_read < part->rows_count)
         {
@@ -523,7 +532,27 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
             {
                 throw Exception(ErrorCodes::LOGICAL_ERROR, "Vector index build is cancelled for part {}", part->name);
             }
-            empty_ids.clear();
+
+            bool found = false;
+            for (auto & vec_index_desc_storage : part->storage.getInMemoryMetadataPtr()->vec_indices)
+            {
+                if (vec_index_desc == vec_index_desc_storage)
+                {
+                    found = true;
+                    break;
+                }
+            }
+            if(!found)
+            {
+                LOG_INFO(log, "Vector index has been dropped, no need to build it.");
+                disk->removeRecursive(vector_tmp_relative_path);
+                return BuildVectorIndexStatus::SUCCESS;
+            }
+
+            /// traning size is bigger than add vector size, may call several times before training.
+            if (!training)
+                empty_ids.clear();
+
             size_t remaining_size = part->rows_count - num_rows_read;
             size_t max_read_row = std::min(remaining_size, read_block_rows_num);
 
@@ -534,7 +563,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
 
             num_rows_read += num_rows;
 
-            for (size_t mask = 0; mask < total_mask - 1; ++mask)
+            for (size_t mask = current_mask; mask < total_mask - 1; ++mask)
             {
                 if (index_granularity.getMarkStartingRow(mask) >= num_rows_read
                     && index_granularity.getMarkStartingRow(mask + 1) < num_rows_read)
@@ -554,11 +583,20 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
 
             const auto & one_column = result.back();
             const ColumnArray * array = checkAndGetColumn<ColumnArray>(one_column.get());
+            if (!array)
+            {
+                throw Exception(ErrorCodes::LOGICAL_ERROR, "[buildVectorIndex] vector column type is not Array in part {}", part->name);
+            }
+
             const IColumn & src_data = array->getData();
             const ColumnArray::Offsets & offsets = array->getOffsets();
             const ColumnFloat32 * src_data_concrete = checkAndGetColumn<ColumnFloat32>(&src_data);
+            if (!src_data_concrete)
+            {
+                throw Exception(ErrorCodes::LOGICAL_ERROR, "[buildVectorIndex] vector column inner type in Array is not Float32 in part {}", part->name);
+            }
+
             const PaddedPODArray<Float32> & src_vec = src_data_concrete->getData();
-            // size_t size = offsets.size();
             if (src_vec.empty())
             {
                 LOG_WARNING(log, "[buildVectorIndex] part:{}, no data read for column {}", part->name, cols.back().name);
@@ -607,17 +645,35 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 vector_raw_data.size(),
                 empty_ids.size());
 
-            vec_data = std::make_shared<VectorIndex::VectorDataset>(
-                static_cast<int32_t>(offsets.size()), static_cast<int32_t>(dim), std::move(vector_raw_data));
+            /// Checks for read rows >= minimum rows for training
+            if (training)
+            {
+                num_rows_train += num_rows;
+                dataset_offsets_size_train += offsets.size();
+                vector_raw_data_train.insert(vector_raw_data_train.end(), vector_raw_data.begin(), vector_raw_data.end());
+
+                if (num_rows_train < train_block_rows_num && part->rows_count - num_rows_read > 0)
+                    continue;
+                else
+                {
+                    vec_data = std::make_shared<VectorIndex::VectorDataset>(
+                        static_cast<int32_t>(dataset_offsets_size_train), static_cast<int32_t>(dim), std::move(vector_raw_data_train));
+                }
+            }
+            else /// Normal add vectors after training
+            {
+                vec_data = std::make_shared<VectorIndex::VectorDataset>(
+                    static_cast<int32_t>(offsets.size()), static_cast<int32_t>(dim), std::move(vector_raw_data));
+            }
 
             /// only run in the first read round
             if (training)
             {
                 LOG_INFO(
                     log,
-                    "[buildVectorIndex] index train: part_name: {}, num_rows: {}, vector index name: {}, path: {}",
+                    "[buildVectorIndex] index train: part_name: {}, num_rows_train: {}, vector index name: {}, path: {}",
                     part->name,
-                    num_rows,
+                    num_rows_train,
                     vec_index_desc.name,
                     vector_tmp_relative_path + index_name);
 
@@ -647,12 +703,13 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 }
                 training = false;
             }
+
             LOG_INFO(log, "[buildVectorIndex] index add vectors: read vector num: {}", vec_data->getVectorNum());
             vec_index_builder->addVectors(vec_data);
+
             if (!empty_ids.empty())
-            {
                 vec_index_builder->removeByIds(empty_ids.size(), empty_ids.data());
-            }
+
             LOG_INFO(log, "[buildVectorIndex] index after read vectors: read vector num: {}", vec_data->getVectorNum());
         }
 
diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp
index bc7ba4ff8f..83ca0936f7 100644
--- a/src/Storages/StorageMergeTree.cpp
+++ b/src/Storages/StorageMergeTree.cpp
@@ -469,19 +469,16 @@ void StorageMergeTree::startVectorIndexJob(const VectorIndexCommands & vector_in
         /// Delete vector index files.
         for (const auto & part : getDataParts())
         {
-            if (part.unique()) /// Remove only parts that are not used by anyone (SELECTs for example).
-            {
-                /// Clear cache first, now getAllSegementIds() is based on vector index files
-                auto segment_ids = VectorIndex::getAllSegmentIds(part->getFullPath(), part, drop_vector_index.index_name, drop_vector_index.column_name);
-                for (auto & segment_id : segment_ids)
-                {
-                    VectorIndex::VectorSegmentExecutor::removeFromCache(segment_id.getCacheKey());
-                }
-
-                /// Delete files in part directory if exists and metadata
-                part->removeVectorIndex(drop_vector_index.index_name, drop_vector_index.column_name);
+            // if (part.unique()) /// Remove only parts that are not used by anyone (SELECTs for example).
 
+            /// Clear cache first, now getAllSegementIds() is based on vector index files
+            auto segment_ids = VectorIndex::getAllSegmentIds(part->getFullPath(), part, drop_vector_index.index_name, drop_vector_index.column_name);
+            for (auto & segment_id : segment_ids)
+            {
+                VectorIndex::VectorSegmentExecutor::removeFromCache(segment_id.getCacheKey());
             }
+            /// Delete files in part directory if exists and metadata
+            part->removeVectorIndex(drop_vector_index.index_name, drop_vector_index.column_name);
         }
     }
     else
diff --git a/tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.reference b/tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.reference
new file mode 100644
index 0000000000..5107cec602
--- /dev/null
+++ b/tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.reference
@@ -0,0 +1,5 @@
+test_drop_table	v1	HNSWSQ	v1 vector TYPE HNSWSQ	NoVectorIndexData
+-- Empty result, no vector index v1
+-- Create a new vector index v2 with different name and different type
+test_drop_table	v2	HNSWPQ	v2 vector TYPE HNSWPQ	Built
+ok
diff --git a/tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.sh b/tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.sh
new file mode 100755
index 0000000000..7478635505
--- /dev/null
+++ b/tests/queries/2_vector_search/00020_mqvs_drop_vector_index_and_drop_table.sh
@@ -0,0 +1,44 @@
+#!/usr/bin/env bash
+
+max_response_time_drop_vector_index=1
+max_response_time_drop_table=10
+
+# create table & insert data
+clickhouse-client -q "DROP TABLE IF EXISTS test_drop_table;"
+clickhouse-client -q "CREATE TABLE test_drop_table(id UInt32, text String, vector FixedArray(Float32, 768)) Engine MergeTree ORDER BY id;"
+clickhouse-client -q "INSERT INTO test_drop_table SELECT number, randomPrintableASCII(80), range(768) FROM numbers(2000000);"
+clickhouse-client -q "optimize table test_drop_table final;"
+
+# when building vector index, drop this vector index
+# drop vector index v1
+clickhouse-client -q "ALTER TABLE test_drop_table ADD VECTOR INDEX v1 vector TYPE HNSWSQ;"
+clickhouse-client -q "select table, name, type, expr, status from system.vector_indices where database = currentDatabase() and table = 'test_drop_table';"
+sleep 3
+clickhouse-client -q "ALTER TABLE test_drop_table DROP VECTOR INDEX v1;"
+clickhouse-client -q "select '-- Empty result, no vector index v1';"
+clickhouse-client -q "select table, name, type, expr, status from system.vector_indices where database = currentDatabase() and table = 'test_drop_table';"
+sleep $max_response_time_drop_vector_index
+
+# create vector index v2
+clickhouse-client -q "ALTER TABLE test_drop_table ADD VECTOR INDEX v2 vector TYPE HNSWFLAT;"
+status="NotBuilt"
+while [[ $status != "Built" ]]
+do
+        status=`clickhouse-client -q "select status from system.vector_indices where table = 'test_drop_table' and name = 'v2';"`
+        sleep 1
+done
+clickhouse-client -q "select '-- Create a new vector index v2 with different name and different type';"
+clickhouse-client -q "select table, name, type, expr, status from system.vector_indices where database = currentDatabase() and table = 'test_drop_table';"
+clickhouse-client -q "ALTER TABLE test_drop_table DROP VECTOR INDEX v2;"
+
+
+# when building vector index, drop the table
+clickhouse-client -q "ALTER TABLE test_drop_table ADD VECTOR INDEX v3 vector TYPE HNSWPQ;"
+sleep 3
+time_start=`date +%s`
+clickhouse-client -q "DROP TABLE IF EXISTS test_drop_table;"
+time_end=`date +%s`
+time_interval=$(( $time_end - $time_start ))
+if [ $time_interval -lt $max_response_time_drop_table ]
+    then echo 'ok'
+fi
-- 
2.32.1 (Apple Git-133)

