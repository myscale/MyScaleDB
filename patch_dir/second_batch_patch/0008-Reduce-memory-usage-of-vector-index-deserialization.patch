From 6977465dda9bb5c7ad59f16d1b4390fba030e8a9 Mon Sep 17 00:00:00 2001
From: Qin Liu <lqgy2001@gmail.com>
Date: Wed, 28 Dec 2022 17:50:12 +0800
Subject: [PATCH 08/85] Reduce memory usage of vector index deserialization

---
 contrib/faiss                                 |   2 +-
 contrib/hnswlib                               |   2 +-
 .../MergeTree/MergeTreeVectorScanManager.cpp  |   4 +-
 src/VectorIndex/BruteForceSearch.cpp          |   5 +-
 src/VectorIndex/BruteForceSearch.h            |   2 +-
 src/VectorIndex/CompositeIndexReader.cpp      | 139 +++++++++++++
 src/VectorIndex/CompositeIndexReader.h        |  32 +++
 src/VectorIndex/FaissIndex.cpp                |  22 +-
 src/VectorIndex/FaissIndex.h                  |   2 +-
 src/VectorIndex/HNSWIndex.cpp                 |  22 +-
 src/VectorIndex/HNSWIndex.h                   |   2 +-
 src/VectorIndex/HNSWPQ.cpp                    |  26 +--
 src/VectorIndex/HNSWPQ.h                      |   6 +-
 src/VectorIndex/HNSWSQ.cpp                    |  28 ++-
 src/VectorIndex/HNSWSQ.h                      |   2 +-
 src/VectorIndex/IndexReader.cpp               |  27 +--
 src/VectorIndex/IndexReader.h                 |  30 +--
 src/VectorIndex/IndexWriter.cpp               |  12 +-
 src/VectorIndex/IndexWriter.h                 |  17 +-
 src/VectorIndex/Status Codes                  |  15 --
 src/VectorIndex/VectorIndex.h                 |  23 +--
 src/VectorIndex/VectorSegmentExecutor.cpp     | 193 +++---------------
 src/VectorIndex/VectorSegmentExecutor.h       |  70 +++----
 .../00001_mqvs_distance.reference             |  10 +
 .../2_vector_search/00001_mqvs_distance.sh    |   4 +
 .../00004_mqvs_filter_by_distance.reference   |   2 +
 .../00004_mqvs_filter_by_distance.sh          |   4 +
 .../00013_mqvs_distance_ivfsq.reference       |  10 +
 .../00013_mqvs_distance_ivfsq.sh              |   4 +
 29 files changed, 360 insertions(+), 357 deletions(-)
 create mode 100644 src/VectorIndex/CompositeIndexReader.cpp
 create mode 100644 src/VectorIndex/CompositeIndexReader.h
 delete mode 100644 src/VectorIndex/Status Codes

diff --git a/contrib/faiss b/contrib/faiss
index 3919ad1b2f..0cc19348e3 160000
--- a/contrib/faiss
+++ b/contrib/faiss
@@ -1 +1 @@
-Subproject commit 3919ad1b2f1ae8387e78763fdfff2a79e85d9e87
+Subproject commit 0cc19348e3f0637bc19d8e77972b885356694067
diff --git a/contrib/hnswlib b/contrib/hnswlib
index 766013341a..959436dc94 160000
--- a/contrib/hnswlib
+++ b/contrib/hnswlib
@@ -1 +1 @@
-Subproject commit 766013341aea209730198daee80a8c71ec32b249
+Subproject commit 959436dc94a62ddf58474a74425b033616c9a598
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index 1b926ac117..614c104049 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -353,7 +353,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             if (!status.fine())
             {
                 /// case of merged vector indices had been removed, we need to use new vector index files
-                LOG_INFO(log, "[vectorScan] fail to load vector index: {}", segment_id.getFullPath());
+                LOG_ERROR(log, "[vectorScan] fail to load vector index: {}", segment_id.getFullPath());
                 retry = true;
                 brute_force = true;
                 break;
@@ -385,7 +385,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
 
                 if (!status.fine())
                 {
-                    LOG_INFO(log, "[vectorScan] fail to load vector index: {}", segment_ids[0].getFullPath());
+                    LOG_ERROR(log, "[vectorScan] fail to load vector index: {}", segment_ids[0].getFullPath());
                 }
                 else
                 {
diff --git a/src/VectorIndex/BruteForceSearch.cpp b/src/VectorIndex/BruteForceSearch.cpp
index 2781583177..d570a2e8f9 100644
--- a/src/VectorIndex/BruteForceSearch.cpp
+++ b/src/VectorIndex/BruteForceSearch.cpp
@@ -5,7 +5,7 @@ namespace VectorIndex
 {
 
 Status tryBruteForceSearch(
-    const float * x, const float * y, size_t d, size_t k, size_t nx, size_t ny, int64_t * result_id, float * distance, const Metrics& m)
+    const float * x, const float * y, size_t d, size_t k, size_t nx, size_t ny, int64_t * result_id, float * distance, const Metrics & m)
 {
     if (m == IP)
     {
@@ -25,11 +25,10 @@ Status tryBruteForceSearch(
         faiss::float_maxheap_array_t res = {size_t(nx), size_t(k), result_id, distance};
         faiss::knn_cosine(x, y, d, nx, ny, &res, nullptr);
     }
-    else 
+    else
     {
         return Status(8, "Metric not implemented in brute force search");
     }
     return Status();
 }
-
 }
diff --git a/src/VectorIndex/BruteForceSearch.h b/src/VectorIndex/BruteForceSearch.h
index b66d282f51..1fd58a2636 100644
--- a/src/VectorIndex/BruteForceSearch.h
+++ b/src/VectorIndex/BruteForceSearch.h
@@ -16,5 +16,5 @@ namespace VectorIndex
 /// k is the top k we desired after distance calculation.
 
 Status tryBruteForceSearch(
-    const float * x, const float * y, size_t d, size_t k, size_t nx, size_t ny, int64_t * result_id, float * distance, const Metrics& m);
+    const float * x, const float * y, size_t d, size_t k, size_t nx, size_t ny, int64_t * result_id, float * distance, const Metrics & m);
 }
diff --git a/src/VectorIndex/CompositeIndexReader.cpp b/src/VectorIndex/CompositeIndexReader.cpp
new file mode 100644
index 0000000000..957427eebe
--- /dev/null
+++ b/src/VectorIndex/CompositeIndexReader.cpp
@@ -0,0 +1,139 @@
+#include <Compression/LZ4_decompress_faster.h>
+#include <VectorIndex/CompositeIndexReader.h>
+#include <VectorIndex/DiskIOReader.h>
+
+namespace DB::ErrorCodes
+{
+extern const int CORRUPTED_DATA;
+}
+
+namespace VectorIndex
+{
+const static UInt32 COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER = LZ4::ADDITIONAL_BYTES_AT_END_OF_BUFFER;
+
+uint32_t compressWithCheckSum(uint8_t cmb, uint8_t * source, size_t size, BinaryPtr des)
+{
+    DB::CompressionCodecPtr codec = DB::CompressionCodecFactory::instance().get(cmb);
+    size_t decompressed_size = size;
+    des->data = new uint8_t[codec->getCompressedReserveSize(decompressed_size) + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
+    /// the reserved size might be much larger than actual compressed size
+    uint32_t size_compressed
+        = codec->compress(reinterpret_cast<const char *>(source), decompressed_size, reinterpret_cast<char *>(des->data));
+    des->size = size_compressed;
+    return size_compressed;
+}
+
+/// Take the compreseed binary of index file, check the checksum, them decompress it using
+/// method provided in header to des.
+uint32_t validateAndDecompress(const BinaryPtr source, size_t uncompressed_size, uint8_t * des)
+{
+    uint8_t method = DB::ICompressionCodec::readMethod(reinterpret_cast<const char *>(source->data));
+    DB::CompressionCodecPtr codec = DB::CompressionCodecFactory::instance().get(method);
+
+    uint32_t size_decompressed
+        = codec->decompress(reinterpret_cast<const char *>(source->data), source->size, reinterpret_cast<char *>(des));
+
+    if (uncompressed_size != size_decompressed)
+    {
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "vector index on disk is corrupted");
+    }
+    return size_decompressed;
+}
+
+CompositeIndexReader::CompositeIndexReader(SegmentId segment_id_, int64_t original_binary_size_)
+    : segment_id(segment_id_), original_binary_size(original_binary_size_)
+{
+}
+
+void CompositeIndexReader::read_part()
+{
+    if (final_mark)
+        return;
+
+    String path = segment_id.getFullPath() + "_" + ItoS(part_count++) + VECTOR_INDEX_FILE_SUFFIX;
+    DiskIOReader reader;
+    if (!reader.open(path))
+    {
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "failed to open " + path);
+    }
+    BinaryPtr index_binary_compressed = std::make_shared<Binary>();
+    /// first 8 bytes is final mark, deciding if this is the last segment
+    reader.read(&final_mark, sizeof(final_mark));
+
+    /// second 8 bytes are meta recording compressed binary size of index
+    reader.seekg(sizeof(int64_t));
+    int64_t binary_length;
+    reader.read(&binary_length, sizeof(binary_length));
+    LOG_INFO(log, "[readPart] compressed data size: {}", binary_length);
+
+    /// third 8 bytes are meta recording uncompressed binary size of index
+    reader.seekg(sizeof(int64_t) * 2);
+    int64_t binary_length_original;
+    reader.read(&binary_length_original, sizeof(binary_length_original));
+    buffer.resize(binary_length_original + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER);
+    LOG_INFO(log, "[readPart] uncompressed data size: {}", binary_length_original);
+
+    /// fourth 8 bytes records total vectors stored, this is repeated many times. Could be d, or not.
+    reader.seekg(sizeof(int64_t) * 3);
+    int64_t total_vec_bin;
+    reader.read(&total_vec_bin, sizeof(total_vec_bin));
+    LOG_INFO(log, "[readPart] total vectors: {}", total_vec_bin);
+
+    /// finally we have the compressed binaries
+    reader.seekg(sizeof(int64_t) * 4);
+    index_binary_compressed->data = new uint8_t[binary_length + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
+    index_binary_compressed->size = binary_length;
+
+    reader.read(index_binary_compressed->data, binary_length);
+
+    validateAndDecompress(index_binary_compressed, binary_length_original, buffer.data());
+
+    current_buffer_start = current_loaded_size;
+    current_loaded_size += binary_length_original;
+    LOG_INFO(log, "[readPart] current_buffer_start: {}, current_loaded_size: {}", current_buffer_start, current_loaded_size);
+
+    if (final_mark && current_loaded_size != original_binary_size)
+    {
+        LOG_ERROR(log, "current_loaded_size {} != original_binary_size {}", current_loaded_size, original_binary_size);
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "current_loaded_size != original_binary_size");
+    }
+}
+
+size_t CompositeIndexReader::operator()(void * ptr, size_t size, size_t nitems)
+{
+    size_t to_read = size * nitems;
+    size_t ret = 0;
+
+    while (offset + to_read > static_cast<size_t>(current_loaded_size))
+    {
+        if (offset < static_cast<size_t>(current_loaded_size))
+        {
+            size_t len = current_loaded_size - offset;
+            LOG_DEBUG(log, "offset: {}, len: {}, to_read: {}", offset, len, to_read);
+            memcpy(ptr, &buffer[offset - current_buffer_start], len);
+            offset += len;
+            ret += len;
+            to_read -= len;
+            ptr = static_cast<char *>(ptr) + len;
+        }
+        read_part();
+        if (final_mark)
+            break;
+    }
+
+    if (offset + to_read <= static_cast<size_t>(current_loaded_size))
+    {
+        LOG_DEBUG(log, "offset: {}, to_read: {}", offset, to_read);
+        memcpy(ptr, &buffer[offset - current_buffer_start], to_read);
+        offset += to_read;
+        ret += to_read;
+    }
+    if (ret == size * nitems)
+        return nitems;
+    else
+    {
+        LOG_WARNING(log, "ret {} != size {} * nitems {}", ret, size, nitems);
+        return ret / size;
+    }
+}
+}
diff --git a/src/VectorIndex/CompositeIndexReader.h b/src/VectorIndex/CompositeIndexReader.h
new file mode 100644
index 0000000000..1215d2d112
--- /dev/null
+++ b/src/VectorIndex/CompositeIndexReader.h
@@ -0,0 +1,32 @@
+#pragma once
+
+#include <VectorIndex/IndexReader.h>
+#include <VectorIndex/SegmentId.h>
+
+namespace VectorIndex
+{
+
+/// Put a checksum of 12 bytes at the head of binary, then append the compressed bytes.
+/// this only compress and checksum the binary index file, not including the metadata.
+uint32_t compressWithCheckSum(uint8_t cmb, uint8_t * source, size_t size, BinaryPtr des);
+
+uint32_t validateAndDecompress(const BinaryPtr source, size_t uncompressed_size, uint8_t * des);
+
+/// CompositeIndexReader reads from multiple compressed .vidx files.
+struct CompositeIndexReader : IndexReader
+{
+    SegmentId segment_id;
+    int64_t original_binary_size;
+    size_t offset = 0;
+    int part_count = 0;
+    int64_t current_buffer_start = 0;
+    int64_t current_loaded_size = 0;
+    bool final_mark = false;
+    Poco::Logger * log = &Poco::Logger::get("CompositeIndexReader");
+    std::vector<uint8_t> buffer;
+
+    CompositeIndexReader(SegmentId segment_id_, int64_t original_binary_size_);
+    void read_part();
+    size_t operator()(void * ptr, size_t size, size_t nitems) override;
+};
+}
diff --git a/src/VectorIndex/FaissIndex.cpp b/src/VectorIndex/FaissIndex.cpp
index 63e705b384..5ab0b21654 100644
--- a/src/VectorIndex/FaissIndex.cpp
+++ b/src/VectorIndex/FaissIndex.cpp
@@ -12,30 +12,20 @@ namespace DB::ErrorCodes
 {
 extern const int EMPTY_DATA_PASSED;
 extern const int STD_EXCEPTION;
+extern const int INCORRECT_DISK_INDEX;
 }
 namespace VectorIndex
 {
 BinaryPtr FaissIndex::serialize(size_t max_bytes, bool & finished)
 {
-    IndexWriter writer;
+    BufferIndexWriter writer;
     faiss::write_index_incremental(index.get(), &writer, max_bytes, finished);
+    index_size += writer.actual_size;
     return convertStructToBinary(writer.data, writer.actual_size);
 }
 
-void FaissIndex::load(BinaryPtr & bi, int64_t /*total_vec*/)
+void FaissIndex::load(IndexReader & reader)
 {
-    ///FLAT is just a vector, so no bother keeping the original data.
-    if (it != FLAT)
-    {
-        setRawData(bi);
-    }
-    if (bi->size == 0 || bi->data == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::EMPTY_DATA_PASSED, "load: failed with empty data");
-    }
-    IndexReader reader;
-    reader.data = bi->data;
-    reader.total = bi->size;
     try
     {
         index.reset(faiss::read_index(&reader));
@@ -46,10 +36,8 @@ void FaissIndex::load(BinaryPtr & bi, int64_t /*total_vec*/)
     }
     catch (const faiss::FaissException & e)
     {
-        throw IndexException(DB::ErrorCodes::STD_EXCEPTION, e.what());
+        throw IndexException(DB::ErrorCodes::INCORRECT_DISK_INDEX, e.what());
     }
-    // reinterpret_cast might seem fishy, but when they returned from read_index they initially
-    // created a child class then cast it to Index.
 }
 
 void * FaissIndex::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
diff --git a/src/VectorIndex/FaissIndex.h b/src/VectorIndex/FaissIndex.h
index 4a2ea345f6..04b573eb9f 100644
--- a/src/VectorIndex/FaissIndex.h
+++ b/src/VectorIndex/FaissIndex.h
@@ -15,7 +15,7 @@ class FaissIndex : public VectorIndex
 public:
     FaissIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_) : VectorIndex(it_, im_, me_, dimension_) { }
     virtual BinaryPtr serialize(size_t max_bytes, bool & finished) override;
-    virtual void load(BinaryPtr & bi, int64_t total_vec) override;
+    void load(IndexReader & reader) override;
     int64_t removeWithIds(int64_t n, int64_t * ids) override;
     AccParametersPack exploreTask(
         const float * query_data,
diff --git a/src/VectorIndex/HNSWIndex.cpp b/src/VectorIndex/HNSWIndex.cpp
index 5e8cd5c4c5..71b5cd42ce 100644
--- a/src/VectorIndex/HNSWIndex.cpp
+++ b/src/VectorIndex/HNSWIndex.cpp
@@ -118,41 +118,29 @@ void HNSWIndex::search(
 
 BinaryPtr HNSWIndex::serialize(size_t max_bytes_to_serialize, bool & finished)
 {
-    IndexWriter writer;
+    BufferIndexWriter writer;
     index->saveIndex(writer, max_bytes_to_serialize, finished);
+    index_size += writer.actual_size;
     return convertStructToBinary(writer.data, writer.actual_size);
 }
 
-void HNSWIndex::load(BinaryPtr & bi, int64_t total_vec)
+
+void HNSWIndex::load(IndexReader & reader)
 {
-    if (bi->size == 0 || bi->data == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::EMPTY_DATA_PASSED, "load: failed with empty data");
-    }
     hnswlib::SpaceInterface<float> * space;
-    Poco::Logger * log = &Poco::Logger::get("HNSW");
     switch (me)
     {
         case (Metrics::L2):
-            LOG_INFO(log, "searching in HNSW, metric type: L2");
             space = new hnswlib::L2Space(dimension);
             break;
         case (Metrics::IP):
-            LOG_INFO(log, "searching in HNSW, metric type: IP");
             space = new hnswlib::InnerProductSpace(dimension);
             break;
         case (Metrics::Cosine):
-            LOG_INFO(log, "searching in HNSW, metric type: Cosine");
             space = new hnswlib::CosineSpace(dimension);
-            break;
     }
-    setRawData(bi);
-    IndexReader reader;
-    reader.data = bi->data;
-    reader.total = bi->size;
     index = std::make_shared<hnswlib::HierarchicalNSW<float>>(space);
-    index->loadIndex(reader, space, total_vec + 1);
-    index->manage_own_fields = false;
+    index->loadIndex(reader, space);
 }
 
 void * HNSWIndex::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
diff --git a/src/VectorIndex/HNSWIndex.h b/src/VectorIndex/HNSWIndex.h
index 5b764b7cf1..cbc0c0128d 100644
--- a/src/VectorIndex/HNSWIndex.h
+++ b/src/VectorIndex/HNSWIndex.h
@@ -39,7 +39,7 @@ public:
 
     BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override;
 
-    void load(BinaryPtr & bi, int64_t total_vec) override;
+    void load(IndexReader & reader) override;
 
     VectorDatasetPtr getInMemVectors() override;
 
diff --git a/src/VectorIndex/HNSWPQ.cpp b/src/VectorIndex/HNSWPQ.cpp
index 3990a00932..066674dd2e 100644
--- a/src/VectorIndex/HNSWPQ.cpp
+++ b/src/VectorIndex/HNSWPQ.cpp
@@ -105,26 +105,26 @@ void HNSWpq::search(
 
 BinaryPtr HNSWpq::serialize(size_t max_bytes_to_serialize, bool & finished)
 {
-    IndexWriter writer;
+    BufferIndexWriter writer;
     faiss::write_index_incremental(index.get(), &writer, max_bytes_to_serialize, finished);
+    index_size += writer.actual_size;
     return convertStructToBinary(writer.data, writer.actual_size);
 }
 
-void HNSWpq::load(BinaryPtr & bi, int64_t /*total_vec*/)
+void HNSWpq::load(IndexReader & reader)
 {
-    if (bi->size == 0 || bi->data == nullptr)
+    try
     {
-        throw IndexException(DB::ErrorCodes::EMPTY_DATA_PASSED, "load: failed with empty data");
+        index.reset(reinterpret_cast<faiss::IndexHNSWfastPQ *>(faiss::read_index(&reader)));
+    }
+    catch (const std::runtime_error & e)
+    {
+        throw IndexException(DB::ErrorCodes::STD_EXCEPTION, e.what());
+    }
+    catch (const faiss::FaissException & e)
+    {
+        throw IndexException(DB::ErrorCodes::INCORRECT_DISK_INDEX, e.what());
     }
-    setRawData(bi);
-    IndexReader reader;
-    reader.data = bi->data;
-    reader.total = bi->size;
-
-    index.reset(reinterpret_cast<faiss::IndexHNSWfastPQ *>(faiss::read_index(&reader)));
-
-    /// reinterpret_cast might seem fishy, but when they returned from read_index they initially
-    /// created a child class then cast it to Index.
 }
 
 void * HNSWpq::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
diff --git a/src/VectorIndex/HNSWPQ.h b/src/VectorIndex/HNSWPQ.h
index 07d0273210..8e8fe93e2f 100644
--- a/src/VectorIndex/HNSWPQ.h
+++ b/src/VectorIndex/HNSWPQ.h
@@ -22,6 +22,8 @@ namespace DB::ErrorCodes
 extern const int LOGICAL_ERROR;
 extern const int UNSUPPORTED_PARAMETER;
 extern const int EMPTY_DATA_PASSED;
+extern const int STD_EXCEPTION;
+extern const int INCORRECT_DISK_INDEX;
 }
 
 namespace VectorIndex
@@ -41,9 +43,9 @@ public:
         const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & param, GeneralBitMapPtr filter)
         override;
 
-    BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override; //searilize index
+    BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override;
 
-    void load(BinaryPtr & bi, int64_t total_vec) override; //reverse serialize index
+    void load(IndexReader & reader) override;
 
     VectorDatasetPtr getInMemVectors() override;
 
diff --git a/src/VectorIndex/HNSWSQ.cpp b/src/VectorIndex/HNSWSQ.cpp
index b6c25da5a4..73d7c8dfe1 100644
--- a/src/VectorIndex/HNSWSQ.cpp
+++ b/src/VectorIndex/HNSWSQ.cpp
@@ -1,15 +1,17 @@
 #include "HNSWSQ.h"
+#include <VectorIndex/VectorIndexCommon.h>
 #include <faiss/index_io.h>
 #include "IndexException.h"
 #include "IndexReader.h"
 #include "IndexWriter.h"
-#include <VectorIndex/VectorIndexCommon.h>
 
 namespace DB::ErrorCodes
 {
 extern const int LOGICAL_ERROR;
 extern const int UNSUPPORTED_PARAMETER;
 extern const int EMPTY_DATA_PASSED;
+extern const int STD_EXCEPTION;
+extern const int INCORRECT_DISK_INDEX;
 }
 
 namespace VectorIndex
@@ -106,24 +108,30 @@ void HNSWsq::search(
     index->search(num_query, query_datas, topK, distances, result_id, ef_s, inner_bit_map.get());
     //distance might not be useful in many cases
 }
+
 BinaryPtr HNSWsq::serialize(size_t max_bytes_to_serialize, bool & finished)
 {
-    IndexWriter writer;
+    BufferIndexWriter writer;
     faiss::write_index_incremental(index.get(), &writer, max_bytes_to_serialize, finished);
+    index_size += writer.actual_size;
     return convertStructToBinary(writer.data, writer.actual_size);
 }
 
-void HNSWsq::load(BinaryPtr & bi, int64_t /*total_vec*/)
+
+void HNSWsq::load(IndexReader & reader)
 {
-    if (bi->size == 0 || bi->data == nullptr)
+    try
     {
-        throw IndexException(DB::ErrorCodes::EMPTY_DATA_PASSED, "load: failed with empty data");
+        index.reset(reinterpret_cast<faiss::IndexHNSWfastSQ *>(faiss::read_index(&reader)));
+    }
+    catch (const std::runtime_error & e)
+    {
+        throw IndexException(DB::ErrorCodes::STD_EXCEPTION, e.what());
+    }
+    catch (const faiss::FaissException & e)
+    {
+        throw IndexException(DB::ErrorCodes::INCORRECT_DISK_INDEX, e.what());
     }
-    IndexReader reader;
-    reader.data = bi->data;
-    reader.total = bi->size;
-
-    index.reset(reinterpret_cast<faiss::IndexHNSWfastSQ *>(faiss::read_index(&reader)));
 }
 
 void * HNSWsq::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
diff --git a/src/VectorIndex/HNSWSQ.h b/src/VectorIndex/HNSWSQ.h
index a2922c6e56..eb92ff648d 100644
--- a/src/VectorIndex/HNSWSQ.h
+++ b/src/VectorIndex/HNSWSQ.h
@@ -37,7 +37,7 @@ public:
 
     BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override; //searilize index
 
-    void load(BinaryPtr & bi, int64_t total_vec) override;
+    void load(IndexReader & reader) override;
 
     VectorDatasetPtr getInMemVectors() override;
 
diff --git a/src/VectorIndex/IndexReader.cpp b/src/VectorIndex/IndexReader.cpp
index 29d9314909..7d057dac16 100644
--- a/src/VectorIndex/IndexReader.cpp
+++ b/src/VectorIndex/IndexReader.cpp
@@ -1,13 +1,10 @@
-//
-// Created by 陈卓 on 2021/6/29.
-//
-#pragma GCC diagnostic ignored "-Wunused-but-set-parameter"
-#include "IndexReader.h"
+#include <VectorIndex/IndexException.h>
+#include <VectorIndex/IndexReader.h>
 
 namespace VectorIndex
 {
-///copy data
-size_t IndexReader::operator()(void * ptr, size_t size, size_t nitems)
+
+size_t BufferIndexReader::operator()(void * ptr, size_t size, size_t nitems)
 {
     if (rp >= total)
         return 0;
@@ -21,20 +18,4 @@ size_t IndexReader::operator()(void * ptr, size_t size, size_t nitems)
     }
     return nitems;
 }
-
-///used for assiging data directly to respective position, no copying
-size_t IndexReader::operator()(char *& ptr, size_t size)
-{
-    if (rp >= total)
-        return 0;
-    size_t nremain = total - rp;
-    if (nremain < size)
-        size = nremain;
-    if (size > 0)
-    {
-        ptr = reinterpret_cast<char *>(data) + rp;
-        rp += size;
-    }
-    return size;
-}
 }
diff --git a/src/VectorIndex/IndexReader.h b/src/VectorIndex/IndexReader.h
index 8243017650..533346caea 100644
--- a/src/VectorIndex/IndexReader.h
+++ b/src/VectorIndex/IndexReader.h
@@ -1,25 +1,25 @@
 #pragma once
+
+#include <vector>
+
+#include <base/logger_useful.h>
+
 #include "faiss/impl/io.h"
 
 namespace VectorIndex
 {
-//in memory reader conforming to faiss IOreader that's used to produce
-// a binary object
-class IndexReader : public faiss::VectorIOReader
-{
-public:
-    /// This is less elegant than it should be for the sack of performance.
-    /// we have two overloaded read functions, the first one, which takes void * as input
-    /// will copy the data from source into ptr.
-    /// The second one, which takes char * & as input, will change the address pointed to
-    /// by the ptr to an existing memory space, saving the copy overhead.
 
-    /// copy operator, copy memory into ptr.
-    size_t operator()(void * ptr, size_t size, size_t nitems) override;
+struct IndexReader : faiss::IOReader
+{
     size_t read(void * ptr, size_t size, size_t nitems = 1) { return operator()(ptr, size, nitems); }
-    /// assign operator, change address pointed to by ptr.
-    size_t operator()(char *& ptr, size_t size) override;
-    size_t read(char *& ptr, size_t size, size_t nitems = 1) { return operator()(ptr, size * nitems); }
 };
 
+struct BufferIndexReader : IndexReader
+{
+    uint8_t * data;
+    uint64_t total = 0;
+    uint64_t rp = 0;
+
+    size_t operator()(void * ptr, size_t size, size_t nitems) override;
+};
 }
diff --git a/src/VectorIndex/IndexWriter.cpp b/src/VectorIndex/IndexWriter.cpp
index d67f03714f..e6c2b8b455 100644
--- a/src/VectorIndex/IndexWriter.cpp
+++ b/src/VectorIndex/IndexWriter.cpp
@@ -2,9 +2,11 @@
 #include "IndexWriter.h"
 namespace VectorIndex
 {
-size_t IndexWriter::operator()(const void * ptr, size_t size, size_t nitems)
+
+#define RESERVE 2
+
+size_t BufferIndexWriter::operator()(const void * ptr, size_t size, size_t nitems)
 {
-    //a copy of VectorIOWriter from faiss
     size_t total_need = size * nitems + actual_size;
     if (total_need > 0)
     {
@@ -19,15 +21,15 @@ size_t IndexWriter::operator()(const void * ptr, size_t size, size_t nitems)
         { //if reserved space if not enough
             reserved_size = total_need * RESERVE;
             auto * new_data = new uint8_t[reserved_size];
-            memcpy(new_data, data, actual_size); //copy old data to new data chunk
+            memcpy(new_data, data, actual_size); // copy old data to new data chunk
             delete[] data;
             data = new_data;
-            memcpy(data + actual_size, ptr, size * nitems); //copy increment to data
+            memcpy(data + actual_size, ptr, size * nitems); // copy increment to data
             actual_size = total_need;
         }
         else
         {
-            memcpy(data + actual_size, ptr, size * nitems); //if still got reserved space
+            memcpy(data + actual_size, ptr, size * nitems); // if still got reserved space
             actual_size = total_need;
         }
     }
diff --git a/src/VectorIndex/IndexWriter.h b/src/VectorIndex/IndexWriter.h
index 1139702b16..5906b58c74 100644
--- a/src/VectorIndex/IndexWriter.h
+++ b/src/VectorIndex/IndexWriter.h
@@ -10,15 +10,18 @@
 
 namespace VectorIndex
 {
-//in memory reader conforming to faiss IOwriter that's used to produce
-// a binary object
-class IndexWriter : public faiss::VectorIOWriter
+struct IndexWriter : faiss::IOWriter
 {
-public:
-    size_t operator()(const void * ptr, size_t size, size_t nitems) override;
     size_t write(const void * ptr, size_t size, size_t nitems = 1) { return operator()(ptr, size, nitems); }
 };
 
-#define RESERVE 2
-
+// in memory reader conforming to faiss IOwriter that's used to produce
+// a binary object
+struct BufferIndexWriter : IndexWriter
+{
+    uint8_t * data;
+    uint64_t actual_size = 0;
+    uint64_t reserved_size = 0;
+    size_t operator()(const void * ptr, size_t size, size_t nitems) override;
+};
 }
diff --git a/src/VectorIndex/Status Codes b/src/VectorIndex/Status Codes
deleted file mode 100644
index 51ec8a1f3e..0000000000
--- a/src/VectorIndex/Status Codes	
+++ /dev/null
@@ -1,15 +0,0 @@
-This file records all the status codes you're see when running vectorIndex library. we use the same code in Status and IndexException
-    .
-
-    0 : ok
-
-
-        1 : index not initialized before training.2 : index not initialized before adding vectors.3
-    : index not initialized before searching.4 : loading empty binary data.5
-    : io error during index serialization.6 : retraining already trained index.7 : index untrained before searching.8
-    : unknown metrics type.9 : unimplemented method.10 : data discrepency.11 : unsupported parameter
-    .
-
-                                                                               100 : cache not initialzied.
-
-                                                                                     200 : index can't satisfy accuracy requirement.
diff --git a/src/VectorIndex/VectorIndex.h b/src/VectorIndex/VectorIndex.h
index d90dc4ae07..03aaa1559c 100644
--- a/src/VectorIndex/VectorIndex.h
+++ b/src/VectorIndex/VectorIndex.h
@@ -2,11 +2,12 @@
 
 #include <memory>
 #include <unordered_map>
-#include <base/logger_useful.h>
 #include <VectorIndex/Binary.h>
 #include <VectorIndex/Dataset.h>
 #include <VectorIndex/GeneralBitMap.h>
 #include <VectorIndex/IndexException.h>
+#include <VectorIndex/IndexReader.h>
+#include <base/logger_useful.h>
 
 namespace VectorIndex
 {
@@ -70,8 +71,8 @@ public:
     /// Serialize index into binaries in memory, returns a pointer to that binary.
     virtual BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) = 0;
 
-    /// Load index from binaries into a usable index.
-    virtual void load(BinaryPtr & bi, int64_t total_vec) = 0;
+    /// Load index from IndexReader into a usable index.
+    virtual void load(IndexReader & reader) = 0;
 
     /// The type of index (IVFFLAT, HNSW, etc)
     IndexType indexType() { return it; }
@@ -84,19 +85,7 @@ public:
 
     bool trainStatus() { return trained; }
 
-    void setRawData(BinaryPtr ptr) { rawData = ptr; }
-
-    size_t sizeInBytes() const
-    {
-        if (rawData != nullptr && rawData->size >= 0)
-        {
-            return static_cast<size_t>(rawData->size);
-        }
-        else
-        {
-            return 0;
-        }
-    }
+    size_t sizeInBytes() const { return index_size; }
 
     /// If possible, get uncompressed vectors stored in memory
     virtual VectorDatasetPtr getInMemVectors() = 0;
@@ -142,8 +131,8 @@ protected:
     IndexMode im; // cpu, gpu
     int dimension; // dimension
     bool trained = false; // searchabled
-    BinaryPtr rawData; // unfortunately to boost load speed we have to manage rawData ourselves
     int64_t total_vector = 0;
+    size_t index_size = 0;
 
 protected:
     virtual void * convertInnerBitMap(GeneralBitMapPtr sharedPtr) = 0; //TODO might be too expensive
diff --git a/src/VectorIndex/VectorSegmentExecutor.cpp b/src/VectorIndex/VectorSegmentExecutor.cpp
index cad2cea7c9..fe85dc9f28 100644
--- a/src/VectorIndex/VectorSegmentExecutor.cpp
+++ b/src/VectorIndex/VectorSegmentExecutor.cpp
@@ -13,6 +13,7 @@
 #include <Interpreters/OpenTelemetrySpanLog.h>
 #include <VectorIndex/BruteForceSearch.h>
 #include <VectorIndex/CacheManager.h>
+#include <VectorIndex/CompositeIndexReader.h>
 #include <VectorIndex/DiskIOReader.h>
 #include <VectorIndex/DiskIOWriter.h>
 #include <VectorIndex/IndexException.h>
@@ -106,9 +107,6 @@ Status VectorSegmentExecutor::buildIndex(VectorDatasetPtr data_set, int64_t tota
     {
         if (!index)
         {
-            //        if(data_set->getVectorNum()< MAX_BRUTE_FORCE_SEARCH_SIZE){
-            //            type = IndexType::FLAT;
-            //        }
             LOG_INFO(log, "Index type actually created {}", VectorIndexFactory::typeToString(type));
             if (para_copy.contains("metric_type"))
             {
@@ -269,8 +267,6 @@ Status VectorSegmentExecutor::serialize()
 Status VectorSegmentExecutor::startWrite()
 {
     DiskIOWriter ready_flag_writer;
-    /// try a more elegant way
-    /// String ready_file_path = segment_id.substr(0, segment_id.find("//")) + "/" + VECTOR_INDEX_READY;
     String ready_file_path = segment_id.getVectorReadyFilePath();
     String index_type = VectorIndexFactory::typeToString(type);
     String paras = "";
@@ -300,7 +296,7 @@ Status VectorSegmentExecutor::writePart(bool final, int segment_count, uint8_t *
     std::string part_id = segment_id.getFullPath() + "_" + ItoS(segment_count) + VECTOR_INDEX_FILE_SUFFIX;
     BinaryPtr index_binary_compressed = std::make_shared<Binary>();
     LOG_INFO(log, "Size of binary before compress: {}", index_segment_size);
-    compressWithCheckSum(index_segment_offset, index_segment_size, index_binary_compressed);
+    compressWithCheckSum(cmb, index_segment_offset, index_segment_size, index_binary_compressed);
     LOG_INFO(log, "Size of binary after compress: {}", index_binary_compressed->size);
     DiskIOWriter writer;
     if (!writer.open(part_id, false))
@@ -311,20 +307,19 @@ Status VectorSegmentExecutor::writePart(bool final, int segment_count, uint8_t *
     int64_t final_mark = final ? 1 : 0;
     int64_t binary_length_compressed = index_binary_compressed->size;
     int64_t binary_length_original = index_segment_size;
-    ///when this is the last part to write, the mark will be 1, else 0.
+    /// When this is the last part to write, the mark will be 1, else 0.
     writer.write(&final_mark, sizeof(final_mark));
-    ///compressed size of binaries of index
+    /// Compressed size of binaries of index
     writer.write(&binary_length_compressed, sizeof(binary_length_compressed));
-    ///uncompressed size of binaries of index
+    /// Uncompressed size of binaries of index
     writer.write(&binary_length_original, sizeof(binary_length_original));
-    ///total vector
+    /// Total vector
     writer.write(&total_vec, sizeof(total_vec));
-    ///compressed binaries of index
+    /// Compressed binaries of index
     writer.write(index_binary_compressed->data, binary_length_compressed);
-    /// writer.write(index_segment_offset, index_segment_size);
     writer.close();
-    ///after serializing the index, we write a ready flag to mark future
-    ///TODO with checksum, we can possiblly drop this
+    /// After serializing the index, we write a ready flag to mark future
+    /// TODO with checksum, we can possiblly drop this
     return Status();
 }
 
@@ -346,8 +341,6 @@ Status VectorSegmentExecutor::finishWrite(int64_t binary_total_size)
     String index_name = segment_id.getIndexNameWithColumn();
     String binary_total_size_str = ItoS(binary_total_size);
     String nextline = "\n";
-    ///TODO,This is hacky, as our segment_id is like store/12345/all_1_1_0//v1, the extra / before v1 gives a delimeter.
-    ///need to find a better way to handle this
     if (!ready_flag_writer.open(ready_file_path + VECTOR_INDEX_FILE_SUFFIX, true))
     {
         if (!ready_flag_writer.open(ready_file_path, true))
@@ -436,8 +429,8 @@ Status VectorSegmentExecutor::load()
     if (new_index == nullptr)
     {
         LOG_DEBUG(log, "[load] miss cache, cache_key_str = {}", cache_key_str);
-        ///we don't want many execution engine reading disk and preserving multiple copies of index, so we use a unique lock to
-        ///ensure that only one execution engine may read from disk at any time.
+        /// We don't want many execution engine reading disk and preserving multiple copies of index, so we use a unique lock to
+        /// ensure that only one execution engine may read from disk at any time.
         LOG_DEBUG(log, "[load] num of item before cache {}", mgr->countItem());
         mgr->startLoading(cache_key);
         std::shared_ptr<std::mutex> this_segment_mutex = mgr->getMutex(cache_key);
@@ -463,7 +456,7 @@ Status VectorSegmentExecutor::load()
             }
 
             DiskIOReader reader;
-            ///TODO this is really funky... have to change it later
+            /// TODO this is really funky... have to change it later
             String ready_file_path = segment_id.getVectorReadyFilePath();
             String index_name = segment_id.getIndexNameWithColumn();
             std::vector<String> index_names{index_name};
@@ -481,34 +474,10 @@ Status VectorSegmentExecutor::load()
                 return Status(5, "unable to parse the original index size " + ready_file_path);
             }
             des = params.at(index_name);
-            BinaryPtr index_binary = std::make_shared<Binary>();
-            index_binary->size = original_binary_size;
-            LOG_INFO(log, "[load] original_binary_size: {}", original_binary_size);
-            index_binary->data = new uint8_t[original_binary_size + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
-
-            bool next = true;
-            int part_count = 0;
-            int64_t current_loaded_size = 0;
-            while (next)
-            {
-                Status stat = readPart(next, part_count, index_binary->data + current_loaded_size, current_loaded_size);
-                if (!stat.fine())
-                {
-                    return stat;
-                }
-                part_count++;
-            }
-            LOG_DEBUG(log, "[load] after read part");
-
-            if (current_loaded_size != original_binary_size)
-            {
-                LOG_ERROR(log, "vector index binary size not matching size recorded in metadata, this might be corrupted data.");
-                return Status(5, "corrupted data: " + segment_id.getFullPath());
-            }
 
             if (!readBitMap())
             {
-                LOG_WARNING(log, "vector bitMap file not readable !");
+                LOG_ERROR(log, "failed to read vector index bitmap: {}", segment_id.getFullPath());
                 return Status(5, "corrupted data: " + segment_id.getFullPath());
             }
 
@@ -519,15 +488,18 @@ Status VectorSegmentExecutor::load()
             Parameters place_holder;
             index = VectorIndexFactory::createIndex(type, mode, me, dimension, place_holder);
             LOG_INFO(log, "[load] start loading index: total_vec: {}", total_vec);
+            CompositeIndexReader index_reader(segment_id, original_binary_size);
             try
             {
-                index->load(index_binary, total_vec);
+                index->load(index_reader);
             }
             catch (const IndexException & e)
             {
+                LOG_ERROR(log, "failed to load index: {}", e.message());
                 return Status(e.code(), e.message());
             }
             index->setTrained();
+            des.erase("type");
             index->parseParameter(des);
             LOG_INFO(log, "[load] finish loading index");
             if (auto_tune && getOps().getCode() != 0)
@@ -584,65 +556,14 @@ Status VectorSegmentExecutor::load()
     }
 }
 
-Status VectorSegmentExecutor::readPart(bool & next, int part_count, uint8_t* index_binary, int64_t & current_loaded_size)
-{
-    DiskIOReader reader;
-    String path = segment_id.getFullPath() + "_" + ItoS(part_count) + VECTOR_INDEX_FILE_SUFFIX;
-    if (!reader.open(path))
-    {
-        return Status(5, "unable to open file " + path);
-    }
-    BinaryPtr index_binary_compressed = std::make_shared<Binary>();
-    /// first 8 bytes is final mark, deciding if this is the last segment
-    int64_t final_mark;
-    reader.read(&final_mark, sizeof(final_mark));
-    if (final_mark)
-    {
-        next = false;
-    }
-
-    /// second 8 bytes are meta recording compressed binary size of index
-    reader.seekg(sizeof(int64_t));
-    int64_t binary_length;
-    reader.read(&binary_length, sizeof(binary_length));
-    LOG_DEBUG(log, "[readPart] binary length in meta {}", binary_length);
-
-    /// third 8 bytes are meta recording uncompressed binary size of index
-    reader.seekg(sizeof(int64_t) * 2);
-    int64_t binary_length_original;
-    reader.read(&binary_length_original, sizeof(binary_length_original));
-    LOG_DEBUG(log, "[readPart] binary length originally in meta {}", binary_length_original);
-
-    /// fourth 8 bytes records total vectors stored, this is repeated many times. Could be d, or not.
-    reader.seekg(sizeof(int64_t) * 3);
-    int64_t total_vec_bin;
-    reader.read(&total_vec_bin, sizeof(total_vec_bin));
-    LOG_DEBUG(log, "[readPart] total vectors read: {}", total_vec_bin);
-    total_vec = total_vec_bin;
-
-    /// finally we have the compressed binaries
-    reader.seekg(sizeof(int64_t) * 4);
-    index_binary_compressed->data = new uint8_t[binary_length + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
-    index_binary_compressed->size = binary_length;
-
-    reader.read(index_binary_compressed->data, binary_length);
-
-    validateAndDecompress(index_binary_compressed, binary_length_original, index_binary);
-
-    current_loaded_size += binary_length_original;
-    LOG_DEBUG(log, "[readPart] current_loaded_size: {}", current_loaded_size);
-
-    return Status();
-}
-
 Status VectorSegmentExecutor::addVectors(VectorDatasetPtr dataset)
 {
     LOG_TRACE(log, "adding {} vectors", dataset->getVectorNum());
     index->addWithoutId(dataset);
     total_vec += dataset->getVectorNum();
     index->setTrained();
-    ///index is only searchable after the first call to addVector.
-    ///this bypassed some concurrency problem.
+    /// Index is only searchable after the first call to addVector.
+    /// this bypassed some concurrency problem.
     return Status();
 }
 
@@ -738,18 +659,6 @@ Status VectorSegmentExecutor::searchWithoutIndex(
         metrics);
 }
 
-Status VectorSegmentExecutor::copyToCpu()
-{
-    //TODO
-    return Status();
-}
-
-// Status VectorSegmentExecutor::copyToGpu(int32_t device_id, bool hybrid)
-// {
-//TODO
-//     return Status();
-// }
-
 IndexType VectorSegmentExecutor::indexType()
 {
     return index->indexType();
@@ -836,8 +745,8 @@ Status VectorSegmentExecutor::tune(VectorDatasetPtr base, std::vector<int64_t> &
 }
 
 
-///if the autoTuning has finished, we try to get the points from the disk
-///and load them into op_points
+/// If the autoTuning has finished, we try to get the points from the disk
+/// and load them into op_points
 Status VectorSegmentExecutor::getOps()
 {
     if (op_points == nullptr)
@@ -887,49 +796,9 @@ Status VectorSegmentExecutor::getOps()
     return Status();
 }
 
-uint32_t VectorSegmentExecutor::compressWithCheckSum(uint8_t * source, size_t size, BinaryPtr des)
-{
-    //DB::WriteBuffer out(des,size);
-    DB::CompressionCodecPtr codec = DB::CompressionCodecFactory::instance().get(cmb);
-    size_t decompressed_size = size;
-    des->data = new uint8_t[codec->getCompressedReserveSize(decompressed_size)];
-    uint32_t size_compressed
-        = codec->compress(reinterpret_cast<const char *>(source), decompressed_size, reinterpret_cast<char *>(des->data));
-    /// although we preallocated much more memory than needed, this is the amount actually need to get
-    /// serialized
-    des->size = size_compressed;
-    return size_compressed;
-}
-
-uint32_t VectorSegmentExecutor::validateAndDecompress(const BinaryPtr source, size_t uncompressed_size, uint8_t * des)
-{
-    uint8_t method = DB::ICompressionCodec::readMethod(reinterpret_cast<const char *>(source->data));
-    //    if(method==static_cast<const UInt8>(DB::CompressionMethodByte::NONE)){
-    //        ///if no compression,don't decompress, just point des to source
-    //        des.swap(source);
-    //        des->data = &des->data[DB::ICompressionCodec::getHeaderSize()];
-    //        des->size-= DB::ICompressionCodec::getHeaderSize();
-    //        return des->size;
-    //    }
-    DB::CompressionCodecPtr codec = DB::CompressionCodecFactory::instance().get(method);
-
-    uint32_t size_decompressed
-        = codec->decompress(reinterpret_cast<const char *>(source->data), source->size, reinterpret_cast<char *>(des));
-
-    LOG_DEBUG(log, "[validateAndDecompress] decompressed size: {}", size_decompressed);
-    
-    if (uncompressed_size != size_decompressed)
-    {
-        LOG_ERROR(
-            log, "The binary is corrupted, decompressed size: {}, recorded decompressed sized: {}", size_decompressed, uncompressed_size);
-        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "vector index on disk is corrupted");
-    }
-    return size_decompressed;
-}
-
 Status VectorSegmentExecutor::cancelBuild()
 {
-    ///TODO implement
+    /// TODO implement
     return Status();
 }
 
@@ -974,6 +843,8 @@ bool VectorSegmentExecutor::writeBitMap()
 
 bool VectorSegmentExecutor::readBitMap()
 {
+    readTotalVec();
+
     DiskIOReader bit_map_reader;
     String read_file_path = segment_id.getBitMapFilePath();
 
@@ -1016,7 +887,7 @@ bool VectorSegmentExecutor::compareVectorIndexParameters(IndexType t1, Parameter
 {
     Metrics me = L2;
     IndexMode mode = CPU;
-    char cmb = static_cast<uint8_t>(DB::CompressionMethodByte::NONE);
+    char cmb = static_cast<uint8_t>(DB::CompressionMethodByte::LZ4);
     if (p1.contains("metric_type"))
     {
         me = VectorIndexFactory::createIndexMetrics(p1.at("metric_type"));
@@ -1035,7 +906,7 @@ bool VectorSegmentExecutor::compareVectorIndexParameters(IndexType t1, Parameter
 
     Metrics me2 = L2;
     IndexMode mode2 = CPU;
-    char cmb2 = static_cast<uint8_t>(DB::CompressionMethodByte::NONE);
+    char cmb2 = static_cast<uint8_t>(DB::CompressionMethodByte::LZ4);
     if (p2.contains("metric_type"))
     {
         me2 = VectorIndexFactory::createIndexMetrics(p2.at("metric_type"));
@@ -1092,12 +963,10 @@ void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64>& deleted_row_
     if (segment_id.fromMergedParts())
         return;
 
-    readTotalVec();
-
     /// Read the delete bitmap
     if (!readBitMap())
     {
-        LOG_WARNING(log, "[updateBitMap] Skip to update not readable vector bitMap file part {}", segment_id.current_part_name);
+        LOG_WARNING(log, "[updateBitMap] skip to update unreadable vector bitmap file for part {}", segment_id.current_part_name);
         return;
     }
 
@@ -1134,12 +1003,14 @@ void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& delete
     if (!segment_id.fromMergedParts())
         return;
 
-    readTotalVec();
-
     /// Read the delete bitmap
     if (!readBitMap())
     {
-        LOG_WARNING(log, "[updateMergedBitMap] Skip to update not readable vector bitMap file for segement: merged part {} in decouple part {}", segment_id.owner_part_name, segment_id.current_part_name);
+        LOG_WARNING(
+            log,
+            "[updateMergedBitMap] skip to update unreadable vector bitmap file: owner part {}, current part {}",
+            segment_id.owner_part_name,
+            segment_id.current_part_name);
         return;
     }
 
diff --git a/src/VectorIndex/VectorSegmentExecutor.h b/src/VectorIndex/VectorSegmentExecutor.h
index 3173cedc3f..cc5db6541d 100644
--- a/src/VectorIndex/VectorSegmentExecutor.h
+++ b/src/VectorIndex/VectorSegmentExecutor.h
@@ -16,7 +16,7 @@
 
 namespace VectorIndex
 {
-static size_t optimal_segment_size = (1LL << 32) - 10; //This is 2^32, or 4GB, we are not maxing it since compression introduce a header.
+static size_t optimal_segment_size = (1LL << 32) - 10; // This is 2^32, or 4GB, we are not maxing it since compression introduce a header.
 
 struct OperatingPoint
 {
@@ -69,62 +69,55 @@ using IndexWithMetaPtr = std::shared_ptr<IndexWithMeta>;
 
 class VectorSegmentExecutor
 {
-    /// the exposed api set which should be called by users trying to use vector index;
+    /// The exposed api set which should be called by users trying to use vector index;
     /// the user should not visit any index directly.
 public:
-    ///create the index but not inserting any data
+    /// Create the index but not inserting any data
     VectorSegmentExecutor(IndexType type_, const SegmentId & segment_id_, Parameters des_, size_t dimension_ = 0);
 
     explicit VectorSegmentExecutor(const SegmentId & segment_id_);
 
-    ///serialize and store index at segment_id
+    /// Serialize and store index at segment_id
     Status serialize();
 
-    /// load index from segment_id,
-    /// if hit in cache then simply redirect pointer.
+    /// Load index from segment_id,
+    /// If hit in cache then simply redirect pointer.
     Status load();
 
-    ///gpu related.
-    // Status copyToGpu(int32_t device_id, [[maybe_unused]] bool hybrid = false);
-    //TODO
-
-    Status copyToCpu();
-    //TODO
-
-    /// a c style method that wraps VectorIndex::Search function and does some preprocessing.
-    /// distance and labels are the pointers to expected results and should be declared before calling this method with proper size.
+    /// A C style method that wraps VectorIndex::Search function and does some preprocessing.
+    /// Distance and labels are the pointers to expected results and should be declared before calling this method with proper size.
     Status
     search(VectorDatasetPtr dataset, int32_t k, float *& distances, int64_t *& labels, GeneralBitMapPtr filter, Parameters parameters);
 
-    /// buildIndex method use data to train an index, does not add data for search.
-    /// it'll call index's train(), but does not write to file io.
+    /// buildIndex() use data to train an index, does not add data for search.
+    /// It'll call index's train(), but does not write to file io.
     Status buildIndex(VectorDatasetPtr data_set, int64_t total_vectors_expected, bool slow_mode);
 
-    ///put the index stored in VectorSegmentExecutor into cache.
+    /// Put the index stored in VectorSegmentExecutor into cache.
     Status cache();
 
-    ///return index type.
+    /// Return index type.
     IndexType indexType();
 
-    ///simply add vectors into index for search.
+    /// Simply add vectors into index for search.
     Status addVectors(VectorDatasetPtr data_set);
 
     Status removeByIds(int64_t n, int64_t * ids);
 
     GeneralBitMapPtr getDeleteBitMap() { return this->delete_bitmap; }
 
-    ///return total number of vectors.
+    /// Return total number of vectors.
     int64_t getRawDataSize();
 
-    ///call to set build parameters in this VectorSegmentExecutor
-    ///just put the values of parameters as "parameter_name":"value"
-    /// exp: "nprobes":128
+    /// Call to set build parameters in this VectorSegmentExecutor.
+    /// Just put the values of parameters as "parameter_name":"value"
+    /// Example: "nprobes":128
     void setIndexParameters(Parameters parameters);
 
-    ///automatically compute some operating points for the current index. An operating point is a
+    /// Automatically compute some operating points for the current index. An operating point is a
     /// combination of all parameters of the index which corresponds to an estimated accuracy of the inedx while searching.
     /// the accuracy is calculated by testing the base vectors against itself.
-    ///this function call only does some preprocessing and then dispatch the task to the autotuner.
+    /// This function call only does some preprocessing and then dispatch the task to the autotuner.
     Status dispathAutoTuneTask(VectorDatasetPtr base); /// deprecated
 
 
@@ -132,8 +125,8 @@ public:
     Status tune(VectorDatasetPtr base, std::vector<int64_t> & empty_ids, size_t current_round_start_row);
 
 
-    ///look into cached OPs in memory, if found nothing then look into file system and read
-    ///the OP file generated by autotuner.
+    /// look into cached OPs in memory, if found nothing then look into file system and read
+    /// the OP file generated by autotuner.
     Status getOps();
 
     /// cancel building the current vector index, free associated resources.
@@ -152,7 +145,7 @@ public:
     static Status
     searchWithoutIndex(VectorDatasetPtr query_data, VectorDatasetPtr bash_data, int32_t k, float *& distances, int64_t *& labels, const Metrics& metrics);
 
-    ///expire the related index from cache.
+    /// expire the related index from cache.
     static Status removeFromCache(const CacheKey & cache_key);
 
     GeneralBitMapPtr getRealBitMap(const std::vector<UInt64>& selected_row_ids)
@@ -206,16 +199,6 @@ private:
 
     Status writePart(bool final, int segment_count, uint8_t * index_segment_offset, size_t index_segment_size);
 
-    Status readPart(bool & next, int part_count, uint8_t* index_binary, int64_t & current_loaded_size);
-
-    ///put a checksum of 12 bytes at the head of binary, then append the compressed bytes.
-    ///this only compress and checksum the binary index file, not including the metadata.
-    uint32_t compressWithCheckSum(uint8_t * source, size_t size, BinaryPtr des);
-
-    ///take the compreseed binary of index file, check the checksum, them decompress it using
-    ///method provided in header to des.
-    uint32_t validateAndDecompress(BinaryPtr source, size_t uncompressed_size, uint8_t * des);
-
     void handleMergedMaps();
 
     void readTotalVec();
@@ -238,19 +221,18 @@ private:
         }
     }
 
-    const static UInt32 COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER = LZ4::ADDITIONAL_BYTES_AT_END_OF_BUFFER;
     const UInt32 dimension;
     const IndexType type;
     IndexMode mode = IndexMode::CPU;
     Metrics me = Metrics::L2;
     bool auto_tune = false;
     uint8_t cmb = static_cast<uint8_t>(DB::CompressionMethodByte::LZ4);
-    VectorIndexPtr index = nullptr; //index related to this VectorSegmentExecutor
-    SegmentId segment_id; //this index's related segment_id and file write position.
+    VectorIndexPtr index = nullptr; // index related to this VectorSegmentExecutor
+    SegmentId segment_id; // this index's related segment_id and file write position.
     Poco::Logger * log;
     UInt64 total_vec = 0;
-    OPsPtr op_points = nullptr; //operating points precomputed as an <accuracy,parameter> map,ordered by acc.
-    GeneralBitMapPtr delete_bitmap = nullptr; //manage deletion from database
+    OPsPtr op_points = nullptr; // operating points precomputed as an <accuracy, parameter> map, ordered by acc.
+    GeneralBitMapPtr delete_bitmap = nullptr; // manage deletion from database
     Parameters des;
     std::shared_ptr<std::vector<UInt64>> row_ids_map = std::make_shared<std::vector<UInt64>>();
     std::shared_ptr<std::vector<UInt64>> inverted_row_ids_map = std::make_shared<std::vector<UInt64>>();
diff --git a/tests/queries/2_vector_search/00001_mqvs_distance.reference b/tests/queries/2_vector_search/00001_mqvs_distance.reference
index 0bcda9c13c..6e19ea12af 100644
--- a/tests/queries/2_vector_search/00001_mqvs_distance.reference
+++ b/tests/queries/2_vector_search/00001_mqvs_distance.reference
@@ -8,3 +8,13 @@
 7	[7,7,7]	142.83
 8	[8,8,8]	187.23
 9	[9,9,9]	237.62997
+0	[0,0,0]	0.030000001
+1	[1,1,1]	2.4299998
+2	[2,2,2]	10.83
+3	[3,3,3]	25.230003
+4	[4,4,4]	45.630005
+5	[5,5,5]	72.03
+6	[6,6,6]	104.43001
+7	[7,7,7]	142.83
+8	[8,8,8]	187.23
+9	[9,9,9]	237.62997
diff --git a/tests/queries/2_vector_search/00001_mqvs_distance.sh b/tests/queries/2_vector_search/00001_mqvs_distance.sh
index 3020422ccf..b556627edd 100755
--- a/tests/queries/2_vector_search/00001_mqvs_distance.sh
+++ b/tests/queries/2_vector_search/00001_mqvs_distance.sh
@@ -5,3 +5,7 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
 clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
+# detach and attach the table to test deserialization of vector index
+clickhouse-client -q "DETACH TABLE test_vector"
+clickhouse-client -q "ATTACH TABLE test_vector"
+clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
diff --git a/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.reference b/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.reference
index c8c79d114e..fa1c854116 100644
--- a/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.reference
+++ b/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.reference
@@ -1,2 +1,4 @@
 0	[0,0,0]	0.030000001
 1	[1,1,1]	2.4299998
+0	[0,0,0]	0.030000001
+1	[1,1,1]	2.4299998
diff --git a/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh b/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh
index c159d9673d..13e3ba12c8 100755
--- a/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh
+++ b/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh
@@ -5,3 +5,7 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
 clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) as d FROM test_vector where d < 10;"
+# detach and attach the table to test deserialization of vector index
+clickhouse-client -q "DETACH TABLE test_vector"
+clickhouse-client -q "ATTACH TABLE test_vector"
+clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) as d FROM test_vector where d < 10;"
diff --git a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference
index 63150b952b..3d8ef1afdd 100644
--- a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference
+++ b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference
@@ -8,3 +8,13 @@
 7	[7,7,7]	143.15494
 8	[8,8,8]	181.51205
 9	[9,9,9]	239.72878
+0	[0,0,0]	0.00970047
+1	[1,1,1]	1.9864521
+2	[2,2,2]	11.696049
+3	[3,3,3]	24.283756
+4	[4,4,4]	48.141277
+5	[5,5,5]	71.33989
+6	[6,6,6]	109.34532
+7	[7,7,7]	143.15494
+8	[8,8,8]	181.51205
+9	[9,9,9]	239.72878
diff --git a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh
index 947b35fca8..0a71e9f493 100755
--- a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh
+++ b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh
@@ -5,3 +5,7 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_3.sh
 
 clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
+# detach and attach the table to test deserialization of vector index
+clickhouse-client -q "DETACH TABLE test_vector"
+clickhouse-client -q "ATTACH TABLE test_vector"
+clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
-- 
2.32.1 (Apple Git-133)

