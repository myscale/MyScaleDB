From f9492d19ba5768c5b5de3aab175a5f6736a604b9 Mon Sep 17 00:00:00 2001
From: xinhuit <xinhuit@moqi.ai>
Date: Fri, 28 Oct 2022 14:06:02 +0800
Subject: [PATCH 01/85] Vector search query refactor

---
 .gitlab-ci.yml                                |   2 +
 docker/mqdb/server.conf/users.xml             |   2 +-
 docker/test/mqdb_test_script/clickhouse-test  |   3 +-
 programs/clickhouse-diagnostics               |   2 +
 src/Interpreters/ExpressionAnalyzer.cpp       |   6 +
 src/Interpreters/GetVectorScanVisitor.h       |  14 +
 src/Interpreters/InterpreterSelectQuery.cpp   |   1 +
 src/Interpreters/TreeRewriter.cpp             |   4 +
 .../QueryPlan/ReadFromMergeTree.cpp           |  17 +-
 .../QueryPlan/ReadWithVectorScan.cpp          | 182 +++++++++
 src/Processors/QueryPlan/ReadWithVectorScan.h |  70 ++++
 .../MergeTree/MergeTreeDataSelectExecutor.cpp |  61 ++-
 ...MergeTreeSelectWithVectorScanProcessor.cpp | 386 ++++++++++++++++++
 .../MergeTreeSelectWithVectorScanProcessor.h  |  39 ++
 .../MergeTreeVectorIndexBuilderUpdater.cpp    |  20 +-
 .../MergeTree/MergeTreeVectorScanManager.cpp  |  50 ++-
 .../MergeTree/MergeTreeVectorScanManager.h    |  19 +-
 .../MergeTree/MergeTreeVectorScanUtils.cpp    | 123 +++---
 .../MergeTree/MergeTreeVectorScanUtils.h      |   6 +-
 .../MergeTree/MergeTreeWhereOptimizer.cpp     |  15 +-
 src/VectorIndex/GeneralBitMap.h               |  13 +-
 src/VectorIndex/VectorSegmentExecutor.cpp     |   2 +-
 src/VectorIndex/VectorSegmentExecutor.h       |   1 +
 ...0003_mqvs_distance_with_prewhere.reference |  40 +-
 .../00003_mqvs_distance_with_prewhere.sh      |   2 +-
 ...vs_brute_force_search_prewhere_0.reference | 200 ++++-----
 ...0009_mqvs_brute_force_search_prewhere_0.sh |   2 +-
 ...vs_brute_force_search_prewhere_1.reference | 200 ++++-----
 ...0010_mqvs_brute_force_search_prewhere_1.sh |   2 +-
 ...11_mqvs_brute_force_search_where.reference |  34 ++
 .../00012_mqvs_brute_force_search.reference   | 200 ++++-----
 .../00012_mqvs_brute_force_search.sh          |   2 +-
 .../00018_mqvs_multi_distance_funcs.reference |   1 +
 .../00018_mqvs_multi_distance_funcs.sh        |   7 +
 .../helpers/00000_prepare_index_2.sh          |   2 +-
 .../vector/alter_index.sql                    |   0
 .../vector/create_table.sql                   |   0
 .../vector/create_table_xhs.sql               |   0
 .../vector/insert.sql                         |   0
 .../vector/search_xhs.sql                     |   0
 40 files changed, 1302 insertions(+), 428 deletions(-)
 create mode 100755 programs/clickhouse-diagnostics
 create mode 100644 src/Processors/QueryPlan/ReadWithVectorScan.cpp
 create mode 100644 src/Processors/QueryPlan/ReadWithVectorScan.h
 create mode 100644 src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.cpp
 create mode 100644 src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.h
 create mode 100644 tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.reference
 create mode 100755 tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh
 rename tests/{queries => vector_search}/vector/alter_index.sql (100%)
 rename tests/{queries => vector_search}/vector/create_table.sql (100%)
 rename tests/{queries => vector_search}/vector/create_table_xhs.sql (100%)
 rename tests/{queries => vector_search}/vector/insert.sql (100%)
 rename tests/{queries => vector_search}/vector/search_xhs.sql (100%)

diff --git a/.gitlab-ci.yml b/.gitlab-ci.yml
index 1f3a23b34d..12ce822171 100644
--- a/.gitlab-ci.yml
+++ b/.gitlab-ci.yml
@@ -39,6 +39,7 @@ build_package:
     - mqdb-master
     - mqdb-staging
     - mqdb-dev
+    - merge_requests
   artifacts:
     name: "mqdb-$CI_COMMIT_BRANCH-$CI_COMMIT_SHORT_SHA-without-license"
     paths:
@@ -77,6 +78,7 @@ build_image:
     - mqdb-master
     - mqdb-staging
     - mqdb-dev
+    - merge_requests
   before_script:
     - docker/builder/tools/docker-info.sh
     - docker/builder/tools/docker-buildx.sh
diff --git a/docker/mqdb/server.conf/users.xml b/docker/mqdb/server.conf/users.xml
index 39f97fcf66..a1d27244d1 100644
--- a/docker/mqdb/server.conf/users.xml
+++ b/docker/mqdb/server.conf/users.xml
@@ -10,7 +10,7 @@
             <!-- <mutations_sync>0</mutations_sync> -->
             <!-- <replication_alter_partitions_sync>1</replication_alter_partitions_sync> -->
             <!-- <insert_distributed_sync>1</insert_distributed_sync> -->
-            <optimize_move_to_prewhere>0</optimize_move_to_prewhere>
+            <optimize_move_to_prewhere>1</optimize_move_to_prewhere>
             <max_query_size>262144000</max_query_size>
             <connect_timeout_with_failover_ms>5000</connect_timeout_with_failover_ms>
             <distributed_directory_monitor_batch_inserts>1</distributed_directory_monitor_batch_inserts>
diff --git a/docker/test/mqdb_test_script/clickhouse-test b/docker/test/mqdb_test_script/clickhouse-test
index 70689de0e5..417198aae5 100644
--- a/docker/test/mqdb_test_script/clickhouse-test
+++ b/docker/test/mqdb_test_script/clickhouse-test
@@ -837,9 +837,8 @@ class TestSuite:
         if 'stateful' in suite and args.no_stateful:
             print("Won't run stateful tests because they were manually disabled.")
             return None
-        # if 'vector_search' in suite or 'bugs' in suite or 'ai_core_support' in suite or 'vector' in suite:
         if 'bugs' in suite or 'ai_core_support' in suite:
-            print("only run statless test")
+            print("Won't run bugs and ai_core_support test")
             return None
         return TestSuite(args, suite_path, suite_tmp_path, suite)
 
diff --git a/programs/clickhouse-diagnostics b/programs/clickhouse-diagnostics
new file mode 100755
index 0000000000..d4728714a4
--- /dev/null
+++ b/programs/clickhouse-diagnostics
@@ -0,0 +1,2 @@
+#!/bin/sh
+echo 'Not implemented for this type of package'
diff --git a/src/Interpreters/ExpressionAnalyzer.cpp b/src/Interpreters/ExpressionAnalyzer.cpp
index 8b7a36f4eb..ca100ceed7 100644
--- a/src/Interpreters/ExpressionAnalyzer.cpp
+++ b/src/Interpreters/ExpressionAnalyzer.cpp
@@ -652,6 +652,12 @@ bool ExpressionAnalyzer::makeVectorScanDescriptions(ActionsDAGPtr & actions)
             throw Exception(ErrorCodes::UNKNOWN_IDENTIFIER,
                 "Unknown identifier '{}' in distance function", arguments[1]->getColumnName());
         }
+
+        if (!dag_node->column)
+        {
+           throw Exception(ErrorCodes::UNKNOWN_IDENTIFIER,
+                "Wrong query vector type in distance function"); 
+        }
         vector_scan_desc.query_column = dag_node->column;
         vector_scan_desc.query_column_name = arguments[1]->getColumnName();
         //vector_scan_desc.parameters = (node->parameters) ? getAggregateFunctionParametersArray(node->parameters, "", getContext()) : Array();
diff --git a/src/Interpreters/GetVectorScanVisitor.h b/src/Interpreters/GetVectorScanVisitor.h
index d65169419c..9c6ef3bd02 100644
--- a/src/Interpreters/GetVectorScanVisitor.h
+++ b/src/Interpreters/GetVectorScanVisitor.h
@@ -3,6 +3,7 @@
 #include <base/logger_useful.h>
 #include <Common/VectorScanUtils.h>
 #include <Interpreters/InDepthNodeVisitor.h>
+#include <Parsers/formatAST.h>
 
 namespace DB
 {
@@ -21,6 +22,7 @@ public:
     struct Data
     {
         const char * assert_no_vector_scan = nullptr;
+        std::unordered_set<String> uniq_names {};
         std::vector<const ASTFunction *> vector_scan_funcs;
     };
 
@@ -60,12 +62,24 @@ private:
         /// Poco::Logger * log = &Poco::Logger::get("GetVectorScanMatcher");
         if (isVectorScanFunc(node.name))
         {
+            auto full_name = getFullName(node);
+            if (data.uniq_names.count(full_name))
+                return;
+            
             if (data.assert_no_vector_scan)
                 throw Exception("Vector Scan function " + node.getColumnName()  + " is found " + String(data.assert_no_vector_scan) + " in query",
                                 ErrorCodes::ILLEGAL_VECTOR_SCAN);
             data.vector_scan_funcs.push_back(&node);
+            data.uniq_names.insert(full_name);
         }
     }
+
+    static String getFullName(ASTFunction & node)
+    {
+        WriteBufferFromOwnString buf;
+        formatAST(node, buf, false, true);
+        return buf.str();
+    }
 };
 
 using GetVectorScanVisitor = GetVectorScanMatcher::Visitor;
diff --git a/src/Interpreters/InterpreterSelectQuery.cpp b/src/Interpreters/InterpreterSelectQuery.cpp
index 50850f237e..04800462f5 100644
--- a/src/Interpreters/InterpreterSelectQuery.cpp
+++ b/src/Interpreters/InterpreterSelectQuery.cpp
@@ -435,6 +435,7 @@ InterpreterSelectQuery::InterpreterSelectQuery(
 
         if (try_move_to_prewhere && storage && storage->canMoveConditionsToPrewhere() && query.where() && !query.prewhere())
         {
+            LOG_DEBUG(log, "[analyze] try to move to prewhere");
             /// PREWHERE optimization: transfer some condition from WHERE to PREWHERE if enabled and viable
             if (const auto & column_sizes = storage->getColumnSizes(); !column_sizes.empty())
             {
diff --git a/src/Interpreters/TreeRewriter.cpp b/src/Interpreters/TreeRewriter.cpp
index 0e60eb3e89..3f8b75d553 100644
--- a/src/Interpreters/TreeRewriter.cpp
+++ b/src/Interpreters/TreeRewriter.cpp
@@ -1344,6 +1344,10 @@ TreeRewriterResultPtr TreeRewriter::analyzeSelect(
     result.aggregates = getAggregates(query, *select_query);
     result.window_function_asts = getWindowFunctions(query, *select_query);
     result.vector_scan_funcs = getVectorScanFunctions(query, *select_query);
+    
+    if (result.vector_scan_funcs.size() > 1)
+        throw Exception("Not support multiple distance funcs in one query now.", ErrorCodes::LOGICAL_ERROR);
+
     result.collectUsedColumns(query, true);
     result.required_source_columns_before_expanding_alias_columns = result.required_source_columns.getNames();
 
diff --git a/src/Processors/QueryPlan/ReadFromMergeTree.cpp b/src/Processors/QueryPlan/ReadFromMergeTree.cpp
index b5b7b8f7f6..0532650bb3 100644
--- a/src/Processors/QueryPlan/ReadFromMergeTree.cpp
+++ b/src/Processors/QueryPlan/ReadFromMergeTree.cpp
@@ -216,6 +216,17 @@ ProcessorPtr ReadFromMergeTree::createSource(
             .colums_to_read = required_columns
         };
     }
+
+    for (auto & col : required_columns)
+    {
+        LOG_DEBUG(log, "[createSource] required_column: {}", col);
+    }
+
+    for (auto & col : virt_column_names)
+    {
+        LOG_DEBUG(log, "[createSource] virt_column: {}", col);
+    }
+
     return std::make_shared<TSource>(
             data, storage_snapshot, part.data_part, max_block_size, preferred_block_size_bytes,
             preferred_max_column_in_block_size_bytes, required_columns, part.ranges, use_uncompressed_cache, prewhere_info,
@@ -1039,7 +1050,7 @@ void ReadFromMergeTree::initializePipeline(QueryPipelineBuilder & pipeline, cons
         LOG_DEBUG(log, "[initializePipeline] need to process vector scan");
         for (auto & part : result.parts_with_ranges)
         {
-            part.vector_scan_manager = std::make_shared<MergeTreeVectorScanManager>(metadata_for_reading, vector_scan_info_ptr);
+            part.vector_scan_manager = std::make_shared<MergeTreeVectorScanManager>(metadata_for_reading, vector_scan_info_ptr, context);
             /// no prewhere info, first perform vector scan
             if (!prewhere_info)
             {
@@ -1051,8 +1062,8 @@ void ReadFromMergeTree::initializePipeline(QueryPipelineBuilder & pipeline, cons
         if (!prewhere_info)
         {
             LOG_DEBUG(log, "[initializePipeline] try to filter mark ranges by vector scan result");
-            filterMarkRangesByVectorScanResult(result.parts_with_ranges, 
-                                               vector_scan_info_ptr->vector_scan_descs, context->getSettingsRef());
+            filterPartsMarkRangesByVectorScanResult(result.parts_with_ranges, 
+                                               vector_scan_info_ptr->vector_scan_descs);
 
             size_t sum_marks = 0;
             size_t sum_ranges = 0;
diff --git a/src/Processors/QueryPlan/ReadWithVectorScan.cpp b/src/Processors/QueryPlan/ReadWithVectorScan.cpp
new file mode 100644
index 0000000000..bdaf6b9835
--- /dev/null
+++ b/src/Processors/QueryPlan/ReadWithVectorScan.cpp
@@ -0,0 +1,182 @@
+#include <Parsers/ASTFunction.h>
+#include <Parsers/ASTSelectQuery.h>
+#include <Processors/QueryPlan/ReadFromMergeTree.h>
+#include <Processors/QueryPlan/ReadWithVectorScan.h>
+#include <QueryPipeline/QueryPipelineBuilder.h>
+#include <Storages/MergeTree/MergeTreeVectorScanManager.h>
+#include <Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.h>
+
+namespace DB
+{
+
+static MergeTreeReaderSettings getMergeTreeReaderSettings(const ContextPtr & context)
+{
+    const auto & settings = context->getSettingsRef();
+    return
+    {
+        .read_settings = context->getReadSettings(),
+        .save_marks_in_cache = true,
+        .checksum_on_read = settings.checksum_on_read,
+        .apply_deleted_mask = context->applyDeletedMask(),
+    };
+}
+
+static const PrewhereInfoPtr & getPrewhereInfo(const SelectQueryInfo & query_info)
+{
+    return query_info.projection ? query_info.projection->prewhere_info
+                                 : query_info.prewhere_info;
+}
+
+ReadWithVectorScan::ReadWithVectorScan(
+    MergeTreeData::DataPartsVector parts_,
+    Names real_column_names_,
+    Names virt_column_names_,
+    const MergeTreeData & data_,
+    const SelectQueryInfo & query_info_,
+    StorageSnapshotPtr storage_snapshot_,
+    ContextPtr context_,
+    size_t max_block_size_,
+    size_t num_streams_,
+    bool sample_factor_column_queried_,
+    std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read_,
+    Poco::Logger * log_,
+    bool enable_parallel_reading)
+    : ISourceStep(DataStream{.header = MergeTreeBaseSelectProcessor::transformHeader(
+        storage_snapshot_->getSampleBlockForColumns(real_column_names_),
+        getPrewhereInfo(query_info_),
+        data_.getPartitionValueType(),
+        virt_column_names_)})
+    , reader_settings(getMergeTreeReaderSettings(context_))
+    , prepared_parts(std::move(parts_))
+    , real_column_names(std::move(real_column_names_))
+    , virt_column_names(std::move(virt_column_names_))
+    , data(data_)
+    , query_info(query_info_)
+    , prewhere_info(getPrewhereInfo(query_info))
+    , actions_settings(ExpressionActionsSettings::fromContext(context_))
+    , storage_snapshot(std::move(storage_snapshot_))
+    , metadata_for_reading(storage_snapshot->getMetadataForQuery())
+    , context(std::move(context_))
+    , max_block_size(max_block_size_)
+    , requested_num_streams(num_streams_)
+    , preferred_block_size_bytes(context->getSettingsRef().preferred_block_size_bytes)
+    , preferred_max_column_in_block_size_bytes(context->getSettingsRef().preferred_max_column_in_block_size_bytes)
+    , sample_factor_column_queried(sample_factor_column_queried_)
+    , max_block_numbers_to_read(std::move(max_block_numbers_to_read_))
+    , log(log_)
+{
+    if (sample_factor_column_queried)
+    {
+        /// Only _sample_factor virtual column is added by ReadFromMergeTree
+        /// Other virtual columns are added by MergeTreeBaseSelectProcessor.
+        auto type = std::make_shared<DataTypeFloat64>();
+        output_stream->header.insert({type->createColumn(), type, "_sample_factor"});
+    }
+
+    if (enable_parallel_reading)
+        read_task_callback = context->getMergeTreeReadTaskCallback();
+}
+
+void ReadWithVectorScan::initializePipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings &)
+{
+    Pipe pipe;
+
+    Names column_names_to_read = real_column_names;
+
+    /// If there are only virtual columns in the query, should be wrong, just return.
+    if (column_names_to_read.empty())
+    {
+        return;
+    }
+
+    pipe = createReadProcessorsAmongParts(
+        prepared_parts,
+        column_names_to_read);
+
+    for (const auto & processor : pipe.getProcessors())
+    {
+        LOG_DEBUG(log, "[initializePipeline] add processor: {}", processor->getName());
+        processors.emplace_back(processor);
+    }
+
+    pipeline.init(std::move(pipe));
+}
+
+
+/// needs to handle:
+/// 
+Pipe ReadWithVectorScan::createReadProcessorsAmongParts(
+    MergeTreeData::DataPartsVector & parts,
+    const Names & column_names)
+{
+    if (parts.size() == 0)
+        return {};
+
+    const auto & settings = context->getSettingsRef();
+    const size_t min_parts_per_stream = (parts.size() - 1) / requested_num_streams + 1;
+    
+    Pipes res;
+
+    for (size_t i = 0; i < requested_num_streams && !parts.empty(); ++i)
+    {
+        MergeTreeData::DataPartsVector new_parts;
+        size_t need_parts = min_parts_per_stream;
+        while (need_parts > 0 && !parts.empty())
+        {
+            new_parts.push_back(parts.back());
+            parts.pop_back();
+        }
+
+        res.emplace_back(readFromParts(new_parts, column_names, settings.use_uncompressed_cache));
+    }
+
+    auto pipe = Pipe::unitePipes(std::move(res));
+
+    return pipe;
+}
+
+Pipe ReadWithVectorScan::readFromParts(
+    MergeTreeData::DataPartsVector & parts,
+    Names required_columns,
+    bool use_uncompressed_cache)
+{
+    Pipes pipes;
+    auto vector_scan_info_ptr = query_info.vector_scan_info;
+    if (!vector_scan_info_ptr)
+        return {};
+
+    const auto & client_info = context->getClientInfo();
+    
+    
+    for (const auto & part : parts)
+    {
+        auto vector_scan_manager = std::make_shared<MergeTreeVectorScanManager>(metadata_for_reading, vector_scan_info_ptr, context);
+
+        /// ToConfirm
+        std::optional<ParallelReadingExtension> extension;
+        if (read_task_callback)
+        {
+            extension = ParallelReadingExtension
+            {
+                .callback = read_task_callback.value(),
+                .count_participating_replicas = client_info.count_participating_replicas,
+                .number_of_current_replica = client_info.number_of_current_replica,
+                .colums_to_read = required_columns
+            };
+        }
+
+        MarkRanges ranges;
+        MarkRange range{0, part->index_granularity.getMarksCount()};
+        ranges.emplace_back(range);
+
+        auto source = std::make_shared<MergeTreeSelectWithVectorScanProcessor>(data, storage_snapshot, part, max_block_size, 
+            preferred_block_size_bytes, preferred_max_column_in_block_size_bytes, required_columns, ranges, use_uncompressed_cache, prewhere_info,
+            actions_settings, reader_settings, virt_column_names, (size_t)0, false, std::move(extension), vector_scan_manager);
+        pipes.emplace_back(std::move(source));
+    }
+
+    auto pipe = Pipe::unitePipes(std::move(pipes));
+    return pipe;
+}
+
+}
diff --git a/src/Processors/QueryPlan/ReadWithVectorScan.h b/src/Processors/QueryPlan/ReadWithVectorScan.h
new file mode 100644
index 0000000000..7fff5a4e33
--- /dev/null
+++ b/src/Processors/QueryPlan/ReadWithVectorScan.h
@@ -0,0 +1,70 @@
+#pragma once
+#include <Processors/QueryPlan/ISourceStep.h>
+#include <Storages/MergeTree/RangesInDataPart.h>
+#include <Storages/MergeTree/MergeTreeVectorScanUtils.h>
+
+namespace DB
+{
+
+class ReadWithVectorScan final : public ISourceStep
+{
+public:
+    ReadWithVectorScan(
+        MergeTreeData::DataPartsVector parts_,
+        Names real_column_names_,
+        Names virt_column_names_,
+        const MergeTreeData & data_,
+        const SelectQueryInfo & query_info_,
+        StorageSnapshotPtr storage_snapshot,
+        ContextPtr context_,
+        size_t max_block_size_,
+        size_t num_streams_,
+        bool sample_factor_column_queried_,
+        std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read_,
+        Poco::Logger * log_,
+        bool enable_parallel_reading
+    );
+
+    String getName() const override { return "ReadWithVectorScan"; }
+
+    void initializePipeline(QueryPipelineBuilder & pipeline, const BuildQueryPipelineSettings &) override;
+
+    Pipe createReadProcessorsAmongParts(MergeTreeData::DataPartsVector & parts,
+    const Names & column_names);
+
+private:
+    std::optional<MergeTreeReadTaskCallback> read_task_callback;
+
+    const MergeTreeReaderSettings reader_settings;
+
+    MergeTreeData::DataPartsVector prepared_parts;
+    Names real_column_names;
+    Names virt_column_names;
+
+    const MergeTreeData & data;
+    SelectQueryInfo query_info;
+    PrewhereInfoPtr prewhere_info;
+    ExpressionActionsSettings actions_settings;
+
+    StorageSnapshotPtr storage_snapshot;
+    StorageMetadataPtr metadata_for_reading;
+
+    ContextPtr context;
+
+    const size_t max_block_size;
+    const size_t requested_num_streams;
+    const size_t preferred_block_size_bytes;
+    const size_t preferred_max_column_in_block_size_bytes;
+    const bool sample_factor_column_queried;
+
+    std::shared_ptr<PartitionIdToMaxBlock> max_block_numbers_to_read;
+
+    Poco::Logger * log;
+
+    Pipe readFromParts(
+        MergeTreeData::DataPartsVector & parts,
+        Names required_columns,
+        bool use_uncompressed_cache);
+};
+
+}
diff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
index 0c61193566..99886f9b68 100644
--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
@@ -23,6 +23,7 @@
 #include <Processors/QueryPlan/ExpressionStep.h>
 #include <Processors/QueryPlan/ReadFromPreparedSource.h>
 #include <Processors/QueryPlan/ReadFromMergeTree.h>
+#include <Processors/QueryPlan/ReadWithVectorScan.h>
 #include <Processors/QueryPlan/UnionStep.h>
 #include <Processors/Sources/SourceFromSingleChunk.h>
 
@@ -1242,25 +1243,49 @@ QueryPlanPtr MergeTreeDataSelectExecutor::readFromParts(
 
     selectColumnNames(column_names_to_return, data, real_column_names, virt_column_names, sample_factor_column_queried);
 
-    auto read_from_merge_tree = std::make_unique<ReadFromMergeTree>(
-        std::move(parts),
-        real_column_names,
-        virt_column_names,
-        data,
-        query_info,
-        storage_snapshot,
-        context,
-        max_block_size,
-        num_streams,
-        sample_factor_column_queried,
-        max_block_numbers_to_read,
-        log,
-        merge_tree_select_result_ptr,
-        enable_parallel_reading
-    );
-
     QueryPlanPtr plan = std::make_unique<QueryPlan>();
-    plan->addStep(std::move(read_from_merge_tree));
+    if (query_info.vector_scan_info)
+    {
+        auto read_with_vector_scan = std::make_unique<ReadWithVectorScan>(
+            std::move(parts),
+            real_column_names,
+            virt_column_names,
+            data,
+            query_info,
+            storage_snapshot,
+            context,
+            max_block_size,
+            num_streams,
+            sample_factor_column_queried,
+            max_block_numbers_to_read,
+            log,
+            enable_parallel_reading
+        );
+
+        plan->addStep(std::move(read_with_vector_scan));
+    }
+    else
+    {
+        auto read_from_merge_tree = std::make_unique<ReadFromMergeTree>(
+            std::move(parts),
+            real_column_names,
+            virt_column_names,
+            data,
+            query_info,
+            storage_snapshot,
+            context,
+            max_block_size,
+            num_streams,
+            sample_factor_column_queried,
+            max_block_numbers_to_read,
+            log,
+            merge_tree_select_result_ptr,
+            enable_parallel_reading
+        );
+
+        plan->addStep(std::move(read_from_merge_tree));
+    }
+
     return plan;
 }
 
diff --git a/src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.cpp b/src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.cpp
new file mode 100644
index 0000000000..6b7571f8df
--- /dev/null
+++ b/src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.cpp
@@ -0,0 +1,386 @@
+#include <Interpreters/OpenTelemetrySpanLog.h>
+#include <Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.h>
+#include <Storages/MergeTree/MergeTreeInOrderSelectProcessor.h>
+#include <Storages/MergeTree/MergeTreeVectorScanUtils.h>
+#include <Processors/Executors/PullingPipelineExecutor.h>
+#include <DataTypes/DataTypeTuple.h>
+
+#include <base/logger_useful.h>
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int MEMORY_LIMIT_EXCEEDED;
+}
+
+void MergeTreeSelectWithVectorScanProcessor::initializeReadersWithVectorScan()
+{
+    OpenTelemetrySpanHolder span("MergeTreeSelectWithVectorScanProcessor::initializeReadersWithVectorScan()");
+    task_columns = getReadTaskColumns(
+        storage, storage_snapshot, data_part,
+        required_columns, virt_column_names, nullptr, /*with_subcolumns=*/ true);
+
+    /// Will be used to distinguish between PREWHERE and WHERE columns when applying filter
+    const auto & column_names = task_columns.columns.getNames();
+    column_name_set = NameSet{column_names.begin(), column_names.end()};
+
+    if (use_uncompressed_cache)
+        owned_uncompressed_cache = storage.getContext()->getUncompressedCache();
+
+    owned_mark_cache = storage.getContext()->getMarkCache();
+
+/*
+    initializeMergeTreeReadersForPart(data_part, task_columns, storage_snapshot->getMetadataForQuery(),
+        all_mark_ranges, {}, {});
+*/
+
+    LOG_DEBUG(log, "[initializeReadersWithVectorScan] task column: {}", task_columns.columns.toString());
+
+    reader = data_part->getReader(task_columns.columns, storage_snapshot->getMetadataForQuery(),
+        all_mark_ranges, owned_uncompressed_cache.get(), owned_mark_cache.get(), reader_settings,
+        {}, {});
+
+    pre_reader_for_step.clear();
+
+    /// Add lightweight delete filtering step
+    if (reader_settings.apply_deleted_mask && data_part->hasLightweightDelete())
+    {
+        pre_reader_for_step.push_back(data_part->getReader({LightweightDeleteDescription::FILTER_COLUMN}, storage_snapshot->getMetadataForQuery(),
+            all_mark_ranges, owned_uncompressed_cache.get(), owned_mark_cache.get(), reader_settings,
+            {}, {}));
+    }
+}
+
+ColumnPtr MergeTreeSelectWithVectorScanProcessor::performPrefilter(MarkRanges & mark_ranges)
+{
+    OpenTelemetrySpanHolder span("MergeTreeSelectWithVectorScanProcessor::performPrefilter()");
+    Names columns;
+    Names system_columns;
+    system_columns.emplace_back("_part_offset");
+
+    ExpressionActionsSettings actions_settings;
+
+    /// TODO: confirm columns are valid?
+    NameSet pre_name_set;
+
+    /// Add column reading steps:
+    /// 1. Columns for row level filter
+    if (prewhere_info->row_level_filter)
+    {
+        Names row_filter_column_names =  prewhere_info->row_level_filter->getRequiredColumnsNames();
+
+        columns.insert(columns.end(), row_filter_column_names.begin(), row_filter_column_names.end());
+        pre_name_set.insert(row_filter_column_names.begin(), row_filter_column_names.end());
+    }
+
+    /// 2. Columns for prewhere
+    Names all_pre_column_names = prewhere_info->prewhere_actions->getRequiredColumnsNames();
+
+    for (const auto & name : all_pre_column_names)
+    {
+        if (pre_name_set.contains(name))
+            continue;
+        columns.push_back(name);
+        pre_name_set.insert(name);
+    }
+
+    prewhere_info->remove_prewhere_column = true;
+    
+    auto input = std::make_unique<MergeTreeInOrderSelectProcessor>(
+            storage, storage_snapshot, data_part, max_block_size_rows, preferred_block_size_bytes,
+            preferred_max_column_in_block_size_bytes, columns, mark_ranges, use_uncompressed_cache, prewhere_info,
+            actions_settings, reader_settings, system_columns);
+
+    Pipe pipe(std::move(input));
+
+    QueryPipeline filter_pipeline(std::move(pipe));
+    PullingPipelineExecutor filter_executor(filter_pipeline);
+
+    size_t num_rows = data_part->rows_count;
+
+    Block block;
+    auto new_filter = ColumnUInt8::create(num_rows);
+    IColumn::Filter & new_data = new_filter->getData();
+    for (int i = 0; i < num_rows; i++)
+    {
+        new_data[i] = 0;
+    }
+    /// new_data.resize_fill(num_rows, 0);
+    OpenTelemetrySpanHolder span_pipe("MergeTreeSelectWithVectorScanProcessor::performPrefilter():StartPipe");
+    while (filter_executor.pull(block))
+    {
+        /*
+        LOG_DEBUG(log, "[performPrefilter] block column size: {}", block.getNames().size());
+        for (const auto & name : block.getNames())
+        {
+            LOG_DEBUG(log, "[performPrefilter] block column: {}", name);
+        }
+        */
+        // OpenTelemetrySpanHolder span_pipe("MergeTreeSelectWithVectorScanProcessor::performPrefilter():StartPipe::CopyToFilter");
+        const PaddedPODArray<UInt64>& col_data = checkAndGetColumn<ColumnUInt64>(*block.getByName("_part_offset").column)->getData();
+        for (size_t i = 0; i < block.rows(); ++i)
+        {
+            new_data[col_data[i]] = 1;
+        }
+    }
+    return new_filter;
+}
+
+MergeTreeBaseSelectProcessor::BlockAndRowCount MergeTreeSelectWithVectorScanProcessor::readFromPart()
+{
+    OpenTelemetrySpanHolder span("MergeTreeSelectWithVectorScanProcessor::readFromPart()");
+    if (!task->range_reader.isInitialized())
+    {
+        MergeTreeRangeReader* prev_reader = nullptr;
+        bool last_reader = false;
+        size_t pre_readers_shift = 0;
+
+        /// Add _part_offset to non_const_virtual_column_names if has vector_scan_manager and no prewhere_info
+        bool found = false;
+        for (const auto & column_name : non_const_virtual_column_names)
+        {
+            if (column_name == "_part_offset")
+            {
+                found = true;
+                break;
+            }
+        }
+
+        if (!found)
+        {
+            non_const_virtual_column_names.emplace_back("_part_offset");
+            need_remove_part_offset = true;
+        }
+
+        /// Add filtering step with lightweight delete mask
+        if (reader_settings.apply_deleted_mask && task->data_part->hasLightweightDelete())
+        {
+            task->pre_range_readers.push_back(
+                MergeTreeRangeReader(pre_reader_for_step[0].get(), prev_reader, &lightweight_delete_filter_step, last_reader, non_const_virtual_column_names));
+            prev_reader = &task->pre_range_readers.back();
+            pre_readers_shift++;
+        }
+
+        task->range_reader = MergeTreeRangeReader(reader.get(), prev_reader, nullptr, true, non_const_virtual_column_names);
+    }
+    /// initializeRangeReaders(*task);
+
+    /// original read logic, considering prewhere optimization
+    return readFromPartWithVectorScan();
+}
+
+/// perform actual read and result merge operation, prewhere has been processed ahead
+MergeTreeBaseSelectProcessor::BlockAndRowCount MergeTreeSelectWithVectorScanProcessor::readFromPartWithVectorScan()
+{
+    OpenTelemetrySpanHolder span("MergeTreeSelectWithVectorScanProcessor::readFromPartWithVectorScan()");
+    if (task->size_predictor)
+        task->size_predictor->startBlock();
+
+    const UInt64 current_max_block_size_rows = max_block_size_rows;
+
+    auto read_start_time = std::chrono::system_clock::now();
+    UInt64 rows_to_read = std::max(UInt64(1), current_max_block_size_rows);
+
+    LOG_DEBUG(log, "[readFromPartImpl] begin read, mark_ranges size = {}", task->mark_ranges.size());
+    auto read_result = task->range_reader.read(rows_to_read, task->mark_ranges);
+    for (auto it = task->mark_ranges.begin(); it != task->mark_ranges.cend(); ++it)
+    {
+        LOG_DEBUG(log, "[readFromPartImpl] mark_range begin = {}, end = {}", it->begin, it->end);
+    }
+
+    /// All rows were filtered. Repeat.
+    if (read_result.num_rows == 0)
+        read_result.columns.clear();
+
+    const auto & sample_block = task->range_reader.getSampleBlock();
+    if (read_result.num_rows != 0 && sample_block.columns() != read_result.columns.size())
+        throw Exception("Inconsistent number of columns got from MergeTreeRangeReader. "
+                        "Have " + toString(sample_block.columns()) + " in sample block "
+                        "and " + toString(read_result.columns.size()) + " columns in list", ErrorCodes::LOGICAL_ERROR);
+
+    /// TODO: check columns have the same types as in header.
+
+    UInt64 num_filtered_rows = read_result.numReadRows() - read_result.num_rows;
+
+    LOG_DEBUG(log, "[readFromPartImpl] num_rows: {}, read_rows: {}", read_result.num_rows, read_result.numReadRows());
+
+    progress({ read_result.numReadRows(), read_result.numBytesRead() });
+
+    auto read_ranges = read_result.readRanges();
+
+    if (task->size_predictor)
+    {
+        task->size_predictor->updateFilteredRowsRation(read_result.numReadRows(), num_filtered_rows);
+
+        if (!read_result.columns.empty())
+            task->size_predictor->update(sample_block, read_result.columns, read_result.num_rows);
+    }
+
+    if (read_result.num_rows == 0)
+        return {};
+
+    /// Remove distance_func column from read_result.columns, it will be added by vector search.
+    Columns ordered_columns;
+    ordered_columns.reserve(sample_block.columns());
+    size_t which_cut = 0;
+    String vector_scan_col_name;
+    for (size_t ps = 0; ps < sample_block.columns(); ++ps)
+    {
+        auto & col_name = sample_block.getByPosition(ps).name;
+        LOG_DEBUG(log, "[readFromPartImpl]: read column: {}", col_name);
+        /// TODO: not add distance column to header_without_virtual_columns
+        if (isVectorScanFunc(col_name))
+        {
+            which_cut = ps;
+            vector_scan_col_name = col_name;
+            continue;
+        }
+
+        ColumnPtr column_ptr = read_result.columns[ps];
+
+        /// Copy _part_offset column
+        if (col_name == "_part_offset")
+        {
+            part_offset = typeid_cast<const ColumnUInt64 *>(column_ptr.get());
+        }
+        ordered_columns.emplace_back(std::move(read_result.columns[ps]));
+    }
+
+    auto read_end_time = std::chrono::system_clock::now();
+
+    LOG_DEBUG(log, "[readFromPartImpl] read time: {}", std::chrono::duration_cast<std::chrono::milliseconds>(read_end_time - read_start_time).count());
+
+
+    if (part_offset)
+    {
+        LOG_DEBUG(log, "[readFromPartImpl] offset values before vector search merge result, and the part name is {}", task->data_part->name);
+        const ColumnUInt64::Container & offset_raw_value = part_offset->getData();
+        const size_t the_size = part_offset->size();
+        for (size_t i = 0; i < the_size && i < 10; ++i)
+        {
+            UInt64 v = offset_raw_value[i];
+            LOG_DEBUG(log, "[readFromPartImpl] offset values --- offset[{}] = {}", i, v);
+        }
+    }
+    /// [MQDB] vector search
+    if (task->vector_scan_manager && task->vector_scan_manager->preComputed())
+    {
+        /// already perform vector scan   
+        task->vector_scan_manager->mergeResult(
+            ordered_columns,
+            read_result.num_rows,
+            read_ranges, nullptr, part_offset);
+    }
+
+    const size_t final_result_num_rows = read_result.num_rows;
+
+    Block res_block;
+    for (size_t i = 0; i < ordered_columns.size(); ++i)
+    {
+        ColumnWithTypeAndName ctn;
+        ctn.column = ordered_columns[i];
+
+        if (i < ordered_columns.size() -1)
+        {
+            size_t src_index = i >= which_cut ? i+1 : i;
+            ctn.type = sample_block.getByPosition(src_index).type;
+            ctn.name = sample_block.getByPosition(src_index).name;
+        }
+        else
+        {
+            ctn.name = vector_scan_col_name;
+            if (isBatchDistance(vector_scan_col_name))
+            {
+                // the result of batch search, it's type is Tuple(UInt32, Float32)
+                DataTypes data_types;
+                data_types.emplace_back(std::make_shared<DataTypeUInt32>());
+                data_types.emplace_back(std::make_shared<DataTypeFloat32>());
+                ctn.type = std::make_shared<DataTypeTuple>(data_types);
+            }
+            else
+            {
+                // the result of single search, it's type is Float32
+                ctn.type = std::make_shared<DataTypeFloat32>();
+            }
+        }
+
+        res_block.insert(ctn);
+    }
+
+    if (need_remove_part_offset)
+    {
+        res_block.erase("_part_offset");
+    }
+
+    BlockAndRowCount res = { res_block, final_result_num_rows };
+
+    return res;
+}
+
+/// perform vector scan in getNewTaskImpl
+bool MergeTreeSelectWithVectorScanProcessor::getNewTaskImpl()
+try
+{
+    if (all_mark_ranges.empty())
+        return false;
+
+    if (!reader)
+        initializeReadersWithVectorScan();
+
+    MarkRanges mark_ranges_for_task;
+    mark_ranges_for_task = std::move(all_mark_ranges);
+    all_mark_ranges.clear();
+
+    auto size_predictor = (preferred_block_size_bytes == 0) ? nullptr
+        : getSizePredictor(data_part, task_columns, sample_block);
+
+    /// perform vector scan, then filter mark ranges of read task
+    if (!prewhere_info)
+    {
+        vector_scan_manager->executeBeforeRead(data_part->getFullPath(), data_part);
+        filterMarkRangesByVectorScanResult(data_part, vector_scan_manager, mark_ranges_for_task);
+    }
+    else
+    {
+        /// try to process prewhere here, get part_offset columns
+        /// 1 read, then get the filtered part_offsets
+        /// 2 perform vector scan based on part_offsets
+        /// 3 filter mark_ranges based on vector scan results
+        auto filter_col = performPrefilter(mark_ranges_for_task);
+        auto filter = typeid_cast<const ColumnUInt8 *>(filter_col.get());
+        ReadRanges read_ranges;
+        ReadRange read_range{0, data_part->rows_count, 0, data_part->index_granularity.getMarksCount()};
+        read_ranges.emplace_back(read_range);
+        vector_scan_manager->executeVectorScanWithFilter(data_part->getFullPath(), data_part, read_ranges, filter);
+        filterMarkRangesByVectorScanResult(data_part, vector_scan_manager, mark_ranges_for_task);
+        /// prewhere_info = nullptr;
+    }
+
+    for (const auto & range : mark_ranges_for_task)
+    {
+        LOG_DEBUG(log, "[getNewTaskImpl] keep range: {} - {}", range.begin, range.end);
+    }
+    
+    if (mark_ranges_for_task.empty())
+    {
+        return false;
+    }
+
+    task = std::make_unique<MergeTreeReadTask>(
+        data_part, mark_ranges_for_task, part_index_in_query, ordered_names, column_name_set, task_columns,
+        prewhere_info && prewhere_info->remove_prewhere_column,
+        std::move(size_predictor), vector_scan_manager);
+
+    return true;
+}
+catch (...)
+{
+    /// Suspicion of the broken part. A part is added to the queue for verification.
+    if (getCurrentExceptionCode() != ErrorCodes::MEMORY_LIMIT_EXCEEDED)
+        storage.reportBrokenPart(data_part->name);
+    throw;
+}
+
+}
diff --git a/src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.h b/src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.h
new file mode 100644
index 0000000000..9b79530a73
--- /dev/null
+++ b/src/Storages/MergeTree/MergeTreeSelectWithVectorScanProcessor.h
@@ -0,0 +1,39 @@
+#pragma once
+#include <Storages/MergeTree/MergeTreeSelectProcessor.h>
+#include <Storages/SelectQueryInfo.h>
+
+#include <base/logger_useful.h>
+
+namespace DB
+{
+class MergeTreeSelectWithVectorScanProcessor final : public MergeTreeSelectProcessor
+{
+public:
+    template <typename... Args>
+    explicit MergeTreeSelectWithVectorScanProcessor(Args &&... args)
+        : MergeTreeSelectProcessor{std::forward<Args>(args)...}
+    {}
+
+    String getName() const override { return "MergeTreeReadWithVectorScan"; }
+protected:
+    BlockAndRowCount readFromPart() override;
+    void initializeReadersWithVectorScan();
+
+private:
+    bool getNewTaskImpl() override;
+    void finalizeNewTask() override {}
+
+    BlockAndRowCount readFromPartWithVectorScan();
+
+    ColumnPtr performPrefilter(MarkRanges & mark_ranges);
+
+    Poco::Logger * log = &Poco::Logger::get("MergeTreeSelectWithVectorScanProcessor");
+
+    /// True if _part_offset column is added for vector scan, but should not exist in select result.
+    bool need_remove_part_offset = false;
+
+    /// Logic row id for rows, used for vector index scan.
+    const ColumnUInt64 * part_offset = nullptr;
+};
+
+}
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
index 2f61461428..47bf89cb2a 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
@@ -291,8 +291,23 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(
                 ProfileEvents::increment(ProfileEvents::VectorIndexBuildFailEvents);
             }
         } 
-
-        LOG_INFO(log, "[buildVectorIndex] VectorIndexBuildTask finished for part {}, status {}", part->name, status);
+        else
+        {
+            if (part->containRowIdsMaps())
+            {
+                auto lock = data.lockParts();
+                LOG_INFO(log, "[buildVectorIndex] try to remove row ids maps files in {}", part->getFullPath());
+                /// currently only consider one vector index
+                auto vec_index_desc = metadata_snapshot->vec_indices[0];
+                auto old_segments = VectorIndex::getAllSegmentIds(part->getFullPath(), part, vec_index_desc.name, vec_index_desc.column);
+                for (auto& old_segment : old_segments)
+                {
+                    VectorIndex::VectorSegmentExecutor::removeFromCache(old_segment.getCacheKey());
+                }
+                part->removeAllRowIdsMaps();
+            }
+            LOG_INFO(log, "[buildVectorIndex] VectorIndexBuildTask finished for part {}.", part->name);
+        }
     }
 
     watch.stop();
@@ -583,6 +598,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                     empty_ids.emplace_back(current_round_start_row + row);
                 }
             }
+            result.clear();
 
             LOG_DEBUG(
                 log,
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index 99a1d0ce5d..1b926ac117 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -8,6 +8,7 @@
 #include <Columns/ColumnArray.h>
 
 #include <Common/FieldVisitorConvertToNumber.h>
+#include <Interpreters/OpenTelemetrySpanLog.h>
 
 #include <Storages/MergeTree/MergeTreeVectorScanManager.h>
 
@@ -46,8 +47,14 @@ VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(
     auto & query_column = desc.query_column;
     int dim = desc.search_column_dim;
 
-    /// LOG_DEBUG(log, "[vectorScanImpl] column: {}", node.column->dumpStructure());
+    /// LOG_DEBUG(log, "[vectorScanImpl] column: {}", query_column->dumpStructure());
+    LOG_DEBUG(log, "[generateVectorDataset] before create holder");
+
+    if (!query_column)
+        throw Exception("Wrong query column type", ErrorCodes::LOGICAL_ERROR); 
+
     ColumnPtr holder = query_column->convertToFullColumnIfConst();
+    LOG_DEBUG(log, "[generateVectorDataset] after create holder");
     const ColumnArray * query_col = checkAndGetColumn<ColumnArray>(holder.get());
 
     if (is_batch)
@@ -74,9 +81,6 @@ VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(
         auto & offsets = query_vectors_col->getOffsets();
 
         int query_vector_num = offsets.size();
-
-        LOG_DEBUG(log, "[batchVectorScan] query_num: {}", query_vector_num);
-
         for (size_t row = 0; row < offsets.size(); ++row)
         {
             size_t vec_start_offset = row != 0 ? offsets[row - 1] : 0;
@@ -114,6 +118,7 @@ VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(
             throw Exception("Wrong query column type, expect Array(float64)", ErrorCodes::LOGICAL_ERROR);
 
         const IColumn & query_data = query_col->getData();
+
         // const ColumnArray::Offsets & offsets = src_col->getOffsets();
         const ColumnFloat64 * query_data_concrete = checkAndGetColumn<ColumnFloat64>(&query_data);
 
@@ -185,10 +190,19 @@ void MergeTreeVectorScanManager::executeAfterRead(
     }
 }
 
+void MergeTreeVectorScanManager::executeVectorScanWithFilter(
+    const String& data_path,
+    const MergeTreeData::DataPartPtr & data_part,
+    const ReadRanges & read_ranges,
+    const ColumnUInt8 * filter)
+{
+    this->vector_scan_result = vectorScan(vector_scan_info->is_batch, data_path, data_part, read_ranges, filter);
+}
 
 VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
     bool is_batch, const String & data_path, const MergeTreeData::DataPartPtr & data_part, const ReadRanges & read_ranges, const ColumnUInt8 * filter)
 {
+    OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()");
     VectorIndexDescription index;
     bool find_index = false;
     const VectorIndicesDescription & vector_indices = metadata->vec_indices;
@@ -282,6 +296,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         std::vector<uint64_t> selected_row_ids;
         if (filter)
         {
+            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::proc_filter");
             auto & filter_data = filter->getData();
             int range_index = 0;
             size_t start_pos = read_ranges[range_index].start_row;
@@ -299,7 +314,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
                 if (filter_data[i])
                 {
                     ++filter_data_size;
-                    /// LOG_DEBUG(log, "set filter: i: {}, start_pos: {}, offset: {}", i, start_pos, offset);
+                    // LOG_DEBUG(log, "set filter: i: {}, start_pos: {}, offset: {}", i, start_pos, offset);
                     selected_row_ids.emplace_back(start_pos + offset);
                 }
                 ++offset;
@@ -310,6 +325,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         }
         else if (!read_ranges.empty()) /// having prewhere, but this read round does not generate a filter
         {
+            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::generate_row_ids");
             size_t start_pos = read_ranges[0].start_row;
             size_t read_row_num = read_ranges[0].row_num;
             for (size_t i = start_pos; i < start_pos + read_row_num; ++i)
@@ -395,13 +411,22 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             /// have no filter
             if (selected_row_ids.empty() && read_ranges.empty())
             {
+                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_set_empty_bitmap");
                 bits = std::make_shared<VectorIndex::GeneralBitMap>(base_vector_size);
                 memset(bits->bitmap, 255, (base_vector_size / 8) + 1);
             }
             else 
             {
+                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_get_real_bitmap");
                 /// handle filter case
                 bits = vec_executor->getRealBitMap(selected_row_ids);
+                span.addAttribute("selected_row_ids.size", selected_row_ids.size());
+            }
+
+            if (!bits->any())
+            {
+                /// don't perform vector search if the segment is completely filtered out
+                continue;
             }
 
             LOG_DEBUG(log, "[vectorScan] start search: vector num: {}", vec_data->getVectorNum());
@@ -431,6 +456,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
 
             if (is_batch)
             {
+                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_batch_generate_results");
                 for (size_t label = 0; label < k * vec_data->getVectorNum(); ++label)
                 {
                     UInt32 vector_id = label / k;
@@ -445,11 +471,11 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             }
             else
             {
+                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_generate_results");
                 for (size_t label = 0; label < k; ++label)
                 {
                     if (per_id[label] > -1)
                     {
-                        LOG_DEBUG(log, "[vectorScan] label: {}, distance: {}", per_id[label], per_distance[label]);
                         label_column->insert(per_id[label]);
                         distance_column->insert(per_distance[label]);
                     }
@@ -459,12 +485,14 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
 
         if (is_batch)
         {
+            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::data_part_batch_generate_results");
             tmp_vector_scan_result->query_vector_num = vec_data->getVectorNum();
             tmp_vector_scan_result->result_columns[1] = std::move(vector_id_column);
             tmp_vector_scan_result->result_columns[2] = std::move(distance_column);
         }
         else
         {
+            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::data_part_generate_results");
             tmp_vector_scan_result->query_vector_num = 1;
             tmp_vector_scan_result->result_columns[1] = std::move(distance_column);
         }
@@ -505,6 +533,7 @@ void MergeTreeVectorScanManager::mergeBatchVectorScanResult(
     const ColumnUInt8 * filter,
     const ColumnUInt64 * part_offset)
 {
+    OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::mergeBatchVectorScanResult()");
     const ColumnUInt32 * label_column = checkAndGetColumn<ColumnUInt32>(vector_scan_result->result_columns[0].get());
     const ColumnUInt32 * vector_id_column = checkAndGetColumn<ColumnUInt32>(vector_scan_result->result_columns[1].get());
     const ColumnFloat32 * distance_column = checkAndGetColumn<ColumnFloat32>(vector_scan_result->result_columns[2].get());
@@ -667,6 +696,7 @@ void MergeTreeVectorScanManager::mergeVectorScanResult(
     const ColumnUInt8 * filter,
     const ColumnUInt64 * part_offset)
 {
+    OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::mergeVectorScanResult()");
     const ColumnUInt32 * label_column = checkAndGetColumn<ColumnUInt32>(vector_scan_result->result_columns[0].get());
     const ColumnFloat32 * distance_column = checkAndGetColumn<ColumnFloat32>(vector_scan_result->result_columns[1].get());
 
@@ -758,6 +788,7 @@ void MergeTreeVectorScanManager::mergeVectorScanResult(
                             Field field;
                             pre_result[i]->get(index_of_arr, field);
                             final_result[i]->insert(field);
+                            LOG_DEBUG(log, "[mergeVectorScanResult] label: {}, distance: {}, field: {}", label_value, distance_column->getFloat32(ind), field);
                         }
 
                         final_distance_column->insert(distance_column->getFloat32(ind));
@@ -768,6 +799,7 @@ void MergeTreeVectorScanManager::mergeVectorScanResult(
         }
         else
         {
+            LOG_DEBUG(log, "[mergeVectorScanResult] get part offset");
             for (auto & read_range : read_ranges)
             {
                 const size_t start_pos = read_range.start_row;
@@ -792,6 +824,7 @@ void MergeTreeVectorScanManager::mergeVectorScanResult(
                                     Field field;
                                     pre_result[i]->get(j, field);
                                     final_result[i]->insert(field);
+                                    LOG_DEBUG(log, "[mergeVectorScanResult] label: {}, distance: {}, field: {}", label_value, distance_column->getFloat32(ind), field);
                                 }
 
                                 final_distance_column->insert(distance_column->getFloat32(ind));
@@ -831,8 +864,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     bool is_batch,
     const VectorIndex::Metrics& metrics)
 {
-    DB::OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScanWithoutIndex");
-
+    OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScanWithoutIndex()");
     NamesAndTypesList cols;
     /// get search vector column info
     auto col_and_type = this->metadata->getColumns().getAllPhysical().tryGetByName(search_column);
@@ -1159,7 +1191,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
         {
             if (final_id[label] > -1 && row_exists->test(final_id[label]))
             {
-                /// LOG_DEBUG(log, "[vectorScan] label: {}, distance: {}", final_id[label], final_distance[label]);
+                LOG_DEBUG(log, "[vectorScan] label: {}, distance: {}", final_id[label], final_distance[label]);
                 label_column->insert(final_id[label]);
                 distance_column->insert(final_distance[label]);
             }
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.h b/src/Storages/MergeTree/MergeTreeVectorScanManager.h
index 7da0787c4a..d69e54740b 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.h
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.h
@@ -16,6 +16,7 @@
 namespace DB
 {
 
+using ReadRange = MergeTreeRangeReader::ReadResult::ReadRangeInfo;
 using ReadRanges = MergeTreeRangeReader::ReadResult::ReadRangesInfo;
 /// vector scan manager, responsible for vector scan result precompute, and vector scan after read
 class MergeTreeVectorScanManager
@@ -23,7 +24,8 @@ class MergeTreeVectorScanManager
 public:
     MergeTreeVectorScanManager(
         StorageMetadataPtr metadata_,
-        VectorScanInfoPtr vector_scan_info_) : metadata(metadata_), vector_scan_info(vector_scan_info_) {}
+        VectorScanInfoPtr vector_scan_info_,
+        ContextPtr context_) : metadata(metadata_), vector_scan_info(vector_scan_info_), context(context_) {}
 
     void executeBeforeRead(const String& data_path, const MergeTreeData::DataPartPtr & data_part);
 
@@ -36,23 +38,32 @@ public:
         bool has_prewhere = false,
         const ColumnUInt8 * filter = nullptr);
 
+    void executeVectorScanWithFilter(
+        const String& data_path,
+        const MergeTreeData::DataPartPtr & data_part,
+        const ReadRanges & read_ranges,
+        const ColumnUInt8 * filter = nullptr);
+
     void mergeResult(
         Columns & pre_result,
         size_t & read_rows,
         const ReadRanges & read_ranges,
-        const ColumnUInt8 * filter,
-        const ColumnUInt64 * part_offset);
-
+        const ColumnUInt8 * filter = nullptr,
+        const ColumnUInt64 * part_offset = nullptr);
+    
     bool preComputed() { return vector_scan_result != nullptr; }
 
     VectorScanResultPtr getVectorScanResult() { return vector_scan_result; }
 
     void eraseResult();
 
+    Settings getSettings() { return context->getSettingsRef(); }
+
 private:
 
     StorageMetadataPtr metadata;
     VectorScanInfoPtr vector_scan_info;
+    ContextPtr context;
 
     /// lock vector scan result
     std::mutex mutex;
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp b/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp
index 6947092236..eb3081c420 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp
@@ -1,4 +1,5 @@
 #include <pdqsort.h>
+#include <Interpreters/OpenTelemetrySpanLog.h>
 #include <Storages/MergeTree/MergeTreeDataSelectExecutor.h>
 #include <Storages/MergeTree/MergeTreeVectorScanUtils.h>
 
@@ -110,31 +111,31 @@ void mergeDataPartsResult(RangesInDataParts & parts_with_ranges, int top_k, cons
 */
 }
 
-void filterMarkRangesByVectorScanResult(
-    RangesInDataParts & parts_with_ranges, const VectorScanDescriptions & vector_scan_descs, const Settings & settings)
+void filterMarkRangesByVectorScanResult(MergeTreeData::DataPartPtr part, MergeTreeVectorScanManagerPtr vector_scan_mgr, MarkRanges & mark_ranges)
 {
-    int top_k = parts_with_ranges.back().vector_scan_manager->getVectorScanResult()->top_k;
-    bool is_batch = parts_with_ranges.back().vector_scan_manager->getVectorScanResult()->is_batch;
-
-    if (is_batch)
-    {
-        mergeDataPartsBatchResult(parts_with_ranges, top_k, vector_scan_descs);
-    }
-    else
-    {
-        mergeDataPartsResult(parts_with_ranges, top_k, vector_scan_descs);
-    }
-
-    auto need_this_range = [&](RangesInDataPart & part_with_ranges, MarkRange & range)
+    OpenTelemetrySpanHolder span("filterMarkRangesByVectorScanResult()");
+    MarkRanges res;
+    // bool has_final_mark = part->index_granularity.hasFinalMark();
+    size_t marks_count = part->index_granularity.getMarksCount();
+    /// const auto & index = part->index;
+    /// marks_count should not be 0 if we reach here
+
+    auto settings = vector_scan_mgr->getSettings();
+
+    size_t min_marks_for_seek = MergeTreeDataSelectExecutor::roundRowsOrBytesToMarks(
+        settings.merge_tree_min_rows_for_seek,
+        settings.merge_tree_min_bytes_for_seek,
+        part->index_granularity_info.fixed_index_granularity,
+        part->index_granularity_info.index_granularity_bytes);
+
+    auto need_this_range = [&](MergeTreeData::DataPartPtr part, MergeTreeVectorScanManagerPtr vector_scan_mgr, MarkRanges & mark_ranges, MarkRange & range)
     {
-        auto part = part_with_ranges.data_part;
-        auto vector_scan_mgr = part_with_ranges.vector_scan_manager;
         auto begin = range.begin;
         auto end = range.end;
         auto start_row = part->index_granularity.getMarkStartingRow(begin);
         auto end_row = start_row + part->index_granularity.getRowsCountInRange(range);
 
-        auto result = part_with_ranges.vector_scan_manager->getVectorScanResult();
+        auto result = vector_scan_mgr->getVectorScanResult();
 
         const ColumnUInt32 * label_column
             = checkAndGetColumn<ColumnUInt32>(vector_scan_mgr->getVectorScanResult()->result_columns[0].get());
@@ -155,59 +156,63 @@ void filterMarkRangesByVectorScanResult(
         return false;
     };
 
-    /// ref: MergeTreeDataSelectExecutor::markRangesFromPKRange
+    std::vector<MarkRange> ranges_stack = {{0, marks_count}};
 
-    for (size_t i = 0; i < parts_with_ranges.size(); ++i)
-    {
-        auto & part_with_ranges = parts_with_ranges[i];
-        MarkRanges res;
-        auto part = part_with_ranges.data_part;
-        // bool has_final_mark = part->index_granularity.hasFinalMark();
-        size_t marks_count = part->index_granularity.getMarksCount();
-        /// const auto & index = part->index;
-        /// marks_count should not be 0 if we reach here
+    size_t steps = 0;
 
-        size_t min_marks_for_seek = MergeTreeDataSelectExecutor::roundRowsOrBytesToMarks(
-            settings.merge_tree_min_rows_for_seek,
-            settings.merge_tree_min_bytes_for_seek,
-            part->index_granularity_info.fixed_index_granularity,
-            part->index_granularity_info.index_granularity_bytes);
+    while (!ranges_stack.empty())
+    {
+        MarkRange range = ranges_stack.back();
+        ranges_stack.pop_back();
 
-        std::vector<MarkRange> ranges_stack = {{0, marks_count}};
+        steps++;
 
-        size_t steps = 0;
+        if (!need_this_range(part, vector_scan_mgr, mark_ranges, range))
+            continue;
 
-        while (!ranges_stack.empty())
+        if (range.end == range.begin + 1)
         {
-            MarkRange range = ranges_stack.back();
-            ranges_stack.pop_back();
+            if (res.empty() || range.begin - res.back().end > min_marks_for_seek)
+                res.push_back(range);
+            else
+                res.back().end = range.end;
+        }
+        else
+        {
+            /// Break the segment and put the result on the stack from right to left.
+            size_t step = (range.end - range.begin - 1) / settings.merge_tree_coarse_index_granularity + 1;
+            size_t end;
 
-            steps++;
+            for (end = range.end; end > range.begin + step; end -= step)
+                ranges_stack.emplace_back(end - step, end);
 
-            if (!need_this_range(part_with_ranges, range))
-                continue;
+            ranges_stack.emplace_back(range.begin, end);
+        }
+    }
 
-            if (range.end == range.begin + 1)
-            {
-                if (res.empty() || range.begin - res.back().end > min_marks_for_seek)
-                    res.push_back(range);
-                else
-                    res.back().end = range.end;
-            }
-            else
-            {
-                /// Break the segment and put the result on the stack from right to left.
-                size_t step = (range.end - range.begin - 1) / settings.merge_tree_coarse_index_granularity + 1;
-                size_t end;
+    mark_ranges = res;
+}
 
-                for (end = range.end; end > range.begin + step; end -= step)
-                    ranges_stack.emplace_back(end - step, end);
+void filterPartsMarkRangesByVectorScanResult(
+    RangesInDataParts & parts_with_ranges, const VectorScanDescriptions & vector_scan_descs)
+{
+    int top_k = parts_with_ranges.back().vector_scan_manager->getVectorScanResult()->top_k;
+    bool is_batch = parts_with_ranges.back().vector_scan_manager->getVectorScanResult()->is_batch;
 
-                ranges_stack.emplace_back(range.begin, end);
-            }
-        }
+    if (is_batch)
+    {
+        mergeDataPartsBatchResult(parts_with_ranges, top_k, vector_scan_descs);
+    }
+    else
+    {
+        mergeDataPartsResult(parts_with_ranges, top_k, vector_scan_descs);
+    }
+
+    /// ref: MergeTreeDataSelectExecutor::markRangesFromPKRange
 
-        part_with_ranges.ranges = res;
+    for (size_t i = 0; i < parts_with_ranges.size(); ++i)
+    {
+        filterMarkRangesByVectorScanResult(parts_with_ranges[i].data_part, parts_with_ranges[i].vector_scan_manager, parts_with_ranges[i].ranges);
     }
 
     /// erase empty part
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanUtils.h b/src/Storages/MergeTree/MergeTreeVectorScanUtils.h
index 1bfbf35de2..f9c8c8f49f 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanUtils.h
+++ b/src/Storages/MergeTree/MergeTreeVectorScanUtils.h
@@ -1,11 +1,15 @@
 #pragma once
 #include <Storages/MergeTree/RangesInDataPart.h>
+#include <Storages/MergeTree/MergeTreeData.h>
+#include <Storages/MergeTree/MergeTreeVectorScanManager.h>
 
 namespace DB
 {
 
 /// if we has precompute vector scan result, use it to filter mark ranges
-void filterMarkRangesByVectorScanResult(RangesInDataParts & parts_with_ranges, const VectorScanDescriptions& vector_scan_descs, const Settings & settings);
+void filterMarkRangesByVectorScanResult(MergeTreeData::DataPartPtr part, MergeTreeVectorScanManagerPtr vector_scan_mgr, MarkRanges & mark_ranges);
+
+void filterPartsMarkRangesByVectorScanResult(RangesInDataParts & parts_with_ranges, const VectorScanDescriptions& vector_scan_descs);
 
 void mergeDataPartsResult(RangesInDataParts & parts_with_ranges, int top_k, const VectorScanDescriptions& vector_scan_descs);
 
diff --git a/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp b/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp
index ac1e5f9d6a..e2062eefeb 100644
--- a/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp
+++ b/src/Storages/MergeTree/MergeTreeWhereOptimizer.cpp
@@ -209,14 +209,25 @@ void MergeTreeWhereOptimizer::analyzeImpl(Conditions & res, const ASTPtr & node,
             return false;
         };
 
+        bool require_distance_func = false;
+        for (const auto & col : queried_columns)
+        {
+            LOG_DEBUG(log, "[MergeTreeWhereOptimizer] queried column: {}", col);
+            if (isVectorScanFunc(col))
+            {
+                require_distance_func = true;
+                break;
+            }
+        }
+
         LOG_DEBUG(log, "[MergeTreeWhereOptimizer] containVectorScanFunc(cond.node): {}", containVectorScanFunc());
 
         cond.viable =
             /// Condition depend on some column. Constant expressions are not moved.
             !cond.identifiers.empty()
             && !cannotBeMoved(node, is_final)
-            /// Do not take into consideration the conditions consisting only of the first primary key column
-            && !hasPrimaryKeyAtoms(node)
+            /// Do not take into consideration the conditions consisting only of the first primary key column, except having distance func
+            && !(hasPrimaryKeyAtoms(node) && !require_distance_func)
             /// Only table columns are considered. Not array joined columns. NOTE We're assuming that aliases was expanded.
             && isSubsetOfTableColumns(cond.identifiers)
             /// Do not move conditions involving all queried columns.
diff --git a/src/VectorIndex/GeneralBitMap.h b/src/VectorIndex/GeneralBitMap.h
index 38f64ee5da..9a737f138e 100644
--- a/src/VectorIndex/GeneralBitMap.h
+++ b/src/VectorIndex/GeneralBitMap.h
@@ -17,7 +17,7 @@ public:
     explicit GeneralBitMap(int64_t size_)
     {
         size = size_;
-        int bytes_count = (size >> 3) + 1; // size/8 = bytes
+        int bytes_count = (size >> 3) + 1; /// size/8 = bytes
         bitmap = new char[bytes_count];
         memset(bitmap, 0, bytes_count);
     }
@@ -34,6 +34,17 @@ public:
 
     void unset(int64_t id) { bitmap[id >> 3] &= ~(0x1 << (id & 0x7)); }
 
+    bool any()
+    {
+        int bytes_count = (size >> 3) + 1; /// size/8 = bytes
+        for(int i = 0; i < bytes_count; ++i)
+        {
+            if (bitmap[i])
+                return true;
+        }
+        return false;
+    }
+
     /// Set bit corresponding to a region, this is much faster than set(),
     /// but can introduce up to 14 items been wrongly set at the margins.
     void set_range(int64_t start_id, int64_t end_id)
diff --git a/src/VectorIndex/VectorSegmentExecutor.cpp b/src/VectorIndex/VectorSegmentExecutor.cpp
index fe932686db..cad2cea7c9 100644
--- a/src/VectorIndex/VectorSegmentExecutor.cpp
+++ b/src/VectorIndex/VectorSegmentExecutor.cpp
@@ -649,7 +649,7 @@ Status VectorSegmentExecutor::addVectors(VectorDatasetPtr dataset)
 Status VectorSegmentExecutor::search(
     VectorDatasetPtr dataset, int32_t k, float *& distances, int64_t *& labels, GeneralBitMapPtr filter, Parameters parameters)
 {
-    DB::OpenTelemetrySpanHolder span("VectorSegmentExecutor::search");
+    DB::OpenTelemetrySpanHolder span("VectorSegmentExecutor::search()");
     bool added = false;
     try
     {
diff --git a/src/VectorIndex/VectorSegmentExecutor.h b/src/VectorIndex/VectorSegmentExecutor.h
index a95efae224..3173cedc3f 100644
--- a/src/VectorIndex/VectorSegmentExecutor.h
+++ b/src/VectorIndex/VectorSegmentExecutor.h
@@ -173,6 +173,7 @@ public:
         {
             for (auto & row_id : selected_row_ids)
             {
+                /// LOG_DEBUG(log, "[getRealBitMap] set row id: {}", row_id);
                 bits->set(row_id);
             }
         }
diff --git a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference
index 5cce2aa907..5af98280f2 100644
--- a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference
+++ b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference
@@ -1,20 +1,20 @@
-61	[61,61,61]	1323
-62	[62,62,62]	1452
-63	[63,63,63]	1587
-64	[64,64,64]	1728
-65	[65,65,65]	1875
-66	[66,66,66]	2028
-67	[67,67,67]	2187
-68	[68,68,68]	2352
-69	[69,69,69]	2523
-70	[70,70,70]	2700
-9	[9,9,9]	2883
-71	[71,71,71]	2883
-8	[8,8,8]	3072
-72	[72,72,72]	3072
-7	[7,7,7]	3267
-73	[73,73,73]	3267
-6	[6,6,6]	3468
-74	[74,74,74]	3468
-5	[5,5,5]	3675
-75	[75,75,75]	3675
+1	[1,1,1]	0
+2	[2,2,2]	3
+0	[0,0,0]	3
+3	[3,3,3]	12
+4	[4,4,4]	27
+5	[5,5,5]	48
+6	[6,6,6]	75
+7	[7,7,7]	108
+8	[8,8,8]	147
+9	[9,9,9]	192
+61	[61,61,61]	10800
+62	[62,62,62]	11163
+63	[63,63,63]	11532
+64	[64,64,64]	11907
+65	[65,65,65]	12288
+66	[66,66,66]	12675
+67	[67,67,67]	13068
+68	[68,68,68]	13467
+69	[69,69,69]	13872
+70	[70,70,70]	14283
diff --git a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
index d3964885e4..cccf5b1882 100755
--- a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
+++ b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=20')(vector, [40.0, 40.0, 40.0]) as d FROM test_vector prewhere id < 10 or id > 60 ORDER BY d;"
+clickhouse-client -q "SELECT id, vector, distance('topK=20')(vector, [1.0, 1.0, 1.0]) as d FROM test_vector prewhere id < 10 or id > 60 ORDER BY d;"
diff --git a/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.reference b/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.reference
index 16222dfda3..325e782128 100644
--- a/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.reference
+++ b/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.reference
@@ -1,100 +1,100 @@
-10020	[10020,10020,10020]	0
-10019	[10019,10019,10019]	3
-10021	[10021,10021,10021]	3
-10018	[10018,10018,10018]	12
-10022	[10022,10022,10022]	12
-10017	[10017,10017,10017]	27
-10023	[10023,10023,10023]	27
-10016	[10016,10016,10016]	48
-10024	[10024,10024,10024]	48
-10025	[10025,10025,10025]	75
-10015	[10015,10015,10015]	75
-10026	[10026,10026,10026]	108
-10014	[10014,10014,10014]	108
-10027	[10027,10027,10027]	147
-10013	[10013,10013,10013]	147
-10028	[10028,10028,10028]	192
-10012	[10012,10012,10012]	192
-10029	[10029,10029,10029]	243
-10011	[10011,10011,10011]	243
-10010	[10010,10010,10010]	300
-10009	[10009,10009,10009]	363
-10008	[10008,10008,10008]	432
-10007	[10007,10007,10007]	507
-10006	[10006,10006,10006]	588
-10005	[10005,10005,10005]	675
-10004	[10004,10004,10004]	768
-10003	[10003,10003,10003]	867
-10002	[10002,10002,10002]	972
-10001	[10001,10001,10001]	1083
-10000	[10000,10000,10000]	1200
-9999	[9999,9999,9999]	1323
-9998	[9998,9998,9998]	1452
-9997	[9997,9997,9997]	1587
-9996	[9996,9996,9996]	1728
-9995	[9995,9995,9995]	1875
-9994	[9994,9994,9994]	2028
-9993	[9993,9993,9993]	2187
-9992	[9992,9992,9992]	2352
-9991	[9991,9991,9991]	2523
-9990	[9990,9990,9990]	2700
-9989	[9989,9989,9989]	2883
-9988	[9988,9988,9988]	3072
-9987	[9987,9987,9987]	3267
-9986	[9986,9986,9986]	3468
-9985	[9985,9985,9985]	3675
-9984	[9984,9984,9984]	3888
-9983	[9983,9983,9983]	4107
-9982	[9982,9982,9982]	4332
-9981	[9981,9981,9981]	4563
-9980	[9980,9980,9980]	4800
-9979	[9979,9979,9979]	5043
-9978	[9978,9978,9978]	5292
-9977	[9977,9977,9977]	5547
-9976	[9976,9976,9976]	5808
-9975	[9975,9975,9975]	6075
-9974	[9974,9974,9974]	6348
-9973	[9973,9973,9973]	6627
-9972	[9972,9972,9972]	6912
-9971	[9971,9971,9971]	7203
-9970	[9970,9970,9970]	7500
-9969	[9969,9969,9969]	7803
-9968	[9968,9968,9968]	8112
-9967	[9967,9967,9967]	8427
-9966	[9966,9966,9966]	8748
-9965	[9965,9965,9965]	9075
-9964	[9964,9964,9964]	9408
-9963	[9963,9963,9963]	9747
-9962	[9962,9962,9962]	10092
-9961	[9961,9961,9961]	10443
-9960	[9960,9960,9960]	10800
-9959	[9959,9959,9959]	11163
-9958	[9958,9958,9958]	11532
-9957	[9957,9957,9957]	11907
-9956	[9956,9956,9956]	12288
-9955	[9955,9955,9955]	12675
-9954	[9954,9954,9954]	13068
-9953	[9953,9953,9953]	13467
-9952	[9952,9952,9952]	13872
-9951	[9951,9951,9951]	14283
-9950	[9950,9950,9950]	14700
-9949	[9949,9949,9949]	15123
-9948	[9948,9948,9948]	15552
-9947	[9947,9947,9947]	15987
-9946	[9946,9946,9946]	16428
-9945	[9945,9945,9945]	16875
-9944	[9944,9944,9944]	17328
-9943	[9943,9943,9943]	17787
-9942	[9942,9942,9942]	18252
-9941	[9941,9941,9941]	18723
-9940	[9940,9940,9940]	19200
-9939	[9939,9939,9939]	19683
-9938	[9938,9938,9938]	20172
-9937	[9937,9937,9937]	20667
-9936	[9936,9936,9936]	21168
-9935	[9935,9935,9935]	21675
-9934	[9934,9934,9934]	22188
-9933	[9933,9933,9933]	22707
-9932	[9932,9932,9932]	23232
-9931	[9931,9931,9931]	23763
-9930	[9930,9930,9930]	24300
+10020	[10020,10020,10020]	0.029766083
+10021	[10021,10021,10021]	2.4321098
+10019	[10019,10019,10019]	3.6274223
+10022	[10022,10022,10022]	10.834454
+10018	[10018,10018,10018]	13.225079
+10023	[10023,10023,10023]	25.236797
+10017	[10017,10017,10017]	28.822735
+10024	[10024,10024,10024]	45.63914
+10016	[10016,10016,10016]	50.42039
+10025	[10025,10025,10025]	72.04149
+10015	[10015,10015,10015]	78.01805
+10026	[10026,10026,10026]	104.44383
+10014	[10014,10014,10014]	111.61571
+10027	[10027,10027,10027]	142.84618
+10013	[10013,10013,10013]	151.21336
+10028	[10028,10028,10028]	187.24852
+10012	[10012,10012,10012]	196.811
+10029	[10029,10029,10029]	237.65085
+10011	[10011,10011,10011]	248.40866
+10010	[10010,10010,10010]	306.00632
+10009	[10009,10009,10009]	369.60397
+10008	[10008,10008,10008]	439.20163
+10007	[10007,10007,10007]	514.7993
+10006	[10006,10006,10006]	596.397
+10005	[10005,10005,10005]	683.9946
+10004	[10004,10004,10004]	777.5923
+10003	[10003,10003,10003]	877.18994
+10002	[10002,10002,10002]	982.7876
+10001	[10001,10001,10001]	1094.3853
+10000	[10000,10000,10000]	1211.9829
+9999	[9999,9999,9999]	1335.5806
+9998	[9998,9998,9998]	1465.1782
+9997	[9997,9997,9997]	1600.7759
+9996	[9996,9996,9996]	1742.3735
+9995	[9995,9995,9995]	1889.9712
+9994	[9994,9994,9994]	2043.5688
+9993	[9993,9993,9993]	2203.1665
+9992	[9992,9992,9992]	2368.7642
+9991	[9991,9991,9991]	2540.3618
+9990	[9990,9990,9990]	2717.9595
+9989	[9989,9989,9989]	2901.5571
+9988	[9988,9988,9988]	3091.1548
+9987	[9987,9987,9987]	3286.7524
+9986	[9986,9986,9986]	3488.35
+9985	[9985,9985,9985]	3695.9478
+9984	[9984,9984,9984]	3909.5454
+9983	[9983,9983,9983]	4129.143
+9982	[9982,9982,9982]	4354.7407
+9981	[9981,9981,9981]	4586.3384
+9980	[9980,9980,9980]	4823.936
+9979	[9979,9979,9979]	5067.5337
+9978	[9978,9978,9978]	5317.1313
+9977	[9977,9977,9977]	5572.729
+9976	[9976,9976,9976]	5834.3267
+9975	[9975,9975,9975]	6101.9243
+9974	[9974,9974,9974]	6375.5225
+9973	[9973,9973,9973]	6655.12
+9972	[9972,9972,9972]	6940.718
+9971	[9971,9971,9971]	7232.3154
+9970	[9970,9970,9970]	7529.913
+9969	[9969,9969,9969]	7833.5107
+9968	[9968,9968,9968]	8143.1084
+9967	[9967,9967,9967]	8458.706
+9966	[9966,9966,9966]	8780.304
+9965	[9965,9965,9965]	9107.901
+9964	[9964,9964,9964]	9441.499
+9963	[9963,9963,9963]	9781.097
+9962	[9962,9962,9962]	10126.694
+9961	[9961,9961,9961]	10478.292
+9960	[9960,9960,9960]	10835.89
+9959	[9959,9959,9959]	11199.487
+9958	[9958,9958,9958]	11569.085
+9957	[9957,9957,9957]	11944.683
+9956	[9956,9956,9956]	12326.279
+9955	[9955,9955,9955]	12713.877
+9954	[9954,9954,9954]	13107.475
+9953	[9953,9953,9953]	13507.072
+9952	[9952,9952,9952]	13912.67
+9951	[9951,9951,9951]	14324.268
+9950	[9950,9950,9950]	14741.865
+9949	[9949,9949,9949]	15165.463
+9948	[9948,9948,9948]	15595.061
+9947	[9947,9947,9947]	16030.658
+9946	[9946,9946,9946]	16472.256
+9945	[9945,9945,9945]	16919.854
+9944	[9944,9944,9944]	17373.451
+9943	[9943,9943,9943]	17833.049
+9942	[9942,9942,9942]	18298.646
+9941	[9941,9941,9941]	18770.244
+9940	[9940,9940,9940]	19247.842
+9939	[9939,9939,9939]	19731.44
+9938	[9938,9938,9938]	20221.037
+9937	[9937,9937,9937]	20716.635
+9936	[9936,9936,9936]	21218.232
+9935	[9935,9935,9935]	21725.83
+9934	[9934,9934,9934]	22239.428
+9933	[9933,9933,9933]	22759.025
+9932	[9932,9932,9932]	23284.623
+9931	[9931,9931,9931]	23816.22
+9930	[9930,9930,9930]	24353.818
diff --git a/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh b/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh
index 05d2eea067..98981b17ec 100755
--- a/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh
+++ b/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.0, 10020.0, 10020.0]) as d FROM test_vector prewhere id>5000 or id =9 or id=31 or id=999 or id=1"
+clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector prewhere id>5000 or id =9 or id=31 or id=999 or id=1"
diff --git a/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.reference b/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.reference
index ca8a9e3743..a44da39de4 100644
--- a/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.reference
+++ b/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.reference
@@ -1,100 +1,100 @@
-10020	[10020,10020,10020]	0
-10019	[10019,10019,10019]	3
-10021	[10021,10021,10021]	3
-10018	[10018,10018,10018]	12
-10022	[10022,10022,10022]	12
-10017	[10017,10017,10017]	27
-10023	[10023,10023,10023]	27
-10016	[10016,10016,10016]	48
-10024	[10024,10024,10024]	48
-10025	[10025,10025,10025]	75
-10015	[10015,10015,10015]	75
-10026	[10026,10026,10026]	108
-10014	[10014,10014,10014]	108
-10027	[10027,10027,10027]	147
-10013	[10013,10013,10013]	147
-10028	[10028,10028,10028]	192
-10012	[10012,10012,10012]	192
-10029	[10029,10029,10029]	243
-10011	[10011,10011,10011]	243
-10010	[10010,10010,10010]	300
-10009	[10009,10009,10009]	363
-10008	[10008,10008,10008]	432
-10007	[10007,10007,10007]	507
-10006	[10006,10006,10006]	588
-10005	[10005,10005,10005]	675
-10004	[10004,10004,10004]	768
-10003	[10003,10003,10003]	867
-10002	[10002,10002,10002]	972
-10001	[10001,10001,10001]	1083
-99	[99,99,99]	295278720
-98	[98,98,98]	295338240
-97	[97,97,97]	295397800
-96	[96,96,96]	295457340
-95	[95,95,95]	295516860
-94	[94,94,94]	295576420
-93	[93,93,93]	295635970
-92	[92,92,92]	295695550
-91	[91,91,91]	295755140
-90	[90,90,90]	295814700
-89	[89,89,89]	295874270
-88	[88,88,88]	295933900
-87	[87,87,87]	295993470
-86	[86,86,86]	296053060
-85	[85,85,85]	296112670
-84	[84,84,84]	296172300
-83	[83,83,83]	296231900
-82	[82,82,82]	296291520
-81	[81,81,81]	296351170
-80	[80,80,80]	296410800
-79	[79,79,79]	296470430
-78	[78,78,78]	296530080
-77	[77,77,77]	296589760
-76	[76,76,76]	296649400
-75	[75,75,75]	296709060
-74	[74,74,74]	296768740
-73	[73,73,73]	296828400
-72	[72,72,72]	296888130
-71	[71,71,71]	296947800
-70	[70,70,70]	297007500
-69	[69,69,69]	297067200
-68	[68,68,68]	297126900
-67	[67,67,67]	297186620
-66	[66,66,66]	297246340
-65	[65,65,65]	297306080
-64	[64,64,64]	297365820
-63	[63,63,63]	297425540
-62	[62,62,62]	297485280
-61	[61,61,61]	297545020
-60	[60,60,60]	297604800
-59	[59,59,59]	297664580
-58	[58,58,58]	297724320
-57	[57,57,57]	297784100
-56	[56,56,56]	297843900
-55	[55,55,55]	297903680
-54	[54,54,54]	297963460
-53	[53,53,53]	298023260
-52	[52,52,52]	298083070
-51	[51,51,51]	298142880
-50	[50,50,50]	298202700
-49	[49,49,49]	298262530
-48	[48,48,48]	298322370
-47	[47,47,47]	298382180
-46	[46,46,46]	298442020
-45	[45,45,45]	298501900
-44	[44,44,44]	298561730
-43	[43,43,43]	298621570
-42	[42,42,42]	298681440
-41	[41,41,41]	298741300
-40	[40,40,40]	298801200
-39	[39,39,39]	298861100
-38	[38,38,38]	298920960
-37	[37,37,37]	298980860
-36	[36,36,36]	299040770
-35	[35,35,35]	299100670
-34	[34,34,34]	299160580
-33	[33,33,33]	299220500
-32	[32,32,32]	299280450
-31	[31,31,31]	299340350
-30	[30,30,30]	299400300
-9	[9,9,9]	300660350
+10020	[10020,10020,10020]	0.029766083
+10021	[10021,10021,10021]	2.4321098
+10019	[10019,10019,10019]	3.6274223
+10022	[10022,10022,10022]	10.834454
+10018	[10018,10018,10018]	13.225079
+10023	[10023,10023,10023]	25.236797
+10017	[10017,10017,10017]	28.822735
+10024	[10024,10024,10024]	45.63914
+10016	[10016,10016,10016]	50.42039
+10025	[10025,10025,10025]	72.04149
+10015	[10015,10015,10015]	78.01805
+10026	[10026,10026,10026]	104.44383
+10014	[10014,10014,10014]	111.61571
+10027	[10027,10027,10027]	142.84618
+10013	[10013,10013,10013]	151.21336
+10028	[10028,10028,10028]	187.24852
+10012	[10012,10012,10012]	196.811
+10029	[10029,10029,10029]	237.65085
+10011	[10011,10011,10011]	248.40866
+10010	[10010,10010,10010]	306.00632
+10009	[10009,10009,10009]	369.60397
+10008	[10008,10008,10008]	439.20163
+10007	[10007,10007,10007]	514.7993
+10006	[10006,10006,10006]	596.397
+10005	[10005,10005,10005]	683.9946
+10004	[10004,10004,10004]	777.5923
+10003	[10003,10003,10003]	877.18994
+10002	[10002,10002,10002]	982.7876
+10001	[10001,10001,10001]	1094.3853
+99	[99,99,99]	295284640
+98	[98,98,98]	295344200
+97	[97,97,97]	295403700
+96	[96,96,96]	295463260
+95	[95,95,95]	295522800
+94	[94,94,94]	295582370
+93	[93,93,93]	295641920
+92	[92,92,92]	295701470
+91	[91,91,91]	295761060
+90	[90,90,90]	295820640
+89	[89,89,89]	295880200
+88	[88,88,88]	295939800
+87	[87,87,87]	295999400
+86	[86,86,86]	296059000
+85	[85,85,85]	296118620
+84	[84,84,84]	296178200
+83	[83,83,83]	296237860
+82	[82,82,82]	296297470
+81	[81,81,81]	296357120
+80	[80,80,80]	296416770
+79	[79,79,79]	296476380
+78	[78,78,78]	296536030
+77	[77,77,77]	296595700
+76	[76,76,76]	296655360
+75	[75,75,75]	296715000
+74	[74,74,74]	296774700
+73	[73,73,73]	296834370
+72	[72,72,72]	296894080
+71	[71,71,71]	296953760
+70	[70,70,70]	297013440
+69	[69,69,69]	297073150
+68	[68,68,68]	297132860
+67	[67,67,67]	297192580
+66	[66,66,66]	297252300
+65	[65,65,65]	297312030
+64	[64,64,64]	297371780
+63	[63,63,63]	297431500
+62	[62,62,62]	297491230
+61	[61,61,61]	297550980
+60	[60,60,60]	297610750
+59	[59,59,59]	297670530
+58	[58,58,58]	297730300
+57	[57,57,57]	297790050
+56	[56,56,56]	297849860
+55	[55,55,55]	297909630
+54	[54,54,54]	297969440
+53	[53,53,53]	298029220
+52	[52,52,52]	298089020
+51	[51,51,51]	298148830
+50	[50,50,50]	298208670
+49	[49,49,49]	298268480
+48	[48,48,48]	298328320
+47	[47,47,47]	298388130
+46	[46,46,46]	298448000
+45	[45,45,45]	298507840
+44	[44,44,44]	298567680
+43	[43,43,43]	298627550
+42	[42,42,42]	298687420
+41	[41,41,41]	298747300
+40	[40,40,40]	298807170
+39	[39,39,39]	298867070
+38	[38,38,38]	298926940
+37	[37,37,37]	298986850
+36	[36,36,36]	299046750
+35	[35,35,35]	299106660
+34	[34,34,34]	299166560
+33	[33,33,33]	299226500
+32	[32,32,32]	299286400
+31	[31,31,31]	299346340
+30	[30,30,30]	299406270
+9	[9,9,9]	300666340
diff --git a/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh b/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh
index be46e553d8..44101a9f3d 100755
--- a/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh
+++ b/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.0, 10020.0, 10020.0]) as d FROM test_vector prewhere id<100 or id>10000"
+clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector prewhere id<100 or id>10000"
diff --git a/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.reference b/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.reference
index 73f9d608b9..0692953e75 100644
--- a/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.reference
+++ b/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.reference
@@ -1 +1,35 @@
 9999	[9999,9999,9999]	1323
+100	[100,100,100]	295219200
+99	[99,99,99]	295278720
+55	[55,55,55]	297903680
+51	[51,51,51]	298142880
+49	[49,49,49]	298262530
+48	[48,48,48]	298322370
+47	[47,47,47]	298382180
+46	[46,46,46]	298442020
+45	[45,45,45]	298501900
+44	[44,44,44]	298561730
+43	[43,43,43]	298621570
+42	[42,42,42]	298681440
+41	[41,41,41]	298741300
+40	[40,40,40]	298801200
+39	[39,39,39]	298861100
+38	[38,38,38]	298920960
+37	[37,37,37]	298980860
+36	[36,36,36]	299040770
+35	[35,35,35]	299100670
+34	[34,34,34]	299160580
+33	[33,33,33]	299220500
+32	[32,32,32]	299280450
+31	[31,31,31]	299340350
+30	[30,30,30]	299400300
+9	[9,9,9]	300660350
+8	[8,8,8]	300720450
+7	[7,7,7]	300780500
+6	[6,6,6]	300840580
+5	[5,5,5]	300900670
+4	[4,4,4]	300960770
+3	[3,3,3]	301020860
+2	[2,2,2]	301080960
+1	[1,1,1]	301141100
+0	[0,0,0]	301201200
diff --git a/tests/queries/2_vector_search/00012_mqvs_brute_force_search.reference b/tests/queries/2_vector_search/00012_mqvs_brute_force_search.reference
index d5d082df76..325e782128 100644
--- a/tests/queries/2_vector_search/00012_mqvs_brute_force_search.reference
+++ b/tests/queries/2_vector_search/00012_mqvs_brute_force_search.reference
@@ -1,100 +1,100 @@
-10020	[10020,10020,10020]	0
-10021	[10021,10021,10021]	3
-10019	[10019,10019,10019]	3
-10022	[10022,10022,10022]	12
-10018	[10018,10018,10018]	12
-10017	[10017,10017,10017]	27
-10023	[10023,10023,10023]	27
-10016	[10016,10016,10016]	48
-10024	[10024,10024,10024]	48
-10025	[10025,10025,10025]	75
-10015	[10015,10015,10015]	75
-10014	[10014,10014,10014]	108
-10026	[10026,10026,10026]	108
-10027	[10027,10027,10027]	147
-10013	[10013,10013,10013]	147
-10012	[10012,10012,10012]	192
-10028	[10028,10028,10028]	192
-10011	[10011,10011,10011]	243
-10029	[10029,10029,10029]	243
-10010	[10010,10010,10010]	300
-10009	[10009,10009,10009]	363
-10008	[10008,10008,10008]	432
-10007	[10007,10007,10007]	507
-10006	[10006,10006,10006]	588
-10005	[10005,10005,10005]	675
-10004	[10004,10004,10004]	768
-10003	[10003,10003,10003]	867
-10002	[10002,10002,10002]	972
-10001	[10001,10001,10001]	1083
-10000	[10000,10000,10000]	1200
-9999	[9999,9999,9999]	1323
-9998	[9998,9998,9998]	1452
-9997	[9997,9997,9997]	1587
-9996	[9996,9996,9996]	1728
-9995	[9995,9995,9995]	1875
-9994	[9994,9994,9994]	2028
-9993	[9993,9993,9993]	2187
-9992	[9992,9992,9992]	2352
-9991	[9991,9991,9991]	2523
-9990	[9990,9990,9990]	2700
-9989	[9989,9989,9989]	2883
-9988	[9988,9988,9988]	3072
-9987	[9987,9987,9987]	3267
-9986	[9986,9986,9986]	3468
-9985	[9985,9985,9985]	3675
-9984	[9984,9984,9984]	3888
-9983	[9983,9983,9983]	4107
-9982	[9982,9982,9982]	4332
-9981	[9981,9981,9981]	4563
-9980	[9980,9980,9980]	4800
-9979	[9979,9979,9979]	5043
-9978	[9978,9978,9978]	5292
-9977	[9977,9977,9977]	5547
-9976	[9976,9976,9976]	5808
-9975	[9975,9975,9975]	6075
-9974	[9974,9974,9974]	6348
-9973	[9973,9973,9973]	6627
-9972	[9972,9972,9972]	6912
-9971	[9971,9971,9971]	7203
-9970	[9970,9970,9970]	7500
-9969	[9969,9969,9969]	7803
-9968	[9968,9968,9968]	8112
-9967	[9967,9967,9967]	8427
-9966	[9966,9966,9966]	8748
-9965	[9965,9965,9965]	9075
-9964	[9964,9964,9964]	9408
-9963	[9963,9963,9963]	9747
-9962	[9962,9962,9962]	10092
-9961	[9961,9961,9961]	10443
-9960	[9960,9960,9960]	10800
-9959	[9959,9959,9959]	11163
-9958	[9958,9958,9958]	11532
-9957	[9957,9957,9957]	11907
-9956	[9956,9956,9956]	12288
-9955	[9955,9955,9955]	12675
-9954	[9954,9954,9954]	13068
-9953	[9953,9953,9953]	13467
-9952	[9952,9952,9952]	13872
-9951	[9951,9951,9951]	14283
-9950	[9950,9950,9950]	14700
-9949	[9949,9949,9949]	15123
-9948	[9948,9948,9948]	15552
-9947	[9947,9947,9947]	15987
-9946	[9946,9946,9946]	16428
-9945	[9945,9945,9945]	16875
-9944	[9944,9944,9944]	17328
-9943	[9943,9943,9943]	17787
-9942	[9942,9942,9942]	18252
-9941	[9941,9941,9941]	18723
-9940	[9940,9940,9940]	19200
-9939	[9939,9939,9939]	19683
-9938	[9938,9938,9938]	20172
-9937	[9937,9937,9937]	20667
-9936	[9936,9936,9936]	21168
-9935	[9935,9935,9935]	21675
-9934	[9934,9934,9934]	22188
-9933	[9933,9933,9933]	22707
-9932	[9932,9932,9932]	23232
-9931	[9931,9931,9931]	23763
-9930	[9930,9930,9930]	24300
+10020	[10020,10020,10020]	0.029766083
+10021	[10021,10021,10021]	2.4321098
+10019	[10019,10019,10019]	3.6274223
+10022	[10022,10022,10022]	10.834454
+10018	[10018,10018,10018]	13.225079
+10023	[10023,10023,10023]	25.236797
+10017	[10017,10017,10017]	28.822735
+10024	[10024,10024,10024]	45.63914
+10016	[10016,10016,10016]	50.42039
+10025	[10025,10025,10025]	72.04149
+10015	[10015,10015,10015]	78.01805
+10026	[10026,10026,10026]	104.44383
+10014	[10014,10014,10014]	111.61571
+10027	[10027,10027,10027]	142.84618
+10013	[10013,10013,10013]	151.21336
+10028	[10028,10028,10028]	187.24852
+10012	[10012,10012,10012]	196.811
+10029	[10029,10029,10029]	237.65085
+10011	[10011,10011,10011]	248.40866
+10010	[10010,10010,10010]	306.00632
+10009	[10009,10009,10009]	369.60397
+10008	[10008,10008,10008]	439.20163
+10007	[10007,10007,10007]	514.7993
+10006	[10006,10006,10006]	596.397
+10005	[10005,10005,10005]	683.9946
+10004	[10004,10004,10004]	777.5923
+10003	[10003,10003,10003]	877.18994
+10002	[10002,10002,10002]	982.7876
+10001	[10001,10001,10001]	1094.3853
+10000	[10000,10000,10000]	1211.9829
+9999	[9999,9999,9999]	1335.5806
+9998	[9998,9998,9998]	1465.1782
+9997	[9997,9997,9997]	1600.7759
+9996	[9996,9996,9996]	1742.3735
+9995	[9995,9995,9995]	1889.9712
+9994	[9994,9994,9994]	2043.5688
+9993	[9993,9993,9993]	2203.1665
+9992	[9992,9992,9992]	2368.7642
+9991	[9991,9991,9991]	2540.3618
+9990	[9990,9990,9990]	2717.9595
+9989	[9989,9989,9989]	2901.5571
+9988	[9988,9988,9988]	3091.1548
+9987	[9987,9987,9987]	3286.7524
+9986	[9986,9986,9986]	3488.35
+9985	[9985,9985,9985]	3695.9478
+9984	[9984,9984,9984]	3909.5454
+9983	[9983,9983,9983]	4129.143
+9982	[9982,9982,9982]	4354.7407
+9981	[9981,9981,9981]	4586.3384
+9980	[9980,9980,9980]	4823.936
+9979	[9979,9979,9979]	5067.5337
+9978	[9978,9978,9978]	5317.1313
+9977	[9977,9977,9977]	5572.729
+9976	[9976,9976,9976]	5834.3267
+9975	[9975,9975,9975]	6101.9243
+9974	[9974,9974,9974]	6375.5225
+9973	[9973,9973,9973]	6655.12
+9972	[9972,9972,9972]	6940.718
+9971	[9971,9971,9971]	7232.3154
+9970	[9970,9970,9970]	7529.913
+9969	[9969,9969,9969]	7833.5107
+9968	[9968,9968,9968]	8143.1084
+9967	[9967,9967,9967]	8458.706
+9966	[9966,9966,9966]	8780.304
+9965	[9965,9965,9965]	9107.901
+9964	[9964,9964,9964]	9441.499
+9963	[9963,9963,9963]	9781.097
+9962	[9962,9962,9962]	10126.694
+9961	[9961,9961,9961]	10478.292
+9960	[9960,9960,9960]	10835.89
+9959	[9959,9959,9959]	11199.487
+9958	[9958,9958,9958]	11569.085
+9957	[9957,9957,9957]	11944.683
+9956	[9956,9956,9956]	12326.279
+9955	[9955,9955,9955]	12713.877
+9954	[9954,9954,9954]	13107.475
+9953	[9953,9953,9953]	13507.072
+9952	[9952,9952,9952]	13912.67
+9951	[9951,9951,9951]	14324.268
+9950	[9950,9950,9950]	14741.865
+9949	[9949,9949,9949]	15165.463
+9948	[9948,9948,9948]	15595.061
+9947	[9947,9947,9947]	16030.658
+9946	[9946,9946,9946]	16472.256
+9945	[9945,9945,9945]	16919.854
+9944	[9944,9944,9944]	17373.451
+9943	[9943,9943,9943]	17833.049
+9942	[9942,9942,9942]	18298.646
+9941	[9941,9941,9941]	18770.244
+9940	[9940,9940,9940]	19247.842
+9939	[9939,9939,9939]	19731.44
+9938	[9938,9938,9938]	20221.037
+9937	[9937,9937,9937]	20716.635
+9936	[9936,9936,9936]	21218.232
+9935	[9935,9935,9935]	21725.83
+9934	[9934,9934,9934]	22239.428
+9933	[9933,9933,9933]	22759.025
+9932	[9932,9932,9932]	23284.623
+9931	[9931,9931,9931]	23816.22
+9930	[9930,9930,9930]	24353.818
diff --git a/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh b/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh
index 97513d17be..4c543cee9f 100755
--- a/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh
+++ b/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.0, 10020.0, 10020.0]) as d FROM test_vector"
+clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector"
diff --git a/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.reference b/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.reference
new file mode 100644
index 0000000000..d86bac9de5
--- /dev/null
+++ b/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.reference
@@ -0,0 +1 @@
+OK
diff --git a/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh b/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh
new file mode 100755
index 0000000000..0f1ac4a6d4
--- /dev/null
+++ b/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh
@@ -0,0 +1,7 @@
+#!/usr/bin/env bash
+# Tags: no-parallel
+
+CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
+. "$CURDIR"/helpers/00000_prepare_index.sh
+
+clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]), distance('topK=10')(vector, [1.1, 1.1, 1.1]) FROM test_vector;" 2>&1 | grep -q "DB::Exception: Not support multiple distance funcs in one query now." && echo 'OK' || echo 'FAIL' || :
diff --git a/tests/queries/2_vector_search/helpers/00000_prepare_index_2.sh b/tests/queries/2_vector_search/helpers/00000_prepare_index_2.sh
index 0389b15f90..6b38d29b31 100755
--- a/tests/queries/2_vector_search/helpers/00000_prepare_index_2.sh
+++ b/tests/queries/2_vector_search/helpers/00000_prepare_index_2.sh
@@ -1,7 +1,7 @@
 #!/usr/bin/env bash
 
 clickhouse-client -q "DROP TABLE IF EXISTS test_vector"
-clickhouse-client -q "CREATE TABLE test_vector(id Float32, vector FixedArray(Float32, 3)) engine MergeTree primary key id SETTINGS index_granularity=128;"
+clickhouse-client -q "CREATE TABLE test_vector(id Float32, vector FixedArray(Float32, 3)) engine MergeTree primary key id SETTINGS index_granularity=128, min_rows_to_build_vector_index=0;"
 clickhouse-client -q "INSERT INTO test_vector SELECT number, [number, number, number] FROM numbers(10);"
 clickhouse-client -q "INSERT INTO test_vector SELECT number + 10, [] FROM numbers(20);"
 clickhouse-client -q "INSERT INTO test_vector SELECT number + 30, [number + 30, number + 30, number + 30] FROM numbers(10000);"
diff --git a/tests/queries/vector/alter_index.sql b/tests/vector_search/vector/alter_index.sql
similarity index 100%
rename from tests/queries/vector/alter_index.sql
rename to tests/vector_search/vector/alter_index.sql
diff --git a/tests/queries/vector/create_table.sql b/tests/vector_search/vector/create_table.sql
similarity index 100%
rename from tests/queries/vector/create_table.sql
rename to tests/vector_search/vector/create_table.sql
diff --git a/tests/queries/vector/create_table_xhs.sql b/tests/vector_search/vector/create_table_xhs.sql
similarity index 100%
rename from tests/queries/vector/create_table_xhs.sql
rename to tests/vector_search/vector/create_table_xhs.sql
diff --git a/tests/queries/vector/insert.sql b/tests/vector_search/vector/insert.sql
similarity index 100%
rename from tests/queries/vector/insert.sql
rename to tests/vector_search/vector/insert.sql
diff --git a/tests/queries/vector/search_xhs.sql b/tests/vector_search/vector/search_xhs.sql
similarity index 100%
rename from tests/queries/vector/search_xhs.sql
rename to tests/vector_search/vector/search_xhs.sql
-- 
2.32.1 (Apple Git-133)

