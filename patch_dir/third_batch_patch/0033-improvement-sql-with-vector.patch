From 5ce85255fc9448573fd1652f8a55fbe3d48a7faf Mon Sep 17 00:00:00 2001
From: Jianmei Zhang <jianmeiz@moqi.ai>
Date: Thu, 20 Apr 2023 05:45:56 +0000
Subject: [PATCH 33/51] improvement sql with vector

---
 .gitlab-ci-integration-test.yml               |   6 +-
 .gitmodules                                   |   9 +-
 annoy                                         |   1 +
 contrib/CMakeLists.txt                        |   3 +
 contrib/annoy                                 |   1 +
 contrib/annoy-cmake/CMakeLists.txt            |  24 +
 src/CMakeLists.txt                            |   4 +
 src/Common/Allocator.h                        |   2 +-
 src/Core/Settings.h                           |   3 +
 src/Functions/array/arrayDistance.cpp         | 520 +++++++++++++++
 src/Functions/array/arrayNorm.cpp             | 323 ++++++++++
 src/Functions/vectorFunctions.cpp             | 263 +++++++-
 src/Interpreters/Context.cpp                  |  15 +
 src/Interpreters/Context.h                    |  10 +
 src/Interpreters/ExpressionAnalyzer.cpp       |  73 ++-
 src/Interpreters/ExpressionAnalyzer.h         |   2 +-
 src/Interpreters/GetVectorScanVisitor.h       |   4 +-
 src/Interpreters/InterpreterCreateQuery.cpp   |   5 +-
 src/Interpreters/TableJoin.cpp                |  11 +
 src/Interpreters/TableJoin.h                  |   9 +
 src/Interpreters/TreeRewriter.cpp             | 380 ++++++-----
 src/Interpreters/TreeRewriter.h               |   8 +
 src/Interpreters/VectorScanDescription.h      |   1 +
 src/Storages/MergeTree/CommonANNIndexes.cpp   | 606 ++++++++++++++++++
 src/Storages/MergeTree/CommonANNIndexes.h     | 236 +++++++
 .../MergeTree/MergeTreeDataSelectExecutor.cpp |  27 +
 .../MergeTree/MergeTreeIndexAnnoy.cpp         | 404 ++++++++++++
 src/Storages/MergeTree/MergeTreeIndexAnnoy.h  | 130 ++++
 src/Storages/MergeTree/MergeTreeIndices.cpp   |   5 +
 src/Storages/MergeTree/MergeTreeIndices.h     |   5 +
 .../MergeTree/MergeTreeVectorScanManager.cpp  |  22 +-
 tests/integration/exclude_test.list           |   4 +-
 .../test.py                                   |   2 +-
 .../test_mqvs_primary_key_cache/test.py       |   6 +-
 .../test.py                                   |   8 +-
 .../02011_tuple_vector_functions.reference    |   5 +
 .../02011_tuple_vector_functions.sql          |   5 +
 .../02282_array_distance.reference            |  82 +++
 .../0_stateless/02282_array_distance.sql      | 102 +++
 .../0_stateless/02283_array_norm.reference    |  42 ++
 .../queries/0_stateless/02283_array_norm.sql  |  47 ++
 .../queries/0_stateless/02354_annoy.reference |   8 +
 tests/queries/0_stateless/02354_annoy.sql     |  34 +
 .../2_vector_search/00001_mqvs_distance.sh    |   4 +-
 .../00002_mqvs_batch_distance.sh              |   4 +-
 .../00003_mqvs_distance_with_prewhere.sh      |   2 +-
 .../00004_mqvs_filter_by_distance.sh          |   4 +-
 .../00007_mqvs_wrong_search_col.sh            |   4 +-
 .../00008_mqvs_empty_vector.sh                |   4 +-
 ...0009_mqvs_brute_force_search_prewhere_0.sh |   2 +-
 ...0010_mqvs_brute_force_search_prewhere_1.sh |   2 +-
 .../00011_mqvs_brute_force_search_where.sh    |   2 +-
 .../00012_mqvs_brute_force_search.sh          |   2 +-
 .../00013_mqvs_distance_ivfsq.sh              |   4 +-
 .../00014_mqvs_distance_cosine_hnsw.sh        |   2 +-
 .../00014_mqvs_distance_cosine_ivfflat.sh     |   2 +-
 .../00014_mqvs_distance_cosine_ivfpq.sh       |   2 +-
 .../00014_mqvs_distance_cosine_ivfsq.sh       |   2 +-
 ...s_index_build_after_lightweight_delete.sql |   2 +-
 ...16_mqvs_lightweight_delete_with_vector.sql |   2 +-
 ..._mqvs_lightweight_delete_with_decouple.sql |  14 +-
 ...cated_lightweight_delete_with_decouple.sql |  14 +-
 .../00018_mqvs_multi_distance_funcs.sh        |   2 +-
 ...0_mqvs_refactor_support_prewhere_where.sql |   2 +-
 .../00021_mqvs_support_primary_key_cache.sql  |   4 +-
 ...licated_lightweight_delete_with_vector.sql |   2 +-
 ...vs_no_threshold_move_to_prewhere.reference |  12 +-
 ...024_mqvs_no_threshold_move_to_prewhere.sql |  30 +-
 .../00025_mqvs_distance_with_subquery.sql     |  20 +-
 ...t_distance_on_right_joined_table.reference |  30 +
 ...support_distance_on_right_joined_table.sql |  36 ++
 ...s_check_order_by_for_metric_type.reference |   9 +
 ...27_mqvs_check_order_by_for_metric_type.sql |  32 +
 73 files changed, 3428 insertions(+), 282 deletions(-)
 create mode 160000 annoy
 create mode 160000 contrib/annoy
 create mode 100644 contrib/annoy-cmake/CMakeLists.txt
 create mode 100644 src/Functions/array/arrayDistance.cpp
 create mode 100644 src/Functions/array/arrayNorm.cpp
 create mode 100644 src/Storages/MergeTree/CommonANNIndexes.cpp
 create mode 100644 src/Storages/MergeTree/CommonANNIndexes.h
 create mode 100644 src/Storages/MergeTree/MergeTreeIndexAnnoy.cpp
 create mode 100644 src/Storages/MergeTree/MergeTreeIndexAnnoy.h
 create mode 100644 tests/queries/0_stateless/02282_array_distance.reference
 create mode 100644 tests/queries/0_stateless/02282_array_distance.sql
 create mode 100644 tests/queries/0_stateless/02283_array_norm.reference
 create mode 100644 tests/queries/0_stateless/02283_array_norm.sql
 create mode 100644 tests/queries/0_stateless/02354_annoy.reference
 create mode 100755 tests/queries/0_stateless/02354_annoy.sql
 create mode 100644 tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.reference
 create mode 100644 tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.sql
 create mode 100644 tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.reference
 create mode 100644 tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.sql

diff --git a/.gitlab-ci-integration-test.yml b/.gitlab-ci-integration-test.yml
index 541eb652fb..5cdc77b9e0 100644
--- a/.gitlab-ci-integration-test.yml
+++ b/.gitlab-ci-integration-test.yml
@@ -12,7 +12,7 @@ integration_test0:
       - $CI_PROJECT_DIR/tests/integration/assets/*
   script:
     - pwd && echo $CI_PROJECT_DIR && echo ${CI_COMMIT_SHA}
-    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 0 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
+    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 0 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" --runner-image-version 1.8 ||:'
   rules:
     - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_TEST_IN_K8S == "false"' # Trigger pipline during scheduled tasks
     - if: $CI_MERGE_REQUEST_LABELS == "test-integration"
@@ -30,7 +30,7 @@ integration_test1:
       - $CI_PROJECT_DIR/tests/integration/assets/*
   script:
     - pwd && echo $CI_PROJECT_DIR && echo ${CI_COMMIT_SHA}
-    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 1 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
+    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 1 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" --runner-image-version 1.8 ||:'
   rules:
     - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_TEST_IN_K8S == "false"' # Trigger pipline during scheduled tasks
     - if: $CI_MERGE_REQUEST_LABELS == "test-integration"
@@ -48,7 +48,7 @@ integration_test2:
       - $CI_PROJECT_DIR/tests/integration/assets/*
   script:
     - pwd && echo $CI_PROJECT_DIR && echo ${CI_COMMIT_SHA}
-    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 2 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
+    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 2 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" --runner-image-version 1.8 ||:'
   rules:
     - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_TEST_IN_K8S == "false"' # Trigger pipline during scheduled tasks
     - if: $CI_MERGE_REQUEST_LABELS == "test-integration"
diff --git a/.gitmodules b/.gitmodules
index 5eb01a4534..23ad152843 100644
--- a/.gitmodules
+++ b/.gitmodules
@@ -262,9 +262,16 @@
 [submodule "contrib/minizip-ng"]
 	path = contrib/minizip-ng
 	url = https://github.com/zlib-ng/minizip-ng
+[submodule "contrib/annoy"]
+	path = contrib/annoy
+	url = https://github.com/ClickHouse/annoy.git
+	branch = ClickHouse-master
 [submodule "contrib/faiss"]
 	path = contrib/faiss
 	url = git@git.moqi.ai:mqdb/faiss.git
 [submodule "contrib/hnswlib"]
 	path = contrib/hnswlib
-	url = git@git.moqi.ai:mqdb/hnswlib.git
\ No newline at end of file
+	url = git@git.moqi.ai:mqdb/hnswlib.git
+[submodule "annoy"]
+	path = annoy
+	url = https://github.com/ClickHouse/annoy.git
diff --git a/annoy b/annoy
new file mode 160000
index 0000000000..ebaa60e5c8
--- /dev/null
+++ b/annoy
@@ -0,0 +1 @@
+Subproject commit ebaa60e5c83d140901b9719471eb47800e5744ac
diff --git a/contrib/CMakeLists.txt b/contrib/CMakeLists.txt
index 1b42d8a455..2b2e7b71a9 100644
--- a/contrib/CMakeLists.txt
+++ b/contrib/CMakeLists.txt
@@ -147,6 +147,9 @@ endif()
 
 add_contrib (sqlite-cmake sqlite-amalgamation)
 add_contrib (s2geometry-cmake s2geometry)
+
+add_contrib (annoy-cmake annoy)
+
 set(FAISS_OPT_LEVEL avx2)
 add_subdirectory (faiss)
 add_subdirectory (hnswlib)
diff --git a/contrib/annoy b/contrib/annoy
new file mode 160000
index 0000000000..ebaa60e5c8
--- /dev/null
+++ b/contrib/annoy
@@ -0,0 +1 @@
+Subproject commit ebaa60e5c83d140901b9719471eb47800e5744ac
diff --git a/contrib/annoy-cmake/CMakeLists.txt b/contrib/annoy-cmake/CMakeLists.txt
new file mode 100644
index 0000000000..bdef7d9213
--- /dev/null
+++ b/contrib/annoy-cmake/CMakeLists.txt
@@ -0,0 +1,24 @@
+option(ENABLE_ANNOY "Enable Annoy index support" ${ENABLE_LIBRARIES})
+
+# Annoy index should be disabled with undefined sanitizer. Because of memory storage optimizations
+# (https://github.com/ClickHouse/annoy/blob/9d8a603a4cd252448589e84c9846f94368d5a289/src/annoylib.h#L442-L463)
+# UBSan fails and leads to crash. Simmilar issue is already opened in Annoy repo
+# https://github.com/spotify/annoy/issues/456
+# Problem with aligment can lead to errors like
+# (https://stackoverflow.com/questions/46790550/c-undefined-behavior-strict-aliasing-rule-or-incorrect-alignment)
+# or will lead to crash on arm https://developer.arm.com/documentation/ka003038/latest
+# This issues should be resolved before annoy became non-experimental (--> setting "allow_experimental_annoy_index")
+if ((NOT ENABLE_ANNOY) OR (SANITIZE STREQUAL "undefined") OR (ARCH_AARCH64))
+    message (STATUS "Not using annoy")
+    return()
+endif()
+
+set(ANNOY_PROJECT_DIR "${ClickHouse_SOURCE_DIR}/contrib/annoy")
+set(ANNOY_SOURCE_DIR "${ANNOY_PROJECT_DIR}/src")
+
+add_library(_annoy INTERFACE)
+target_include_directories(_annoy SYSTEM INTERFACE ${ANNOY_SOURCE_DIR})
+
+add_library(ch_contrib::annoy ALIAS _annoy)
+target_compile_definitions(_annoy INTERFACE ENABLE_ANNOY)
+target_compile_definitions(_annoy INTERFACE ANNOYLIB_MULTITHREADED_BUILD)
diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index 4660fbc13c..2475a08edd 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -542,6 +542,10 @@ endif()
 
 dbms_target_link_libraries(PUBLIC ch_contrib::consistent_hashing)
 
+if (TARGET ch_contrib::annoy)
+    dbms_target_link_libraries(PUBLIC ch_contrib::annoy)
+endif()
+
 find_package(OpenMP REQUIRED)
 dbms_target_link_libraries(PUBLIC OpenMP::OpenMP_CXX)
 
diff --git a/src/Common/Allocator.h b/src/Common/Allocator.h
index c2c9ecd689..711a343351 100644
--- a/src/Common/Allocator.h
+++ b/src/Common/Allocator.h
@@ -201,7 +201,7 @@ protected:
 private:
     void * allocNoTrack(size_t size, size_t alignment)
     {
-        void * buf;
+        void * buf = nullptr; /// Initialize it to avoid warning in memory sanitizer
         size_t mmap_min_alignment = ::getPageSize();
 
         if (size >= MMAP_THRESHOLD)
diff --git a/src/Core/Settings.h b/src/Core/Settings.h
index 2041863e7c..42f079183e 100644
--- a/src/Core/Settings.h
+++ b/src/Core/Settings.h
@@ -1155,6 +1155,9 @@ class IColumn;
     M(Bool, allow_experimental_nlp_functions, false, "Enable experimental functions for natural language processing.", 0) \
     M(Bool, allow_experimental_object_type, false, "Allow Object and JSON data types", 0) \
     M(String, insert_deduplication_token, "", "If not empty, used for duplicate detection instead of data digest", 0)                    \
+    M(String, ann_index_select_query_params, "", "Parameters passed to ANN indexes in SELECT queries, the format is 'param1=x, param2=y, ...'", 0) \
+    M(UInt64, max_limit_for_ann_queries, 1000000, "Maximum limit value for using ANN indexes is used to prevent memory overflow in search queries for indexes", 0) \
+    M(Bool, allow_experimental_annoy_index, false, "Allows to use Annoy index. Disabled by default because this feature is experimental", 0) \
     M(Bool, throw_on_unsupported_query_inside_transaction, true, "Throw exception if unsupported query is used inside transaction", 0)   \
     M(TransactionsWaitCSNMode, wait_changes_become_visible_after_commit_mode, TransactionsWaitCSNMode::WAIT_UNKNOWN, "Wait for committed changes to become actually visible in the latest snapshot", 0) \
     M(Bool, atomic_insert, false, "If enabled and not already inside a transaction, wraps the insert query inside a full transaction (begin + commit or rollback)", 0) \
diff --git a/src/Functions/array/arrayDistance.cpp b/src/Functions/array/arrayDistance.cpp
new file mode 100644
index 0000000000..c1137848cc
--- /dev/null
+++ b/src/Functions/array/arrayDistance.cpp
@@ -0,0 +1,520 @@
+#include <Columns/ColumnArray.h>
+#include <Columns/ColumnsNumber.h>
+#include <Columns/IColumn.h>
+#include <DataTypes/DataTypeArray.h>
+#include <DataTypes/DataTypesNumber.h>
+#include <DataTypes/IDataType.h>
+#include <DataTypes/getLeastSupertype.h>
+#include <Functions/FunctionFactory.h>
+#include <Functions/FunctionHelpers.h>
+#include <base/range.h>
+
+namespace DB
+{
+namespace ErrorCodes
+{
+    extern const int ILLEGAL_COLUMN;
+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;
+    extern const int LOGICAL_ERROR;
+    extern const int SIZES_OF_ARRAYS_DOESNT_MATCH;
+    extern const int ARGUMENT_OUT_OF_BOUND;
+}
+
+struct L1Distance
+{
+    static constexpr auto name = "L1";
+
+    struct ConstParams {};
+
+    template <typename FloatType>
+    struct State
+    {
+        FloatType sum = 0;
+    };
+
+    template <typename ResultType>
+    static void accumulate(State<ResultType> & state, ResultType x, ResultType y, const ConstParams &)
+    {
+        state.sum += fabs(x - y);
+    }
+
+    template <typename ResultType>
+    static void combine(State<ResultType> & state, const State<ResultType> & other_state, const ConstParams &)
+    {
+        state.sum += other_state.sum;
+    }
+
+    template <typename ResultType>
+    static ResultType finalize(const State<ResultType> & state, const ConstParams &)
+    {
+        return state.sum;
+    }
+};
+
+struct L2Distance
+{
+    static constexpr auto name = "L2";
+
+    struct ConstParams {};
+
+    template <typename FloatType>
+    struct State
+    {
+        FloatType sum = 0;
+    };
+
+    template <typename ResultType>
+    static void accumulate(State<ResultType> & state, ResultType x, ResultType y, const ConstParams &)
+    {
+        state.sum += (x - y) * (x - y);
+    }
+
+    template <typename ResultType>
+    static void combine(State<ResultType> & state, const State<ResultType> & other_state, const ConstParams &)
+    {
+        state.sum += other_state.sum;
+    }
+
+    template <typename ResultType>
+    static ResultType finalize(const State<ResultType> & state, const ConstParams &)
+    {
+        return sqrt(state.sum);
+    }
+};
+
+struct L2SquaredDistance : L2Distance
+{
+    static constexpr auto name = "L2Squared";
+
+    template <typename ResultType>
+    static ResultType finalize(const State<ResultType> & state, const ConstParams &)
+    {
+        return state.sum;
+    }
+};
+
+struct LpDistance
+{
+    static constexpr auto name = "Lp";
+
+    struct ConstParams
+    {
+        Float64 power;
+        Float64 inverted_power;
+    };
+
+    template <typename FloatType>
+    struct State
+    {
+        FloatType sum = 0;
+    };
+
+    template <typename ResultType>
+    static void accumulate(State<ResultType> & state, ResultType x, ResultType y, const ConstParams & params)
+    {
+        state.sum += static_cast<ResultType>(std::pow(fabs(x - y), params.power));
+    }
+
+    template <typename ResultType>
+    static void combine(State<ResultType> & state, const State<ResultType> & other_state, const ConstParams &)
+    {
+        state.sum += other_state.sum;
+    }
+
+    template <typename ResultType>
+    static ResultType finalize(const State<ResultType> & state, const ConstParams & params)
+    {
+        return static_cast<ResultType>(std::pow(state.sum, params.inverted_power));
+    }
+};
+
+struct LinfDistance
+{
+    static constexpr auto name = "Linf";
+
+    struct ConstParams {};
+
+    template <typename FloatType>
+    struct State
+    {
+        FloatType dist = 0;
+    };
+
+    template <typename ResultType>
+    static void accumulate(State<ResultType> & state, ResultType x, ResultType y, const ConstParams &)
+    {
+        state.dist = fmax(state.dist, fabs(x - y));
+    }
+
+    template <typename ResultType>
+    static void combine(State<ResultType> & state, const State<ResultType> & other_state, const ConstParams &)
+    {
+        state.dist = fmax(state.dist, other_state.dist);
+    }
+
+    template <typename ResultType>
+    static ResultType finalize(const State<ResultType> & state, const ConstParams &)
+    {
+        return state.dist;
+    }
+};
+
+struct CosineDistance
+{
+    static constexpr auto name = "Cosine";
+
+    struct ConstParams {};
+
+    template <typename FloatType>
+    struct State
+    {
+        FloatType dot_prod = 0;
+        FloatType x_squared = 0;
+        FloatType y_squared = 0;
+    };
+
+    template <typename ResultType>
+    static void accumulate(State<ResultType> & state, ResultType x, ResultType y, const ConstParams &)
+    {
+        state.dot_prod += x * y;
+        state.x_squared += x * x;
+        state.y_squared += y * y;
+    }
+
+    template <typename ResultType>
+    static void combine(State<ResultType> & state, const State<ResultType> & other_state, const ConstParams &)
+    {
+        state.dot_prod += other_state.dot_prod;
+        state.x_squared += other_state.x_squared;
+        state.y_squared += other_state.y_squared;
+    }
+
+    template <typename ResultType>
+    static ResultType finalize(const State<ResultType> & state, const ConstParams &)
+    {
+        return 1 - state.dot_prod / sqrt(state.x_squared * state.y_squared);
+    }
+};
+
+template <class Kernel>
+class FunctionArrayDistance : public IFunction
+{
+public:
+    String getName() const override { static auto name = String("array") + Kernel::name + "Distance"; return name; }
+    static FunctionPtr create(ContextPtr) { return std::make_shared<FunctionArrayDistance<Kernel>>(); }
+    size_t getNumberOfArguments() const override { return 2; }
+    ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {}; }
+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }
+    bool useDefaultImplementationForConstants() const override { return true; }
+
+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override
+    {
+        DataTypes types;
+        for (size_t i = 0; i < 2; ++i)
+        {
+            const auto * array_type = checkAndGetDataType<DataTypeArray>(arguments[i].type.get());
+            if (!array_type)
+                throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, "Argument {} of function {} must be array.", i, getName());
+
+            types.push_back(array_type->getNestedType());
+        }
+        const auto & common_type = getLeastSupertype(types);
+        switch (common_type->getTypeId())
+        {
+            case TypeIndex::UInt8:
+            case TypeIndex::UInt16:
+            case TypeIndex::UInt32:
+            case TypeIndex::Int8:
+            case TypeIndex::Int16:
+            case TypeIndex::Int32:
+            case TypeIndex::UInt64:
+            case TypeIndex::Int64:
+            case TypeIndex::Float64:
+                return std::make_shared<DataTypeFloat64>();
+            case TypeIndex::Float32:
+                return std::make_shared<DataTypeFloat32>();
+            default:
+                throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Arguments of function {} has nested type {}. "
+                    "Support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.",
+                    getName(),
+                    common_type->getName());
+        }
+    }
+
+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr & result_type, size_t input_rows_count) const override
+    {
+        switch (result_type->getTypeId())
+        {
+            case TypeIndex::Float32:
+                return executeWithResultType<Float32>(arguments, input_rows_count);
+                break;
+            case TypeIndex::Float64:
+                return executeWithResultType<Float64>(arguments, input_rows_count);
+                break;
+            default:
+                throw Exception(ErrorCodes::LOGICAL_ERROR, "Unexpected result type {}", result_type->getName());
+        }
+    }
+
+
+#define SUPPORTED_TYPES(action) \
+    action(UInt8)   \
+    action(UInt16)  \
+    action(UInt32)  \
+    action(UInt64)  \
+    action(Int8)    \
+    action(Int16)   \
+    action(Int32)   \
+    action(Int64)   \
+    action(Float32) \
+    action(Float64)
+
+
+private:
+    template <typename ResultType>
+    ColumnPtr executeWithResultType(const ColumnsWithTypeAndName & arguments, size_t input_rows_count) const
+    {
+        DataTypePtr type_x = typeid_cast<const DataTypeArray *>(arguments[0].type.get())->getNestedType();
+
+        /// Dynamic disaptch based on the 1st argument type
+        switch (type_x->getTypeId())
+        {
+        #define ON_TYPE(type) \
+            case TypeIndex::type: \
+                return executeWithFirstType<ResultType, type>(arguments, input_rows_count); \
+                break;
+
+            SUPPORTED_TYPES(ON_TYPE)
+        #undef ON_TYPE
+
+            default:
+                throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Arguments of function {} has nested type {}. "
+                    "Support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.",
+                    getName(),
+                    type_x->getName());
+        }
+    }
+
+    template <typename ResultType, typename FirstArgType>
+    ColumnPtr executeWithFirstType(const ColumnsWithTypeAndName & arguments, size_t input_rows_count) const
+    {
+        DataTypePtr type_y = typeid_cast<const DataTypeArray *>(arguments[1].type.get())->getNestedType();
+
+        /// Dynamic disaptch based on the 2nd argument type
+        switch (type_y->getTypeId())
+        {
+        #define ON_TYPE(type) \
+            case TypeIndex::type: \
+                return executeWithTypes<ResultType, FirstArgType, type>(arguments[0].column, arguments[1].column, input_rows_count, arguments); \
+                break;
+
+            SUPPORTED_TYPES(ON_TYPE)
+        #undef ON_TYPE
+
+            default:
+                throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Arguments of function {} has nested type {}. "
+                    "Support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.",
+                    getName(),
+                    type_y->getName());
+        }
+    }
+
+    template <typename ResultType, typename FirstArgType, typename SecondArgType>
+    ColumnPtr executeWithTypes(ColumnPtr col_x, ColumnPtr col_y, size_t input_rows_count, const ColumnsWithTypeAndName & arguments) const
+    {
+        if (typeid_cast<const ColumnConst *>(col_x.get()))
+        {
+            return executeWithTypesFirstArgConst<ResultType, FirstArgType, SecondArgType>(col_x, col_y, input_rows_count, arguments);
+        }
+        else if (typeid_cast<const ColumnConst *>(col_y.get()))
+        {
+            return executeWithTypesFirstArgConst<ResultType, SecondArgType, FirstArgType>(col_y, col_x, input_rows_count, arguments);
+        }
+
+        col_x = col_x->convertToFullColumnIfConst();
+        col_y = col_y->convertToFullColumnIfConst();
+
+        const auto & array_x = *assert_cast<const ColumnArray *>(col_x.get());
+        const auto & array_y = *assert_cast<const ColumnArray *>(col_y.get());
+
+        const auto & data_x = typeid_cast<const ColumnVector<FirstArgType> &>(array_x.getData()).getData();
+        const auto & data_y = typeid_cast<const ColumnVector<SecondArgType> &>(array_y.getData()).getData();
+
+        const auto & offsets_x = array_x.getOffsets();
+        const auto & offsets_y = array_y.getOffsets();
+
+        /// Check that arrays in both columns are the sames size
+        for (size_t row = 0; row < offsets_x.size(); ++row)
+        {
+            if (unlikely(offsets_x[row] != offsets_y[row]))
+            {
+                ColumnArray::Offset prev_offset = row > 0 ? offsets_x[row] : 0;
+                throw Exception(
+                    ErrorCodes::SIZES_OF_ARRAYS_DOESNT_MATCH,
+                    "Arguments of function {} have different array sizes: {} and {}",
+                    getName(),
+                    offsets_x[row] - prev_offset,
+                    offsets_y[row] - prev_offset);
+            }
+        }
+
+        const typename Kernel::ConstParams kernel_params = initConstParams(arguments);
+
+        auto result = ColumnVector<ResultType>::create(input_rows_count);
+        auto & result_data = result->getData();
+
+        /// Do the actual computation
+        ColumnArray::Offset prev = 0;
+        size_t row = 0;
+        for (auto off : offsets_x)
+        {
+            /// Process chunks in vectorized manner
+            static constexpr size_t VEC_SIZE = 4;
+            typename Kernel::template State<ResultType> states[VEC_SIZE];
+            for (; prev + VEC_SIZE < off; prev += VEC_SIZE)
+            {
+                for (size_t s = 0; s < VEC_SIZE; ++s)
+                    Kernel::template accumulate<ResultType>(
+                        states[s], static_cast<ResultType>(data_x[prev + s]), static_cast<ResultType>(data_y[prev + s]), kernel_params);
+            }
+
+            typename Kernel::template State<ResultType> state;
+            for (const auto & other_state : states)
+                Kernel::template combine<ResultType>(state, other_state, kernel_params);
+
+            /// Process the tail
+            for (; prev < off; ++prev)
+            {
+                Kernel::template accumulate<ResultType>(
+                    state, static_cast<ResultType>(data_x[prev]), static_cast<ResultType>(data_y[prev]), kernel_params);
+            }
+            result_data[row] = Kernel::finalize(state, kernel_params);
+            row++;
+        }
+        return result;
+    }
+
+    /// Special case when the 1st parameter is Const
+    template <typename ResultType, typename FirstArgType, typename SecondArgType>
+    ColumnPtr executeWithTypesFirstArgConst(ColumnPtr col_x, ColumnPtr col_y, size_t input_rows_count, const ColumnsWithTypeAndName & arguments) const
+    {
+        col_x = assert_cast<const ColumnConst *>(col_x.get())->getDataColumnPtr();
+        col_y = col_y->convertToFullColumnIfConst();
+
+        const auto & array_x = *assert_cast<const ColumnArray *>(col_x.get());
+        const auto & array_y = *assert_cast<const ColumnArray *>(col_y.get());
+
+        const auto & data_x = typeid_cast<const ColumnVector<FirstArgType> &>(array_x.getData()).getData();
+        const auto & data_y = typeid_cast<const ColumnVector<SecondArgType> &>(array_y.getData()).getData();
+
+        const auto & offsets_x = array_x.getOffsets();
+        const auto & offsets_y = array_y.getOffsets();
+
+        /// Check that arrays in both columns are the sames size
+        ColumnArray::Offset prev_offset = 0;
+        for (size_t row : collections::range(0, offsets_y.size()))
+        {
+            if (unlikely(offsets_x[0] != offsets_y[row] - prev_offset))
+            {
+                throw Exception(
+                    ErrorCodes::SIZES_OF_ARRAYS_DOESNT_MATCH,
+                    "Arguments of function {} have different array sizes: {} and {}",
+                    getName(),
+                    offsets_x[0],
+                    offsets_y[row] - prev_offset);
+            }
+            prev_offset = offsets_y[row];
+        }
+
+        const typename Kernel::ConstParams kernel_params = initConstParams(arguments);
+
+        auto result = ColumnVector<ResultType>::create(input_rows_count);
+        auto & result_data = result->getData();
+
+        /// Do the actual computation
+        ColumnArray::Offset prev = 0;
+        size_t row = 0;
+        for (auto off : offsets_y)
+        {
+            /// Process chunks in vectorized manner
+            static constexpr size_t VEC_SIZE = 4;
+            typename Kernel::template State<ResultType> states[VEC_SIZE];
+            size_t i = 0;
+            for (; prev + VEC_SIZE < off; i += VEC_SIZE, prev += VEC_SIZE)
+            {
+                for (size_t s = 0; s < VEC_SIZE; ++s)
+                    Kernel::template accumulate<ResultType>(
+                        states[s], static_cast<ResultType>(data_x[i + s]), static_cast<ResultType>(data_y[prev + s]), kernel_params);
+            }
+
+            typename Kernel::template State<ResultType> state;
+            for (const auto & other_state : states)
+                Kernel::template combine<ResultType>(state, other_state, kernel_params);
+
+            /// Process the tail
+            for (; prev < off; ++i, ++prev)
+            {
+                Kernel::template accumulate<ResultType>(
+                    state, static_cast<ResultType>(data_x[i]), static_cast<ResultType>(data_y[prev]), kernel_params);
+            }
+            result_data[row] = Kernel::finalize(state, kernel_params);
+            row++;
+        }
+        return result;
+    }
+
+    typename Kernel::ConstParams initConstParams(const ColumnsWithTypeAndName &) const { return {}; }
+};
+
+
+template <>
+size_t FunctionArrayDistance<LpDistance>::getNumberOfArguments() const { return 3; }
+
+template <>
+ColumnNumbers FunctionArrayDistance<LpDistance>::getArgumentsThatAreAlwaysConstant() const { return {2}; }
+
+template <>
+LpDistance::ConstParams FunctionArrayDistance<LpDistance>::initConstParams(const ColumnsWithTypeAndName & arguments) const
+{
+    if (arguments.size() < 3)
+        throw Exception(
+                    ErrorCodes::LOGICAL_ERROR,
+                    "Argument p of function {} was not provided",
+                    getName());
+
+    if (!arguments[2].column->isNumeric())
+        throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Argument p of function {} must be numeric constant",
+                    getName());
+
+    if (!isColumnConst(*arguments[2].column) && arguments[2].column->size() != 1)
+        throw Exception(
+                    ErrorCodes::ILLEGAL_COLUMN,
+                    "Second argument for function {} must be either constant Float64 or constant UInt",
+                    getName());
+
+    Float64 p = arguments[2].column->getFloat64(0);
+    if (p < 1 || p >= HUGE_VAL)
+        throw Exception(
+                    ErrorCodes::ARGUMENT_OUT_OF_BOUND,
+                    "Second argument for function {} must be not less than one and not be an infinity",
+                    getName());
+
+    return LpDistance::ConstParams{p, 1 / p};
+}
+
+/// These functions are used by TupleOrArrayFunction
+FunctionPtr createFunctionArrayL1Distance(ContextPtr context_) { return FunctionArrayDistance<L1Distance>::create(context_); }
+FunctionPtr createFunctionArrayL2Distance(ContextPtr context_) { return FunctionArrayDistance<L2Distance>::create(context_); }
+FunctionPtr createFunctionArrayL2SquaredDistance(ContextPtr context_) { return FunctionArrayDistance<L2SquaredDistance>::create(context_); }
+FunctionPtr createFunctionArrayLpDistance(ContextPtr context_) { return FunctionArrayDistance<LpDistance>::create(context_); }
+FunctionPtr createFunctionArrayLinfDistance(ContextPtr context_) { return FunctionArrayDistance<LinfDistance>::create(context_); }
+FunctionPtr createFunctionArrayCosineDistance(ContextPtr context_) { return FunctionArrayDistance<CosineDistance>::create(context_); }
+}
diff --git a/src/Functions/array/arrayNorm.cpp b/src/Functions/array/arrayNorm.cpp
new file mode 100644
index 0000000000..e14133f931
--- /dev/null
+++ b/src/Functions/array/arrayNorm.cpp
@@ -0,0 +1,323 @@
+#include <cmath>
+#include <Columns/ColumnArray.h>
+#include <Columns/ColumnsNumber.h>
+#include <Columns/IColumn.h>
+#include <DataTypes/DataTypeArray.h>
+#include <DataTypes/DataTypesNumber.h>
+#include <DataTypes/IDataType.h>
+#include <DataTypes/getLeastSupertype.h>
+#include <Functions/FunctionFactory.h>
+#include <Functions/FunctionHelpers.h>
+
+namespace DB
+{
+namespace ErrorCodes
+{
+    extern const int ILLEGAL_COLUMN;
+    extern const int ILLEGAL_TYPE_OF_ARGUMENT;
+    extern const int LOGICAL_ERROR;
+    extern const int ARGUMENT_OUT_OF_BOUND;
+}
+
+struct L1Norm
+{
+    static constexpr auto name = "L1";
+
+    struct ConstParams {};
+
+    template <typename ResultType>
+    inline static ResultType accumulate(ResultType result, ResultType value, const ConstParams &)
+    {
+        return result + fabs(value);
+    }
+
+    template <typename ResultType>
+    inline static ResultType combine(ResultType result, ResultType other_result, const ConstParams &)
+    {
+        return result + other_result;
+    }
+
+    template <typename ResultType>
+    inline static ResultType finalize(ResultType result, const ConstParams &)
+    {
+        return result;
+    }
+};
+
+struct L2Norm
+{
+    static constexpr auto name = "L2";
+
+    struct ConstParams {};
+
+    template <typename ResultType>
+    inline static ResultType accumulate(ResultType result, ResultType value, const ConstParams &)
+    {
+        return result + value * value;
+    }
+
+    template <typename ResultType>
+    inline static ResultType combine(ResultType result, ResultType other_result, const ConstParams &)
+    {
+        return result + other_result;
+    }
+
+    template <typename ResultType>
+    inline static ResultType finalize(ResultType result, const ConstParams &)
+    {
+        return sqrt(result);
+    }
+};
+
+struct L2SquaredNorm : L2Norm
+{
+    static constexpr auto name = "L2Squared";
+
+    template <typename ResultType>
+    inline static ResultType finalize(ResultType result, const ConstParams &)
+    {
+        return result;
+    }
+};
+
+
+struct LpNorm
+{
+    static constexpr auto name = "Lp";
+
+    struct ConstParams
+    {
+        Float64 power;
+        Float64 inverted_power = 1 / power;
+    };
+
+    template <typename ResultType>
+    inline static ResultType accumulate(ResultType result, ResultType value, const ConstParams & params)
+    {
+        return result + static_cast<ResultType>(std::pow(fabs(value), params.power));
+    }
+
+    template <typename ResultType>
+    inline static ResultType combine(ResultType result, ResultType other_result, const ConstParams &)
+    {
+        return result + other_result;
+    }
+
+    template <typename ResultType>
+    inline static ResultType finalize(ResultType result, const ConstParams & params)
+    {
+        return static_cast<ResultType>(std::pow(result, params.inverted_power));
+    }
+};
+
+struct LinfNorm
+{
+    static constexpr auto name = "Linf";
+
+    struct ConstParams {};
+
+    template <typename ResultType>
+    inline static ResultType accumulate(ResultType result, ResultType value, const ConstParams &)
+    {
+        return fmax(result, fabs(value));
+    }
+
+    template <typename ResultType>
+    inline static ResultType combine(ResultType result, ResultType other_result, const ConstParams &)
+    {
+        return fmax(result, other_result);
+    }
+
+    template <typename ResultType>
+    inline static ResultType finalize(ResultType result, const ConstParams &)
+    {
+        return result;
+    }
+};
+
+
+template <class Kernel>
+class FunctionArrayNorm : public IFunction
+{
+public:
+    String getName() const override { static auto name = String("array") + Kernel::name + "Norm"; return name; }
+    static FunctionPtr create(ContextPtr) { return std::make_shared<FunctionArrayNorm<Kernel>>(); }
+    size_t getNumberOfArguments() const override { return 1; }
+    ColumnNumbers getArgumentsThatAreAlwaysConstant() const override { return {}; }
+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return true; }
+    bool useDefaultImplementationForConstants() const override { return true; }
+
+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override
+    {
+        const auto * array_type = checkAndGetDataType<DataTypeArray>(arguments[0].type.get());
+        if (!array_type)
+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, "Argument of function {} must be array.", getName());
+
+        switch (array_type->getNestedType()->getTypeId())
+        {
+            case TypeIndex::UInt8:
+            case TypeIndex::UInt16:
+            case TypeIndex::UInt32:
+            case TypeIndex::Int8:
+            case TypeIndex::Int16:
+            case TypeIndex::Int32:
+            case TypeIndex::UInt64:
+            case TypeIndex::Int64:
+            case TypeIndex::Float64:
+                return std::make_shared<DataTypeFloat64>();
+            case TypeIndex::Float32:
+                return std::make_shared<DataTypeFloat32>();
+            default:
+                throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Arguments of function {} has nested type {}. "
+                    "Support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.",
+                    getName(), array_type->getNestedType()->getName());
+        }
+    }
+
+    ColumnPtr
+    executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr & result_type, size_t input_rows_count) const override
+    {
+        DataTypePtr type = typeid_cast<const DataTypeArray *>(arguments[0].type.get())->getNestedType();
+        ColumnPtr column = arguments[0].column->convertToFullColumnIfConst();
+        const auto * arr = assert_cast<const ColumnArray *>(column.get());
+
+        switch (result_type->getTypeId())
+        {
+            case TypeIndex::Float32:
+                return executeWithResultType<Float32>(*arr, type, input_rows_count, arguments);
+                break;
+            case TypeIndex::Float64:
+                return executeWithResultType<Float64>(*arr, type, input_rows_count, arguments);
+                break;
+            default:
+                throw Exception(ErrorCodes::LOGICAL_ERROR, "Unexpected result type {}", result_type->getName());
+        }
+    }
+
+private:
+
+#define SUPPORTED_TYPES(action) \
+    action(UInt8)   \
+    action(UInt16)  \
+    action(UInt32)  \
+    action(UInt64)  \
+    action(Int8)    \
+    action(Int16)   \
+    action(Int32)   \
+    action(Int64)   \
+    action(Float32) \
+    action(Float64)
+
+
+    template <typename ResultType>
+    ColumnPtr executeWithResultType(const ColumnArray & array, const DataTypePtr & nested_type, size_t input_rows_count, const ColumnsWithTypeAndName & arguments) const
+    {
+        switch (nested_type->getTypeId())
+        {
+        #define ON_TYPE(type) \
+            case TypeIndex::type: \
+                return executeWithTypes<ResultType, type>(array, input_rows_count, arguments); \
+                break;
+
+            SUPPORTED_TYPES(ON_TYPE)
+        #undef ON_TYPE
+
+            default:
+                throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Arguments of function {} has nested type {}. "
+                    "Support: UInt8, UInt16, UInt32, UInt64, Int8, Int16, Int32, Int64, Float32, Float64.",
+                    getName(), nested_type->getName());
+        }
+    }
+
+    template <typename ResultType, typename ArgumentType>
+    ColumnPtr executeWithTypes(const ColumnArray & array, size_t input_rows_count, const ColumnsWithTypeAndName & arguments) const
+    {
+        const auto & data = typeid_cast<const ColumnVector<ArgumentType> &>(array.getData()).getData();
+        const auto & offsets = array.getOffsets();
+
+        auto result_col = ColumnVector<ResultType>::create(input_rows_count);
+        auto & result_data = result_col->getData();
+
+        const typename Kernel::ConstParams kernel_params = initConstParams(arguments);
+
+        ColumnArray::Offset prev = 0;
+        size_t row = 0;
+        for (auto off : offsets)
+        {
+            /// Process chunks in vectorized manner
+            static constexpr size_t VEC_SIZE = 4;
+            ResultType results[VEC_SIZE] = {0};
+            for (; prev + VEC_SIZE < off; prev += VEC_SIZE)
+            {
+                for (size_t s = 0; s < VEC_SIZE; ++s)
+                    results[s] = Kernel::template accumulate<ResultType>(results[s], static_cast<ResultType>(data[prev + s]), kernel_params);
+            }
+
+            ResultType result = 0;
+            for (const auto & other_state : results)
+                result = Kernel::template combine<ResultType>(result, other_state, kernel_params);
+
+            /// Process the tail
+            for (; prev < off; ++prev)
+            {
+                result = Kernel::template accumulate<ResultType>(result, static_cast<ResultType>(data[prev]), kernel_params);
+            }
+            result_data[row] = Kernel::finalize(result, kernel_params);
+            row++;
+        }
+        return result_col;
+    }
+
+    typename Kernel::ConstParams initConstParams(const ColumnsWithTypeAndName &) const { return {}; }
+};
+
+template <>
+size_t FunctionArrayNorm<LpNorm>::getNumberOfArguments() const { return 2; }
+
+template <>
+ColumnNumbers FunctionArrayNorm<LpNorm>::getArgumentsThatAreAlwaysConstant() const { return {1}; }
+
+template <>
+LpNorm::ConstParams FunctionArrayNorm<LpNorm>::initConstParams(const ColumnsWithTypeAndName & arguments) const
+{
+    if (arguments.size() < 2)
+        throw Exception(
+                    ErrorCodes::LOGICAL_ERROR,
+                    "Argument p of function {} was not provided",
+                    getName());
+
+    if (!arguments[1].column->isNumeric())
+        throw Exception(
+                    ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT,
+                    "Argument p of function {} must be numeric constant",
+                    getName());
+
+    if (!isColumnConst(*arguments[1].column) && arguments[1].column->size() != 1)
+        throw Exception(
+                    ErrorCodes::ILLEGAL_COLUMN,
+                    "Second argument for function {} must be either constant Float64 or constant UInt",
+                    getName());
+
+    Float64 p = arguments[1].column->getFloat64(0);
+    if (p < 1 || p >= HUGE_VAL)
+        throw Exception(
+                    ErrorCodes::ARGUMENT_OUT_OF_BOUND,
+                    "Second argument for function {} must be not less than one and not be an infinity",
+                    getName());
+
+    return LpNorm::ConstParams{p, 1 / p};
+}
+
+
+/// These functions are used by TupleOrArrayFunction
+FunctionPtr createFunctionArrayL1Norm(ContextPtr context_) { return FunctionArrayNorm<L1Norm>::create(context_); }
+FunctionPtr createFunctionArrayL2Norm(ContextPtr context_) { return FunctionArrayNorm<L2Norm>::create(context_); }
+FunctionPtr createFunctionArrayL2SquaredNorm(ContextPtr context_) { return FunctionArrayNorm<L2SquaredNorm>::create(context_); }
+FunctionPtr createFunctionArrayLpNorm(ContextPtr context_) { return FunctionArrayNorm<LpNorm>::create(context_); }
+FunctionPtr createFunctionArrayLinfNorm(ContextPtr context_) { return FunctionArrayNorm<LinfNorm>::create(context_); }
+
+}
diff --git a/src/Functions/vectorFunctions.cpp b/src/Functions/vectorFunctions.cpp
index 62cfdcd9ee..8607666b9d 100644
--- a/src/Functions/vectorFunctions.cpp
+++ b/src/Functions/vectorFunctions.cpp
@@ -1,4 +1,5 @@
 #include <Columns/ColumnTuple.h>
+#include <DataTypes/DataTypeArray.h>
 #include <DataTypes/DataTypeTuple.h>
 #include <DataTypes/DataTypesNumber.h>
 #include <DataTypes/DataTypeNothing.h>
@@ -18,6 +19,7 @@ namespace ErrorCodes
 
 struct PlusName { static constexpr auto name = "plus"; };
 struct MinusName { static constexpr auto name = "minus"; };
+struct L2SquaredLabel { static constexpr auto name = "2Squared"; };
 struct MultiplyName { static constexpr auto name = "multiply"; };
 struct DivideName { static constexpr auto name = "divide"; };
 
@@ -519,10 +521,10 @@ public:
 using FunctionL1Norm = FunctionLNorm<L1Label>;
 
 template <>
-class FunctionLNorm<L2Label> : public ITupleFunction
+class FunctionLNorm<L2SquaredLabel> : public ITupleFunction
 {
 public:
-    static constexpr auto name = "L2Norm";
+    static constexpr auto name = "L2SquaredNorm";
 
     explicit FunctionLNorm(ContextPtr context_) : ITupleFunction(context_) {}
     static FunctionPtr create(ContextPtr context_) { return std::make_shared<FunctionLNorm>(context_); }
@@ -577,8 +579,7 @@ public:
             }
         }
 
-        auto sqrt = FunctionFactory::instance().get("sqrt", context);
-        return sqrt->build({ColumnWithTypeAndName{res_type, {}}})->getResultType();
+        return res_type;
     }
 
     ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override
@@ -616,9 +617,56 @@ public:
             }
         }
 
+        return res.column;
+    }
+};
+using FunctionL2SquaredNorm = FunctionLNorm<L2SquaredLabel>;
+
+template <>
+class FunctionLNorm<L2Label> : public FunctionL2SquaredNorm
+{
+private:
+    using Base =  FunctionL2SquaredNorm;
+public:
+    static constexpr auto name = "L2Norm";
+
+    explicit FunctionLNorm(ContextPtr context_) : Base(context_) {}
+    static FunctionPtr create(ContextPtr context_) { return std::make_shared<FunctionLNorm>(context_); }
+
+    String getName() const override { return name; }
+
+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override
+    {
+        const auto * cur_tuple = checkAndGetDataType<DataTypeTuple>(arguments[0].type.get());
+
+        if (!cur_tuple)
+            throw Exception(ErrorCodes::ILLEGAL_TYPE_OF_ARGUMENT, "Argument 0 of function {} should be tuple, got {}",
+                            getName(), arguments[0].type->getName());
+
+        const auto & cur_types = cur_tuple->getElements();
+        size_t tuple_size = cur_types.size();
+        if (tuple_size == 0)
+            return std::make_shared<DataTypeUInt8>();
+
         auto sqrt = FunctionFactory::instance().get("sqrt", context);
-        auto sqrt_elem = sqrt->build({res});
-        return sqrt_elem->execute({res}, sqrt_elem->getResultType(), input_rows_count);
+        return sqrt->build({ColumnWithTypeAndName{Base::getReturnTypeImpl(arguments), {}}})->getResultType();
+    }
+
+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override
+    {
+        auto cur_elements = getTupleElements(*arguments[0].column);
+
+        size_t tuple_size = cur_elements.size();
+        if (tuple_size == 0)
+            return DataTypeUInt8().createColumnConstWithDefaultValue(input_rows_count);
+
+        ColumnWithTypeAndName squared_res;
+        squared_res.type = Base::getReturnTypeImpl(arguments);
+        squared_res.column = Base::executeImpl(arguments, squared_res.type, input_rows_count);
+
+        auto sqrt = FunctionFactory::instance().get("sqrt", context);
+        auto sqrt_elem = sqrt->build({squared_res});
+        return sqrt_elem->execute({squared_res}, sqrt_elem->getResultType(), input_rows_count);
     }
 };
 using FunctionL2Norm = FunctionLNorm<L2Label>;
@@ -808,17 +856,21 @@ public:
 
         const auto & p_column = arguments[1];
 
-        const auto * p_column_const = assert_cast<const ColumnConst *>(p_column.column.get());
+        if (!isColumnConst(*p_column.column) && p_column.column->size() != 1)
+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Second argument for function {} must be either constant Float64 or constant UInt", getName());
+
         double p;
-        if (isFloat(p_column_const->getDataType()))
-            p = p_column_const->getFloat64(0);
-        else if (isUnsignedInteger(p_column_const->getDataType()))
-            p = p_column_const->getUInt(0);
+        if (isFloat(p_column.column->getDataType()))
+            p = p_column.column->getFloat64(0);
+        else if (isUnsignedInteger(p_column.column->getDataType()))
+            p = p_column.column->getUInt(0);
         else
-            throw Exception{"Second argument for function " + getName() + " must be either constant Float64 or constant UInt", ErrorCodes::ILLEGAL_COLUMN};
+            throw Exception(ErrorCodes::ILLEGAL_COLUMN, "Second argument for function {} must be either constant Float64 or constant UInt", getName());
 
-        if (p < 1 || p == HUGE_VAL)
-            throw Exception{"Second argument for function " + getName() + " must be not less than one and not be an infinity", ErrorCodes::ARGUMENT_OUT_OF_BOUND};
+        if (p < 1 || p >= HUGE_VAL)
+            throw Exception(ErrorCodes::ARGUMENT_OUT_OF_BOUND,
+                            "Second argument for function {} must be not less than one and not be an infinity",
+                            getName());
 
         auto abs = FunctionFactory::instance().get("abs", context);
         auto pow = FunctionFactory::instance().get("pow", context);
@@ -926,6 +978,8 @@ using FunctionL1Distance = FunctionLDistance<L1Label>;
 
 using FunctionL2Distance = FunctionLDistance<L2Label>;
 
+using FunctionL2SquaredDistance = FunctionLDistance<L2SquaredLabel>;
+
 using FunctionLinfDistance = FunctionLDistance<LinfLabel>;
 
 using FunctionLpDistance = FunctionLDistance<LpLabel>;
@@ -1065,6 +1119,159 @@ public:
     }
 };
 
+/// An adaptor to call Norm/Distance function for tuple or array depending on the 1st argument type
+template <class Traits>
+class TupleOrArrayFunction : public IFunction
+{
+public:
+    static constexpr auto name = Traits::name;
+
+    explicit TupleOrArrayFunction(ContextPtr context_)
+        : IFunction()
+        , tuple_function(Traits::CreateTupleFunction(context_))
+        , array_function(Traits::CreateArrayFunction(context_)) {}
+
+    static FunctionPtr create(ContextPtr context_) { return std::make_shared<TupleOrArrayFunction>(context_); }
+
+    String getName() const override { return name; }
+
+    size_t getNumberOfArguments() const override { return tuple_function->getNumberOfArguments(); }
+
+    bool useDefaultImplementationForConstants() const override { return true; }
+
+    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return false; }
+
+    DataTypePtr getReturnTypeImpl(const ColumnsWithTypeAndName & arguments) const override
+    {
+        bool is_array = checkDataTypes<DataTypeArray>(arguments[0].type.get());
+        return (is_array ? array_function : tuple_function)->getReturnTypeImpl(arguments);
+    }
+
+    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr & result_type, size_t input_rows_count) const override
+    {
+        bool is_array = checkDataTypes<DataTypeArray>(arguments[0].type.get());
+        return (is_array ? array_function : tuple_function)->executeImpl(arguments, result_type, input_rows_count);
+    }
+
+private:
+    FunctionPtr tuple_function;
+    FunctionPtr array_function;
+};
+
+extern FunctionPtr createFunctionArrayL1Norm(ContextPtr context_);
+extern FunctionPtr createFunctionArrayL2Norm(ContextPtr context_);
+extern FunctionPtr createFunctionArrayL2SquaredNorm(ContextPtr context_);
+extern FunctionPtr createFunctionArrayLpNorm(ContextPtr context_);
+extern FunctionPtr createFunctionArrayLinfNorm(ContextPtr context_);
+
+extern FunctionPtr createFunctionArrayL1Distance(ContextPtr context_);
+extern FunctionPtr createFunctionArrayL2Distance(ContextPtr context_);
+extern FunctionPtr createFunctionArrayL2SquaredDistance(ContextPtr context_);
+extern FunctionPtr createFunctionArrayLpDistance(ContextPtr context_);
+extern FunctionPtr createFunctionArrayLinfDistance(ContextPtr context_);
+extern FunctionPtr createFunctionArrayCosineDistance(ContextPtr context_);
+
+struct L1NormTraits
+{
+    static constexpr auto name = "L1Norm";
+
+    static constexpr auto CreateTupleFunction = FunctionL1Norm::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayL1Norm;
+};
+
+struct L2NormTraits
+{
+    static constexpr auto name = "L2Norm";
+
+    static constexpr auto CreateTupleFunction = FunctionL2Norm::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayL2Norm;
+};
+
+struct L2SquaredNormTraits
+{
+    static constexpr auto name = "L2SquaredNorm";
+
+    static constexpr auto CreateTupleFunction = FunctionL2SquaredNorm::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayL2SquaredNorm;
+};
+
+struct LpNormTraits
+{
+    static constexpr auto name = "LpNorm";
+
+    static constexpr auto CreateTupleFunction = FunctionLpNorm::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayLpNorm;
+};
+
+struct LinfNormTraits
+{
+    static constexpr auto name = "LinfNorm";
+
+    static constexpr auto CreateTupleFunction = FunctionLinfNorm::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayLinfNorm;
+};
+
+struct L1DistanceTraits
+{
+    static constexpr auto name = "L1Distance";
+
+    static constexpr auto CreateTupleFunction = FunctionL1Distance::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayL1Distance;
+};
+
+struct L2DistanceTraits
+{
+    static constexpr auto name = "L2Distance";
+
+    static constexpr auto CreateTupleFunction = FunctionL2Distance::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayL2Distance;
+};
+
+struct L2SquaredDistanceTraits
+{
+    static constexpr auto name = "L2SquaredDistance";
+
+    static constexpr auto CreateTupleFunction = FunctionL2SquaredDistance::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayL2SquaredDistance;
+};
+
+struct LpDistanceTraits
+{
+    static constexpr auto name = "LpDistance";
+
+    static constexpr auto CreateTupleFunction = FunctionLpDistance::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayLpDistance;
+};
+
+struct LinfDistanceTraits
+{
+    static constexpr auto name = "LinfDistance";
+
+    static constexpr auto CreateTupleFunction = FunctionLinfDistance::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayLinfDistance;
+};
+
+struct CosineDistanceTraits
+{
+    static constexpr auto name = "cosineDistance";
+
+    static constexpr auto CreateTupleFunction = FunctionCosineDistance::create;
+    static constexpr auto CreateArrayFunction = createFunctionArrayCosineDistance;
+};
+
+using TupleOrArrayFunctionL1Norm = TupleOrArrayFunction<L1NormTraits>;
+using TupleOrArrayFunctionL2Norm = TupleOrArrayFunction<L2NormTraits>;
+using TupleOrArrayFunctionL2SquaredNorm = TupleOrArrayFunction<L2SquaredNormTraits>;
+using TupleOrArrayFunctionLpNorm = TupleOrArrayFunction<LpNormTraits>;
+using TupleOrArrayFunctionLinfNorm = TupleOrArrayFunction<LinfNormTraits>;
+
+using TupleOrArrayFunctionL1Distance = TupleOrArrayFunction<L1DistanceTraits>;
+using TupleOrArrayFunctionL2Distance = TupleOrArrayFunction<L2DistanceTraits>;
+using TupleOrArrayFunctionL2SquaredDistance = TupleOrArrayFunction<L2SquaredDistanceTraits>;
+using TupleOrArrayFunctionLpDistance = TupleOrArrayFunction<LpDistanceTraits>;
+using TupleOrArrayFunctionLinfDistance = TupleOrArrayFunction<LinfDistanceTraits>;
+using TupleOrArrayFunctionCosineDistance = TupleOrArrayFunction<CosineDistanceTraits>;
+
 void registerVectorFunctions(FunctionFactory & factory)
 {
     factory.registerFunction<FunctionTuplePlus>();
@@ -1081,23 +1288,27 @@ void registerVectorFunctions(FunctionFactory & factory)
     factory.registerFunction<FunctionDotProduct>();
     factory.registerAlias("scalarProduct", FunctionDotProduct::name, FunctionFactory::CaseInsensitive);
 
-    factory.registerFunction<FunctionL1Norm>();
-    factory.registerFunction<FunctionL2Norm>();
-    factory.registerFunction<FunctionLinfNorm>();
-    factory.registerFunction<FunctionLpNorm>();
+    factory.registerFunction<TupleOrArrayFunctionL1Norm>();
+    factory.registerFunction<TupleOrArrayFunctionL2Norm>();
+    factory.registerFunction<TupleOrArrayFunctionL2SquaredNorm>();
+    factory.registerFunction<TupleOrArrayFunctionLinfNorm>();
+    factory.registerFunction<TupleOrArrayFunctionLpNorm>();
 
-    factory.registerAlias("normL1", FunctionL1Norm::name, FunctionFactory::CaseInsensitive);
-    factory.registerAlias("normL2", FunctionL2Norm::name, FunctionFactory::CaseInsensitive);
-    factory.registerAlias("normLinf", FunctionLinfNorm::name, FunctionFactory::CaseInsensitive);
+    factory.registerAlias("normL1", TupleOrArrayFunctionL1Norm::name, FunctionFactory::CaseInsensitive);
+    factory.registerAlias("normL2", TupleOrArrayFunctionL2Norm::name, FunctionFactory::CaseInsensitive);
+    factory.registerAlias("normL2Squared", TupleOrArrayFunctionL2SquaredNorm::name, FunctionFactory::CaseInsensitive);
+    factory.registerAlias("normLinf", TupleOrArrayFunctionLinfNorm::name, FunctionFactory::CaseInsensitive);
     factory.registerAlias("normLp", FunctionLpNorm::name, FunctionFactory::CaseInsensitive);
 
-    factory.registerFunction<FunctionL1Distance>();
-    factory.registerFunction<FunctionL2Distance>();
-    factory.registerFunction<FunctionLinfDistance>();
-    factory.registerFunction<FunctionLpDistance>();
+    factory.registerFunction<TupleOrArrayFunctionL1Distance>();
+    factory.registerFunction<TupleOrArrayFunctionL2Distance>();
+    factory.registerFunction<TupleOrArrayFunctionL2SquaredDistance>();
+    factory.registerFunction<TupleOrArrayFunctionLinfDistance>();
+    factory.registerFunction<TupleOrArrayFunctionLpDistance>();
 
     factory.registerAlias("distanceL1", FunctionL1Distance::name, FunctionFactory::CaseInsensitive);
     factory.registerAlias("distanceL2", FunctionL2Distance::name, FunctionFactory::CaseInsensitive);
+    factory.registerAlias("distanceL2Squared", FunctionL2SquaredDistance::name, FunctionFactory::CaseInsensitive);
     factory.registerAlias("distanceLinf", FunctionLinfDistance::name, FunctionFactory::CaseInsensitive);
     factory.registerAlias("distanceLp", FunctionLpDistance::name, FunctionFactory::CaseInsensitive);
 
@@ -1111,6 +1322,6 @@ void registerVectorFunctions(FunctionFactory & factory)
     factory.registerAlias("normalizeLinf", FunctionLinfNormalize::name, FunctionFactory::CaseInsensitive);
     factory.registerAlias("normalizeLp", FunctionLpNormalize::name, FunctionFactory::CaseInsensitive);
 
-    factory.registerFunction<FunctionCosineDistance>();
+    factory.registerFunction<TupleOrArrayFunctionCosineDistance>();
 }
 }
diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp
index 6d3613d33e..7655e824c1 100644
--- a/src/Interpreters/Context.cpp
+++ b/src/Interpreters/Context.cpp
@@ -3304,4 +3304,19 @@ ReadSettings Context::getReadSettings() const
     return res;
 }
 
+std::optional<VectorScanDescription> Context::getVecScanDescription() const
+{
+    return vector_scan_description;
+}
+
+void Context::setVecScanDescription(VectorScanDescription & vec_scan_desc) const
+{
+    vector_scan_description = vec_scan_desc;
+}
+
+void Context::resetVecScanDescription() const
+{
+    vector_scan_description.reset();
+}
+
 }
diff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h
index 7d644ea9b7..fc565bc302 100644
--- a/src/Interpreters/Context.h
+++ b/src/Interpreters/Context.h
@@ -12,6 +12,7 @@
 #include <Interpreters/Context_fwd.h>
 #include <Interpreters/DatabaseCatalog.h>
 #include <Interpreters/MergeTreeTransactionHolder.h>
+#include <Interpreters/VectorScanDescription.h>
 #include <Parsers/IAST_fwd.h>
 #include <Storages/IStorage_fwd.h>
 #include <Common/MultiVersion.h>
@@ -314,6 +315,10 @@ private:
     /// A flag, used to mark if reader needs to apply deleted rows mask.
     bool apply_deleted_mask = true;
 
+    /// TODO: will be enhanced similar as scalars.
+    /// Used when vector scan func exists in right joined table
+    mutable std::optional<VectorScanDescription> vector_scan_description;
+
 public:
     // Top-level OpenTelemetry trace context for the query. Makes sense only for a query context.
     OpenTelemetryTraceContext query_trace_context;
@@ -925,6 +930,11 @@ public:
     /** Get settings for reading from filesystem. */
     ReadSettings getReadSettings() const;
 
+    /// Used for vector scan functions
+    std::optional<VectorScanDescription> getVecScanDescription() const;
+    void setVecScanDescription(VectorScanDescription & vec_scan_desc) const;
+    void resetVecScanDescription() const;
+
 private:
     std::unique_lock<std::recursive_mutex> getLock() const;
 
diff --git a/src/Interpreters/ExpressionAnalyzer.cpp b/src/Interpreters/ExpressionAnalyzer.cpp
index 4489273a19..84a4a737d1 100644
--- a/src/Interpreters/ExpressionAnalyzer.cpp
+++ b/src/Interpreters/ExpressionAnalyzer.cpp
@@ -261,7 +261,7 @@ ExpressionAnalyzer::ExpressionAnalyzer(
     /// will contain out-of-date information, which will lead to an error when the query is executed.
     analyzeAggregation(temp_actions);
 
-    analyzeVectorScan();
+    analyzeVectorScan(temp_actions);
 }
 
 NamesAndTypesList ExpressionAnalyzer::getColumnsAfterArrayJoin(ActionsDAGPtr & actions, const NamesAndTypesList & src_columns)
@@ -419,11 +419,32 @@ void ExpressionAnalyzer::analyzeAggregation(ActionsDAGPtr & temp_actions)
 }
 
 /// put vector scan ops column name into aggregated_columns
-void ExpressionAnalyzer::analyzeVectorScan()
+void ExpressionAnalyzer::analyzeVectorScan(ActionsDAGPtr & temp_actions)
 {
-    auto temp_actions = std::make_shared<ActionsDAG>(sourceColumns());
-    // auto * select_query = query->as<ASTSelectQuery>();
-    has_vector_scan = makeVectorScanDescriptions(temp_actions);
+    if (!syntax->vector_scan_funcs.empty())
+        has_vector_scan = makeVectorScanDescriptions(temp_actions);
+    else if (auto vec_scan_desc = getContext()->getVecScanDescription())
+    {
+        /// vector search column exists in right joined table
+        vector_scan_descriptions.emplace_back(*vec_scan_desc);
+        has_vector_scan = true;
+    }
+    /// Fill in dim from metadata
+    if (has_vector_scan)
+    {
+        if (syntax->storage_snapshot && syntax->storage_snapshot->metadata)
+        {
+            auto & vector_scan_desc = vector_scan_descriptions[0];
+            vector_scan_desc.search_column_dim
+                = syntax->storage_snapshot->metadata->getConstraints().getArrayLengthByColumnName(vector_scan_desc.search_column_name).first;
+            if (vector_scan_desc.search_column_dim == 0)
+            {
+                LOG_ERROR(log, "wrong type dim: 0, please check length constraint on search column.");
+                throw Exception(ErrorCodes::BAD_ARGUMENTS, "wrong type dim: 0, please check length constraint on search column.");
+            }
+            LOG_DEBUG(log, "type dim: {}", vector_scan_desc.search_column_dim);
+        }
+    }
 }
 
 void ExpressionAnalyzer::initGlobalSubqueriesAndExternalTables(bool do_global)
@@ -625,8 +646,15 @@ bool ExpressionAnalyzer::makeVectorScanDescriptions(ActionsDAGPtr & actions)
         vector_scan_desc.search_column_name = arguments[0]->getColumnName();
 
         std::optional<NameAndTypePair> search_column_type = std::nullopt;
-        if (syntax->storage_snapshot && syntax->storage_snapshot->metadata)
+        if (syntax->vector_from_right_table)
+        {
+            search_column_type = analyzedJoin().columnsFromJoinedTable().tryGetByName(vector_scan_desc.search_column_name);
+        }
+        else if (syntax->storage_snapshot && syntax->storage_snapshot->metadata)
+        {
+            /// Cannot use sourceColumns() as vector column is not needed
             search_column_type = syntax->storage_snapshot->metadata->columns.getAllPhysical().tryGetByName(vector_scan_desc.search_column_name);
+        }
 
         if (search_column_type)
         {
@@ -644,14 +672,7 @@ bool ExpressionAnalyzer::makeVectorScanDescriptions(ActionsDAGPtr & actions)
             throw Exception(ErrorCodes::BAD_ARGUMENTS,
                 "Search column {} should be Array type", vector_scan_desc.search_column_name);
 
-        vector_scan_desc.search_column_dim
-            = syntax->storage_snapshot->metadata->getConstraints().getArrayLengthByColumnName(vector_scan_desc.search_column_name).first;
-        if (vector_scan_desc.search_column_dim == 0)
-        {
-            LOG_ERROR(log, "wrong type dim: 0, please check length constraint on search column.");
-            throw Exception(ErrorCodes::BAD_ARGUMENTS, "wrong type dim: 0, please check length constraint on search column.");
-        }
-        LOG_DEBUG(log, "type dim: {}", vector_scan_desc.search_column_dim);
+        /// Not initialize dim here
 
         const auto * dag_node = actions->tryFindInIndex(arguments[1]->getColumnName());
         if (!dag_node)
@@ -688,12 +709,20 @@ bool ExpressionAnalyzer::makeVectorScanDescriptions(ActionsDAGPtr & actions)
             }
         }
 
+        /// top_k is get from limit N
+        vector_scan_desc.topk = syntax->limit_length;
+
         LOG_DEBUG(log, "[makeVectorScanDescriptions] create vector scan function: {}", node->name);
 
-        vector_scan_descriptions.push_back(vector_scan_desc);
+        if (syntax->vector_from_right_table)
+        {
+            analyzedJoin().setVecScanDescription(vector_scan_desc);
+        }
+        else
+            vector_scan_descriptions.push_back(vector_scan_desc);
     }
 
-    return !vector_scan_funcs().empty();
+    return !vector_scan_descriptions.empty();
 }
 
 void makeWindowDescriptionFromAST(const Context & context,
@@ -1053,6 +1082,14 @@ static std::unique_ptr<QueryPlan> buildJoinedPlan(
     TableJoin & analyzed_join,
     SelectQueryOptions query_options)
 {
+    /// Add vector scan description to Context for subquery of joined table
+    bool has_vector_scan = false;
+    if (auto vec_scan_desc = analyzed_join.getVecScanDescription())
+    {
+        has_vector_scan = true;
+        context->setVecScanDescription(*vec_scan_desc);
+    }
+
     /// Actions which need to be calculated on joined block.
     auto joined_block_actions = createJoinedBlockActions(context, analyzed_join);
     Names original_right_columns;
@@ -1097,6 +1134,10 @@ static std::unique_ptr<QueryPlan> buildJoinedPlan(
     joined_actions_step->setStepDescription("Joined actions");
     joined_plan->addStep(std::move(joined_actions_step));
 
+    /// Reset vector scan description
+    if (has_vector_scan)
+        context->resetVecScanDescription();
+
     return joined_plan;
 }
 
diff --git a/src/Interpreters/ExpressionAnalyzer.h b/src/Interpreters/ExpressionAnalyzer.h
index 78a1624a7c..ca7628840c 100644
--- a/src/Interpreters/ExpressionAnalyzer.h
+++ b/src/Interpreters/ExpressionAnalyzer.h
@@ -206,7 +206,7 @@ protected:
     void analyzeAggregation(ActionsDAGPtr & temp_actions);
     void makeAggregateDescriptions(ActionsDAGPtr & actions, AggregateDescriptions & descriptions);
 
-    void analyzeVectorScan();
+    void analyzeVectorScan(ActionsDAGPtr & temp_actions);
     bool makeVectorScanDescriptions(ActionsDAGPtr & actions);
 
     const ASTSelectQuery * getSelectQuery() const;
diff --git a/src/Interpreters/GetVectorScanVisitor.h b/src/Interpreters/GetVectorScanVisitor.h
index 9c6ef3bd02..a13f490bda 100644
--- a/src/Interpreters/GetVectorScanVisitor.h
+++ b/src/Interpreters/GetVectorScanVisitor.h
@@ -58,8 +58,6 @@ public:
 private:
     static void visit(ASTFunction & node, const ASTPtr &, Data & data)
     {
-        // throw Exception(ErrorCodes::ILLEGAL_VECTOR_SCAN, "Unknown function");
-        /// Poco::Logger * log = &Poco::Logger::get("GetVectorScanMatcher");
         if (isVectorScanFunc(node.name))
         {
             auto full_name = getFullName(node);
@@ -67,7 +65,7 @@ private:
                 return;
             
             if (data.assert_no_vector_scan)
-                throw Exception("Vector Scan function " + node.getColumnName()  + " is found " + String(data.assert_no_vector_scan) + " in query",
+                throw Exception("Vector Scan function " + full_name  + " is found " + String(data.assert_no_vector_scan) + " in query",
                                 ErrorCodes::ILLEGAL_VECTOR_SCAN);
             data.vector_scan_funcs.push_back(&node);
             data.uniq_names.insert(full_name);
diff --git a/src/Interpreters/InterpreterCreateQuery.cpp b/src/Interpreters/InterpreterCreateQuery.cpp
index 7aca18e23d..6964e7c4d3 100644
--- a/src/Interpreters/InterpreterCreateQuery.cpp
+++ b/src/Interpreters/InterpreterCreateQuery.cpp
@@ -630,9 +630,12 @@ InterpreterCreateQuery::TableProperties InterpreterCreateQuery::getTableProperti
 
         if (create.columns_list->indices)
             for (const auto & index : create.columns_list->indices->children)
+            {
                 properties.indices.push_back(
                     IndexDescription::getIndexFromAST(index->clone(), properties.columns, getContext()));
-
+                    if (properties.indices.back().type == "annoy" && !getContext()->getSettingsRef().allow_experimental_annoy_index)
+                        throw Exception("Annoy index is disabled. Turn on allow_experimental_annoy_index", ErrorCodes::INCORRECT_QUERY);
+            }
         if (create.columns_list->vec_indices)
             for (const auto & vec_index : create.columns_list->vec_indices->children)
                 properties.vec_indices.push_back(
diff --git a/src/Interpreters/TableJoin.cpp b/src/Interpreters/TableJoin.cpp
index 8ad201b78a..3f7c2f33a8 100644
--- a/src/Interpreters/TableJoin.cpp
+++ b/src/Interpreters/TableJoin.cpp
@@ -130,6 +130,7 @@ void TableJoin::resetCollected()
     renames.clear();
     left_type_map.clear();
     right_type_map.clear();
+    vector_scan_description.reset();
 }
 
 void TableJoin::addUsingKey(const ASTPtr & ast)
@@ -775,4 +776,14 @@ void TableJoin::resetToCross()
     this->table_join.kind = ASTTableJoin::Kind::Cross;
 }
 
+std::optional<VectorScanDescription> TableJoin::getVecScanDescription() const
+{
+    return vector_scan_description;
+}
+
+void TableJoin::setVecScanDescription(VectorScanDescription & vec_scan_desc) const
+{
+    vector_scan_description = vec_scan_desc;
+}
+
 }
diff --git a/src/Interpreters/TableJoin.h b/src/Interpreters/TableJoin.h
index 96c6e1c7da..1f6ee2b035 100644
--- a/src/Interpreters/TableJoin.h
+++ b/src/Interpreters/TableJoin.h
@@ -7,6 +7,7 @@
 #include <Interpreters/IJoin.h>
 #include <Interpreters/join_common.h>
 #include <Interpreters/asof.h>
+#include <Interpreters/VectorScanDescription.h>
 #include <QueryPipeline/SizeLimits.h>
 #include <DataTypes/getLeastSupertype.h>
 #include <Storages/IStorage_fwd.h>
@@ -102,6 +103,7 @@ private:
       */
 
     friend class TreeRewriter;
+    friend struct TreeRewriterResult;
 
     SizeLimits size_limits;
     const size_t default_max_bytes = 0;
@@ -132,6 +134,9 @@ private:
     /// Note: without corrected Nullability or type, see correctedColumnsAddedByJoin
     NamesAndTypesList columns_added_by_join;
 
+    /// vector scan functions from joined table
+    mutable std::optional<VectorScanDescription> vector_scan_description;
+
     /// Target type to convert key columns before join
     NameToTypeMap left_type_map;
     NameToTypeMap right_type_map;
@@ -302,6 +307,10 @@ public:
 
     bool isSpecialStorage() const { return right_storage_dictionary || right_storage_join; }
     const DictionaryReader * getDictionaryReader() const { return dictionary_reader.get(); }
+
+    /// Used for vector scan functions
+    std::optional<VectorScanDescription> getVecScanDescription() const;
+    void setVecScanDescription(VectorScanDescription & vec_scan_desc) const;
 };
 
 }
diff --git a/src/Interpreters/TreeRewriter.cpp b/src/Interpreters/TreeRewriter.cpp
index 6fdddd7086..9c8f4a5b7e 100644
--- a/src/Interpreters/TreeRewriter.cpp
+++ b/src/Interpreters/TreeRewriter.cpp
@@ -30,6 +30,7 @@
 #include <Interpreters/replaceAliasColumnsInQuery.h>
 #include <Interpreters/evaluateConstantExpression.h>
 #include <Interpreters/PredicateExpressionsOptimizer.h>
+#include <Interpreters/convertFieldToType.h>
 
 #include <Parsers/ASTExpressionList.h>
 #include <Parsers/ASTFunction.h>
@@ -49,11 +50,14 @@
 #include <IO/WriteHelpers.h>
 #include <Storages/IStorage.h>
 #include <Storages/MergeTree/MergeTreeData.h>
+#include <Storages/StorageInMemoryMetadata.h>
 
 #include <AggregateFunctions/AggregateFunctionFactory.h>
 #include <Interpreters/parseVectorScanParameters.h>
 #include <VectorIndex/VectorIndexCommon.h>
 
+#include <Parsers/formatAST.h>
+
 namespace DB
 {
 
@@ -744,6 +748,8 @@ std::vector<const ASTFunction *> getAggregates(ASTPtr & query, const ASTSelectQu
                 // We also can't have window functions inside aggregate functions,
                 // because the window functions are calculated later.
                 assertNoWindows(arg, "inside an aggregate function");
+                /// Currently not support distance function inside aggregate functions
+                assertNoVectorScan(arg, "inside an aggregate function");
             }
         }
     }
@@ -840,132 +846,71 @@ struct RewriteShardNum
     }
 };
 using RewriteShardNumVisitor = InDepthNodeVisitor<RewriteShardNum, true>;
+
 /// Get all distance functions, remove duplicated functions
-std::vector<const ASTFunction *> getVectorScanFunctions(ASTPtr & query, const ASTSelectQuery &)
+std::vector<const ASTFunction *> getVectorScanFunctions(ASTPtr & query, const ASTSelectQuery & select_query)
 {
     GetVectorScanVisitor::Data data;
     GetVectorScanVisitor(data).visit(query);
 
-    /// There can not be other aggregate functions within the aggregate functions.
-    return data.vector_scan_funcs;
-}
+    /// Addtional check for distance functions
+    if (data.vector_scan_funcs.size() > 1)
+        throw Exception("Not support multiple distance funcs in one query now.", ErrorCodes::SYNTAX_ERROR);
 
-void optimizeVectorScan(
-    ASTSelectQuery * select_query,
-    const VectorIndicesDescription & vector_indices_description,
-    std::vector<const ASTFunction *> & vector_scan_funcs,
-    ContextPtr context,
-    String & vector_scan_metric_type)
-{
-    /// only consider one distance function case
-    if (vector_scan_funcs.size() == 1)
+    /// vector scan function is found, check exists in order by / where clauses.
+    if (data.vector_scan_funcs.size() == 1)
     {
-        const auto * vector_scan_func_node = vector_scan_funcs[0];
-        String param_str = parseVectorScanParameters(vector_scan_func_node, context);
-        VectorIndex::Parameters vec_parameters;
-        if (!param_str.empty())
+        if (!select_query.orderBy())
         {
-            try
-            {
-                Poco::JSON::Parser json_parser;
-                auto object = json_parser.parse(param_str).extract<Poco::JSON::Object::Ptr>();
-                vec_parameters = VectorIndex::convertPocoJsonToMap(object);
-            }
-            catch ([[maybe_unused]] const std::exception & e)
-            {
-                throw Exception(ErrorCodes::BAD_ARGUMENTS, "The input JSON's format is illegal ");
-            }
+            /// TODO: Will be removed when distance functions are implemented
+            throw Exception("Not support distance function without ORDER BY clause", ErrorCodes::SYNTAX_ERROR);
         }
 
-        const auto vector_scan_func_node_cloumn_name = vector_scan_func_node->getColumnName();
-        std::shared_ptr<ASTFunction> tuple_function_a;
-        if (!select_query->orderBy())
-        {
-            /// Basically copy-and-paste from ExpressionAnalyzer, dirty
-            if (!vector_scan_func_node->arguments || vector_scan_func_node->arguments->children.size() != 2)
-            {
-                throw Exception(ErrorCodes::BAD_ARGUMENTS, "wrong argument number in distance function");
-            }
-            const auto search_column_name = vector_scan_func_node->arguments->children[0]->getColumnName();
+        bool is_batch = isBatchDistance(data.vector_scan_funcs[0]->getColumnName());
+        if (!is_batch && !select_query.limitLength())
+            throw Exception("Not support distance function without LIMIT N clause", ErrorCodes::SYNTAX_ERROR);
+        else if (is_batch && !select_query.limitByLength())
+            throw Exception("Not support batch distance function without LIMIT N BY clause", ErrorCodes::SYNTAX_ERROR);
 
-            /// Empty is ok, l2 as default
-            String metric_type = vec_parameters["metric_type"];
-            for (const auto & vector_index_description : vector_indices_description)
-            {
-                /// index metric_type has higher priority
-                if (vector_index_description.column == search_column_name)
-                {
-                    const auto index_parameter = VectorIndex::convertPocoJsonToMap(vector_index_description.parameters);
-                    if(index_parameter.contains("metric_type")){
-                        metric_type = index_parameter.at("metric_type");
-                        break;
-                    }
-                }
-            }
-            Poco::toUpperInPlace(metric_type);
+        if (select_query.orderBy())
+        {
+            GetVectorScanVisitor::Data order_by_data;
+            GetVectorScanVisitor(order_by_data).visit(select_query.orderBy());
 
-            /// Stored in TreeRewriterResult, pass such info to ExpressionAnalyzer
-            vector_scan_metric_type = metric_type;
-            auto order_by_exp_ast = std::make_shared<ASTExpressionList>();
-            if (isDistance(vector_scan_func_node_cloumn_name))
-            {
-                auto order_by_elem = std::make_shared<ASTOrderByElement>();
-                auto order_by_col = std::make_shared<ASTIdentifier>(vector_scan_func_node_cloumn_name);
-                order_by_elem->children.emplace_back(order_by_col);
-                order_by_elem->direction = metric_type == "IP" ? -1 : 1;
-                order_by_elem->nulls_direction = 1;
-
-                order_by_exp_ast->children.emplace_back(order_by_elem);
-                select_query->setExpression(ASTSelectQuery::Expression::ORDER_BY, order_by_exp_ast);
-            }
-            else if (isBatchDistance(vector_scan_func_node_cloumn_name))
-            {
-                auto order_by_elem_a = std::make_shared<ASTOrderByElement>();
-                auto order_by_col_a = std::make_shared<ASTIdentifier>(vector_scan_func_node_cloumn_name);
-                auto order_by_literal_a = std::make_shared<ASTLiteral>(1u);
-                tuple_function_a = makeASTFunction("tupleElement", order_by_col_a, order_by_literal_a);
-                order_by_elem_a->children.emplace_back(tuple_function_a);
-                order_by_elem_a->direction = 1;
-                order_by_elem_a->nulls_direction = 1;
-
-                auto order_by_elem_b = std::make_shared<ASTOrderByElement>();
-                auto order_by_col_b = std::make_shared<ASTIdentifier>(vector_scan_func_node_cloumn_name);
-                auto order_by_literal_b = std::make_shared<ASTLiteral>(2u);
-                auto tuple_function_b = makeASTFunction("tupleElement", order_by_col_b, order_by_literal_b);
-                order_by_elem_b->children.emplace_back(tuple_function_b);
-                order_by_elem_b->direction = metric_type == "IP" ? -1 : 1;
-                order_by_elem_b->nulls_direction = 1;
-
-                order_by_exp_ast->children.emplace_back(order_by_elem_a);
-                order_by_exp_ast->children.emplace_back(order_by_elem_b);
-                select_query->setExpression(ASTSelectQuery::Expression::ORDER_BY, order_by_exp_ast);
-            }
+            if (order_by_data.vector_scan_funcs.size() != 1)
+                throw Exception("Not support without distance function inside ORDER BY clause", ErrorCodes::SYNTAX_ERROR);
         }
+    }
 
-        if (!select_query->limitBy() && !select_query->limitLength() && !select_query->limitOffset() && !select_query->limitByOffset()
-            && !select_query->limitByLength() && vec_parameters.contains("topK"))
+    return data.vector_scan_funcs;
+}
+
+void addDistanceFuncColName(const String & distance_col_name, NamesAndTypesList & source_columns)
+{
+    if (isDistance(distance_col_name))
+    {
+        if (!source_columns.contains(distance_col_name)) /* consider second analysis round */
         {
-            auto limit_by_ast = std::make_shared<ASTLiteral>(VectorIndex::StoI(vec_parameters.at("topK")));
-            if (isDistance(vector_scan_func_node_cloumn_name))
-            {
-                select_query->setExpression(ASTSelectQuery::Expression::LIMIT_LENGTH, limit_by_ast);
-            }
-            else if (isBatchDistance(vector_scan_func_node_cloumn_name))
-            {
-                select_query->setExpression(ASTSelectQuery::Expression::LIMIT_BY_LENGTH, limit_by_ast);
-                auto limit_by_exp_ast = std::make_shared<ASTExpressionList>();
-                if(!tuple_function_a)
-                {
-                    auto order_by_col_a = std::make_shared<ASTIdentifier>(vector_scan_func_node_cloumn_name);
-                    auto order_by_literal_a = std::make_shared<ASTLiteral>(1u);
-                    tuple_function_a = makeASTFunction("tupleElement", order_by_col_a, order_by_literal_a);
-                }
-                limit_by_exp_ast->children.emplace_back(tuple_function_a);
-                select_query->setExpression(ASTSelectQuery::Expression::LIMIT_BY, limit_by_exp_ast);
-            }
+            NameAndTypePair new_name_pair(distance_col_name, std::make_shared<DataTypeFloat32>());
+            source_columns.push_back(new_name_pair);
+        }
+    }
+    else if (isBatchDistance(distance_col_name))
+    {
+        if (!source_columns.contains(distance_col_name)) /* consider second analysis round */
+        {
+            auto id_type = std::make_shared<DataTypeUInt32>();
+            auto distance_type = std::make_shared<DataTypeFloat32>();
+            DataTypes types;
+            types.emplace_back(id_type);
+            types.emplace_back(distance_type);
+            auto type = std::make_shared<DataTypeTuple>(types);
+            NameAndTypePair new_name_pair(distance_col_name, type);
+            source_columns.push_back(new_name_pair);
         }
     }
 }
+
 }
 
 TreeRewriterResult::TreeRewriterResult(
@@ -1041,6 +986,9 @@ void TreeRewriterResult::collectUsedColumns(const ASTPtr & query, bool is_select
 
                 required.erase(name);
             }
+            /// Add vector scan function column name when exists in right joined table
+            else if (isVectorScanFunc(name))
+                analyzed_join->addJoinedColumn(joined_column);
         }
     }
 
@@ -1167,34 +1115,13 @@ void TreeRewriterResult::collectUsedColumns(const ASTPtr & query, bool is_select
     }
 
     /// insert distance func columns into source columns here
-    if (!vector_scan_funcs.empty())
+    if (!vector_scan_funcs.empty() && !vector_from_right_table)
     {
         for (auto node : vector_scan_funcs)
         {
-            if (isDistance(node->getColumnName()))
-            {
-                if (!source_columns.contains(node->getColumnName())) /* consider second analysis round */
-                {
-                    NameAndTypePair new_name_pair(node->getColumnName(), std::make_shared<DataTypeFloat32>());
-                    source_columns.push_back(new_name_pair);
-                    unknown_required_source_columns.erase(node->getColumnName());
-                }
-            }
-            else if (isBatchDistance(node->getColumnName()))
-            {
-                if (!source_columns.contains(node->getColumnName())) /* consider second analysis round */
-                {
-                    auto id_type = std::make_shared<DataTypeUInt32>();
-                    auto distance_type = std::make_shared<DataTypeFloat32>();
-                    DataTypes types;
-                    types.emplace_back(id_type);
-                    types.emplace_back(distance_type);
-                    auto type = std::make_shared<DataTypeTuple>(types);
-                    NameAndTypePair new_name_pair(node->getColumnName(), type);
-                    source_columns.push_back(new_name_pair);
-                    unknown_required_source_columns.erase(node->getColumnName());
-                }
-            }
+            const String distance_col_name = node->getColumnName();
+            addDistanceFuncColName(distance_col_name, source_columns);
+            unknown_required_source_columns.erase(distance_col_name);
         }
     }
 
@@ -1266,6 +1193,177 @@ NameSet TreeRewriterResult::getArrayJoinSourceNameSet() const
     return forbidden_columns;
 }
 
+void TreeRewriterResult::collectForVectorScanFunctions(
+    ASTSelectQuery * select_query,
+    const std::vector<TableWithColumnNamesAndTypes> & tables_with_columns,
+    ContextPtr context)
+{
+    /// distance function exists in main query's select caluse
+    if (vector_scan_funcs.size() == 1)
+    {
+        /// Get topK from limit N
+        bool is_batch = isBatchDistance(vector_scan_funcs[0]->getColumnName());
+        ASTPtr length_ast = nullptr;
+        if (!is_batch && select_query->limitLength())
+            length_ast = select_query->limitLength();
+        else if (is_batch && select_query->limitByLength())
+            length_ast = select_query->limitByLength();
+
+        if (length_ast)
+        {
+            const auto & [field, type] = evaluateConstantExpression(length_ast, context);
+
+            if (isNativeNumber(type))
+            {
+                Field converted = convertFieldToType(field, DataTypeUInt64());
+                if (!converted.isNull())
+                    limit_length = converted.safeGet<UInt64>();
+            }
+        }
+
+        /// TODO: Will be removed when distance functions are implemented
+        if (limit_length == 0)
+            throw Exception("Not support distance function without LIMIT N clause", ErrorCodes::SYNTAX_ERROR);
+
+        /// Check if vector column in vector scan func exists in left table or right joined table
+        /// Insert distance func columns into source columns here
+        const ASTFunction * node = vector_scan_funcs[0];
+        const ASTs & arguments = node->arguments ? node->arguments->children : ASTs();
+
+        if (arguments.size() != 2)
+            throw Exception(ErrorCodes::BAD_ARGUMENTS, "wrong argument number in distance function");
+
+        String vec_col_name = arguments[0]->getColumnName();
+        String distance_col_name = node->getColumnName();
+        StorageMetadataPtr metadata_snapshot = nullptr;
+
+        if (storage_snapshot && storage_snapshot->metadata->getColumns().has(vec_col_name))
+        {
+            /// distance func column name should add to left table's source_columns
+            /// Will be added inside collectUsedColumns() after erase unrequired columns.
+            /// addDistanceFuncColName(distance_col_name, source_columns);
+            metadata_snapshot = storage_snapshot->metadata;
+        }
+        else if (tables_with_columns.size() > 1)
+        {
+            /// Check if vector column name exists in right joined table
+            const auto & right_table = tables_with_columns[1];
+            String table_name = right_table.table.getQualifiedNamePrefix(false);
+
+            if (!right_table.hasColumn(vec_col_name))
+            {
+                throw Exception(ErrorCodes::UNKNOWN_IDENTIFIER, "There is no column '{}' in table '{}'", vec_col_name, table_name);
+            }
+
+            vector_from_right_table = true;
+
+            /// distance func column name should add to right joined table's source columns
+            addDistanceFuncColName(distance_col_name, analyzed_join->columns_from_joined_table);
+
+            /// Add distance func column to original_names too
+            auto & original_names = analyzed_join->original_names;
+            original_names[distance_col_name] = distance_col_name;
+
+            /// Get metadata for right table
+            auto table_id = context->resolveStorageID(StorageID(right_table.table.database, right_table.table.table, right_table.table.uuid));
+            const auto & right_table_storage = DatabaseCatalog::instance().getTable(table_id, context);
+            metadata_snapshot = right_table_storage->getInMemoryMetadataPtr();
+        }
+        else
+        {
+            throw Exception(ErrorCodes::UNKNOWN_IDENTIFIER, "There is no column '{}'", vec_col_name);
+        }
+
+        /// When metric_type = IP in definition of vector index, order by must be DESC.
+        if (metadata_snapshot)
+        {
+            /// 1 for ASC, -1 for DESC
+            int direction = 1;
+
+            auto order_by = select_query->orderBy();
+            if (!order_by)
+                throw Exception("Not support distance function without ORDER BY clause", ErrorCodes::SYNTAX_ERROR);
+
+            /// Find the direction for distance func
+            for (const auto & child : order_by->children)
+            {
+                auto * order_by_element = child->as<ASTOrderByElement>();
+                if (!order_by_element || order_by_element->children.empty())
+                    continue;
+                ASTPtr order_expression = order_by_element->children.at(0);
+
+                if (!is_batch && isDistance(order_expression->getColumnName()))
+                {
+                    direction = order_by_element->direction;
+                    break;
+                }
+                else if (is_batch)
+                {
+                    /// order by batch_distance column name's 1 and 2, where 2 is distance column.
+                    if (auto * function = order_expression->as<ASTFunction>(); function->name == "tupleElement")
+                    {
+                        const ASTs & func_arguments = function->arguments->as<ASTExpressionList &>().children;
+                        if (func_arguments.size() >= 2 && isBatchDistance(func_arguments[0]->getColumnName()))
+                        {
+                            if (func_arguments[1]->getColumnName() == "2")
+                            {
+                                direction = order_by_element->direction;
+                                break;
+                            }
+                        }
+                    }
+                }
+            }
+
+            /// Get metric_type in index definition
+            String metric_type;
+            for (const auto & vector_index_desc : metadata_snapshot->getVectorIndices())
+            {
+                if (vector_index_desc.column == vec_col_name)
+                {
+                    const auto index_parameter = VectorIndex::convertPocoJsonToMap(vector_index_desc.parameters);
+                    if(index_parameter.contains("metric_type"))
+                    {
+                        metric_type = index_parameter.at("metric_type");
+                        break;
+                    }
+                }
+            }
+
+            Poco::toUpperInPlace(metric_type);
+            if (metric_type == "IP")
+            {
+                if (direction == 1)
+                    throw Exception("ORDER BY on distance function column should be DESC when metric type is IP", ErrorCodes::SYNTAX_ERROR);
+            }
+            else if (direction == -1)
+                throw Exception("ORDER BY on distance function column should be ASC when metric type is not IP", ErrorCodes::SYNTAX_ERROR);
+        }
+    }
+    /// Interpreter select on the right joined table where vector column exists, insert distance func column name.
+    else if (auto vector_scan_desc = context->getVecScanDescription())
+    {
+        /// Add vector scan func name and type to source columns
+        addDistanceFuncColName(vector_scan_desc->column_name, source_columns);
+
+        /// Add vector scan func name to select clauses if not exists
+        const auto select_expression_list = select_query->select();
+        bool found = false;
+        for (const auto & elem : select_expression_list->children)
+        {
+            String name = elem->getAliasOrColumnName();
+            if (name == vector_scan_desc->column_name)
+            {
+                found = true;
+                break;
+            }
+        }
+
+        if (!found)
+            select_expression_list->children.emplace_back(std::make_shared<ASTIdentifier>(vector_scan_desc->column_name));
+    }
+}
+
 TreeRewriterResultPtr TreeRewriter::analyzeSelect(
     ASTPtr & query,
     TreeRewriterResult && result,
@@ -1358,9 +1456,9 @@ TreeRewriterResultPtr TreeRewriter::analyzeSelect(
     result.aggregates = getAggregates(query, *select_query);
     result.window_function_asts = getWindowFunctions(query, *select_query);
     result.vector_scan_funcs = getVectorScanFunctions(query, *select_query);
-    
-    if (result.vector_scan_funcs.size() > 1)
-        throw Exception("Not support multiple distance funcs in one query now.", ErrorCodes::SYNTAX_ERROR);
+
+    /// Special handling for vector scan function
+    result.collectForVectorScanFunctions(select_query, tables_with_columns, getContext());
 
     result.collectUsedColumns(query, true);
     result.required_source_columns_before_expanding_alias_columns = result.required_source_columns.getNames();
@@ -1404,16 +1502,6 @@ TreeRewriterResultPtr TreeRewriter::analyzeSelect(
             !select_query->sampleSize() && !select_query->sampleOffset() && !select_query->final() &&
             (tables_with_columns.size() < 2 || isLeft(result.analyzed_join->kind()));
 
-    if (result.storage)
-    {
-        optimizeVectorScan(
-            select_query,
-            result.storage->getInMemoryMetadataPtr()->getVectorIndices(),
-            result.vector_scan_funcs,
-            getContext(),
-            result.vector_scan_metric_type);
-    }
-
     return std::make_shared<const TreeRewriterResult>(result);
 }
 
diff --git a/src/Interpreters/TreeRewriter.h b/src/Interpreters/TreeRewriter.h
index 4b6abede9c..dfd7910717 100644
--- a/src/Interpreters/TreeRewriter.h
+++ b/src/Interpreters/TreeRewriter.h
@@ -51,6 +51,8 @@ struct TreeRewriterResult
     std::vector<const ASTFunction *> vector_scan_funcs;
 
     String vector_scan_metric_type;
+    UInt64 limit_length = 0;
+    bool vector_from_right_table = false;
 
     /// Which column is needed to be ARRAY-JOIN'ed to get the specified.
     /// For example, for `SELECT s.v ... ARRAY JOIN a AS s` will get "s.v" -> "a.v".
@@ -99,6 +101,12 @@ struct TreeRewriterResult
     const Names & requiredSourceColumnsForAccessCheck() const { return required_source_columns_before_expanding_alias_columns; }
     NameSet getArrayJoinSourceNameSet() const;
     const Scalars & getScalars() const { return scalars; }
+
+    /// Special handings for vector scan funcs: get limit_length, cases when distance func in right joined table
+    void collectForVectorScanFunctions(
+        ASTSelectQuery * select_query,
+        const std::vector<TableWithColumnNamesAndTypes> & tables_with_columns,
+        ContextPtr context);
 };
 
 using TreeRewriterResultPtr = std::shared_ptr<const TreeRewriterResult>;
diff --git a/src/Interpreters/VectorScanDescription.h b/src/Interpreters/VectorScanDescription.h
index e5043a4753..6e8cd8a558 100644
--- a/src/Interpreters/VectorScanDescription.h
+++ b/src/Interpreters/VectorScanDescription.h
@@ -27,6 +27,7 @@ struct VectorScanDescription
     String column_name;             /// What name to use for a column with vector scan function values
 
     uint64_t search_column_dim{0};
+    int topk = -1;    /// topK value extracted from limit N
 
     // void explain(WriteBuffer & out, size_t indent) const; /// Get description for EXPLAIN query.
     // void explain(JSONBuilder::JSONMap & map) const;
diff --git a/src/Storages/MergeTree/CommonANNIndexes.cpp b/src/Storages/MergeTree/CommonANNIndexes.cpp
new file mode 100644
index 0000000000..4b360e029e
--- /dev/null
+++ b/src/Storages/MergeTree/CommonANNIndexes.cpp
@@ -0,0 +1,606 @@
+#include <Storages/MergeTree/CommonANNIndexes.h>
+#include <Storages/MergeTree/KeyCondition.h>
+
+#include <Parsers/ASTFunction.h>
+#include <Parsers/ASTIdentifier.h>
+#include <Parsers/ASTLiteral.h>
+#include <Parsers/ASTOrderByElement.h>
+#include <Parsers/ASTSelectQuery.h>
+#include <Parsers/ASTSetQuery.h>
+
+#include <Storages/MergeTree/MergeTreeSettings.h>
+
+#include <Interpreters/Context.h>
+
+namespace DB
+{
+
+namespace ErrorCodes
+{
+    extern const int LOGICAL_ERROR;
+    extern const int INCORRECT_QUERY;
+}
+
+namespace
+{
+
+namespace ANN = ApproximateNearestNeighbour;
+
+template <typename Literal>
+void extractTargetVectorFromLiteral(ANN::ANNQueryInformation::Embedding & target, Literal literal)
+{
+    Float64 float_element_of_target_vector;
+    Int64 int_element_of_target_vector;
+
+    for (const auto & value : literal.value())
+    {
+        if (value.tryGet(float_element_of_target_vector))
+        {
+            target.emplace_back(float_element_of_target_vector);
+        }
+        else if (value.tryGet(int_element_of_target_vector))
+        {
+            target.emplace_back(static_cast<float>(int_element_of_target_vector));
+        }
+        else
+        {
+            throw Exception(ErrorCodes::INCORRECT_QUERY, "Wrong type of elements in target vector. Only float or int are supported.");
+        }
+    }
+}
+
+ANN::ANNQueryInformation::Metric castMetricFromStringToType(String metric_name)
+{
+    if (metric_name == "L2Distance")
+        return ANN::ANNQueryInformation::Metric::L2;
+    if (metric_name == "LpDistance")
+        return ANN::ANNQueryInformation::Metric::Lp;
+    return ANN::ANNQueryInformation::Metric::Unknown;
+}
+
+}
+
+namespace ApproximateNearestNeighbour
+{
+
+ANNCondition::ANNCondition(const SelectQueryInfo & query_info,
+                                 ContextPtr context) :
+    block_with_constants{KeyCondition::getBlockWithConstants(query_info.query, query_info.syntax_analyzer_result, context)},
+    ann_index_select_query_params{context->getSettings().get("ann_index_select_query_params").get<String>()},
+    index_granularity{context->getMergeTreeSettings().get("index_granularity").get<UInt64>()},
+    limit_restriction{context->getSettings().get("max_limit_for_ann_queries").get<UInt64>()},
+    index_is_useful{checkQueryStructure(query_info)} {}
+
+bool ANNCondition::alwaysUnknownOrTrue(String metric_name) const
+{
+    if (!index_is_useful)
+    {
+        return true; // Query isn't supported
+    }
+    // If query is supported, check metrics for match
+    return !(castMetricFromStringToType(metric_name) == query_information->metric);
+}
+
+float ANNCondition::getComparisonDistanceForWhereQuery() const
+{
+    if (index_is_useful && query_information.has_value()
+        && query_information->query_type == ANNQueryInformation::Type::Where)
+    {
+        return query_information->distance;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "Not supported method for this query type");
+}
+
+UInt64 ANNCondition::getLimit() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->limit;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "No LIMIT section in query, not supported");
+}
+
+std::vector<float> ANNCondition::getTargetVector() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->target;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "Target vector was requested for useless or uninitialized index.");
+}
+
+size_t ANNCondition::getNumOfDimensions() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->target.size();
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "Number of dimensions was requested for useless or uninitialized index.");
+}
+
+String ANNCondition::getColumnName() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->column_name;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "Column name was requested for useless or uninitialized index.");
+}
+
+ANNQueryInformation::Metric ANNCondition::getMetricType() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->metric;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "Metric name was requested for useless or uninitialized index.");
+}
+
+float ANNCondition::getPValueForLpDistance() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->p_for_lp_dist;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "P from LPDistance was requested for useless or uninitialized index.");
+}
+
+ANNQueryInformation::Type ANNCondition::getQueryType() const
+{
+    if (index_is_useful && query_information.has_value())
+    {
+        return query_information->query_type;
+    }
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "Query type was requested for useless or uninitialized index.");
+}
+
+bool ANNCondition::checkQueryStructure(const SelectQueryInfo & query)
+{
+    // RPN-s for different sections of the query
+    RPN rpn_prewhere_clause;
+    RPN rpn_where_clause;
+    RPN rpn_order_by_clause;
+    RPNElement rpn_limit;
+    UInt64 limit;
+
+    ANNQueryInformation prewhere_info;
+    ANNQueryInformation where_info;
+    ANNQueryInformation order_by_info;
+
+    // Build rpns for query sections
+    const auto & select = query.query->as<ASTSelectQuery &>();
+
+    if (select.prewhere()) // If query has PREWHERE clause
+    {
+        traverseAST(select.prewhere(), rpn_prewhere_clause);
+    }
+
+    if (select.where()) // If query has WHERE clause
+    {
+        traverseAST(select.where(), rpn_where_clause);
+    }
+
+    if (select.limitLength()) // If query has LIMIT clause
+    {
+        traverseAtomAST(select.limitLength(), rpn_limit);
+    }
+
+    if (select.orderBy()) // If query has ORDERBY clause
+    {
+        traverseOrderByAST(select.orderBy(), rpn_order_by_clause);
+    }
+
+    // Reverse RPNs for conveniences during parsing
+    std::reverse(rpn_prewhere_clause.begin(), rpn_prewhere_clause.end());
+    std::reverse(rpn_where_clause.begin(), rpn_where_clause.end());
+    std::reverse(rpn_order_by_clause.begin(), rpn_order_by_clause.end());
+
+    // Match rpns with supported types and extract information
+    const bool prewhere_is_valid = matchRPNWhere(rpn_prewhere_clause, prewhere_info);
+    const bool where_is_valid = matchRPNWhere(rpn_where_clause, where_info);
+    const bool order_by_is_valid = matchRPNOrderBy(rpn_order_by_clause, order_by_info);
+    const bool limit_is_valid = matchRPNLimit(rpn_limit, limit);
+
+    // Query without a LIMIT clause or with a limit greater than a restriction is not supported
+    if (!limit_is_valid || limit_restriction < limit)
+    {
+        return false;
+    }
+
+    // Search type query in both sections isn't supported
+    if (prewhere_is_valid && where_is_valid)
+    {
+        return false;
+    }
+
+    // Search type should be in WHERE or PREWHERE clause
+    if (prewhere_is_valid || where_is_valid)
+    {
+        query_information = std::move(prewhere_is_valid ? prewhere_info : where_info);
+    }
+
+    if (order_by_is_valid)
+    {
+        // Query with valid where and order by type is not supported
+        if (query_information.has_value())
+        {
+            return false;
+        }
+
+        query_information = std::move(order_by_info);
+    }
+
+    if (query_information)
+        query_information->limit = limit;
+
+    return query_information.has_value();
+}
+
+void ANNCondition::traverseAST(const ASTPtr & node, RPN & rpn)
+{
+    // If the node is ASTFunction, it may have children nodes
+    if (const auto * func = node->as<ASTFunction>())
+    {
+        const ASTs & children = func->arguments->children;
+        // Traverse children nodes
+        for (const auto& child : children)
+        {
+            traverseAST(child, rpn);
+        }
+    }
+
+    RPNElement element;
+    // Get the data behind node
+    if (!traverseAtomAST(node, element))
+    {
+        element.function = RPNElement::FUNCTION_UNKNOWN;
+    }
+
+    rpn.emplace_back(std::move(element));
+}
+
+bool ANNCondition::traverseAtomAST(const ASTPtr & node, RPNElement & out)
+{
+    // Match Functions
+    if (const auto * function = node->as<ASTFunction>())
+    {
+        // Set the name
+        out.func_name = function->name;
+
+        if (function->name == "L1Distance" ||
+            function->name == "L2Distance" ||
+            function->name == "LinfDistance" ||
+            function->name == "cosineDistance" ||
+            function->name == "dotProduct" ||
+            function->name == "LpDistance")
+        {
+            out.function = RPNElement::FUNCTION_DISTANCE;
+        }
+        else if (function->name == "tuple")
+        {
+            out.function = RPNElement::FUNCTION_TUPLE;
+        }
+        else if (function->name == "array")
+        {
+            out.function = RPNElement::FUNCTION_ARRAY;
+        }
+        else if (function->name == "less" ||
+                 function->name == "greater" ||
+                 function->name == "lessOrEquals" ||
+                 function->name == "greaterOrEquals")
+        {
+            out.function = RPNElement::FUNCTION_COMPARISON;
+        }
+        else if (function->name == "_CAST")
+        {
+            out.function = RPNElement::FUNCTION_CAST;
+        }
+        else
+        {
+            return false;
+        }
+
+        return true;
+    }
+    // Match identifier
+    else if (const auto * identifier = node->as<ASTIdentifier>())
+    {
+        out.function = RPNElement::FUNCTION_IDENTIFIER;
+        out.identifier.emplace(identifier->name());
+        out.func_name = "column identifier";
+
+        return true;
+    }
+
+    // Check if we have constants behind the node
+    return tryCastToConstType(node, out);
+}
+
+bool ANNCondition::tryCastToConstType(const ASTPtr & node, RPNElement & out)
+{
+    Field const_value;
+    DataTypePtr const_type;
+
+    if (KeyCondition::getConstant(node, block_with_constants, const_value, const_type))
+    {
+        /// Check for constant types
+        if (const_value.getType() == Field::Types::Float64)
+        {
+            out.function = RPNElement::FUNCTION_FLOAT_LITERAL;
+            out.float_literal.emplace(const_value.get<Float32>());
+            out.func_name = "Float literal";
+            return true;
+        }
+
+        if (const_value.getType() == Field::Types::UInt64)
+        {
+            out.function = RPNElement::FUNCTION_INT_LITERAL;
+            out.int_literal.emplace(const_value.get<UInt64>());
+            out.func_name = "Int literal";
+            return true;
+        }
+
+        if (const_value.getType() == Field::Types::Int64)
+        {
+            out.function = RPNElement::FUNCTION_INT_LITERAL;
+            out.int_literal.emplace(const_value.get<Int64>());
+            out.func_name = "Int literal";
+            return true;
+        }
+
+        if (const_value.getType() == Field::Types::Tuple)
+        {
+            out.function = RPNElement::FUNCTION_LITERAL_TUPLE;
+            out.tuple_literal = const_value.get<Tuple>();
+            out.func_name = "Tuple literal";
+            return true;
+        }
+
+        if (const_value.getType() == Field::Types::Array)
+        {
+            out.function = RPNElement::FUNCTION_LITERAL_ARRAY;
+            out.array_literal = const_value.get<Array>();
+            out.func_name = "Array literal";
+            return true;
+        }
+
+        if (const_value.getType() == Field::Types::String)
+        {
+            out.function = RPNElement::FUNCTION_STRING_LITERAL;
+            out.func_name = const_value.get<String>();
+            return true;
+        }
+    }
+
+    return false;
+}
+
+void ANNCondition::traverseOrderByAST(const ASTPtr & node, RPN & rpn)
+{
+    if (const auto * expr_list = node->as<ASTExpressionList>())
+    {
+        if (const auto * order_by_element = expr_list->children.front()->as<ASTOrderByElement>())
+        {
+            traverseAST(order_by_element->children.front(), rpn);
+        }
+    }
+}
+
+// Returns true and stores ANNQueryInformation if the query has valid WHERE clause
+bool ANNCondition::matchRPNWhere(RPN & rpn, ANNQueryInformation & expr)
+{
+    /// Fill query type field
+    expr.query_type = ANNQueryInformation::Type::Where;
+
+    // WHERE section must have at least 5 expressions
+    // Operator->Distance(float)->DistanceFunc->Column->Tuple(Array)Func(TargetVector(floats))
+    if (rpn.size() < 5)
+    {
+        return false;
+    }
+
+    auto iter = rpn.begin();
+
+    // Query starts from operator less
+    if (iter->function != RPNElement::FUNCTION_COMPARISON)
+    {
+        return false;
+    }
+
+    const bool greater_case = iter->func_name == "greater" || iter->func_name == "greaterOrEquals";
+    const bool less_case = iter->func_name == "less" || iter->func_name == "lessOrEquals";
+
+    ++iter;
+
+    if (less_case)
+    {
+        if (iter->function != RPNElement::FUNCTION_FLOAT_LITERAL)
+        {
+            return false;
+        }
+
+        expr.distance = getFloatOrIntLiteralOrPanic(iter);
+        if (expr.distance < 0)
+            throw Exception(ErrorCodes::INCORRECT_QUERY, "Distance can't be negative. Got {}", expr.distance);
+
+        ++iter;
+
+    }
+    else if (!greater_case)
+    {
+        return false;
+    }
+
+    auto end = rpn.end();
+    if (!matchMainParts(iter, end, expr))
+    {
+        return false;
+    }
+
+    if (greater_case)
+    {
+        if (expr.target.size() < 2)
+        {
+            return false;
+        }
+        expr.distance = expr.target.back();
+        if (expr.distance < 0)
+            throw Exception(ErrorCodes::INCORRECT_QUERY, "Distance can't be negative. Got {}", expr.distance);
+        expr.target.pop_back();
+    }
+
+    // query is ok
+    return true;
+}
+
+// Returns true and stores ANNExpr if the query has valid ORDERBY clause
+bool ANNCondition::matchRPNOrderBy(RPN & rpn, ANNQueryInformation & expr)
+{
+    /// Fill query type field
+    expr.query_type = ANNQueryInformation::Type::OrderBy;
+
+    // ORDER BY clause must have at least 3 expressions
+    if (rpn.size() < 3)
+    {
+        return false;
+    }
+
+    auto iter = rpn.begin();
+    auto end = rpn.end();
+
+    return ANNCondition::matchMainParts(iter, end, expr);
+}
+
+// Returns true and stores Length if we have valid LIMIT clause in query
+bool ANNCondition::matchRPNLimit(RPNElement & rpn, UInt64 & limit)
+{
+    if (rpn.function == RPNElement::FUNCTION_INT_LITERAL)
+    {
+        limit = rpn.int_literal.value();
+        return true;
+    }
+
+    return false;
+}
+
+/* Matches dist function, target vector, column name */
+bool ANNCondition::matchMainParts(RPN::iterator & iter, const RPN::iterator & end, ANNQueryInformation & expr)
+{
+    bool identifier_found = false;
+
+    // Matches DistanceFunc->[Column]->[Tuple(array)Func]->TargetVector(floats)->[Column]
+    if (iter->function != RPNElement::FUNCTION_DISTANCE)
+    {
+        return false;
+    }
+
+    expr.metric = castMetricFromStringToType(iter->func_name);
+    ++iter;
+
+    if (expr.metric == ANN::ANNQueryInformation::Metric::Lp)
+    {
+        if (iter->function != RPNElement::FUNCTION_FLOAT_LITERAL &&
+            iter->function != RPNElement::FUNCTION_INT_LITERAL)
+        {
+            return false;
+        }
+        expr.p_for_lp_dist = getFloatOrIntLiteralOrPanic(iter);
+        ++iter;
+    }
+
+    if (iter->function == RPNElement::FUNCTION_IDENTIFIER)
+    {
+        identifier_found = true;
+        expr.column_name = std::move(iter->identifier.value());
+        ++iter;
+    }
+
+    if (iter->function == RPNElement::FUNCTION_TUPLE || iter->function == RPNElement::FUNCTION_ARRAY)
+    {
+        ++iter;
+    }
+
+    if (iter->function == RPNElement::FUNCTION_LITERAL_TUPLE)
+    {
+        extractTargetVectorFromLiteral(expr.target, iter->tuple_literal);
+        ++iter;
+    }
+
+    if (iter->function == RPNElement::FUNCTION_LITERAL_ARRAY)
+    {
+        extractTargetVectorFromLiteral(expr.target, iter->array_literal);
+        ++iter;
+    }
+
+    /// further conditions are possible if there is no tuple or array, or no identifier is found
+    /// the tuple or array can be inside a cast function. For other cases, see the loop after this condition
+    if (iter != end && iter->function == RPNElement::FUNCTION_CAST)
+    {
+        ++iter;
+        /// Cast should be made to array or tuple
+        if (!iter->func_name.starts_with("Array") && !iter->func_name.starts_with("Tuple"))
+        {
+            return false;
+        }
+        ++iter;
+        if (iter->function == RPNElement::FUNCTION_LITERAL_TUPLE)
+        {
+            extractTargetVectorFromLiteral(expr.target, iter->tuple_literal);
+            ++iter;
+        }
+        else if (iter->function == RPNElement::FUNCTION_LITERAL_ARRAY)
+        {
+            extractTargetVectorFromLiteral(expr.target, iter->array_literal);
+            ++iter;
+        }
+        else
+        {
+            return false;
+        }
+    }
+
+    while (iter != end)
+    {
+        if (iter->function == RPNElement::FUNCTION_FLOAT_LITERAL ||
+            iter->function == RPNElement::FUNCTION_INT_LITERAL)
+        {
+            expr.target.emplace_back(getFloatOrIntLiteralOrPanic(iter));
+        }
+        else if (iter->function == RPNElement::FUNCTION_IDENTIFIER)
+        {
+            if (identifier_found)
+            {
+                return false;
+            }
+            expr.column_name = std::move(iter->identifier.value());
+            identifier_found = true;
+        }
+        else
+        {
+            return false;
+        }
+
+        ++iter;
+    }
+
+    // Final checks of correctness
+    return identifier_found && !expr.target.empty();
+}
+
+// Gets float or int from AST node
+float ANNCondition::getFloatOrIntLiteralOrPanic(const RPN::iterator& iter)
+{
+    if (iter->float_literal.has_value())
+    {
+        return iter->float_literal.value();
+    }
+    if (iter->int_literal.has_value())
+    {
+        return static_cast<float>(iter->int_literal.value());
+    }
+    throw Exception(ErrorCodes::INCORRECT_QUERY, "Wrong parsed AST in buildRPN\n");
+}
+
+}
+
+}
diff --git a/src/Storages/MergeTree/CommonANNIndexes.h b/src/Storages/MergeTree/CommonANNIndexes.h
new file mode 100644
index 0000000000..fefb958486
--- /dev/null
+++ b/src/Storages/MergeTree/CommonANNIndexes.h
@@ -0,0 +1,236 @@
+#pragma once
+
+#include <Storages/MergeTree/MergeTreeIndices.h>
+#include "base/types.h"
+
+#include <optional>
+#include <vector>
+
+namespace DB
+{
+
+namespace ApproximateNearestNeighbour
+{
+
+/**
+ * Queries for Approximate Nearest Neighbour Search
+ * have similar structure:
+ *    1) target vector from which all distances are calculated
+ *    2) metric name (e.g L2Distance, LpDistance, etc.)
+ *    3) name of column with embeddings
+ *    4) type of query
+ *    5) Number of elements, that should be taken (limit)
+ *
+ * And two optional parameters:
+ *    1) p for LpDistance function
+ *    2) distance to compare with (only for where queries)
+ */
+struct ANNQueryInformation
+{
+    using Embedding = std::vector<float>;
+
+    // Extracted data from valid query
+    Embedding target;
+    enum class Metric
+    {
+        Unknown,
+        L2,
+        Lp
+    } metric;
+    String column_name;
+    UInt64 limit;
+
+    enum class Type
+    {
+        OrderBy,
+        Where
+    } query_type;
+
+    float p_for_lp_dist = -1.0;
+    float distance = -1.0;
+};
+
+/**
+    Class ANNCondition, is responsible for recognizing special query types which
+    can be speeded up by ANN Indexes. It parses the SQL query and checks
+    if it matches ANNIndexes. The recognizing method - alwaysUnknownOrTrue
+    returns false if we can speed up the query, and true otherwise.
+    It has only one argument, name of the metric with which index was built.
+    There are two main patterns of queries being supported
+
+    1) Search query type
+    SELECT * FROM * WHERE DistanceFunc(column, target_vector) < floatLiteral LIMIT count
+
+    2) OrderBy query type
+    SELECT * FROM * WHERE * ORDERBY DistanceFunc(column, target_vector) LIMIT count
+
+    *Query without LIMIT count is not supported*
+
+    target_vector(should have float coordinates) examples:
+        tuple(0.1, 0.1, ...., 0.1) or (0.1, 0.1, ...., 0.1)
+        [the word tuple is not needed]
+
+    If the query matches one of these two types, than the class extracts useful information
+    from the query. If the query has both 1 and 2 types, than we can't speed and alwaysUnknownOrTrue
+    returns true.
+
+    From matching query it extracts
+    * targetVector
+    * metricName(DistanceFunction)
+    * dimension size if query uses LpDistance
+    * distance to compare(ONLY for search types, otherwise you get exception)
+    * spaceDimension(which is targetVector's components count)
+    * column
+    * objects count from LIMIT clause(for both queries)
+    * settings str, if query has settings section with new 'ann_index_select_query_params' value,
+        than you can get the new value(empty by default) calling method getSettingsStr
+    * queryHasOrderByClause and queryHasWhereClause return true if query matches the type
+
+    Search query type is also recognized for PREWHERE clause
+*/
+
+class ANNCondition
+{
+public:
+    ANNCondition(const SelectQueryInfo & query_info,
+                    ContextPtr context);
+
+    // false if query can be speeded up, true otherwise
+    bool alwaysUnknownOrTrue(String metric_name) const;
+
+    // returns the distance to compare with for search query
+    float getComparisonDistanceForWhereQuery() const;
+
+    // distance should be calculated regarding to targetVector
+    std::vector<float> getTargetVector() const;
+
+    // targetVector dimension size
+    size_t getNumOfDimensions() const;
+
+    String getColumnName() const;
+
+    ANNQueryInformation::Metric getMetricType() const;
+
+    // the P- value if the metric is 'LpDistance'
+    float getPValueForLpDistance() const;
+
+    ANNQueryInformation::Type getQueryType() const;
+
+    UInt64 getIndexGranularity() const { return index_granularity; }
+
+    // length's value from LIMIT clause
+    UInt64 getLimit() const;
+
+    // value of 'ann_index_select_query_params' if have in SETTINGS clause, empty string otherwise
+    String getParamsStr() const { return ann_index_select_query_params; }
+
+private:
+
+    struct RPNElement
+    {
+        enum Function
+        {
+            // DistanceFunctions
+            FUNCTION_DISTANCE,
+
+            //tuple(0.1, ..., 0.1)
+            FUNCTION_TUPLE,
+
+            //array(0.1, ..., 0.1)
+            FUNCTION_ARRAY,
+
+            // Operators <, >, <=, >=
+            FUNCTION_COMPARISON,
+
+            // Numeric float value
+            FUNCTION_FLOAT_LITERAL,
+
+            // Numeric int value
+            FUNCTION_INT_LITERAL,
+
+            // Column identifier
+            FUNCTION_IDENTIFIER,
+
+            // Unknown, can be any value
+            FUNCTION_UNKNOWN,
+
+            // (0.1, ...., 0.1) vector without word 'tuple'
+            FUNCTION_LITERAL_TUPLE,
+
+            // [0.1, ...., 0.1] vector without word 'array'
+            FUNCTION_LITERAL_ARRAY,
+
+            // if client parameters are used, cast will always be in the query
+            FUNCTION_CAST,
+
+            // name of type in cast function
+            FUNCTION_STRING_LITERAL,
+        };
+
+        explicit RPNElement(Function function_ = FUNCTION_UNKNOWN)
+        : function(function_), func_name("Unknown"), float_literal(std::nullopt), identifier(std::nullopt) {}
+
+        Function function;
+        String func_name;
+
+        std::optional<float> float_literal;
+        std::optional<String> identifier;
+        std::optional<int64_t> int_literal;
+
+        std::optional<Tuple> tuple_literal;
+        std::optional<Array> array_literal;
+
+        UInt32 dim = 0;
+    };
+
+    using RPN = std::vector<RPNElement>;
+
+    bool checkQueryStructure(const SelectQueryInfo & query);
+
+    // Util functions for the traversal of AST, parses AST and builds rpn
+    void traverseAST(const ASTPtr & node, RPN & rpn);
+    // Return true if we can identify our node type
+    bool traverseAtomAST(const ASTPtr & node, RPNElement & out);
+    // Checks if the AST stores ConstType expression
+    bool tryCastToConstType(const ASTPtr & node, RPNElement & out);
+    // Traverses the AST of ORDERBY section
+    void traverseOrderByAST(const ASTPtr & node, RPN & rpn);
+
+    // Returns true and stores ANNExpr if the query has valid WHERE section
+    static bool matchRPNWhere(RPN & rpn, ANNQueryInformation & expr);
+
+    // Returns true and stores ANNExpr if the query has valid ORDERBY section
+    static bool matchRPNOrderBy(RPN & rpn, ANNQueryInformation & expr);
+
+    // Returns true and stores Length if we have valid LIMIT clause in query
+    static bool matchRPNLimit(RPNElement & rpn, UInt64 & limit);
+
+    /* Matches dist function, target vector, column name */
+    static bool matchMainParts(RPN::iterator & iter, const RPN::iterator & end, ANNQueryInformation & expr);
+
+    // Gets float or int from AST node
+    static float getFloatOrIntLiteralOrPanic(const RPN::iterator& iter);
+
+    Block block_with_constants;
+
+    // true if we have one of two supported query types
+    std::optional<ANNQueryInformation> query_information;
+
+    // Get from settings ANNIndex parameters
+    String ann_index_select_query_params;
+    UInt64 index_granularity;
+    /// only queries with a lower limit can be considered to avoid memory overflow
+    UInt64 limit_restriction;
+    bool index_is_useful = false;
+};
+
+// condition interface for Ann indexes. Returns vector of indexes of ranges in granule which are useful for query.
+class IMergeTreeIndexConditionAnn : public IMergeTreeIndexCondition
+{
+public:
+    virtual std::vector<size_t> getUsefulRanges(MergeTreeIndexGranulePtr idx_granule) const = 0;
+};
+
+}
+
+}
diff --git a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
index 1547050c5e..ba48b9f4a1 100644
--- a/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
+++ b/src/Storages/MergeTree/MergeTreeDataSelectExecutor.cpp
@@ -42,6 +42,8 @@
 #include <Storages/MergeTree/StorageFromMergeTreeDataPart.h>
 #include <IO/WriteBufferFromOStream.h>
 
+#include <Storages/MergeTree/CommonANNIndexes.h>
+
 namespace DB
 {
 
@@ -1598,6 +1600,31 @@ MarkRanges MergeTreeDataSelectExecutor::filterMarksUsingIndex(
         {
             if (index_mark != index_range.begin || !granule || last_index_mark != index_range.begin)
                 granule = reader.read();
+            // Cast to Ann condition
+            auto ann_condition = std::dynamic_pointer_cast<ApproximateNearestNeighbour::IMergeTreeIndexConditionAnn>(condition);
+            if (ann_condition != nullptr)
+            {
+                // vector of indexes of useful ranges
+                auto result = ann_condition->getUsefulRanges(granule);
+                if (result.empty())
+                {
+                    ++granules_dropped;
+                }
+
+                for (auto range : result)
+                {
+                    // range for corresponding index
+                    MarkRange data_range(
+                        std::max(ranges[i].begin, index_mark * index_granularity + range),
+                        std::min(ranges[i].end, index_mark * index_granularity + range + 1));
+
+                    if (res.empty() || res.back().end - data_range.begin > min_marks_for_seek)
+                        res.push_back(data_range);
+                    else
+                        res.back().end = data_range.end;
+                }
+                continue;
+            }
 
             MarkRange data_range(
                     std::max(ranges[i].begin, index_mark * index_granularity),
diff --git a/src/Storages/MergeTree/MergeTreeIndexAnnoy.cpp b/src/Storages/MergeTree/MergeTreeIndexAnnoy.cpp
new file mode 100644
index 0000000000..f64d6104ac
--- /dev/null
+++ b/src/Storages/MergeTree/MergeTreeIndexAnnoy.cpp
@@ -0,0 +1,404 @@
+#ifdef ENABLE_ANNOY
+
+#include <Storages/MergeTree/MergeTreeIndexAnnoy.h>
+
+#include <Common/typeid_cast.h>
+#include <Core/Field.h>
+#include <IO/ReadHelpers.h>
+#include <IO/WriteHelpers.h>
+#include <Interpreters/castColumn.h>
+#include <Columns/ColumnArray.h>
+#include <DataTypes/DataTypeArray.h>
+#include <DataTypes/DataTypeTuple.h>
+
+
+namespace DB
+{
+
+namespace ApproximateNearestNeighbour
+{
+
+template<typename Dist>
+void AnnoyIndex<Dist>::serialize(WriteBuffer& ostr) const
+{
+    assert(Base::_built);
+    writeIntBinary(Base::_s, ostr);
+    writeIntBinary(Base::_n_items, ostr);
+    writeIntBinary(Base::_n_nodes, ostr);
+    writeIntBinary(Base::_nodes_size, ostr);
+    writeIntBinary(Base::_K, ostr);
+    writeIntBinary(Base::_seed, ostr);
+    writeVectorBinary(Base::_roots, ostr);
+    ostr.write(reinterpret_cast<const char*>(Base::_nodes), Base::_s * Base::_n_nodes);
+}
+
+template<typename Dist>
+void AnnoyIndex<Dist>::deserialize(ReadBuffer& istr)
+{
+    assert(!Base::_built);
+    readIntBinary(Base::_s, istr);
+    readIntBinary(Base::_n_items, istr);
+    readIntBinary(Base::_n_nodes, istr);
+    readIntBinary(Base::_nodes_size, istr);
+    readIntBinary(Base::_K, istr);
+    readIntBinary(Base::_seed, istr);
+    readVectorBinary(Base::_roots, istr);
+    Base::_nodes = realloc(Base::_nodes, Base::_s * Base::_n_nodes);
+    istr.readStrict(reinterpret_cast<char *>(Base::_nodes), Base::_s * Base::_n_nodes);
+
+    Base::_fd = 0;
+    // set flags
+    Base::_loaded = false;
+    Base::_verbose = false;
+    Base::_on_disk = false;
+    Base::_built = true;
+}
+
+template<typename Dist>
+uint64_t AnnoyIndex<Dist>::getNumOfDimensions() const
+{
+    return Base::get_f();
+}
+
+}
+
+
+namespace ErrorCodes
+{
+    extern const int ILLEGAL_COLUMN;
+    extern const int INCORRECT_DATA;
+    extern const int INCORRECT_NUMBER_OF_COLUMNS;
+    extern const int INCORRECT_QUERY;
+    extern const int LOGICAL_ERROR;
+    extern const int BAD_ARGUMENTS;
+}
+
+template <typename Distance>
+MergeTreeIndexGranuleAnnoy<Distance>::MergeTreeIndexGranuleAnnoy(const String & index_name_, const Block & index_sample_block_)
+    : index_name(index_name_)
+    , index_sample_block(index_sample_block_)
+    , index(nullptr)
+{}
+
+template <typename Distance>
+MergeTreeIndexGranuleAnnoy<Distance>::MergeTreeIndexGranuleAnnoy(
+    const String & index_name_,
+    const Block & index_sample_block_,
+    AnnoyIndexPtr index_base_)
+    : index_name(index_name_)
+    , index_sample_block(index_sample_block_)
+    , index(std::move(index_base_))
+{}
+
+template <typename Distance>
+void MergeTreeIndexGranuleAnnoy<Distance>::serializeBinary(WriteBuffer & ostr) const
+{
+    /// number of dimensions is required in the constructor,
+    /// so it must be written and read separately from the other part
+    writeIntBinary(index->getNumOfDimensions(), ostr); // write dimension
+    index->serialize(ostr);
+}
+
+template <typename Distance>
+void MergeTreeIndexGranuleAnnoy<Distance>::deserializeBinary(ReadBuffer & istr, MergeTreeIndexVersion /*version*/)
+{
+    uint64_t dimension;
+    readIntBinary(dimension, istr);
+    index = std::make_shared<AnnoyIndex>(dimension);
+    index->deserialize(istr);
+}
+
+template <typename Distance>
+MergeTreeIndexAggregatorAnnoy<Distance>::MergeTreeIndexAggregatorAnnoy(
+    const String & index_name_,
+    const Block & index_sample_block_,
+    uint64_t number_of_trees_)
+    : index_name(index_name_)
+    , index_sample_block(index_sample_block_)
+    , number_of_trees(number_of_trees_)
+{}
+
+template <typename Distance>
+MergeTreeIndexGranulePtr MergeTreeIndexAggregatorAnnoy<Distance>::getGranuleAndReset()
+{
+    // NOLINTNEXTLINE(*)
+    index->build(static_cast<int>(number_of_trees), /*number_of_threads=*/1);
+    auto granule = std::make_shared<MergeTreeIndexGranuleAnnoy<Distance> >(index_name, index_sample_block, index);
+    index = nullptr;
+    return granule;
+}
+
+template <typename Distance>
+void MergeTreeIndexAggregatorAnnoy<Distance>::update(const Block & block, size_t * pos, size_t limit)
+{
+    if (*pos >= block.rows())
+        throw Exception(
+            ErrorCodes::LOGICAL_ERROR,
+            "The provided position is not less than the number of block rows. Position: {}, Block rows: {}.",
+            toString(*pos), toString(block.rows()));
+
+    size_t rows_read = std::min(limit, block.rows() - *pos);
+    if (rows_read == 0)
+        return;
+
+    if (index_sample_block.columns() > 1)
+        throw Exception(ErrorCodes::LOGICAL_ERROR, "Only one column is supported");
+
+    auto index_column_name = index_sample_block.getByPosition(0).name;
+    const auto & column_cut = block.getByName(index_column_name).column->cut(*pos, rows_read);
+    const auto & column_array = typeid_cast<const ColumnArray*>(column_cut.get());
+    if (column_array)
+    {
+        const auto & data = column_array->getData();
+        const auto & array = typeid_cast<const ColumnFloat32&>(data).getData();
+        if (array.empty())
+            throw Exception(ErrorCodes::LOGICAL_ERROR, "Array has 0 rows, {} rows expected", rows_read);
+        const auto & offsets = column_array->getOffsets();
+        size_t num_rows = offsets.size();
+
+        /// Check all sizes are the same
+        size_t size = offsets[0];
+        for (size_t i = 0; i < num_rows - 1; ++i)
+            if (offsets[i + 1] - offsets[i] != size)
+                throw Exception(ErrorCodes::INCORRECT_DATA, "Arrays should have same length");
+
+        index = std::make_shared<AnnoyIndex>(size);
+
+        index->add_item(index->get_n_items(), array.data());
+        /// add all rows from 1 to num_rows - 1 (this is the same as the beginning of the last element)
+        for (size_t current_row = 1; current_row < num_rows; ++current_row)
+            index->add_item(index->get_n_items(), &array[offsets[current_row - 1]]);
+    }
+    else
+    {
+        /// Other possible type of column is Tuple
+        const auto & column_tuple = typeid_cast<const ColumnTuple*>(column_cut.get());
+
+        if (!column_tuple)
+            throw Exception(ErrorCodes::INCORRECT_QUERY, "Wrong type was given to index.");
+
+        const auto & columns = column_tuple->getColumns();
+
+        std::vector<std::vector<Float32>> data{column_tuple->size(), std::vector<Float32>()};
+        for (const auto& column : columns)
+        {
+            const auto& pod_array = typeid_cast<const ColumnFloat32*>(column.get())->getData();
+            for (size_t i = 0; i < pod_array.size(); ++i)
+                data[i].push_back(pod_array[i]);
+        }
+        assert(!data.empty());
+        if (!index)
+            index = std::make_shared<AnnoyIndex>(data[0].size());
+        for (const auto& item : data)
+            index->add_item(index->get_n_items(), item.data());
+    }
+
+    *pos += rows_read;
+}
+
+
+MergeTreeIndexConditionAnnoy::MergeTreeIndexConditionAnnoy(
+    const IndexDescription & /*index*/,
+    const SelectQueryInfo & query,
+    ContextPtr context,
+    const String& distance_name_)
+    : condition(query, context), distance_name(distance_name_)
+{}
+
+
+bool MergeTreeIndexConditionAnnoy::mayBeTrueOnGranule(MergeTreeIndexGranulePtr /* idx_granule */) const
+{
+    throw Exception(ErrorCodes::LOGICAL_ERROR, "mayBeTrueOnGranule is not supported for ANN skip indexes");
+}
+
+bool MergeTreeIndexConditionAnnoy::alwaysUnknownOrTrue() const
+{
+    return condition.alwaysUnknownOrTrue(distance_name);
+}
+
+std::vector<size_t> MergeTreeIndexConditionAnnoy::getUsefulRanges(MergeTreeIndexGranulePtr idx_granule) const
+{
+    if (distance_name == "L2Distance")
+    {
+        return getUsefulRangesImpl<::Annoy::Euclidean>(idx_granule);
+    }
+    else if (distance_name == "cosineDistance")
+    {
+        return getUsefulRangesImpl<::Annoy::Angular>(idx_granule);
+    }
+    else
+    {
+        throw Exception(ErrorCodes::BAD_ARGUMENTS, "Unknown distance name. Must be 'L2Distance' or 'cosineDistance'. Got {}", distance_name);
+    }
+}
+
+
+template <typename Distance>
+std::vector<size_t> MergeTreeIndexConditionAnnoy::getUsefulRangesImpl(MergeTreeIndexGranulePtr idx_granule) const
+{
+    UInt64 limit = condition.getLimit();
+    UInt64 index_granularity = condition.getIndexGranularity();
+    std::optional<float> comp_dist = condition.getQueryType() == ApproximateNearestNeighbour::ANNQueryInformation::Type::Where ?
+     std::optional<float>(condition.getComparisonDistanceForWhereQuery()) : std::nullopt;
+
+    if (comp_dist && comp_dist.value() < 0)
+        throw Exception(ErrorCodes::LOGICAL_ERROR, "Attempt to optimize query with where without distance");
+
+    std::vector<float> target_vec = condition.getTargetVector();
+
+    auto granule = std::dynamic_pointer_cast<MergeTreeIndexGranuleAnnoy<Distance> >(idx_granule);
+    if (granule == nullptr)
+        throw Exception(ErrorCodes::LOGICAL_ERROR, "Granule has the wrong type");
+
+    auto annoy = granule->index;
+
+    if (condition.getNumOfDimensions() != annoy->getNumOfDimensions())
+        throw Exception(ErrorCodes::INCORRECT_QUERY, "The dimension of the space in the request ({}) "
+                        "does not match with the dimension in the index ({})",
+                        toString(condition.getNumOfDimensions()), toString(annoy->getNumOfDimensions()));
+
+    /// neighbors contain indexes of dots which were closest to target vector
+    std::vector<UInt64> neighbors;
+    std::vector<Float32> distances;
+    neighbors.reserve(limit);
+    distances.reserve(limit);
+
+    int k_search = -1;
+    String params_str = condition.getParamsStr();
+    if (!params_str.empty())
+    {
+        try
+        {
+            /// k_search=... (algorithm will inspect up to search_k nodes which defaults to n_trees * n if not provided)
+            k_search = std::stoi(params_str.data() + 9);
+        }
+        catch (...)
+        {
+            throw Exception(ErrorCodes::INCORRECT_QUERY, "Setting of the annoy index should be int");
+        }
+    }
+    annoy->get_nns_by_vector(target_vec.data(), limit, k_search, &neighbors, &distances);
+    std::unordered_set<size_t> granule_numbers;
+    for (size_t i = 0; i < neighbors.size(); ++i)
+    {
+        if (comp_dist && distances[i] > comp_dist)
+            continue;
+        granule_numbers.insert(neighbors[i] / index_granularity);
+    }
+
+    std::vector<size_t> result_vector;
+    result_vector.reserve(granule_numbers.size());
+    for (auto granule_number : granule_numbers)
+        result_vector.push_back(granule_number);
+
+    return result_vector;
+}
+
+MergeTreeIndexGranulePtr MergeTreeIndexAnnoy::createIndexGranule() const
+{
+    if (distance_name == "L2Distance")
+    {
+        return std::make_shared<MergeTreeIndexGranuleAnnoy<::Annoy::Euclidean> >(index.name, index.sample_block);
+    }
+    if (distance_name == "cosineDistance")
+    {
+        return std::make_shared<MergeTreeIndexGranuleAnnoy<::Annoy::Angular> >(index.name, index.sample_block);
+    }
+    throw Exception(ErrorCodes::BAD_ARGUMENTS, "Unknown distance name. Must be 'L2Distance' or 'cosineDistance'. Got {}", distance_name);
+}
+
+MergeTreeIndexAggregatorPtr MergeTreeIndexAnnoy::createIndexAggregator() const
+{
+    if (distance_name == "L2Distance")
+    {
+        return std::make_shared<MergeTreeIndexAggregatorAnnoy<::Annoy::Euclidean> >(index.name, index.sample_block, number_of_trees);
+    }
+    if (distance_name == "cosineDistance")
+    {
+        return std::make_shared<MergeTreeIndexAggregatorAnnoy<::Annoy::Angular> >(index.name, index.sample_block, number_of_trees);
+    }
+    throw Exception(ErrorCodes::BAD_ARGUMENTS, "Unknown distance name. Must be 'L2Distance' or 'cosineDistance'. Got {}", distance_name);
+}
+
+MergeTreeIndexConditionPtr MergeTreeIndexAnnoy::createIndexCondition(
+    const SelectQueryInfo & query, ContextPtr context) const
+{
+    return std::make_shared<MergeTreeIndexConditionAnnoy>(index, query, context, distance_name);
+};
+
+MergeTreeIndexPtr annoyIndexCreator(const IndexDescription & index)
+{
+    uint64_t param = 100;
+    String distance_name = "L2Distance";
+    if (!index.arguments.empty() && !index.arguments[0].tryGet<uint64_t>(param))
+    {
+        if (!index.arguments[0].tryGet<String>(distance_name))
+        {
+            throw Exception(ErrorCodes::INCORRECT_DATA, "Can't parse first argument");
+        }
+    }
+    if (index.arguments.size() > 1 && !index.arguments[1].tryGet<String>(distance_name))
+    {
+        throw Exception(ErrorCodes::INCORRECT_DATA, "Can't parse second argument");
+    }
+    return std::make_shared<MergeTreeIndexAnnoy>(index, param, distance_name);
+}
+
+static void assertIndexColumnsType(const Block & header)
+{
+    DataTypePtr column_data_type_ptr = header.getDataTypes()[0];
+
+    if (const auto * array_type = typeid_cast<const DataTypeArray *>(column_data_type_ptr.get()))
+    {
+        TypeIndex nested_type_index = array_type->getNestedType()->getTypeId();
+        if (!WhichDataType(nested_type_index).isFloat32())
+            throw Exception(
+                ErrorCodes::ILLEGAL_COLUMN,
+                "Unexpected type {} of Annoy index. Only Array(Float32) and Tuple(Float32) are supported.",
+                column_data_type_ptr->getName());
+    }
+    else if (const auto * tuple_type = typeid_cast<const DataTypeTuple *>(column_data_type_ptr.get()))
+    {
+        const DataTypes & nested_types = tuple_type->getElements();
+        for (const auto & type : nested_types)
+        {
+            TypeIndex nested_type_index = type->getTypeId();
+            if (!WhichDataType(nested_type_index).isFloat32())
+                throw Exception(
+                    ErrorCodes::ILLEGAL_COLUMN,
+                    "Unexpected type {} of Annoy index. Only Array(Float32) and Tuple(Float32) are supported.",
+                    column_data_type_ptr->getName());
+        }
+    }
+    else
+        throw Exception(
+            ErrorCodes::ILLEGAL_COLUMN,
+            "Unexpected type {} of Annoy index. Only Array(Float32) and Tuple(Float32) are supported.",
+            column_data_type_ptr->getName());
+
+}
+
+void annoyIndexValidator(const IndexDescription & index, bool /* attach */)
+{
+    if (index.arguments.size() > 2)
+    {
+        throw Exception(ErrorCodes::INCORRECT_QUERY, "Annoy index must not have more than two parameters");
+    }
+    if (!index.arguments.empty() && index.arguments[0].getType() != Field::Types::UInt64
+        && index.arguments[0].getType() != Field::Types::String)
+    {
+        throw Exception(ErrorCodes::INCORRECT_QUERY, "Annoy index first argument must be UInt64 or String.");
+    }
+    if (index.arguments.size() > 1 && index.arguments[1].getType() != Field::Types::String)
+    {
+        throw Exception(ErrorCodes::INCORRECT_QUERY, "Annoy index second argument must be String.");
+    }
+
+    if (index.column_names.size() != 1 || index.data_types.size() != 1)
+        throw Exception(ErrorCodes::INCORRECT_NUMBER_OF_COLUMNS, "Annoy indexes must be created on a single column");
+
+    assertIndexColumnsType(index.sample_block);
+}
+
+}
+#endif // ENABLE_ANNOY
diff --git a/src/Storages/MergeTree/MergeTreeIndexAnnoy.h b/src/Storages/MergeTree/MergeTreeIndexAnnoy.h
new file mode 100644
index 0000000000..3b1a41eb85
--- /dev/null
+++ b/src/Storages/MergeTree/MergeTreeIndexAnnoy.h
@@ -0,0 +1,130 @@
+#pragma once
+
+#ifdef ENABLE_ANNOY
+
+#include <Storages/MergeTree/CommonANNIndexes.h>
+
+#include <annoylib.h>
+#include <kissrandom.h>
+
+namespace DB
+{
+
+// auxiliary namespace for working with spotify-annoy library
+// mainly for serialization and deserialization of the index
+namespace ApproximateNearestNeighbour
+{
+    using AnnoyIndexThreadedBuildPolicy = ::Annoy::AnnoyIndexMultiThreadedBuildPolicy;
+    // TODO: Support different metrics. List of available metrics can be taken from here:
+    // https://github.com/spotify/annoy/blob/master/src/annoymodule.cc#L151-L171
+    template <typename Distance>
+    class AnnoyIndex : public ::Annoy::AnnoyIndex<UInt64, Float32, Distance, ::Annoy::Kiss64Random, AnnoyIndexThreadedBuildPolicy>
+    {
+        using Base = ::Annoy::AnnoyIndex<UInt64, Float32, Distance, ::Annoy::Kiss64Random, AnnoyIndexThreadedBuildPolicy>;
+    public:
+        explicit AnnoyIndex(const uint64_t dim) : Base::AnnoyIndex(dim) {}
+        void serialize(WriteBuffer& ostr) const;
+        void deserialize(ReadBuffer& istr);
+        uint64_t getNumOfDimensions() const;
+    };
+}
+
+template <typename Distance>
+struct MergeTreeIndexGranuleAnnoy final : public IMergeTreeIndexGranule
+{
+    using AnnoyIndex = ApproximateNearestNeighbour::AnnoyIndex<Distance>;
+    using AnnoyIndexPtr = std::shared_ptr<AnnoyIndex>;
+
+    MergeTreeIndexGranuleAnnoy(const String & index_name_, const Block & index_sample_block_);
+    MergeTreeIndexGranuleAnnoy(
+        const String & index_name_,
+        const Block & index_sample_block_,
+        AnnoyIndexPtr index_base_);
+
+    ~MergeTreeIndexGranuleAnnoy() override = default;
+
+    void serializeBinary(WriteBuffer & ostr) const override;
+    void deserializeBinary(ReadBuffer & istr, MergeTreeIndexVersion version) override;
+
+    bool empty() const override { return !index.get(); }
+
+    String index_name;
+    Block index_sample_block;
+    AnnoyIndexPtr index;
+};
+
+template <typename Distance>
+struct MergeTreeIndexAggregatorAnnoy final : IMergeTreeIndexAggregator
+{
+    using AnnoyIndex = ApproximateNearestNeighbour::AnnoyIndex<Distance>;
+    using AnnoyIndexPtr = std::shared_ptr<AnnoyIndex>;
+
+    MergeTreeIndexAggregatorAnnoy(const String & index_name_, const Block & index_sample_block, uint64_t number_of_trees);
+    ~MergeTreeIndexAggregatorAnnoy() override = default;
+
+    bool empty() const override { return !index || index->get_n_items() == 0; }
+    MergeTreeIndexGranulePtr getGranuleAndReset() override;
+    void update(const Block & block, size_t * pos, size_t limit) override;
+
+    String index_name;
+    Block index_sample_block;
+    const uint64_t number_of_trees;
+    AnnoyIndexPtr index;
+};
+
+
+class MergeTreeIndexConditionAnnoy final : public ApproximateNearestNeighbour::IMergeTreeIndexConditionAnn
+{
+public:
+    MergeTreeIndexConditionAnnoy(
+        const IndexDescription & index,
+        const SelectQueryInfo & query,
+        ContextPtr context,
+        const String& distance_name);
+
+    bool alwaysUnknownOrTrue() const override;
+
+    bool mayBeTrueOnGranule(MergeTreeIndexGranulePtr idx_granule) const override;
+
+    std::vector<size_t> getUsefulRanges(MergeTreeIndexGranulePtr idx_granule) const override;
+
+    ~MergeTreeIndexConditionAnnoy() override = default;
+
+private:
+    template <typename Distance>
+    std::vector<size_t> getUsefulRangesImpl(MergeTreeIndexGranulePtr idx_granule) const;
+
+    ApproximateNearestNeighbour::ANNCondition condition;
+    const String distance_name;
+};
+
+
+class MergeTreeIndexAnnoy : public IMergeTreeIndex
+{
+public:
+
+    MergeTreeIndexAnnoy(const IndexDescription & index_, uint64_t number_of_trees_, const String& distance_name_)
+        : IMergeTreeIndex(index_)
+        , number_of_trees(number_of_trees_)
+        , distance_name(distance_name_)
+    {}
+
+    ~MergeTreeIndexAnnoy() override = default;
+
+    MergeTreeIndexGranulePtr createIndexGranule() const override;
+    MergeTreeIndexAggregatorPtr createIndexAggregator() const override;
+
+    MergeTreeIndexConditionPtr createIndexCondition(
+        const SelectQueryInfo & query, ContextPtr context) const override;
+
+    bool mayBenefitFromIndexForIn(const ASTPtr & /*node*/) const override { return false; }
+
+private:
+    const uint64_t number_of_trees;
+    const String distance_name;
+};
+
+
+}
+
+#endif // ENABLE_ANNOY
diff --git a/src/Storages/MergeTree/MergeTreeIndices.cpp b/src/Storages/MergeTree/MergeTreeIndices.cpp
index 9d7e0cdfdb..eeeef27699 100644
--- a/src/Storages/MergeTree/MergeTreeIndices.cpp
+++ b/src/Storages/MergeTree/MergeTreeIndices.cpp
@@ -101,6 +101,11 @@ MergeTreeIndexFactory::MergeTreeIndexFactory()
 
     registerCreator("hypothesis", hypothesisIndexCreator);
     registerValidator("hypothesis", hypothesisIndexValidator);
+
+#ifdef ENABLE_ANNOY
+    registerCreator("annoy", annoyIndexCreator);
+    registerValidator("annoy", annoyIndexValidator);
+#endif
 }
 
 MergeTreeIndexFactory & MergeTreeIndexFactory::instance()
diff --git a/src/Storages/MergeTree/MergeTreeIndices.h b/src/Storages/MergeTree/MergeTreeIndices.h
index 984a2bb776..3a21d788da 100644
--- a/src/Storages/MergeTree/MergeTreeIndices.h
+++ b/src/Storages/MergeTree/MergeTreeIndices.h
@@ -223,4 +223,9 @@ void bloomFilterIndexValidatorNew(const IndexDescription & index, bool attach);
 MergeTreeIndexPtr hypothesisIndexCreator(const IndexDescription & index);
 void hypothesisIndexValidator(const IndexDescription & index, bool attach);
 
+#ifdef ENABLE_ANNOY
+MergeTreeIndexPtr annoyIndexCreator(const IndexDescription & index);
+void annoyIndexValidator(const IndexDescription & index, bool attach);
+#endif
+
 }
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index 82a4aba729..25aef5786a 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -140,11 +140,8 @@ VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(
         // default value
         VectorIndex::Parameters vec_parameters = VectorIndex::convertPocoJsonToMap(desc.vector_parameters);
         int k = 50;
-        if (vec_parameters.contains("topK"))
-        {
-            k = VectorIndex::StoI(vec_parameters.at("topK"));
-            vec_parameters.erase("topK");
-        }
+        if (desc.topk > 0)
+            k = desc.topk;
 
         LOG_DEBUG(log, "Set k to {}, dim to {}", k, dim);
 
@@ -158,11 +155,13 @@ VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(
 
         const IColumn & query_data = query_col->getData();
 
+        LOG_DEBUG(log, "dim to {}", dim);
+
         std::vector<float> query_new_data;
         if (checkColumn<ColumnFloat32>(&query_data))
-            query_new_data = getQueryVector<Float32>(&query_data, false, dim);
+            query_new_data = getQueryVector<Float32>(&query_data, dim, false);
         else if (checkColumn<ColumnFloat64>(&query_data))
-            query_new_data = getQueryVector<Float64>(&query_data, false, dim);
+            query_new_data = getQueryVector<Float64>(&query_data, dim, false);
         else
             throw Exception("Wrong query column type, expect Float32 or Float64 inside Array() in distance function", ErrorCodes::LOGICAL_ERROR);
 
@@ -247,11 +246,10 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
     VectorIndex::Parameters vec_parameters = VectorIndex::convertPocoJsonToMap(desc.vector_parameters);
 
     int k = 50;
-    if (vec_parameters.contains("topK"))
-    {
-        k = VectorIndex::StoI(vec_parameters.at("topK"));
-        vec_parameters.erase("topK");
-    }
+    if (desc.topk > 0)
+        k = desc.topk;
+
+    LOG_DEBUG(log, "Set k to {}, dim to {}", k, dim);
 
     String metrics_str = data_part->storage.getSettings()->vector_search_metric_type;
 
diff --git a/tests/integration/exclude_test.list b/tests/integration/exclude_test.list
index d981ec9304..cea4b8d34b 100644
--- a/tests/integration/exclude_test.list
+++ b/tests/integration/exclude_test.list
@@ -47,4 +47,6 @@ test_keeper_three_nodes_start
 test_keeper_three_nodes_two_alive
 test_keeper_two_nodes_cluster
 test_keeper_znode_time
-test_keeper_zookeeper_converter
\ No newline at end of file
+test_keeper_zookeeper_converter
+test_mqvs_load_vector_index_failed
+test_mqvs_cancel_building_vector_index
\ No newline at end of file
diff --git a/tests/integration/test_mqvs_load_vector_index_failed/test.py b/tests/integration/test_mqvs_load_vector_index_failed/test.py
index 435167c2f2..8a2d153e8f 100644
--- a/tests/integration/test_mqvs_load_vector_index_failed/test.py
+++ b/tests/integration/test_mqvs_load_vector_index_failed/test.py
@@ -37,6 +37,6 @@ def test_load_vector_index_failed(started_cluster):
         user="root",
     )
 
-    instance.query("SELECT id, vector, distance('topK = 10')(vector, [300.0, 300, 300]) AS dist FROM test_load_vector_index_failed;")
+    instance.query("SELECT id, vector, distance(vector, [300.0, 300, 300]) AS dist FROM test_load_vector_index_failed ORDER BY dist LIMIT 10;")
 
     assert instance.contains_in_log("Load vector index: 5")
diff --git a/tests/integration/test_mqvs_primary_key_cache/test.py b/tests/integration/test_mqvs_primary_key_cache/test.py
index 6c447132be..5b9632d947 100644
--- a/tests/integration/test_mqvs_primary_key_cache/test.py
+++ b/tests/integration/test_mqvs_primary_key_cache/test.py
@@ -28,10 +28,10 @@ def test_primary_key_cache_enabled(started_cluster):
 
     time.sleep(2)
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("Miss primary key cache")
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("Hit primary key cache")
 
     instance.query("DROP TABLE IF EXISTS test_pk_cache")
@@ -49,7 +49,7 @@ def test_primary_key_cache_disabled(started_cluster):
 
     time.sleep(2)
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache_disable")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache_disable ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("enable_primary_key_cache = false")
 
     instance.query("DROP TABLE IF EXISTS test_pk_cache_disable")
diff --git a/tests/integration/test_mqvs_primary_key_cache_data_type/test.py b/tests/integration/test_mqvs_primary_key_cache_data_type/test.py
index 8b0123cb35..83150ceeaa 100644
--- a/tests/integration/test_mqvs_primary_key_cache_data_type/test.py
+++ b/tests/integration/test_mqvs_primary_key_cache_data_type/test.py
@@ -28,10 +28,10 @@ def primary_key_cache_test(data_type):
 
     time.sleep(2)
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("Miss primary key cache")
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("Hit primary key cache")
 
 
@@ -112,8 +112,8 @@ def test_primary_key_cache_enum(started_cluster):
 
     time.sleep(2)
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("Miss primary key cache")
 
-    instance.query("SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache")
+    instance.query("SELECT id, distance(vector, [0.1, 0.1, 0.1]) as dist FROM test_pk_cache ORDER BY dist LIMIT 5")
     assert instance.contains_in_log("Hit primary key cache")
diff --git a/tests/queries/0_stateless/02011_tuple_vector_functions.reference b/tests/queries/0_stateless/02011_tuple_vector_functions.reference
index 4c5067c7da..1b54179cc8 100644
--- a/tests/queries/0_stateless/02011_tuple_vector_functions.reference
+++ b/tests/queries/0_stateless/02011_tuple_vector_functions.reference
@@ -21,7 +21,9 @@
 6
 7.1
 1.4142135623730951
+2
 13
+169
 1.5
 -3
 2.3
@@ -34,8 +36,10 @@
 2.0000887587111964
 4
 2.8284271247461903
+8
 1
 0
+0
 -4.413254828250501e-8
 (0.2,-0.8)
 (0.6,0.8)
@@ -48,6 +52,7 @@
 (NULL,NULL)
 \N
 \N
+\N
 (2,4,NULL)
 \N
 \N
diff --git a/tests/queries/0_stateless/02011_tuple_vector_functions.sql b/tests/queries/0_stateless/02011_tuple_vector_functions.sql
index f34fb91586..14f013937b 100644
--- a/tests/queries/0_stateless/02011_tuple_vector_functions.sql
+++ b/tests/queries/0_stateless/02011_tuple_vector_functions.sql
@@ -28,7 +28,9 @@ SELECT scalarProduct(tuple(1), tuple(0));
 SELECT L1Norm((-1, 2, -3));
 SELECT L1Norm((-1, 2.5, -3.6));
 SELECT L2Norm((1, 1.0));
+SELECT L2SquaredNorm((1, 1.0));
 SELECT L2Norm(materialize((-12, 5)));
+SELECT L2SquaredNorm(materialize((-12, 5)));
 
 SELECT max2(materialize(1), 1.5);
 SELECT min2(-1, -3);
@@ -44,8 +46,10 @@ SELECT LpNorm((-1, -2), 11.);
 
 SELECT L1Distance((1, 2, 3), (2, 3, 1));
 SELECT L2Distance(materialize((1, 1)), (3, -1));
+SELECT L2SquaredDistance(materialize((1, 1)), (3, -1));
 SELECT LinfDistance((1, 1), (1, 2));
 SELECT L2Distance((5, 5), (5, 5));
+SELECT L2SquaredDistance((5, 5), (5, 5));
 SELECT LpDistance((1800, 1900), (18, 59), 12) - LpDistance(tuple(-22), tuple(1900), 12.);
 
 SELECT L1Normalize(materialize((1, -4)));
@@ -61,6 +65,7 @@ SELECT cosineDistance((1, 0), (0.5, sqrt(3) / 2));
 SELECT (NULL, 1) + (1, NULL);
 SELECT (NULL, 1) * materialize((1, NULL));
 SELECT L2Norm((NULL, 3, 4));
+SELECT L2SquaredNorm((NULL, 3, 4));
 SELECT 2 * (1, 2, NULL);
 SELECT (1, 1.0, NULL) / NULL;
 SELECT (1, 1.0, NULL) / materialize(NULL);
diff --git a/tests/queries/0_stateless/02282_array_distance.reference b/tests/queries/0_stateless/02282_array_distance.reference
new file mode 100644
index 0000000000..9758da9a83
--- /dev/null
+++ b/tests/queries/0_stateless/02282_array_distance.reference
@@ -0,0 +1,82 @@
+6
+3.7416573867739413
+14
+3.2071843327373397
+3
+0.00258509695694209
+\N
+\N
+nan
+0	0	0	0	0
+12
+14
+21
+7.0710678118654755
+9.16515138991168
+12.12435565298214
+50
+84
+147
+5.917593844525055
+8.308858759453505
+9.932246380845738
+2
+5
+4
+0.16847815937970012
+0.3584669721282153
+0.07417990022744847
+6
+8
+9
+0.020204102886728692
+0.11808289631180313
+0
+1	1	0	0	0	0	0	0
+1	2	2031	788	981.3289733414064	1182.129011571918	1397429	0.1939823640079572
+2	1	2031	788	981.3289733414064	1182.129011571918	1397429	0.1939823640079572
+2	2	0	0	0	0	0	0
+3	3	0	0	0	0	0	0
+3	4	68	2	6.238144819822316	11.661903789690601	136	0.0010041996325123037
+4	3	68	2	6.238144819822316	11.661903789690601	136	0.0010041996325123037
+4	4	0	0	0	0	0	0
+5	5	0	0	0	0	0	0
+5	6	268	2	9.70940985211151	23.15167380558045	536	0.00007815428961455151
+6	5	268	2	9.70940985211151	23.15167380558045	536	0.00007815428961455151
+6	6	0	0	0	0	0	0
+1	1	0	0	0	0	0	0
+1	2	2031	788	992.2102	1182.129	1397429	0.19398236
+2	1	2031	788	992.2102	1182.129	1397429	0.19398236
+2	2	0	0	0	0	0	0
+3	3	0	0	0	0	0	0
+3	4	68	2	6.4792237	11.661903	136	0.0010041595
+4	3	68	2	6.4792237	11.661903	136	0.0010041595
+4	4	0	0	0	0	0	0
+5	5	0	0	0	0	0	0
+5	6	268	2	10.23446	23.151674	536	0.00007814169
+6	5	268	2	10.23446	23.151674	536	0.00007814169
+6	6	0	0	0	0	0	0
+1	1	0	0	0	0	0	0
+1	2	2031	788	992.2102104083964	1182.129011571918	1397429	0.1939823640079572
+2	1	2031	788	992.2102104083964	1182.129011571918	1397429	0.1939823640079572
+2	2	0	0	0	0	0	0
+3	3	0	0	0	0	0	0
+3	4	68	2	6.479223602554966	11.661903789690601	136	0.0010041996325123037
+4	3	68	2	6.479223602554966	11.661903789690601	136	0.0010041996325123037
+4	4	0	0	0	0	0	0
+5	5	0	0	0	0	0	0
+5	6	268	2	10.234459893824097	23.15167380558045	536	0.00007815428961455151
+6	5	268	2	10.234459893824097	23.15167380558045	536	0.00007815428961455151
+6	6	0	0	0	0	0	0
+1	1	0	0	0	0	0	0
+1	2	2031	788	992.2102104083964	1182.129011571918	1397429	0.1939823640079572
+2	1	2031	788	992.2102104083964	1182.129011571918	1397429	0.1939823640079572
+2	2	0	0	0	0	0	0
+3	3	0	0	0	0	0	0
+3	4	68	2	6.479223602554966	11.661903789690601	136	0.0010041996325123037
+4	3	68	2	6.479223602554966	11.661903789690601	136	0.0010041996325123037
+4	4	0	0	0	0	0	0
+5	5	0	0	0	0	0	0
+5	6	268	2	10.234459893824097	23.15167380558045	536	0.00007815428961455151
+6	5	268	2	10.234459893824097	23.15167380558045	536	0.00007815428961455151
+6	6	0	0	0	0	0	0
diff --git a/tests/queries/0_stateless/02282_array_distance.sql b/tests/queries/0_stateless/02282_array_distance.sql
new file mode 100644
index 0000000000..9c16071dc1
--- /dev/null
+++ b/tests/queries/0_stateless/02282_array_distance.sql
@@ -0,0 +1,102 @@
+SELECT L1Distance([0, 0, 0], [1, 2, 3]);
+SELECT L2Distance([1, 2, 3], [0, 0, 0]);
+SELECT L2SquaredDistance([1, 2, 3], [0, 0, 0]);
+SELECT LpDistance([1, 2, 3], [0, 0, 0], 3.5);
+SELECT LinfDistance([1, 2, 3], [0, 0, 0]);
+SELECT cosineDistance([1, 2, 3], [3, 5, 7]);
+
+SELECT L2Distance([1, 2, 3], NULL);
+SELECT L2SquaredDistance([1, 2, 3], NULL);
+SELECT cosineDistance([1, 2, 3], [0, 0, 0]);
+
+-- Overflows
+WITH CAST([-547274980, 1790553898, 1981517754, 1908431500, 1352428565, -573412550, -552499284, 2096941042], 'Array(Int32)') AS a
+SELECT
+    L1Distance(a,a),
+    L2Distance(a,a),
+    L2SquaredDistance(a,a),
+    LinfDistance(a,a),
+    cosineDistance(a, a);
+
+DROP TABLE IF EXISTS vec1;
+DROP TABLE IF EXISTS vec2;
+DROP TABLE IF EXISTS vec2f;
+DROP TABLE IF EXISTS vec2d;
+CREATE TABLE vec1 (id UInt64, v Array(UInt8)) ENGINE = Memory;
+CREATE TABLE vec2 (id UInt64, v Array(Int64)) ENGINE = Memory;
+CREATE TABLE vec2f (id UInt64, v Array(Float32)) ENGINE = Memory;
+CREATE TABLE vec2d (id UInt64, v Array(Float64)) ENGINE = Memory;
+
+INSERT INTO vec1 VALUES (1, [3, 4, 5]), (2, [2, 4, 8]), (3, [7, 7, 7]);
+SELECT L1Distance(v, [0, 0, 0]) FROM vec1;
+SELECT L2Distance(v, [0, 0, 0]) FROM vec1;
+SELECT L2SquaredDistance(v, [0, 0, 0]) FROM vec1;
+SELECT LpDistance(v, [0, 0, 0], 3.14) FROM vec1;
+SELECT LinfDistance([5, 4, 3], v) FROM vec1;
+SELECT cosineDistance([3, 2, 1], v) FROM vec1;
+SELECT LinfDistance(v, materialize([0, -2, 0])) FROM vec1;
+SELECT cosineDistance(v, materialize([1., 1., 1.])) FROM vec1;
+
+INSERT INTO vec2 VALUES (1, [100, 200, 0]), (2, [888, 777, 666]), (3, range(1, 35, 1)), (4, range(3, 37, 1)), (5, range(1, 135, 1)), (6, range(3, 137, 1));
+SELECT
+    v1.id,
+    v2.id,
+    L1Distance(v1.v, v2.v),
+    LinfDistance(v1.v, v2.v),
+    LpDistance(v1.v, v2.v, 3.1),
+    L2Distance(v1.v, v2.v),
+    L2SquaredDistance(v1.v, v2.v),
+    cosineDistance(v1.v, v2.v)
+FROM vec2 v1, vec2 v2
+WHERE length(v1.v) == length(v2.v);
+
+INSERT INTO vec2f VALUES (1, [100, 200, 0]), (2, [888, 777, 666]), (3, range(1, 35, 1)), (4, range(3, 37, 1)), (5, range(1, 135, 1)), (6, range(3, 137, 1));
+SELECT
+    v1.id,
+    v2.id,
+    L1Distance(v1.v, v2.v),
+    LinfDistance(v1.v, v2.v),
+    LpDistance(v1.v, v2.v, 3),
+    L2Distance(v1.v, v2.v),
+    L2SquaredDistance(v1.v, v2.v),
+    cosineDistance(v1.v, v2.v)
+FROM vec2f v1, vec2f v2
+WHERE length(v1.v) == length(v2.v);
+
+INSERT INTO vec2d VALUES (1, [100, 200, 0]), (2, [888, 777, 666]), (3, range(1, 35, 1)), (4, range(3, 37, 1)), (5, range(1, 135, 1)), (6, range(3, 137, 1));
+SELECT
+    v1.id,
+    v2.id,
+    L1Distance(v1.v, v2.v),
+    LinfDistance(v1.v, v2.v),
+    LpDistance(v1.v, v2.v, 3),
+    L2Distance(v1.v, v2.v),
+    L2SquaredDistance(v1.v, v2.v),
+    cosineDistance(v1.v, v2.v)
+FROM vec2d v1, vec2d v2
+WHERE length(v1.v) == length(v2.v);
+
+SELECT
+    v1.id,
+    v2.id,
+    L1Distance(v1.v, v2.v),
+    LinfDistance(v1.v, v2.v),
+    LpDistance(v1.v, v2.v, 3),
+    L2Distance(v1.v, v2.v),
+    L2SquaredDistance(v1.v, v2.v),
+    cosineDistance(v1.v, v2.v)
+FROM vec2f v1, vec2d v2
+WHERE length(v1.v) == length(v2.v);
+
+SELECT L1Distance([0, 0], [1]); -- { serverError 190 }
+SELECT L2Distance([1, 2], (3,4)); -- { serverError 43 }
+SELECT L2SquaredDistance([1, 2], (3,4)); -- { serverError 43 }
+SELECT LpDistance([1, 2], [3,4]); -- { serverError 42 }
+SELECT LpDistance([1, 2], [3,4], -1.); -- { serverError 69 }
+SELECT LpDistance([1, 2], [3,4], 'aaa'); -- { serverError 43 }
+SELECT LpDistance([1, 2], [3,4], materialize(2.7)); -- { serverError 44 }
+
+DROP TABLE vec1;
+DROP TABLE vec2;
+DROP TABLE vec2f;
+DROP TABLE vec2d;
diff --git a/tests/queries/0_stateless/02283_array_norm.reference b/tests/queries/0_stateless/02283_array_norm.reference
new file mode 100644
index 0000000000..ed819e1125
--- /dev/null
+++ b/tests/queries/0_stateless/02283_array_norm.reference
@@ -0,0 +1,42 @@
+6
+7.0710678118654755
+50
+10.882246697870885
+2
+10803059573	4234902446.7343364	17934398733356468000	10803059573	4234902446.7343364	3122003357.3280888	2096941042
+1	7	5	25	4.601724723020627	4
+2	2	2	4	2	2
+3	9	5.196152422706632	27	4.506432087111623	3
+4	0	0	0	0	0
+5	330	78.16648898345122	6110	54.82161001608108	26
+6	5250	599.12436104702	358950	350.73959029428204	102
+1	11
+2	11
+3	11
+4	11
+5	11
+6	11
+1	7	5	25	4.6017246	4
+2	2	2	4	2	2
+3	9	5.196152	27	4.506432	3
+4	0	0	0	0	0
+5	330	78.16649	6110	54.82161	26
+6	5250	599.1244	358950	350.7396	102
+1	11
+2	11
+3	11
+4	11
+5	11
+6	11
+1	7	5	25	4.601724723020627	4
+2	2	2	4	2	2
+3	9	5.196152422706632	27	4.506432087111623	3
+4	0	0	0	0	0
+5	330	78.16648898345122	6110	54.82161001608108	26
+6	5250	599.12436104702	358950	350.73959029428204	102
+1	11
+2	11
+3	11
+4	11
+5	11
+6	11
diff --git a/tests/queries/0_stateless/02283_array_norm.sql b/tests/queries/0_stateless/02283_array_norm.sql
new file mode 100644
index 0000000000..dcb5288a1a
--- /dev/null
+++ b/tests/queries/0_stateless/02283_array_norm.sql
@@ -0,0 +1,47 @@
+SELECT L1Norm([1, 2, 3]);
+SELECT L2Norm([3., 4., 5.]);
+SELECT L2SquaredNorm([3., 4., 5.]);
+SELECT LpNorm([3., 4., 5.], 1.1);
+SELECT LinfNorm([0, 0, 2]);
+
+-- Overflows
+WITH CAST([-547274980, 1790553898, 1981517754, 1908431500, 1352428565, -573412550, -552499284, 2096941042], 'Array(Int32)') AS a
+SELECT
+    L1Norm(a),
+    L2Norm(a),
+    L2SquaredNorm(a),
+    LpNorm(a,1),
+    LpNorm(a,2),
+    LpNorm(a,3.14),
+    LinfNorm(a);
+
+DROP TABLE IF EXISTS vec1;
+DROP TABLE IF EXISTS vec1f;
+DROP TABLE IF EXISTS vec1d;
+CREATE TABLE vec1 (id UInt64, v Array(UInt8)) ENGINE = Memory;
+CREATE TABLE vec1f (id UInt64, v Array(Float32)) ENGINE = Memory;
+CREATE TABLE vec1d (id UInt64, v Array(Float64)) ENGINE = Memory;
+INSERT INTO vec1 VALUES (1, [3, 4]), (2, [2]), (3, [3, 3, 3]), (4, NULL), (5, range(7, 27)), (6, range(3, 103));
+INSERT INTO vec1f VALUES (1, [3, 4]), (2, [2]), (3, [3, 3, 3]), (4, NULL), (5, range(7, 27)), (6, range(3, 103));
+INSERT INTO vec1d VALUES (1, [3, 4]), (2, [2]), (3, [3, 3, 3]), (4, NULL), (5, range(7, 27)), (6, range(3, 103));
+
+SELECT id, L1Norm(v), L2Norm(v), L2SquaredNorm(v), LpNorm(v, 2.7), LinfNorm(v) FROM vec1;
+SELECT id, L1Norm(materialize([5., 6.])) FROM vec1;
+
+SELECT id, L1Norm(v), L2Norm(v), L2SquaredNorm(v), LpNorm(v, 2.7), LinfNorm(v) FROM vec1f;
+SELECT id, L1Norm(materialize([5., 6.])) FROM vec1f;
+
+SELECT id, L1Norm(v), L2Norm(v), L2SquaredNorm(v), LpNorm(v, 2.7), LinfNorm(v) FROM vec1d;
+SELECT id, L1Norm(materialize([5., 6.])) FROM vec1d;
+
+SELECT L1Norm(1, 2); -- { serverError 42 }
+
+SELECT LpNorm([1,2]); -- { serverError 42 }
+SELECT LpNorm([1,2], -3.4); -- { serverError 69 }
+SELECT LpNorm([1,2], 'aa'); -- { serverError 43 }
+SELECT LpNorm([1,2], [1]); -- { serverError 43 }
+SELECT LpNorm([1,2], materialize(3.14)); -- { serverError 44 }
+
+DROP TABLE vec1;
+DROP TABLE vec1f;
+DROP TABLE vec1d;
diff --git a/tests/queries/0_stateless/02354_annoy.reference b/tests/queries/0_stateless/02354_annoy.reference
new file mode 100644
index 0000000000..ce861179b8
--- /dev/null
+++ b/tests/queries/0_stateless/02354_annoy.reference
@@ -0,0 +1,8 @@
+1	[0,0,10]
+2	[0,0,10.5]
+3	[0,0,9.5]
+4	[0,0,9.7]
+5	[0,0,10.2]
+1	[0,0,10]
+5	[0,0,10.2]
+4	[0,0,9.7]
diff --git a/tests/queries/0_stateless/02354_annoy.sql b/tests/queries/0_stateless/02354_annoy.sql
new file mode 100755
index 0000000000..6a0ff60179
--- /dev/null
+++ b/tests/queries/0_stateless/02354_annoy.sql
@@ -0,0 +1,34 @@
+-- Tags: no-fasttest, no-ubsan, no-cpu-aarch64
+
+SET allow_experimental_annoy_index = 1;
+
+DROP TABLE IF EXISTS 02354_annoy;
+
+CREATE TABLE 02354_annoy
+(
+    id Int32,
+    embedding Array(Float32),
+    INDEX annoy_index embedding TYPE annoy(100) GRANULARITY 1
+)
+ENGINE = MergeTree
+ORDER BY id
+SETTINGS index_granularity=5;
+
+INSERT INTO 02354_annoy VALUES (1, [0.0, 0.0, 10.0]), (2, [0.0, 0.0, 10.5]), (3, [0.0, 0.0, 9.5]), (4, [0.0, 0.0, 9.7]), (5, [0.0, 0.0, 10.2]), (6, [10.0, 0.0, 0.0]), (7, [9.5, 0.0, 0.0]), (8, [9.7, 0.0, 0.0]), (9, [10.2, 0.0, 0.0]), (10, [10.5, 0.0, 0.0]), (11, [0.0, 10.0, 0.0]), (12, [0.0, 9.5, 0.0]), (13, [0.0, 9.7, 0.0]), (14, [0.0, 10.2, 0.0]), (15, [0.0, 10.5, 0.0]);
+
+SELECT *
+FROM 02354_annoy
+WHERE L2Distance(embedding, [0.0, 0.0, 10.0]) < 1.0
+LIMIT 5;
+
+SELECT *
+FROM 02354_annoy
+ORDER BY L2Distance(embedding, [0.0, 0.0, 10.0])
+LIMIT 3;
+
+SELECT *
+FROM 02354_annoy
+ORDER BY L2Distance(embedding, [0.0, 0.0])
+LIMIT 3; -- { serverError 80 }
+
+DROP TABLE IF EXISTS 02354_annoy;
diff --git a/tests/queries/2_vector_search/00001_mqvs_distance.sh b/tests/queries/2_vector_search/00001_mqvs_distance.sh
index b556627edd..1a4ffdce88 100755
--- a/tests/queries/2_vector_search/00001_mqvs_distance.sh
+++ b/tests/queries/2_vector_search/00001_mqvs_distance.sh
@@ -4,8 +4,8 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) FROM test_vector order by distance(vector, [0.1, 0.1, 0.1]) limit 10;"
 # detach and attach the table to test deserialization of vector index
 clickhouse-client -q "DETACH TABLE test_vector"
 clickhouse-client -q "ATTACH TABLE test_vector"
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) FROM test_vector order by distance(vector, [0.1, 0.1, 0.1]) limit 10;"
diff --git a/tests/queries/2_vector_search/00002_mqvs_batch_distance.sh b/tests/queries/2_vector_search/00002_mqvs_batch_distance.sh
index b4388b09df..985cfdcb36 100755
--- a/tests/queries/2_vector_search/00002_mqvs_batch_distance.sh
+++ b/tests/queries/2_vector_search/00002_mqvs_batch_distance.sh
@@ -22,7 +22,7 @@ if [ $time -eq 5 ]; then
         echo "fail to build index"
 fi
 clickhouse-client -q "select '-- batch_distance of metric_type=L2';"
-clickhouse-client -q "SELECT id, vector, batch_distance('topK=10')(vector, [[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [50.1, 50.1, 50.1]]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, batch_distance(vector, [[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [50.1, 50.1, 50.1]]) as dist FROM test_vector order by dist.1,dist.2 limit 10 by dist.1;"
 
 clickhouse-client -q "ALTER TABLE test_vector DROP VECTOR INDEX v1;"
 
@@ -39,7 +39,7 @@ if [ $time -eq 5 ]; then
         echo "fail to build index"
 fi
 clickhouse-client -q "select '-- batch_distance of metric_type=IP';"
-clickhouse-client -q "SELECT id, vector, batch_distance('topK=10')(vector, [[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [50.1, 50.1, 50.1]]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, batch_distance(vector, [[0.1, 0.1, 0.1], [0.2, 0.2, 0.2], [50.1, 50.1, 50.1]]) as dist FROM test_vector order by dist.1,dist.2 DESC limit 10 by dist.1;"
 
 clickhouse-client -q "DROP TABLE IF EXISTS test_vector"
 
diff --git a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
index cccf5b1882..6695890837 100755
--- a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
+++ b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=20')(vector, [1.0, 1.0, 1.0]) as d FROM test_vector prewhere id < 10 or id > 60 ORDER BY d;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector prewhere id < 10 or id > 60 ORDER BY d limit 20;"
diff --git a/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh b/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh
index 13e3ba12c8..a9f4fbd822 100755
--- a/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh
+++ b/tests/queries/2_vector_search/00004_mqvs_filter_by_distance.sh
@@ -4,8 +4,8 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) as d FROM test_vector where d < 10;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector where d < 10 order by d limit 10;"
 # detach and attach the table to test deserialization of vector index
 clickhouse-client -q "DETACH TABLE test_vector"
 clickhouse-client -q "ATTACH TABLE test_vector"
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) as d FROM test_vector where d < 10;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector where d < 10 order by d limit 10;"
diff --git a/tests/queries/2_vector_search/00007_mqvs_wrong_search_col.sh b/tests/queries/2_vector_search/00007_mqvs_wrong_search_col.sh
index 7b24ecad05..8b8f204b1d 100755
--- a/tests/queries/2_vector_search/00007_mqvs_wrong_search_col.sh
+++ b/tests/queries/2_vector_search/00007_mqvs_wrong_search_col.sh
@@ -3,5 +3,5 @@
 
 clickhouse-client -q "DROP TABLE IF EXISTS test_vector"
 clickhouse-client -q "CREATE TABLE test_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id"
-clickhouse-client -q "SELECT id, distance('topK=10')(vectore, [0.1, 0.1, 0.1]) FROM test_vector;" 2>&1 | grep -q "DB::Exception: wrong search column name 'vectore'." && echo 'OK' || echo 'FAIL' || :
-clickhouse-client -q "SELECT [1.0, 1.1, 2.0], distance('topK=10')(vector, [0.1, 0.1, 0.1]), number FROM ( SELECT number FROM system.numbers LIMIT 100)" 2>&1 | grep -q "DB::Exception: wrong search column name 'vector'." && echo 'OK' || echo 'FAIL' || :
+clickhouse-client -q "SELECT id, distance(vectore, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;" 2>&1 | grep -q "There is no column 'vectore'." && echo 'OK' || echo 'FAIL' || :
+clickhouse-client -q "SELECT [1.0, 1.1, 2.0], distance(vector, [0.1, 0.1, 0.1]) as d, number FROM ( SELECT number FROM system.numbers LIMIT 100) order by d limit 10" 2>&1 | grep -q "DB::Exception: There is no column 'vector'." && echo 'OK' || echo 'FAIL' || :
diff --git a/tests/queries/2_vector_search/00008_mqvs_empty_vector.sh b/tests/queries/2_vector_search/00008_mqvs_empty_vector.sh
index 724e72ce8d..8e7a42b9ef 100755
--- a/tests/queries/2_vector_search/00008_mqvs_empty_vector.sh
+++ b/tests/queries/2_vector_search/00008_mqvs_empty_vector.sh
@@ -6,13 +6,13 @@ CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 
 # no enforce_fixed_vector_length_constraint
 # test empty vector with IVFFLAT
-clickhouse-client -q "SELECT id, vector, distance('topK = 10')(vector, [20.0, 20.0, 20.0]) as dist FROM test_vector ORDER BY (dist, id);"
+clickhouse-client -q "SELECT id, vector, distance(vector, [20.0, 20.0, 20.0]) as dist FROM test_vector ORDER BY (dist, id) limit 10;"
 
 # test empty vector with FLAT
 clickhouse-client -q "ALTER TABLE test_vector DROP VECTOR INDEX v1;"
 clickhouse-client -q "ALTER TABLE test_vector ADD VECTOR INDEX v1 vector TYPE FLAT;"
 sleep 1
-clickhouse-client -q "SELECT id, vector, distance('topK = 10')(vector, [20.0, 20.0, 20.0]) as dist FROM test_vector ORDER BY (dist, id);"
+clickhouse-client -q "SELECT id, vector, distance(vector, [20.0, 20.0, 20.0]) as dist FROM test_vector ORDER BY (dist, id) limit 10;"
 
 # default enforce_fixed_vector_length_constraint
 clickhouse-client -q "select table, name, expr, status, latest_failed_part, substr(latest_fail_reason, position(latest_fail_reason,'ception') + 8) from system.vector_indices where database = currentDatabase() and table != 'test_vector' order by table;"
diff --git a/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh b/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh
index 98981b17ec..497d206428 100755
--- a/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh
+++ b/tests/queries/2_vector_search/00009_mqvs_brute_force_search_prewhere_0.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector prewhere id>5000 or id =9 or id=31 or id=999 or id=1"
+clickhouse-client -q "SELECT id, vector, distance(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector prewhere id>5000 or id =9 or id=31 or id=999 or id=1 order by d limit 100"
diff --git a/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh b/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh
index 44101a9f3d..596dfc63e4 100755
--- a/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh
+++ b/tests/queries/2_vector_search/00010_mqvs_brute_force_search_prewhere_1.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector prewhere id<100 or id>10000"
+clickhouse-client -q "SELECT id, vector, distance(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector prewhere id<100 or id>10000 order by d limit 100"
diff --git a/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.sh b/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.sh
index 2f9465726b..82e23321a5 100755
--- a/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.sh
+++ b/tests/queries/2_vector_search/00011_mqvs_brute_force_search_where.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.0, 10020.0, 10020.0]) as d FROM test_vector where id<50 or id = 51 or id = 55 or id =99 or id =100 or id =9999"
+clickhouse-client -q "SELECT id, vector, distance(vector, [10020.0, 10020.0, 10020.0]) as d FROM test_vector where id<50 or id = 51 or id = 55 or id =99 or id =100 or id =9999 order by d limit 100"
diff --git a/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh b/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh
index 4c543cee9f..ed568be6ac 100755
--- a/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh
+++ b/tests/queries/2_vector_search/00012_mqvs_brute_force_search.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_2.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=100')(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector"
+clickhouse-client -q "SELECT id, vector, distance(vector, [10020.1, 10020.1, 10020.1]) as d FROM test_vector order by d limit 100"
diff --git a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh
index 0a71e9f493..a31c3d4bdb 100755
--- a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh
+++ b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.sh
@@ -4,8 +4,8 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_3.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;"
 # detach and attach the table to test deserialization of vector index
 clickhouse-client -q "DETACH TABLE test_vector"
 clickhouse-client -q "ATTACH TABLE test_vector"
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;"
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.sh b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.sh
index e5d0792937..5c9c2cb070 100755
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.sh
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_cosine.sh HNSWFLAT
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.5, 0.5, 0.5, 0.5]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.5, 0.5, 0.5, 0.5]) as d FROM test_vector order by d limit 10;"
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfflat.sh b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfflat.sh
index 28c480eee7..88373b1f8f 100755
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfflat.sh
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfflat.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_cosine.sh IVFFlat
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10', 'nprobe = 32')(vector, [0.5, 0.5, 0.5, 0.5]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance('nprobe = 32')(vector, [0.5, 0.5, 0.5, 0.5]) as d FROM test_vector order by d limit 10;"
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.sh b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.sh
index 3a7fc54b05..a10cc7b624 100755
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.sh
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_cosine_ivfpq.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10', 'nprobe = 8')(vector, [0.5, 0.5, 0.5, 0.5]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance('nprobe = 8')(vector, [0.5, 0.5, 0.5, 0.5]) as d FROM test_vector order by d limit 10;"
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.sh b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.sh
index 7b59781526..628c222f3d 100755
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.sh
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index_cosine.sh IVFSQ
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10', 'nprobe = 8')(vector, [0.5, 0.5, 0.5, 0.5]) FROM test_vector;"
+clickhouse-client -q "SELECT id, vector, distance('nprobe = 8')(vector, [0.5, 0.5, 0.5, 0.5]) as d FROM test_vector order by d limit 10;"
diff --git a/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.sql b/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.sql
index b7a13d6ef7..17ac9e4d73 100644
--- a/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.sql
+++ b/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.sql
@@ -13,6 +13,6 @@ ALTER TABLE test_vector ADD VECTOR INDEX v1 vector TYPE HNSWFLAT;
 
 SELECT sleep(2);
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;
 
 drop table test_vector;
\ No newline at end of file
diff --git a/tests/queries/2_vector_search/00016_mqvs_lightweight_delete_with_vector.sql b/tests/queries/2_vector_search/00016_mqvs_lightweight_delete_with_vector.sql
index f248ea230d..b4bf9342d5 100644
--- a/tests/queries/2_vector_search/00016_mqvs_lightweight_delete_with_vector.sql
+++ b/tests/queries/2_vector_search/00016_mqvs_lightweight_delete_with_vector.sql
@@ -14,6 +14,6 @@ delete from test_vector where id = 2;
 
 SELECT sleep(2);
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;
 
 drop table test_vector;
diff --git a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
index f5ff0a4f31..0684d2c936 100644
--- a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
+++ b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
@@ -12,7 +12,7 @@ INSERT INTO test_vector SELECT number + 200, [number + 200, number + 200, number
 
 SELECT sleep(3);
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;
 
 set allow_experimental_lightweight_delete=1;
 set mutations_sync=1;
@@ -20,12 +20,12 @@ set mutations_sync=1;
 delete from test_vector where id = 2;
 delete from test_vector where id = 10;
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector prewhere id > 5;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector prewhere id > 5 order by d limit 10;
 optimize table test_vector final;
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector prewhere id > 5;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector prewhere id > 5 order by d limit 10;
 
 SELECT '--- lightweight delete on decoupled part';
 delete from test_vector where id = 3;
@@ -33,7 +33,7 @@ delete from test_vector where id = 15;
 
 select table, name, type, total_parts, status from system.vector_indices where database = currentDatabase() and table = 'test_vector';
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector prewhere id > 5;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector order by d limit 10;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_vector prewhere id > 5 order by d limit 10;
 
 drop table test_vector;
diff --git a/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql b/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql
index c1ecf47a81..5f6d7dd4c7 100644
--- a/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql
+++ b/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql
@@ -14,7 +14,7 @@ INSERT INTO test_replicated_vector SELECT number + 200, [number + 200, number +
 
 SELECT sleep(3);
 SELECT '--- Original topK result';
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector order by d limit 10;
 
 set allow_experimental_lightweight_delete=1;
 set mutations_sync=2;
@@ -23,15 +23,15 @@ SELECT '--- Lightweight delete on parts with vector index';
 delete from test_replicated_vector where id = 2;
 delete from test_replicated_vector where id = 10;
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector2;
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector prewhere id > 5;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector2 order by d limit 10;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector prewhere id > 5 order by d limit 10;
 
 SELECT '--- Decoupled part when source parts contain lightweight delete';
 optimize table test_replicated_vector final;
 SELECT sleep(2);
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector;
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector2 prewhere id > 5;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector order by d limit 10;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector2 prewhere id > 5 order by d limit 10;
 
 SELECT '--- Lightweight delete on decoupled part';
 delete from test_replicated_vector where id = 3;
@@ -39,8 +39,8 @@ delete from test_replicated_vector where id = 15;
 
 select table, name, type, total_parts, status from system.vector_indices where database = currentDatabase() and table = 'test_replicated_vector';
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector2;
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector prewhere id > 5;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector2 order by d limit 10;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector prewhere id > 5 order by d limit 10;
 
 DROP TABLE IF EXISTS test_replicated_vector SYNC;
 DROP TABLE IF EXISTS test_replicated_vector2 SYNC;
diff --git a/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh b/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh
index 0f1ac4a6d4..91544bdaac 100755
--- a/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh
+++ b/tests/queries/2_vector_search/00018_mqvs_multi_distance_funcs.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
-clickhouse-client -q "SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]), distance('topK=10')(vector, [1.1, 1.1, 1.1]) FROM test_vector;" 2>&1 | grep -q "DB::Exception: Not support multiple distance funcs in one query now." && echo 'OK' || echo 'FAIL' || :
+clickhouse-client -q "SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d1, distance(vector, [1.1, 1.1, 1.1]) as d2 FROM test_vector;" 2>&1 | grep -q "DB::Exception: Not support multiple distance funcs in one query now." && echo 'OK' || echo 'FAIL' || :
diff --git a/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.sql b/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.sql
index 1989d58dce..54d12efa88 100644
--- a/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.sql
+++ b/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.sql
@@ -21,4 +21,4 @@ alter table test_vector add vector index vector_idx data type IVFFLAT;
 select sleep(1);
 select table, name, type, status from system.vector_indices where database = currentDatabase() and table = 'test_vector';
 
-select id, date, label, distance('topK=10')(data, [0,1.0,2.0]) as dist from test_vector where toYear(date) >= 2020 and label = 'animal';
+select id, date, label, distance(data, [0,1.0,2.0]) as dist from test_vector where toYear(date) >= 2020 and label = 'animal' order by dist limit 10;
diff --git a/tests/queries/2_vector_search/00021_mqvs_support_primary_key_cache.sql b/tests/queries/2_vector_search/00021_mqvs_support_primary_key_cache.sql
index 087271be61..ee6e23c2b1 100644
--- a/tests/queries/2_vector_search/00021_mqvs_support_primary_key_cache.sql
+++ b/tests/queries/2_vector_search/00021_mqvs_support_primary_key_cache.sql
@@ -5,7 +5,7 @@ INSERT INTO test_pk_cache SELECT number, [number, number, number] FROM numbers(2
 ALTER TABLE test_pk_cache ADD VECTOR INDEX v1 vector TYPE IVFFLAT;
 SELECT sleep(2);
 
-SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache;
+SELECT id, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_pk_cache order by d limit 5;
 
 set allow_experimental_lightweight_delete=1;
 set mutations_sync=1;
@@ -13,6 +13,6 @@ set mutations_sync=1;
 delete from test_pk_cache where id = 3;
 SELECT sleep(1);
 
-SELECT id, distance('topK=5')(vector, [0.1, 0.1, 0.1]) FROM test_pk_cache;
+SELECT id, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_pk_cache order by d limit 5;
 
 drop table test_pk_cache;
diff --git a/tests/queries/2_vector_search/00022_mqvs_replicated_lightweight_delete_with_vector.sql b/tests/queries/2_vector_search/00022_mqvs_replicated_lightweight_delete_with_vector.sql
index 353c8fd49a..874bab3290 100644
--- a/tests/queries/2_vector_search/00022_mqvs_replicated_lightweight_delete_with_vector.sql
+++ b/tests/queries/2_vector_search/00022_mqvs_replicated_lightweight_delete_with_vector.sql
@@ -14,7 +14,7 @@ delete from test_replicated_vector where id = 2;
 
 SELECT sleep(2);
 
-SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_replicated_vector;
+SELECT id, vector, distance(vector, [0.1, 0.1, 0.1]) as d FROM test_replicated_vector order by d limit 10;
 
 SELECT 'Test build vector index for new inserted part after lightweight delete';
 INSERT INTO test_replicated_vector SELECT number, [number, number, number] FROM numbers(2100,1001);
diff --git a/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.reference b/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.reference
index 516e8016c9..34966e2454 100644
--- a/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.reference
+++ b/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.reference
@@ -9,10 +9,10 @@ SELECT
     id,
     date,
     label,
-    distance(\'topK=10\')(data, [0, 1., 2.]) AS dist
+    distance(data, [0, 1., 2.]) AS dist
 FROM test_vector
 PREWHERE (toYear(date) >= 2000) AND (label = \'animal\')
-ORDER BY distance_func ASC
+ORDER BY dist ASC
 LIMIT 10
 1001	2022-12-29	animal	2
 1000	2022-12-29	animal	5
@@ -29,11 +29,11 @@ SELECT
     id,
     date,
     label,
-    distance(\'topK=10\')(data, [0, 1., 2.]) AS dist
+    distance(data, [0, 1., 2.]) AS dist
 FROM test_vector
 PREWHERE (toYear(date) >= 2000) AND (label = \'animal\')
 WHERE ((toYear(date) >= 2000) AND (label = \'animal\')) AND (dist < 10)
-ORDER BY distance_func ASC
+ORDER BY dist ASC
 LIMIT 10
 1001	2022-12-29	animal	2
 1000	2022-12-29	animal	5
@@ -43,9 +43,9 @@ SELECT
     id,
     date,
     label,
-    distance(\'topK=10\')(data, [0, 1., 2.]) AS dist
+    distance(data, [0, 1., 2.]) AS dist
 FROM test_vector
 PREWHERE toYear(date) >= 2000
 WHERE (toYear(date) >= 2000) AND (label = \'animal\')
-ORDER BY distance_func ASC
+ORDER BY dist ASC
 LIMIT 10
diff --git a/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.sql b/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.sql
index 1a9607e400..58206d374c 100644
--- a/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.sql
+++ b/tests/queries/2_vector_search/00024_mqvs_no_threshold_move_to_prewhere.sql
@@ -24,27 +24,37 @@ SELECT 'explain syntax for sql w/o vector search';
 EXPLAIN SYNTAX SELECT id FROM test_vector WHERE toYear(date) >= 2000 AND label = 'animal';
 
 SELECT 'explain syntax for sql with vector search';
-EXPLAIN SYNTAX SELECT id, date, label, distance('topK=10')(data, [0,1.0,2.0]) as dist
+EXPLAIN SYNTAX SELECT id, date, label, distance(data, [0,1.0,2.0]) as dist
 FROM test_vector
-WHERE toYear(date) >= 2000 AND label = 'animal';
+WHERE toYear(date) >= 2000 AND label = 'animal'
+order by dist
+limit 10;
 
-SELECT id, date, label, distance('topK=10')(data, [0,1.0,2.0]) as dist
+SELECT id, date, label, distance(data, [0,1.0,2.0]) as dist
 FROM test_vector
-WHERE toYear(date) >= 2000 AND label = 'animal';
+WHERE toYear(date) >= 2000 AND label = 'animal'
+order by dist
+limit 10;
 
 SELECT 'explain syntax for sql with vector search and dist in where conditions';
-EXPLAIN SYNTAX SELECT id, date, label, distance('topK=10')(data, [0,1.0,2.0]) as dist
+EXPLAIN SYNTAX SELECT id, date, label, distance(data, [0,1.0,2.0]) as dist
 FROM test_vector
-WHERE toYear(date) >= 2000 AND label = 'animal' AND dist < 10;
+WHERE toYear(date) >= 2000 AND label = 'animal' AND dist < 10
+order by dist
+limit 10;
 
-SELECT id, date, label, distance('topK=10')(data, [0,1.0,2.0]) as dist
+SELECT id, date, label, distance(data, [0,1.0,2.0]) as dist
 FROM test_vector
-WHERE toYear(date) >= 2000 AND label = 'animal' AND dist < 10;
+WHERE toYear(date) >= 2000 AND label = 'animal' AND dist < 10
+order by dist
+limit 10;
 
 SELECT 'set optimize_move_to_prewhere_for_vector_search = 0';
 SET optimize_move_to_prewhere_for_vector_search=0;
-EXPLAIN SYNTAX SELECT id, date, label, distance('topK=10')(data, [0,1.0,2.0]) as dist
+EXPLAIN SYNTAX SELECT id, date, label, distance(data, [0,1.0,2.0]) as dist
 FROM test_vector
-WHERE toYear(date) >= 2000 AND label = 'animal';
+WHERE toYear(date) >= 2000 AND label = 'animal'
+order by dist
+limit 10;
 
 DROP TABLE test_vector;
\ No newline at end of file
diff --git a/tests/queries/2_vector_search/00025_mqvs_distance_with_subquery.sql b/tests/queries/2_vector_search/00025_mqvs_distance_with_subquery.sql
index eafb089426..0fd7c36b9e 100644
--- a/tests/queries/2_vector_search/00025_mqvs_distance_with_subquery.sql
+++ b/tests/queries/2_vector_search/00025_mqvs_distance_with_subquery.sql
@@ -18,34 +18,40 @@ SELECT sleep(2);
 
 SELECT 'Scalar Subquery in distance function';
 select id FROM (
-select id, distance('topK=10')(vector, (
+select id, distance(vector, (
     select arrayMap(x->CAST(x AS Float64), vector)
     FROM test_vector_subquery
     LIMIT 1)
 ) as dist
 from test_vector_subquery
+order by dist
+limit 10
 )
 limit 10;
 
 SELECT 'Scalar Subquery with float32 data type in distance function';
 select id FROM (
-select id, distance('topK=10')(vector, (
+select id, distance(vector, (
     select vector
     FROM test_vector_subquery
     LIMIT 1)
 ) as dist
 from test_vector_subquery
+order by dist
+limit 10
 )
 limit 10;
 
 SELECT 'Scalar Subquery with float32 data type in batch distance function';
 select id FROM (
-select id, batch_distance('topK=5')(vector, (
+select id, batch_distance(vector, (
     select [vector,vector]
     FROM test_vector_subquery
     LIMIT 1)
 ) as dist
 from test_vector_subquery
+order by dist.1, dist.2
+limit 5 by dist.1
 )
 limit 10;
 
@@ -57,14 +63,18 @@ WITH
     LIMIT 1
 ) AS target_vector
 select id FROM (
-select id, distance('topK=10')(vector, target_vector) as dist
+select id, distance(vector, target_vector) as dist
 from test_vector_subquery
+order by dist
+limit 10
 );
 
 SELECT 'Test remove unneeded distance function column in subquery';
 SELECT id FROM (
-    SELECT id, distance('topK=1')(vector, [1.0,1.0,1.0]) as dist
+    SELECT id, distance(vector, [1.0,1.0,1.0]) as dist
     FROM test_vector_subquery
+    order by dist
+    limit 1
 );
 
 DROP TABLE test_vector_subquery;
diff --git a/tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.reference b/tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.reference
new file mode 100644
index 0000000000..a471f2c487
--- /dev/null
+++ b/tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.reference
@@ -0,0 +1,30 @@
+1	1	0
+1	11	0
+2	2	3
+2	12	3
+3	3	12
+3	13	12
+4	4	27
+4	14	27
+5	5	48
+5	15	48
+1	1	0
+1	11	0
+2	2	3
+2	12	3
+3	3	12
+3	13	12
+4	4	27
+4	14	27
+5	5	48
+5	15	48
+1	1	0
+1	11	0
+2	2	3
+2	12	3
+3	3	12
+3	13	12
+4	4	27
+4	14	27
+5	5	48
+5	15	48
diff --git a/tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.sql b/tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.sql
new file mode 100644
index 0000000000..22cd43f45e
--- /dev/null
+++ b/tests/queries/2_vector_search/00026_mqvs_support_distance_on_right_joined_table.sql
@@ -0,0 +1,36 @@
+
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS test_vector_join;
+CREATE TABLE test_vector_join
+(
+    id    UInt32,
+    vector  Array(Float32),
+    CONSTRAINT check_length CHECK length(vector) = 3
+)
+engine = MergeTree ORDER BY id;
+
+INSERT INTO test_vector_join SELECT number, [number, number, number] from numbers(1, 100);
+
+DROP TABLE IF EXISTS t_00026;
+CREATE TABLE t_00026(a int, id int) engine=MergeTree ORDER BY a;
+INSERT INTO t_00026 SELECT number, number FROM numbers(10);
+INSERT INTO t_00026 SELECT number+10, number FROM numbers(10);
+
+SELECT t1.id, t2.a, distance(t1.vector, [1.0,1.0,1.0]) as dist
+FROM test_vector_join as t1 JOIN t_00026 as t2 ON t1.id = t2.id
+ORDER BY dist, t2.a
+LIMIT 10;
+
+SELECT t1.id, t1.a, distance(t2.vector, [1.0,1.0,1.0]) as dist
+FROM t_00026 as t1 JOIN test_vector_join as t2 ON t1.id = t2.id
+ORDER BY dist, t1.a
+LIMIT 10;
+
+SELECT t1.id, t1.a, distance(vector, [1.0,1.0,1.0]) as dist
+FROM t_00026 as t1 JOIN test_vector_join ON t1.id = test_vector_join.id
+ORDER BY dist, t1.a
+LIMIT 10;
+
+DROP TABLE t_00026;
+DROP TABLE test_vector_join;
diff --git a/tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.reference b/tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.reference
new file mode 100644
index 0000000000..25a436bfd4
--- /dev/null
+++ b/tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.reference
@@ -0,0 +1,9 @@
+No vector index
+1	0
+2	3
+metric_type=L2
+1	0
+2	3
+metric_type=IP
+100	300
+99	297
diff --git a/tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.sql b/tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.sql
new file mode 100644
index 0000000000..72608d856e
--- /dev/null
+++ b/tests/queries/2_vector_search/00027_mqvs_check_order_by_for_metric_type.sql
@@ -0,0 +1,32 @@
+
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS test_vector_metric_type;
+CREATE TABLE test_vector_metric_type
+(
+    id    UInt32,
+    vector  Array(Float32),
+    CONSTRAINT check_length CHECK length(vector) = 3
+)
+engine = MergeTree ORDER BY id;
+
+INSERT INTO test_vector_metric_type SELECT number, [number, number, number] from numbers(1, 100);
+
+SELECT 'No vector index';
+SELECT id, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector_metric_type order by d limit 2;
+SELECT id, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector_metric_type order by d DESC limit 2; -- { serverError 62 }
+
+SELECT 'metric_type=L2';
+ALTER TABLE test_vector_metric_type ADD VECTOR INDEX v2 vector TYPE HNSWFLAT('metric_type=L2');
+
+SELECT id, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector_metric_type order by d limit 2;
+SELECT id, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector_metric_type order by d DESC limit 2; -- { serverError 62 }
+ALTER TABLE test_vector_metric_type DROP VECTOR INDEX v2;
+
+SELECT 'metric_type=IP';
+ALTER TABLE test_vector_metric_type ADD VECTOR INDEX v2 vector TYPE HNSWFLAT('metric_type=IP');
+
+SELECT id, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector_metric_type order by d DESC limit 2;
+SELECT id, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector_metric_type order by d limit 2; -- { serverError 62 }
+
+DROP TABLE test_vector_metric_type;
-- 
2.32.1 (Apple Git-133)

