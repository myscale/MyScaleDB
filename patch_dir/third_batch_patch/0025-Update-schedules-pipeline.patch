From ee4c6868a0717eb542d57f079f71322af597537c Mon Sep 17 00:00:00 2001
From: Shanfeng Pang <shanfengp@moqi.ai>
Date: Mon, 20 Mar 2023 11:19:38 +0000
Subject: [PATCH 25/51] Update schedules pipeline

---
 .gitlab-ci-build.yml                          |  2 +-
 .gitlab-ci-integration-test.yml               |  6 +--
 docker/builder/tools/check_job_states.sh      | 16 ++++++-
 docker/test/mqdb_run_stress/run.sh            |  9 ++--
 .../mqdb_test_integration/runner/Dockerfile   |  5 +--
 .../runner/dockerd-entrypoint.sh              | 45 ++++++++++++-------
 src/Interpreters/TreeRewriter.cpp             |  3 +-
 tests/integration/helpers/cluster.py          | 13 +++---
 tests/integration/mqdb-ci-runner.py           | 29 +++++++++---
 9 files changed, 85 insertions(+), 43 deletions(-)

diff --git a/.gitlab-ci-build.yml b/.gitlab-ci-build.yml
index fc36f8acbd..f5a4e084d6 100644
--- a/.gitlab-ci-build.yml
+++ b/.gitlab-ci-build.yml
@@ -21,7 +21,7 @@ build_binary:
     - ssh-keyscan -H git.moqi.ai > ~/.ssh/known_hosts
     - docker/builder/tools/submodule-update.sh
     - docker/builder/build.py --output artifacts --arch linux-x86_64 --package
-    - mv build/programs/clickhouse artifacts/.
+    - cp build/programs/clickhouse artifacts/.
     - docker/builder/tools/package_performance.sh all
     - tar -zcf performance_pack_amd64.tar.gz performance_pack
     # - docker/builder/build.py --output artifacts --arch linux-aarch64 --package
diff --git a/.gitlab-ci-integration-test.yml b/.gitlab-ci-integration-test.yml
index c0029e2aa2..c5f2a73689 100644
--- a/.gitlab-ci-integration-test.yml
+++ b/.gitlab-ci-integration-test.yml
@@ -12,7 +12,7 @@ integration_test0:
       - $CI_PROJECT_DIR/tests/integration/assets/*
   script:
     - pwd && echo $CI_PROJECT_DIR && echo ${CI_COMMIT_SHA}
-    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 0 --runner-image-version 1.2 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
+    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 0 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
   rules:
     - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_TEST_VECTOR_DB != "true"' # Trigger pipline during scheduled tasks
     - if: $CI_MERGE_REQUEST_LABELS == "test-integration"
@@ -30,7 +30,7 @@ integration_test1:
       - $CI_PROJECT_DIR/tests/integration/assets/*
   script:
     - pwd && echo $CI_PROJECT_DIR && echo ${CI_COMMIT_SHA}
-    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 1 --runner-image-version 1.2 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
+    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 1 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
   rules:
     - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_TEST_VECTOR_DB != "true"' # Trigger pipline during scheduled tasks
     - if: $CI_MERGE_REQUEST_LABELS == "test-integration"
@@ -48,7 +48,7 @@ integration_test2:
       - $CI_PROJECT_DIR/tests/integration/assets/*
   script:
     - pwd && echo $CI_PROJECT_DIR && echo ${CI_COMMIT_SHA}
-    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 2 --runner-image-version 1.2 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
+    - 'python3 tests/integration/mqdb-ci-runner.py --hash-test --hash-test-total 3 --hash-test-num 2 --exclude-test-list-file tests/integration/exclude_test.list -n 2 "--timeout=300 --log-level=INFO --log-file-level=INFO" ||:'
   rules:
     - if: '$CI_PIPELINE_SOURCE == "schedule" && $CI_TEST_VECTOR_DB != "true"' # Trigger pipline during scheduled tasks
     - if: $CI_MERGE_REQUEST_LABELS == "test-integration"
diff --git a/docker/builder/tools/check_job_states.sh b/docker/builder/tools/check_job_states.sh
index 67df6788c2..99b3db6d44 100755
--- a/docker/builder/tools/check_job_states.sh
+++ b/docker/builder/tools/check_job_states.sh
@@ -65,6 +65,19 @@ function check_stress
     fi
 }
 
+# It only detects sanitizer-related problems and is a temporary solution
+function check_stress_temporary
+{
+    TEST_STATE=$(cat $WORKPATH/test_results.tsv | grep sanitizer | awk '{print $NF}')
+    cat $WORKPATH/test_results.tsv
+    if [[ "$TEST_STATE" != "OK" ]]; then
+        echo "sanitizer check error, please check the test log"
+        exit 1
+    else
+        echo "test pass"
+    fi
+}
+
 function check_performance
 {
     echo "don't support"
@@ -84,7 +97,8 @@ elif [[ "$TEST_NAME" == "mqdb_run_fuzzer" ]]; then
 elif [[ "$TEST_NAME" == "mqdb_run_smoke" ]]; then
     check_smoke
 elif [[ "$TEST_NAME" == "mqdb_run_stress" ]]; then
-    check_stress
+    # check_stress
+    check_stress_temporary
 elif [[ "$TEST_NAME" == "mqdb_run_performance" ]]; then
     check_performance
 elif [[ "$TEST_NAME" == "mqdb_run_integration" ]]; then
diff --git a/docker/test/mqdb_run_stress/run.sh b/docker/test/mqdb_run_stress/run.sh
index a584a3e4f7..115122b58b 100755
--- a/docker/test/mqdb_run_stress/run.sh
+++ b/docker/test/mqdb_run_stress/run.sh
@@ -308,7 +308,8 @@ clickhouse-local --structure "test String, res String" -q "SELECT 'failure', tes
 
 # Core dumps (see gcore)
 # Default filename is 'core.PROCESS_ID'
-for core in core.*; do
-    pigz $core ||:
-    mv $core.gz $WORKPATH/test_output/ ||:
-done
+# skip save core file
+# for core in core.*; do
+#     pigz $core ||:
+#     mv $core.gz $WORKPATH/test_output/ ||:
+# done
diff --git a/docker/test/mqdb_test_integration/runner/Dockerfile b/docker/test/mqdb_test_integration/runner/Dockerfile
index 9a90a35a8c..933d76281c 100644
--- a/docker/test/mqdb_test_integration/runner/Dockerfile
+++ b/docker/test/mqdb_test_integration/runner/Dockerfile
@@ -1,4 +1,4 @@
-# docker build -t clickhouse/integration-tests-runner .
+# docker build -t harbor.internal.moqi.ai/mqdb/mqdb-test-integration-runner:1.6 .
 FROM harbor.internal.moqi.ai/mqdb/mqdb-test-base:1.2
 
 # ARG for quick switch to a given ubuntu mirror
@@ -80,6 +80,7 @@ RUN python3 -m pip install \
     pytest-timeout \
     pytest-xdist \
     pytest-repeat \
+    pytest-html \
     pytz \
     redis \
     tzlocal==2.1 \
@@ -103,8 +104,6 @@ RUN set -x \
 ENV DOCKER_CLIENT_TIMEOUT=300
 ENV COMPOSE_HTTP_TIMEOUT=600
 ENV XTABLES_LOCKFILE=/run/host/xtables.lock
-ENV USER='shanfengp'
-ENV PASSWORD='Psf00401..'
 
 EXPOSE 2375
 ENTRYPOINT ["dockerd-entrypoint.sh"]
diff --git a/docker/test/mqdb_test_integration/runner/dockerd-entrypoint.sh b/docker/test/mqdb_test_integration/runner/dockerd-entrypoint.sh
index 154311abbd..4b07430a6a 100755
--- a/docker/test/mqdb_test_integration/runner/dockerd-entrypoint.sh
+++ b/docker/test/mqdb_test_integration/runner/dockerd-entrypoint.sh
@@ -12,20 +12,31 @@ echo '{
     "registry-mirrors" : ["http://dockerhub-proxy.dockerhub-proxy-zone:5000"]
 }' | dd of=/etc/docker/daemon.json 2>/dev/null
 
-dockerd --host=unix:///var/run/docker.sock --host=tcp://0.0.0.0:2376 --default-address-pool base=172.17.0.0/12,size=24 &>/var/log/dockerd.log &
-
-set +e
-reties=0
-while true; do
-    docker info &>/dev/null && break
-    reties=$((reties+1))
-    if [[ $reties -ge 100 ]]; then # 10 sec max
-        echo "Can't start docker daemon, timeout exceeded." >&2
-        exit 1;
-    fi
-    sleep 10
-done
-set -e
+dockerd --host=unix:///var/run/docker.sock --host=tcp://0.0.0.0:2376 \
+        --default-address-pool base=172.17.0.0/12,size=24 \
+        --http-proxy=http://clash.internal.moqi.ai:7890 \
+        --https-proxy=http://clash.internal.moqi.ai:7890 \
+        --no-proxy=localhost,127.0.0.1,172.17.0.0/12,172.16.0.0/12,192.168.0.0/16,harbor.internal.moqi.ai,pypi.tuna.tsinghua.edu.cn \
+        &>/var/log/dockerd.log &
+
+
+function waitDockerSetup
+{
+    set +e
+    reties=0
+    while true; do
+        docker info &>/dev/null && break
+        reties=$((reties+1))
+        if [[ $reties -ge 100 ]]; then # 10 sec max
+            echo "Can't start docker daemon, timeout exceeded." >&2
+            exit 1;
+        fi
+        sleep 10
+    done
+    set -e
+}
+
+waitDockerSetup
 
 # cleanup for retry run if volume is not recreated
 # shellcheck disable=SC2046
@@ -34,10 +45,10 @@ set -e
   docker rm $(docker ps -aq) || true
 }
 
-USER=shanfengp
-PASSWORD=Psf00401..
+HARBOR_USER=shanfengp
+HARBOR_PASSWORD=Psf00401..
 
-docker login harbor.internal.moqi.ai/mqdb -u $USER -p $PASSWORD
+docker login harbor.internal.moqi.ai/mqdb -u $HARBOR_USER -p $HARBOR_PASSWORD
 
 echo "Start tests"
 export CLICKHOUSE_TESTS_SERVER_BIN_PATH=/clickhouse
diff --git a/src/Interpreters/TreeRewriter.cpp b/src/Interpreters/TreeRewriter.cpp
index dbd74ad8a4..6fdddd7086 100644
--- a/src/Interpreters/TreeRewriter.cpp
+++ b/src/Interpreters/TreeRewriter.cpp
@@ -66,6 +66,7 @@ namespace ErrorCodes
     extern const int LOGICAL_ERROR;
     extern const int NOT_IMPLEMENTED;
     extern const int NUMBER_OF_ARGUMENTS_DOESNT_MATCH;
+    extern const int SYNTAX_ERROR;
     extern const int UNKNOWN_IDENTIFIER;
 }
 
@@ -1359,7 +1360,7 @@ TreeRewriterResultPtr TreeRewriter::analyzeSelect(
     result.vector_scan_funcs = getVectorScanFunctions(query, *select_query);
     
     if (result.vector_scan_funcs.size() > 1)
-        throw Exception("Not support multiple distance funcs in one query now.", ErrorCodes::LOGICAL_ERROR);
+        throw Exception("Not support multiple distance funcs in one query now.", ErrorCodes::SYNTAX_ERROR);
 
     result.collectUsedColumns(query, true);
     result.required_source_columns_before_expanding_alias_columns = result.required_source_columns.getNames();
diff --git a/tests/integration/helpers/cluster.py b/tests/integration/helpers/cluster.py
index 6b495e2e22..5f4be94efd 100644
--- a/tests/integration/helpers/cluster.py
+++ b/tests/integration/helpers/cluster.py
@@ -315,7 +315,7 @@ class ClickHouseCluster:
             "CLICKHOUSE_TESTS_DOCKERD_HOST"
         )
         self.docker_api_version = os.environ.get("DOCKER_API_VERSION")
-        self.docker_base_tag = os.environ.get("DOCKER_BASE_TAG", "1.0")
+        self.docker_base_tag = os.environ.get("DOCKER_BASE_TAG", "1.6")
 
         self.base_cmd = ["docker-compose"]
         if custom_dockerd_host:
@@ -691,7 +691,7 @@ class ClickHouseCluster:
             binary_path = binary_path[: -len("-server")]
 
         env_variables["keeper_binary"] = binary_path
-        env_variables["image"] = "harbor.internal.moqi.ai/mqdb/mqdb-test-integration:" + self.docker_base_tag
+        env_variables["image"] = "harbor.internal.moqi.ai/mqdb/mqdb-test-integration-runner:" + self.docker_base_tag
         env_variables["user"] = str(os.getuid())
         env_variables["keeper_fs"] = "bind"
         for i in range(1, 4):
@@ -1171,9 +1171,8 @@ class ClickHouseCluster:
         with_hive=False,
         hostname=None,
         env_variables=None,
-        image="harbor.internal.moqi.ai/mqdb/mqdb-test-integration",
-        # image="harbor.internal.moqi.ai/mqdb/mqdb-test-integration",
-        tag=1.0,
+        image="harbor.internal.moqi.ai/mqdb/mqdb-test-integration-runner",
+        tag=1.6,
         stay_alive=False,
         ipv4_address=None,
         ipv6_address=None,
@@ -2646,8 +2645,8 @@ class ClickHouseInstance:
         copy_common_configs=True,
         hostname=None,
         env_variables=None,
-        image="harbor.internal.moqi.ai/mqdb/mqdb-test-integration",
-        tag="1.0",
+        image="harbor.internal.moqi.ai/mqdb/mqdb-test-integration-runner",
+        tag="1.6",
         # tag="latest",
         stay_alive=False,
         ipv4_address=None,
diff --git a/tests/integration/mqdb-ci-runner.py b/tests/integration/mqdb-ci-runner.py
index 92715ad3b8..1a30076894 100755
--- a/tests/integration/mqdb-ci-runner.py
+++ b/tests/integration/mqdb-ci-runner.py
@@ -13,6 +13,7 @@ import subprocess
 import signal
 import time
 import zlib  # for crc32
+import pathlib
 
 RUNNER_FILE_PATH = os.path.split(os.path.realpath(__file__))[0]
 TEST_NAME_FORMAT = f"test_[a-zA-Z0-9]*/"
@@ -38,6 +39,18 @@ def ret_multi_directory(back_num: int,
     for i in range(back_num):
         ret_path = os.path.split(ret_path)[0]
     return ret_path
+
+def replace_build_dir(args, old_path) -> os.path:
+    replace_dir = args.build_dir
+    if replace_dir == 'build':
+        return old_path
+    path = pathlib.Path(old_path)
+    index = path.parts.index('programs')
+    new_prefix_path = os.path.join(get_project_path(),replace_dir)
+    new_path = pathlib.Path(new_prefix_path).joinpath(*path.parts[index:])
+    logging.info("this is new path {}".format(new_path))
+    return new_path
+    
         
 def check_args_and_update_paths(args):
     if not os.path.isabs(args.clickhouse_root):
@@ -45,15 +58,15 @@ def check_args_and_update_paths(args):
     else:
         CLICKHOUSE_ROOT = args.clickhouse_root
     
-    if not os.path.isabs(args.odbc_bridge_binary):
-        args.odbc_bridge_binary = os.path.abspath(args.odbc_bridge_binary)
+    args.odbc_bridge_binary = replace_build_dir(args, os.path.abspath(args.odbc_bridge_binary))
 
-    if not os.path.isabs(args.library_bridge_binary):
-        args.library_bridge_binary = os.path.abspath(args.library_bridge_binary)
+    args.library_bridge_binary = replace_build_dir(args, os.path.abspath(args.library_bridge_binary))
     
     if not os.path.isabs(args.base_configs_dir):
         args.base_configs_dir = os.path.abspath(args.base_configs_dir)
         
+    args.binary = replace_build_dir(args, os.path.abspath(args.binary))
+        
     if not os.path.isabs(args.cases_dir):
         args.cases_dir = os.path.abspath(args.cases_dir)
     
@@ -143,6 +156,10 @@ def get_test_list(args):
 if __name__ == "__main__":
     # logging.basicConfig(level=logging.INFO, format='%(asctime)s [ %(process)d ] %(levelname)s : %(message)s (%(filename)s:%(lineno)s, %(funcName)s)')
     parser = argparse.ArgumentParser(description="MQDB integration tests runner")
+    parser.add_argument(
+        "--build-dir",
+        default="build",
+        help="ck compiled build directory, such as \"build-debug\", \"build-debug-asan\", default build dir \"build\"")
     parser.add_argument(
         "--binary",
         default=os.environ.get("CLICKHOUSE_TESTS_SERVER_BIN_PATH", 
@@ -292,7 +309,7 @@ if __name__ == "__main__":
     
     parser.add_argument(
         "--runner-image-version",
-        default="1.0",
+        default="1.6",
         help="MQDB Integration tests runner version")
     
     parser.add_argument(
@@ -396,7 +413,7 @@ if __name__ == "__main__":
     
     try:
         logging.info("Trying to kill container {} if it's already running".format(CONTAINER_NAME))
-        subprocess.check_call(f'docker kill $(docker ps -a -q --filter name={CONTAINER_NAME} --format="{{{{.ID}}}}")', shell=True)
+        subprocess.check_call(f'docker rm $(docker ps -a -q --filter name={CONTAINER_NAME} --format="{{{{.ID}}}}")', shell=True)
         logging.info("Container killed")
     except:
         logging.info("Nothing to kill")
-- 
2.32.1 (Apple Git-133)

