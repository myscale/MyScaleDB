From 83542806f3140c1f9a95ea400aa500db98195c80 Mon Sep 17 00:00:00 2001
From: Zhenjia Li <zhenjial@moqi.ai>
Date: Thu, 6 Apr 2023 09:07:50 +0000
Subject: [PATCH 30/51] Refine VectorIndexCache

---
 src/Common/LRUResourceCache.h                 |   6 +
 src/Storages/MergeTree/IMergeTreeDataPart.cpp |   4 +-
 src/Storages/MergeTree/IMergeTreeDataPart.h   |   5 +-
 src/Storages/MergeTree/MergeTreeData.h        |   2 +
 .../MergeTreeVectorIndexBuilderUpdater.cpp    |  10 +-
 .../MergeTree/MergeTreeVectorScanManager.cpp  |  76 ++++++++---
 src/Storages/StorageMergeTree.h               |   2 +
 src/Storages/StorageReplicatedMergeTree.h     |   2 +
 src/VectorIndex/CacheManager.cpp              |  75 +++--------
 src/VectorIndex/CacheManager.h                |  60 ++++-----
 src/VectorIndex/IndexException.h              |  11 ++
 src/VectorIndex/VectorSegmentExecutor.cpp     | 127 ++++++++++--------
 .../test.py                                   |   2 +-
 .../__init__.py                               |   0
 .../test.py                                   |  42 ++++++
 15 files changed, 256 insertions(+), 168 deletions(-)
 create mode 100644 tests/integration/test_mqvs_load_vector_index_failed/__init__.py
 create mode 100644 tests/integration/test_mqvs_load_vector_index_failed/test.py

diff --git a/src/Common/LRUResourceCache.h b/src/Common/LRUResourceCache.h
index afc2ba5baf..aad06677ec 100644
--- a/src/Common/LRUResourceCache.h
+++ b/src/Common/LRUResourceCache.h
@@ -9,6 +9,11 @@
 #include <unordered_set>
 #include <base/logger_useful.h>
 
+namespace VectorIndex
+{
+class VectorIndexCache;
+}
+
 namespace DB
 {
 template <typename T>
@@ -206,6 +211,7 @@ private:
     };
 
     friend struct InsertTokenHolder;
+    friend class VectorIndex::VectorIndexCache;
     InsertTokenById insert_tokens;
     WeightFunction weight_function;
     ReleaseFunction release_function;
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
index 5455e2571a..7d3f1c1149 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
@@ -1126,7 +1126,7 @@ void IMergeTreeDataPart::loadColumns(bool require)
     setSerializationInfos(infos);
 }
 
-void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const String & col_name) const
+void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const String & col_name, bool skip_decouple) const
 {
     /// No need to check metadata of table, because for drop index, the metadata has erased it.
     /// Remove all the files which end with .vidx
@@ -1136,7 +1136,7 @@ void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const Stri
     {
         String file_name = it->name();
 
-        if (!endsWith(file_name, VECTOR_INDEX_FILE_SUFFIX))
+        if (!endsWith(file_name, VECTOR_INDEX_FILE_SUFFIX) || (skip_decouple && startsWith(file_name, "merged-")))
             continue;
 
         disk->removeFileIfExists(fs::path(getFullRelativePath()) / file_name);
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h
index 9c99b7995e..ea2da84d93 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.h
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h
@@ -378,8 +378,9 @@ public:
         vector_indexed.insert(index_name);
     }
 
-    /// remove specified vector index from part, both disk and metadata.
-    void removeVectorIndex(const String & index_name, const String & col_name) const;
+    /// Remove specified vector index from part, both disk and metadata.
+    /// If skip_decouple, skip the vector index of old part in decouple part.
+    void removeVectorIndex(const String & index_name, const String & col_name, bool skip_decouple = false) const;
 
     void setBuildError() const { vector_index_build_error = true; }
 
diff --git a/src/Storages/MergeTree/MergeTreeData.h b/src/Storages/MergeTree/MergeTreeData.h
index 5805f6b57c..8baf355bd3 100644
--- a/src/Storages/MergeTree/MergeTreeData.h
+++ b/src/Storages/MergeTree/MergeTreeData.h
@@ -1005,6 +1005,8 @@ public:
     /// merging (also with TTL), mutating or moving.
     mutable std::mutex currently_processing_in_background_mutex;
 
+    virtual bool isShutdown() const { return false; }
+
 protected:
     friend class IMergeTreeDataPart;
     friend class MergeTreeDataMergerMutator;
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
index d79150c125..4955b31a39 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
@@ -858,10 +858,18 @@ void MergeTreeVectorIndexBuilderUpdater::undoBuildVectorIndexForOnePart(
     for (auto & vec_index_desc : metadata_snapshot->vec_indices)
     {
         String index_name = vec_index_desc.name + "_" + vec_index_desc.column;
-        part->removeVectorIndex(vec_index_desc.name, vec_index_desc.column);
+        part->removeVectorIndex(vec_index_desc.name, vec_index_desc.column, true);
         VectorIndex::SegmentId segment_id(part->getFullPath(), part->name, vec_index_desc.name, vec_index_desc.column, 0);
         VectorIndex::VectorSegmentExecutor::removeFromCache(segment_id.getCacheKey());
     }
+    auto disk = part->volume->getDisk();
+    String part_name_prefix = part->info.getPartNameWithoutMutation();
+    String vector_tmp_relative_path = data.getRelativeDataPath() + "vector_tmp_" + part_name_prefix + "/";
+    String vector_index_ready_file_name = DB::toString("vector_index_ready") + VECTOR_INDEX_FILE_SUFFIX;
+    if (disk->exists(vector_tmp_relative_path) && !disk->exists(vector_tmp_relative_path + "/" + vector_index_ready_file_name))
+    {
+        disk->removeRecursive(vector_tmp_relative_path);
+    }
 }
 
 void MergeTreeVectorIndexBuilderUpdater::Counter::put(const String & key, int value)
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index a3aa05a27e..82a4aba729 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -28,6 +28,11 @@
 namespace DB
 {
 
+namespace ErrorCodes
+{
+    extern const int QUERY_WAS_CANCELLED;
+}
+
 template <typename FloatType>
 std::vector<float> getQueryVector(const IColumn * query_vector_column, int dim, bool is_batch)
 {
@@ -350,6 +355,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         std::vector<VectorIndex::VectorSegmentExecutorPtr> vec_executors;
         bool retry = false;
         bool brute_force = false;
+        bool is_shutdown = false;
 
         for (VectorIndex::SegmentId & segment_id : segment_ids)
         {
@@ -359,21 +365,38 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
                 segment_id,
                 vec_parameters,
                 dim);
-            VectorIndex::Status status = vec_executor->load();
-            LOG_DEBUG(log, "Vector number in index: {}", vec_executor->getRawDataSize());
-            LOG_DEBUG(log, "Load vector index: {}", status.getCode());
+            is_shutdown = data_part->storage.isShutdown();
+            if (!is_shutdown)
+            {
+                VectorIndex::Status status = vec_executor->load();
+                LOG_DEBUG(log, "Vector number in index: {}", vec_executor->getRawDataSize());
+                LOG_DEBUG(log, "Load vector index: {}", status.getCode());
 
-            if (!status.fine())
+                if (!status.fine())
+                {
+                    /// case of merged vector indices had been removed, we need to use new vector index files
+                    LOG_ERROR(log, "Fail to load vector index: {}", segment_id.getFullPath());
+                    retry = true;
+                    brute_force = true;
+                    break;
+                }
+            }
+            else
             {
-                /// case of merged vector indices had been removed, we need to use new vector index files
-                LOG_ERROR(log, "Fail to load vector index: {}", segment_id.getFullPath());
-                retry = true;
-                brute_force = true;
                 break;
             }
             vec_executors.emplace_back(vec_executor);
         }
 
+        if (!is_shutdown && data_part->storage.isShutdown())
+        {
+            retry = false;
+            for (VectorIndex::SegmentId & segment_id : segment_ids)
+            {
+                VectorIndex::VectorSegmentExecutor::removeFromCache(segment_id.getCacheKey());
+            }
+        }
+
         if (retry)
         {
             vec_executors.clear();
@@ -392,22 +415,37 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
                     segment_ids[0],
                     vec_parameters,
                     dim);
-                VectorIndex::Status status = vec_executor->load();
-                LOG_DEBUG(log, "Vector number in index: {}", vec_executor->getRawDataSize());
-                LOG_DEBUG(log, "Load vector index: {}", status.getCode());
-
-                if (!status.fine())
+                is_shutdown = data_part->storage.isShutdown();
+                if (!is_shutdown)
                 {
-                    LOG_ERROR(log, "Fail to load vector index: {}", segment_ids[0].getFullPath());
-                }
-                else
-                {
-                    vec_executors.emplace_back(vec_executor);
-                    brute_force = false;
+                    VectorIndex::Status status = vec_executor->load();
+                    LOG_DEBUG(log, "Vector number in index: {}", vec_executor->getRawDataSize());
+                    LOG_DEBUG(log, "Load vector index: {}", status.getCode());
+
+                    if (!status.fine())
+                    {
+                        LOG_ERROR(log, "Fail to load vector index: {}", segment_ids[0].getFullPath());
+                    }
+                    else
+                    {
+                        vec_executors.emplace_back(vec_executor);
+                        brute_force = false;
+                    }
                 }
             }
         }
 
+        if (is_shutdown || data_part->storage.isShutdown())
+        {
+            if (retry && !is_shutdown && segment_ids.size() == 1)
+            {
+                VectorIndex::VectorSegmentExecutor::removeFromCache(segment_ids[0].getCacheKey());
+            }
+            LOG_WARNING(log, "Query using vector index was canceled due to a concurrent detach or drop table or database query.");
+            context->getQueryContext()->killCurrentQuery();
+            throw Exception("Query was cancelled.", ErrorCodes::QUERY_WAS_CANCELLED);
+        }
+
         if (brute_force)
             return vectorScanWithoutIndex(data_part, read_ranges, filter, vec_data, search_column_name, dim, k, is_batch, metrics);
 
diff --git a/src/Storages/StorageMergeTree.h b/src/Storages/StorageMergeTree.h
index d3e33d5868..f705c98662 100644
--- a/src/Storages/StorageMergeTree.h
+++ b/src/Storages/StorageMergeTree.h
@@ -42,6 +42,8 @@ public:
 
     std::string getName() const override { return merging_params.getModeName() + "MergeTree"; }
 
+    bool isShutdown() const override { return shutdown_called.load(); }
+
     bool supportsParallelInsert() const override { return true; }
 
     bool supportsIndexForIn() const override { return true; }
diff --git a/src/Storages/StorageReplicatedMergeTree.h b/src/Storages/StorageReplicatedMergeTree.h
index 32753670fb..c7b9b64fd5 100644
--- a/src/Storages/StorageReplicatedMergeTree.h
+++ b/src/Storages/StorageReplicatedMergeTree.h
@@ -93,6 +93,8 @@ public:
 
     std::string getName() const override { return "Replicated" + merging_params.getModeName() + "MergeTree"; }
 
+    bool isShutdown() const override { return shutdown_called.load(); }
+
     bool supportsParallelInsert() const override { return true; }
     bool supportsReplication() const override { return true; }
     bool supportsDeduplication() const override { return true; }
diff --git a/src/VectorIndex/CacheManager.cpp b/src/VectorIndex/CacheManager.cpp
index 5f0f1e8eb3..bc4c7577fc 100644
--- a/src/VectorIndex/CacheManager.cpp
+++ b/src/VectorIndex/CacheManager.cpp
@@ -11,14 +11,14 @@ extern const int LOGICAL_ERROR;
 namespace VectorIndex
 {
 
-CacheManager::CacheManager(int): log(&Poco::Logger::get("CacheManager"))
+CacheManager::CacheManager(int) : log(&Poco::Logger::get("CacheManager"))
 {
     while (!m)
     {
         sleep(100);
     }
 
-    cache_ = std::make_unique<VectorIndexCache>(cache_size_in_bytes);
+    cache = std::make_unique<VectorIndexCache>(cache_size_in_bytes);
 }
 
 CacheManager * CacheManager::getInstance()
@@ -28,79 +28,47 @@ CacheManager * CacheManager::getInstance()
     return &cache_mgr;
 }
 
-IndexWithMetaPtr CacheManager::get(const CacheKey& cache_key)
+IndexWithMetaHolderPtr CacheManager::get(const CacheKey & cache_key)
 {
-    if (!cache_)
+    if (!cache)
     {
         throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "cache not allocated");
     }
-    IndexAndMutexPtr iam_ptr = cache_->get(cache_key);
-    if (iam_ptr)
-    {
-        return iam_ptr->index_ptr;
-    }
-    else
-    {
-        return nullptr;
-    }
+
+    return cache->get(cache_key);
 }
 
-void CacheManager::put(const CacheKey& cache_key, IndexWithMetaPtr index)
+void CacheManager::put(const CacheKey & cache_key, IndexWithMetaPtr index)
 {
-    if (!cache_)
+    if (!cache)
     {
         throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "cache not allocated");
     }
     LOG_INFO(log, "Put into cache: cache_key = {}", cache_key.toString());
 
-    IndexAndMutexPtr iam_ptr = std::make_shared<IndexAndMutex>(index, nullptr);
-
-    cache_->set(cache_key, iam_ptr);
+    cache->getOrSet(cache_key, [&]() { return index; });
 }
 
 size_t CacheManager::countItem() const
 {
-    return cache_->count();
+    return cache->size();
 }
 
-void CacheManager::forceExpire(const CacheKey& cache_key)
+void CacheManager::forceExpire(const CacheKey & cache_key)
 {
     LOG_INFO(log, "Force expire cache: cache_key = {}", cache_key.toString());
-    return cache_->remove(cache_key);
+    return cache->tryRemove(cache_key);
 }
 
-void CacheManager::startLoading(const CacheKey& cache_key)
+IndexWithMetaHolderPtr CacheManager::load(const CacheKey & cache_key, std::function<IndexWithMetaPtr()> load_func)
 {
-    if (!cache_)
+    if (!cache)
     {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "startLoading: cache not allocated");
+        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "load: cache not allocated");
     }
     LOG_INFO(log, "Start loading cache: cache_key = {}", cache_key.toString());
-    std::shared_ptr<std::mutex> new_mutex = std::make_shared<std::mutex>();
-
-    std::shared_ptr<IndexAndMutex> im_ptr = std::make_shared<IndexAndMutex>(nullptr, new_mutex);
-
-    cache_->getOrSet(cache_key, [&](){
-        return im_ptr;
-    });
-}
 
-std::shared_ptr<std::mutex> CacheManager::getMutex(const CacheKey& cache_key)
-{
-    if (!cache_)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "getMutex: cache not allocated");
-    }
-
-    IndexAndMutexPtr iam_ptr = cache_->get(cache_key);
-    if (iam_ptr)
-    {
-        return iam_ptr->mu_ptr;
-    }
-    else
-    {
-        return nullptr;
-    }
+    return cache->getOrSet(cache_key, load_func);
 }
 
 void CacheManager::setCacheSize(size_t size_in_bytes)
@@ -113,16 +81,13 @@ std::list<std::pair<CacheKey, Parameters>> CacheManager::getAllItems()
 {
     std::list<std::pair<CacheKey, Parameters>> result;
 
-    std::list<std::pair<CacheKey, std::shared_ptr<IndexAndMutex>>> cache_list = cache_->getCacheList();
+    std::list<std::pair<CacheKey, std::shared_ptr<IndexWithMeta>>> cache_list = cache->getCacheList();
 
-    for (auto im_ptr : cache_list)
+    for (auto cache_item : cache_list)
     {
         // key   --- string
-        // value --- std::shared_ptr<IndexAndMutex>
-        if (im_ptr.second->index_ptr)
-        {
-            result.emplace_back(std::make_pair(im_ptr.first, im_ptr.second->index_ptr->des));
-        }
+        // value --- std::shared_ptr<IndexWithMeta>
+        result.emplace_back(std::make_pair(cache_item.first, cache_item.second->des));
     }
     return result;
 }
diff --git a/src/VectorIndex/CacheManager.h b/src/VectorIndex/CacheManager.h
index cb97285a9e..67d6aaaf4e 100644
--- a/src/VectorIndex/CacheManager.h
+++ b/src/VectorIndex/CacheManager.h
@@ -5,7 +5,7 @@
 #include <list>
 #include <functional>
 
-#include <Common/LRUCache.h>
+#include <Common/LRUResourceCache.h>
 
 #include <VectorIndex/VectorIndex.h>
 #include <VectorIndex/VectorSegmentExecutor.h>
@@ -28,48 +28,47 @@ namespace VectorIndex
 static bool m = false;
 static size_t cache_size_in_bytes = 0;
 
-struct IndexAndMutex
+class IndexWithMetaWeightFunc
 {
-    IndexWithMetaPtr index_ptr;
-    std::shared_ptr<std::mutex> mu_ptr;
-
-    IndexAndMutex(IndexWithMetaPtr index_ptr_, std::shared_ptr<std::mutex> mu_ptr_) : index_ptr(index_ptr_), mu_ptr(mu_ptr_) { }
+public:
+    size_t operator()(const IndexWithMeta & index_meta) const
+    {
+        return index_meta.index->sizeInBytes();
+    }
 };
-using IndexAndMutexPtr = std::shared_ptr<IndexAndMutex>;
 
-class IndexAndMutexWeightFunc
+class IndexWithMetaReleaseFunction
 {
 public:
-    size_t operator()(const IndexAndMutex & iam) const
+    void operator()(std::shared_ptr<IndexWithMeta> index_meta_ptr)
     {
-        if (iam.index_ptr == nullptr)
-        {
-            return 0;
-        }
-
-        return iam.index_ptr->index->sizeInBytes();
+        if (index_meta_ptr)
+            index_meta_ptr.reset();
     }
 };
 
-class VectorIndexCache : public DB::LRUCache<CacheKey, IndexAndMutex, std::hash<CacheKey>, IndexAndMutexWeightFunc>
+using VectorIndexCacheType
+    = DB::LRUResourceCache<CacheKey, IndexWithMeta, IndexWithMetaWeightFunc, IndexWithMetaReleaseFunction, std::hash<CacheKey>>;
+using IndexWithMetaHolderPtr = VectorIndexCacheType::MappedHolderPtr;
+
+class VectorIndexCache
+    : public DB::LRUResourceCache<CacheKey, IndexWithMeta, IndexWithMetaWeightFunc, IndexWithMetaReleaseFunction, std::hash<CacheKey>>
 {
 public:
-    using Base = DB::LRUCache<CacheKey, IndexAndMutex, std::hash<CacheKey>, IndexAndMutexWeightFunc>;
+    explicit VectorIndexCache(size_t max_size) : VectorIndexCacheType(max_size) { }
 
-    explicit VectorIndexCache(size_t max_size) : Base(max_size) {}
-
-    std::list<std::pair<CacheKey, IndexAndMutexPtr>> getCacheList()
+    std::list<std::pair<CacheKey, IndexWithMetaPtr>> getCacheList()
     {
         std::lock_guard lock(mutex);
 
-        std::list<std::pair<CacheKey, IndexAndMutexPtr>> l;
+        std::list<std::pair<CacheKey, IndexWithMetaPtr>> res;
 
         for (auto it = cells.begin(); it != cells.cend(); ++it)
         {
-            l.push_back(std::make_pair(it->first, it->second.value));
+            res.push_back(std::make_pair(it->first, it->second.value));
         }
 
-        return l;
+        return res;
     }
 };
 
@@ -84,22 +83,19 @@ private:
     explicit CacheManager(int);
 
 public:
-    void put(const CacheKey& cache_key, IndexWithMetaPtr index);
-    IndexWithMetaPtr get(const CacheKey& cache_key);
+    void put(const CacheKey & cache_key, IndexWithMetaPtr index);
+    IndexWithMetaHolderPtr get(const CacheKey & cache_key);
     size_t countItem() const;
-    void forceExpire(const CacheKey& cache_key);
-    void startLoading(const CacheKey& cache_key);
-    std::shared_ptr<std::mutex> getMutex(const CacheKey& cache_key);
+    void forceExpire(const CacheKey & cache_key);
+    IndexWithMetaHolderPtr load(const CacheKey & cache_key, std::function<IndexWithMetaPtr()> load_func);
     std::list<std::pair<CacheKey, Parameters>> getAllItems();
-    void updateKey(const CacheKey& old_key, const CacheKey& new_key);
 
     static CacheManager * getInstance();
     static void setCacheSize(size_t size_in_bytes);
 
 protected:
-    mutable std::unique_ptr<VectorIndexCache> cache_;
-    Poco::Logger *log;
-
+    mutable std::unique_ptr<VectorIndexCache> cache;
+    Poco::Logger * log;
 };
 
 }
diff --git a/src/VectorIndex/IndexException.h b/src/VectorIndex/IndexException.h
index 701e6c28b4..107db33861 100644
--- a/src/VectorIndex/IndexException.h
+++ b/src/VectorIndex/IndexException.h
@@ -8,12 +8,23 @@ class IndexException : public DB::Exception
 public:
     IndexException(int code_, const std::string & message_) : DB::Exception(code_, "[VectorIndex] " + message_) { }
 
+    /// Just record index status code and message, and wait for further processing.
+    IndexException(const std::string & message_, int code_) : status_code(code_), status_message(message_) { }
+
+    int statusCode() const { return status_code; }
+    String statusMessage() const { return status_message; }
+
     // Format message with fmt::format, like the logging functions.
     template <typename... Args>
     IndexException(int code, const std::string & fmt, Args &&... args)
         : DB::Exception(fmt::format(fmt::runtime("vector index: " + fmt), std::forward<Args>(args)...), code)
     {
     }
+
+private:
+    /// Record index status code and message
+    int status_code;
+    String status_message;
 };
 
 }
diff --git a/src/VectorIndex/VectorSegmentExecutor.cpp b/src/VectorIndex/VectorSegmentExecutor.cpp
index 5093008a37..6dc746a2b7 100644
--- a/src/VectorIndex/VectorSegmentExecutor.cpp
+++ b/src/VectorIndex/VectorSegmentExecutor.cpp
@@ -177,12 +177,13 @@ void VectorSegmentExecutor::updateCacheValueWithRowIdsMaps()
     }
     CacheKey cache_key = segment_id.getCacheKey();
     CacheManager * mgr = CacheManager::getInstance();
-    IndexWithMetaPtr index = mgr->get(cache_key);
-    if (index != nullptr)
+    IndexWithMetaHolderPtr index_holder = mgr->get(cache_key);
+    if (index_holder)
     {
-        index->row_ids_map = this->row_ids_map;
-        index->inverted_row_ids_map = this->inverted_row_ids_map;
-        index->inverted_row_sources_map = this->inverted_row_sources_map;
+        IndexWithMeta & index = index_holder->value();
+        index.row_ids_map = this->row_ids_map;
+        index.inverted_row_ids_map = this->inverted_row_ids_map;
+        index.inverted_row_sources_map = this->inverted_row_sources_map;
     }
     /// not handle empty cache case here.
 }
@@ -423,36 +424,16 @@ Status VectorSegmentExecutor::load()
     LOG_DEBUG(log, "segment_id.getBitMapFilePath() = {}", segment_id.getBitMapFilePath());
     LOG_DEBUG(log, "cache_key_str = {}", cache_key_str);
 
-    IndexWithMetaPtr new_index = mgr->get(cache_key);
-    if (new_index == nullptr)
+    IndexWithMetaHolderPtr index_holder = mgr->get(cache_key);
+    if (index_holder == nullptr)
     {
         LOG_DEBUG(log, "Miss cache, cache_key_str = {}", cache_key_str);
-        /// We don't want many execution engine reading disk and preserving multiple copies of index, so we use a unique lock to
-        /// ensure that only one execution engine may read from disk at any time.
+        /// We don't want multiple execution engines loading index concurrently, so we use getOrSet method of LRUResourceCache
+        /// to ensure that only one execution engine may read from disk at any time.
         LOG_DEBUG(log, "Num of item before cache {}", mgr->countItem());
-        mgr->startLoading(cache_key);
-        std::shared_ptr<std::mutex> this_segment_mutex = mgr->getMutex(cache_key);
-        if (this_segment_mutex != nullptr)
-        {
-            LOG_TRACE(log, "entering critical area");
-            const std::lock_guard<std::mutex> lock(*this_segment_mutex);
-            LOG_TRACE(log, "acquired lock");
-            /// when it acquires the lock, it has to double check if the index was cached by its previous execution engine
-            IndexWithMetaPtr new_index = mgr->get(cache_key);
-            if (new_index != nullptr)
-            {
-                index = new_index->index;
-                total_vec = new_index->total_vec;
-                op_points = new_index->op_points;
-                delete_bitmap = new_index->getDeleteBitmap();
-                des = new_index->des;
-                if (auto_tune && getOps().getCode() != 0)
-                {
-                    LOG_WARNING(log, "Index not autotuned");
-                }
-                return Status();
-            }
 
+        auto load_func = [&]() -> IndexWithMetaPtr
+        {
             DiskIOReader reader;
             /// TODO this is really funky... have to change it later
             String ready_file_path = segment_id.getVectorReadyFilePath();
@@ -464,19 +445,19 @@ Status VectorSegmentExecutor::load()
             if (original_binary_sizes.find(index_name) == original_binary_sizes.end())
             {
                 LOG_DEBUG(log, "Unable to parse the original index size {}", ready_file_path);
-                return Status(5, "unable to parse the original index size " + ready_file_path);
+                throw IndexException("Unable to parse the original index size " + ready_file_path, 5);
             }
             int64_t original_binary_size = original_binary_sizes.find(index_name)->second;
             if (original_binary_size < 0)
             {
-                return Status(5, "unable to parse the original index size " + ready_file_path);
+                throw IndexException("Unable to parse the original index size " + ready_file_path, 5);
             }
             des = params.at(index_name);
 
             if (!readBitMap())
             {
                 LOG_ERROR(log, "Failed to read vector index bitmap: {}", segment_id.getFullPath());
-                return Status(5, "corrupted data: " + segment_id.getFullPath());
+                throw IndexException("Corrupted data: " + segment_id.getFullPath(), 5);
             }
 
             if (des.contains("metric_type"))
@@ -494,7 +475,7 @@ Status VectorSegmentExecutor::load()
             catch (const IndexException & e)
             {
                 LOG_ERROR(log, "failed to load index: {}", e.message());
-                return Status(e.code(), e.message());
+                throw;
             }
             index->setTrained();
             des.erase("type");
@@ -510,33 +491,67 @@ Status VectorSegmentExecutor::load()
                 /// May failed to load merged row ids map due to background index build may remove them when finished.
                 handleMergedMaps();
             }
-            catch(const DB::Exception & e)
+            catch (const DB::Exception & e)
             {
                 LOG_DEBUG(log, "Failed to load inverted row ids map entries, error: {}", e.what());
-                return Status(e.code(), e.message());
+                throw IndexException(e.message(), e.code());
+            }
+
+            if (index == nullptr)
+            {
+                LOG_INFO(log, "{} index is null, not caching", segment_id.getCacheKey().toString());
+                throw IndexException(segment_id.getCacheKey().toString() + " index is null, not caching", 3);
+            }
+            if (!des.contains("type"))
+            {
+                des.insert(std::make_pair("type", VectorIndexFactory::typeToString(type)));
             }
 
-            return cache();
+            return std::make_shared<IndexWithMeta>(
+                index, total_vec, op_points, delete_bitmap, des, row_ids_map, inverted_row_ids_map, inverted_row_sources_map);
+        };
+
+        try
+        {
+            IndexWithMetaHolderPtr index_holder_ = mgr->load(cache_key, load_func);
+            LOG_DEBUG(log, "Num of item after cache {}", mgr->countItem());
+            if (index_holder_)
+            {
+                IndexWithMeta & new_index = index_holder_->value();
+                index = new_index.index;
+                total_vec = new_index.total_vec;
+                op_points = new_index.op_points;
+                delete_bitmap = new_index.getDeleteBitmap();
+                des = new_index.des;
+                if (auto_tune && getOps().getCode() != 0)
+                {
+                    LOG_WARNING(log, "Index not autotuned");
+                }
+                return Status();
+            }
         }
-        else
+        catch (const IndexException & e)
         {
-            return Status(4, "can't lock this segment, aborting: " + segment_id.getCacheKey().toString());
+            return Status(e.statusCode(), e.statusMessage());
         }
+
+        return Status(2, "Load failed");
     }
     else
     {
         LOG_DEBUG(log, "Hit cache, cache_key_str = {}", cache_key_str);
-        index = new_index->index;
-        total_vec = new_index->total_vec;
-        op_points = new_index->op_points;
-        delete_bitmap = new_index->getDeleteBitmap();
-
-        des = new_index->des;
-        if (!new_index->row_ids_map->empty())
+        IndexWithMeta & new_index = index_holder->value();
+        index = new_index.index;
+        total_vec = new_index.total_vec;
+        op_points = new_index.op_points;
+        delete_bitmap = new_index.getDeleteBitmap();
+
+        des = new_index.des;
+        if (!new_index.row_ids_map->empty())
         {
-            row_ids_map = new_index->row_ids_map;
-            inverted_row_ids_map = new_index->inverted_row_ids_map;
-            inverted_row_sources_map = new_index->inverted_row_sources_map;
+            row_ids_map = new_index.row_ids_map;
+            inverted_row_ids_map = new_index.inverted_row_ids_map;
+            inverted_row_sources_map = new_index.inverted_row_sources_map;
         }
         else
         {
@@ -988,9 +1003,9 @@ void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64>& deleted_row_
     CacheManager * mgr = CacheManager::getInstance();
     CacheKey cache_key = segment_id.getCacheKey();
 
-    IndexWithMetaPtr cache_index = mgr->get(cache_key);
-    if (cache_index)
-        cache_index->setDeleteBitmap(delete_bitmap);
+    IndexWithMetaHolderPtr index_holder = mgr->get(cache_key);
+    if (index_holder)
+        index_holder->value().setDeleteBitmap(delete_bitmap);
 }
 
 void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& deleted_row_ids)
@@ -1047,9 +1062,9 @@ void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& delete
     CacheManager * mgr = CacheManager::getInstance();
     CacheKey cache_key = segment_id.getCacheKey();
 
-    IndexWithMetaPtr cache_index = mgr->get(cache_key);
-    if (cache_index)
-        cache_index->setDeleteBitmap(delete_bitmap);
+    IndexWithMetaHolderPtr index_holder = mgr->get(cache_key);
+    if (index_holder)
+        index_holder->value().setDeleteBitmap(delete_bitmap);
 }
 
 
diff --git a/tests/integration/test_mqvs_cancel_building_vector_index/test.py b/tests/integration/test_mqvs_cancel_building_vector_index/test.py
index 4f06566bbd..2e4d20aeb7 100644
--- a/tests/integration/test_mqvs_cancel_building_vector_index/test.py
+++ b/tests/integration/test_mqvs_cancel_building_vector_index/test.py
@@ -67,4 +67,4 @@ def test_drop_table_release_index_cache(started_cluster):
     assert instance.query("select status from system.vector_indices where database = currentDatabase() and table = 'test_drop_table_release_cache'") == "Built\n"
     instance.query("DROP TABLE test_drop_table_release_cache SYNC")
 
-    assert instance.contains_in_log("num of cache items after forceExpire 0")
+    assert instance.contains_in_log("Num of cache items after forceExpire 0")
diff --git a/tests/integration/test_mqvs_load_vector_index_failed/__init__.py b/tests/integration/test_mqvs_load_vector_index_failed/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/tests/integration/test_mqvs_load_vector_index_failed/test.py b/tests/integration/test_mqvs_load_vector_index_failed/test.py
new file mode 100644
index 0000000000..435167c2f2
--- /dev/null
+++ b/tests/integration/test_mqvs_load_vector_index_failed/test.py
@@ -0,0 +1,42 @@
+import pytest
+import time
+from helpers.cluster import ClickHouseCluster
+
+cluster = ClickHouseCluster(__file__)
+instance = cluster.add_instance("instance", stay_alive=True)
+path_to_index_ready_file = "/var/lib/clickhouse/data/default/test_load_vector_index_failed/all_1_1_0/vector_index_ready.vidx"
+
+
+@pytest.fixture(scope="module")
+def started_cluster():
+    try:
+        cluster.start()
+        yield cluster
+
+    finally:
+        cluster.shutdown()
+
+
+def test_load_vector_index_failed(started_cluster):
+    instance.query(
+        """
+    CREATE TABLE test_load_vector_index_failed(id UInt32, text String, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) Engine MergeTree ORDER BY id;
+    INSERT INTO test_load_vector_index_failed SELECT number, randomPrintableASCII(80), range(3) FROM numbers(1000);
+    ALTER TABLE test_load_vector_index_failed ADD VECTOR INDEX v1 vector TYPE HNSWSQ;
+    """
+    )
+
+    instance.wait_for_log_line("index build complete")
+
+    instance.restart_clickhouse()
+    time.sleep(3)
+
+    instance.exec_in_container(
+        ["bash", "-c", "mv {} {}".format(path_to_index_ready_file, path_to_index_ready_file + ".bak")],
+        privileged=True,
+        user="root",
+    )
+
+    instance.query("SELECT id, vector, distance('topK = 10')(vector, [300.0, 300, 300]) AS dist FROM test_load_vector_index_failed;")
+
+    assert instance.contains_in_log("Load vector index: 5")
-- 
2.32.1 (Apple Git-133)

