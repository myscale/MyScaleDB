From 17af858a75521e6e3ccda03727f48aa715f3980a Mon Sep 17 00:00:00 2001
From: Shelly <shelly@moqi.ai>
Date: Wed, 7 Jun 2023 03:44:20 +0000
Subject: [PATCH 41/49] 148_support_replacing_merge_tree

---
 src/Storages/MergeTree/MergeTask.cpp          | 165 +++++++++++++-----
 src/Storages/MergeTree/MergeTask.h            |   2 +
 .../MergeTree/MergeTreeVectorScanManager.cpp  |  31 ++--
 ...qvs_support_replacing_merge_tree.reference |  34 ++++
 ...0031_mqvs_support_replacing_merge_tree.sql |  89 ++++++++++
 5 files changed, 262 insertions(+), 59 deletions(-)
 create mode 100644 tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.reference
 create mode 100644 tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.sql

diff --git a/src/Storages/MergeTree/MergeTask.cpp b/src/Storages/MergeTree/MergeTask.cpp
index f05df9bf60..3e71e1862c 100644
--- a/src/Storages/MergeTree/MergeTask.cpp
+++ b/src/Storages/MergeTree/MergeTask.cpp
@@ -444,11 +444,11 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
             global_ctx->future_part->parts[part_num],
             global_ctx->context->getSettingsRef().max_block_size,
             global_ctx->context->getSettingsRef().preferred_block_size_bytes,
-            global_ctx->context->getSettingsRef().preferred_max_column_in_block_size_bytes, 
+            global_ctx->context->getSettingsRef().preferred_max_column_in_block_size_bytes,
             primary_key_columns,
-            ranges, 
+            ranges,
             false, nullptr, actions_settings, reader_settings, system_columns);
-        
+
         Pipe pipe(std::move(input));
 
         QueryPipeline filter_pipeline(std::move(pipe));
@@ -465,7 +465,7 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
             }
         }
     }
-    
+
     ctx->rows_sources_write_buf->next();
     ctx->rows_sources_uncompressed_write_buf->next();
     /// Ensure data has written to disk.
@@ -476,55 +476,142 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
     auto rows_sources_read_buf = std::make_unique<CompressedReadBufferFromFile>(ctx->tmp_disk->readFile(fileName(ctx->rows_sources_file->path())));
     LOG_DEBUG(ctx->log, "Try to read from rows_sources_file: {}, rows_sources_count: {}", ctx->rows_sources_file->path(), rows_sources_count);
     rows_sources_read_buf->seek(0, 0);
-    
+
     /// read data into buffer
     uint64_t new_part_row_id = 0;
     std::vector<uint64_t> source_row_ids(global_ctx->future_part->parts.size(), 0);
     /// used to store new row ids for each old part
     std::vector<std::unordered_map<UInt64, UInt64>> parts_new_row_ids(global_ctx->future_part->parts.size());
     /// TODO: confirm read all in one round?
-    while (!rows_sources_read_buf->eof())
+
+    /// Replacing Merge Tree
+    if (ctx->merging_params.mode == MergeTreeData::MergingParams::Collapsing
+        || ctx->merging_params.mode == MergeTreeData::MergingParams::Replacing
+        || ctx->merging_params.mode == MergeTreeData::MergingParams::VersionedCollapsing)
     {
-        RowSourcePart * row_source_pos = reinterpret_cast<RowSourcePart *>(rows_sources_read_buf->position());
-        RowSourcePart * row_sources_end = reinterpret_cast<RowSourcePart *>(rows_sources_read_buf->buffer().end());
-        while (row_source_pos < row_sources_end)
+        /// write one file(inverted row ids map), new part -> pos in old part, if not in, skip writing
+        while (!rows_sources_read_buf->eof())
         {
-            RowSourcePart row_source = *row_source_pos;
-            size_t source_num = row_source.getSourceNum();
-            auto old_part_offset = part_offsets[source_num][source_row_ids[source_num]];
-            parts_new_row_ids[source_num][old_part_offset] = new_part_row_id;
-            /// writeIntText(new_part_row_id, *global_ctx->row_ids_map_bufs[source_num]);
-            writeIntText(old_part_offset, *global_ctx->inverted_row_ids_map_buf);
-            /// need to add this, or we cannot correctly read uint64 value
-            /// writeChar('\t', *global_ctx->row_ids_map_bufs[source_num]);
-            writeChar('\t', *global_ctx->inverted_row_ids_map_buf);
-
-            ++new_part_row_id;
-            ++source_row_ids[source_num];
-
-            ++row_source_pos;
+            RowSourcePart * row_source_pos = reinterpret_cast<RowSourcePart *>(rows_sources_read_buf->position());
+            RowSourcePart * row_sources_end = reinterpret_cast<RowSourcePart *>(rows_sources_read_buf->buffer().end());
+            while (row_source_pos < row_sources_end)
+            {
+                /// row_source is the part from which row comes
+                RowSourcePart row_source = *row_source_pos;
+                /// part pos number in part_offsets
+                size_t source_num = row_source.getSourceNum() ;
+
+                if (!row_source_pos->getSkipFlag())
+                {
+                    /// source_row_ids stores the row offset of the corresponding part
+                    auto old_part_offset = part_offsets[source_num][source_row_ids[source_num]];
+
+                    /// parts_new_row_ids stores mapping from a formal row in old part to its current pos in new merged part
+                    parts_new_row_ids[source_num][old_part_offset] = new_part_row_id;
+                    writeIntText(old_part_offset, *global_ctx->inverted_row_ids_map_buf);
+                    /// need to add this, or we cannot correctly read uint64 value
+                    writeChar('\t', *global_ctx->inverted_row_ids_map_buf);
+                    ++new_part_row_id;
+                }
+                ++source_row_ids[source_num];
+
+                ++row_source_pos;
+            }
+            rows_sources_read_buf->position() = reinterpret_cast<char *>(row_source_pos);
         }
 
-        rows_sources_read_buf->position() = reinterpret_cast<char *>(row_source_pos);
-    }
+        /// write row_ids_map_bufs,
+        for (size_t source_num = 0; source_num < old_parts_num; source_num++)
+        /// write multiple files(row id map buf), old part -> pos in new part,if not in skip writing
+        {
+            auto metadata_snapshot = global_ctx->data->getInMemoryMetadataPtr();
+            UInt64 old_row_id = 0;
+            auto partRowNum = global_ctx->future_part->parts[source_num]->rows_count;
+            std::vector<uint64_t> deleteRowIds(partRowNum, 0);
+            int i = 0;
+            while (old_row_id < partRowNum)
+            {
+                if (parts_new_row_ids[source_num].count(old_row_id) > 0)
+                {
+                    UInt64 new_row_id = parts_new_row_ids[source_num][old_row_id];
+                    writeIntText(new_row_id, *global_ctx->row_ids_map_bufs[source_num]);
+                    writeChar('\t', *global_ctx->row_ids_map_bufs[source_num]);
+                }
+                else
+                {
+                    //generate delete row id for using in vector index
+                    deleteRowIds[i] = static_cast<UInt64>(old_row_id);
+                    i++;
+                }
+                ++old_row_id;
+            }
 
-    /// write row_ids_map_bufs
-    for (size_t source_num = 0; source_num < old_parts_num; source_num++)
+            if(i > 0)
+            {
+                auto vec_index_desc = metadata_snapshot->vec_indices[0];
+
+                VectorIndex::SegmentId segment_id(
+                    global_ctx->future_part->parts[source_num]->volume,
+                    global_ctx->future_part->parts[source_num]->getFullPath(),
+                    global_ctx->future_part->parts[source_num]->name,
+                    vec_index_desc.name,
+                    vec_index_desc.column,
+                    "");
+                VectorIndex::VectorSegmentExecutor vec_executor(segment_id);
+                vec_executor.updateBitMap(deleteRowIds);
+            }
+        }
+    }
+    else
     {
-        UInt64 old_row_id = 0;
-        while (old_row_id < global_ctx->future_part->parts[source_num]->rows_count)
+        while (!rows_sources_read_buf->eof())
+        {
+            RowSourcePart * row_source_pos = reinterpret_cast<RowSourcePart *>(rows_sources_read_buf->position());
+            RowSourcePart * row_sources_end = reinterpret_cast<RowSourcePart *>(rows_sources_read_buf->buffer().end());
+            while (row_source_pos < row_sources_end)
+            {
+                /// row_source is the part from which row comes
+                RowSourcePart row_source = *row_source_pos;
+                /// part pos number in part_offsets
+                size_t source_num = row_source.getSourceNum();
+                /// source_row_ids stores the row offset of the corresponding part
+                auto old_part_offset = part_offsets[source_num][source_row_ids[source_num]];
+                /// stores mapping from a formal row in old part to its current pos in new merged part
+                parts_new_row_ids[source_num][old_part_offset] = new_part_row_id;
+
+                /// writeIntText(new_part_row_id, *global_ctx->row_ids_map_bufs[source_num]);
+                writeIntText(old_part_offset, *global_ctx->inverted_row_ids_map_buf);
+                /// need to add this, or we cannot correctly read uint64 value
+                /// writeChar('\t', *global_ctx->row_ids_map_bufs[source_num]);
+                writeChar('\t', *global_ctx->inverted_row_ids_map_buf);
+
+                ++new_part_row_id;
+                ++source_row_ids[source_num];
+
+                ++row_source_pos;
+            }
+
+            rows_sources_read_buf->position() = reinterpret_cast<char *>(row_source_pos);
+        }
+
+        /// write row_ids_map_bufs
+        for (size_t source_num = 0; source_num < old_parts_num; source_num++)
         {
-            UInt64 new_row_id = -1;
-            if (parts_new_row_ids[source_num].count(old_row_id) > 0)
+            UInt64 old_row_id = 0;
+            while (old_row_id < global_ctx->future_part->parts[source_num]->rows_count)
             {
-                new_row_id = parts_new_row_ids[source_num][old_row_id];   
+                UInt64 new_row_id = -1;
+                if (parts_new_row_ids[source_num].count(old_row_id) > 0)
+                {
+                    new_row_id = parts_new_row_ids[source_num][old_row_id];
+                }
+                writeIntText(new_row_id, *global_ctx->row_ids_map_bufs[source_num]);
+                writeChar('\t', *global_ctx->row_ids_map_bufs[source_num]);
+                ++old_row_id;
             }
-            writeIntText(new_row_id, *global_ctx->row_ids_map_bufs[source_num]);
-            writeChar('\t', *global_ctx->row_ids_map_bufs[source_num]); 
-            ++old_row_id;
         }
     }
-    
+
     LOG_DEBUG(ctx->log, "After write row_source_pos: inverted_row_ids_map_buf size: {}", global_ctx->inverted_row_ids_map_buf->count());
 
     if (global_ctx->chosen_merge_algorithm == MergeAlgorithm::Horizontal)
@@ -543,7 +630,7 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
     global_ctx->inverted_row_ids_map_buf->next();
     global_ctx->inverted_row_ids_map_uncompressed_buf->next();
     global_ctx->inverted_row_ids_map_uncompressed_buf->finalize();
-    
+
     return false;
 }
 
@@ -835,7 +922,7 @@ bool MergeTask::MergeProjectionsStage::finalizeProjectionsAndWholeMerge() const
             LOG_DEBUG(ctx->log, "Row ids map tmp file path: {} new file: {}", row_ids_map_tmp_file, row_ids_map_file_path);
             std::filesystem::rename(row_ids_map_tmp_file, row_ids_map_file_path);
             /// move and rename vector index files to new dir
-            VectorIndex::renameVectorIndexFiles(toString(i), global_ctx->future_part->parts[i]->name, global_ctx->future_part->parts[i]->getFullPath(), global_ctx->new_data_part->getFullPath());        
+            VectorIndex::renameVectorIndexFiles(toString(i), global_ctx->future_part->parts[i]->name, global_ctx->future_part->parts[i]->getFullPath(), global_ctx->new_data_part->getFullPath());
         }
 
         String inverted_row_ids_map_file_path = global_ctx->new_data_part->getFullPath() + "merged-inverted_row_ids_map" + VECTOR_INDEX_FILE_SUFFIX;
@@ -977,7 +1064,7 @@ void MergeTask::ExecuteAndFinalizeHorizontalPart::createMergedStream()
             true,
             false,
             global_ctx->input_rows_filtered);
-        
+
         if (global_ctx->metadata_snapshot->hasSortingKey())
         {
             pipe.addSimpleTransform([this](const Block & header)
diff --git a/src/Storages/MergeTree/MergeTask.h b/src/Storages/MergeTree/MergeTask.h
index 081d2a9442..f90641b091 100644
--- a/src/Storages/MergeTree/MergeTask.h
+++ b/src/Storages/MergeTree/MergeTask.h
@@ -13,6 +13,8 @@
 #include <Compression/CompressedReadBufferFromFile.h>
 #include <Common/filesystemHelpers.h>
 
+#include <VectorIndex/SegmentId.h>
+
 #include <memory>
 #include <list>
 
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index 949ff08a17..398b8e7485 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -851,7 +851,6 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
         cols.emplace_back(LightweightDeleteDescription::FILTER_COLUMN);
     }
 
-    Search::DenseBitmapPtr row_exists = std::make_shared<Search::DenseBitmap>(part->rows_count, true);
 
     VectorScanResultPtr tmp_vector_scan_result = std::make_shared<VectorScanResult>();
     tmp_vector_scan_result->result_columns.resize(is_batch ? 3 : 2);
@@ -877,16 +876,13 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
         reader_settings);
 
     size_t current_mark = 0;
-    size_t total_mask = part->getMarksCount();
     size_t total_rows_to_read = part->rows_count;
     const auto & index_granularity = part->index_granularity;
 
-    /// compute how many rows to read in one round
-    size_t max_search_block_size_bytes = part->storage.getContext()->getSettingsRef().preferred_block_size_bytes;
-
     size_t num_rows_read = 0;
 
-    size_t default_read_num = std::max(index_granularity.getMarkRows(current_mark), max_search_block_size_bytes / 4 / dim);
+    ///size_t default_read_num = std::max(index_granularity.getMarkRows(current_mark), max_search_block_size_bytes / 4 / dim);
+    size_t default_read_num = index_granularity.getMarkRows(current_mark);
 
     bool continue_read = false;
 
@@ -923,6 +919,8 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
             Columns result;
             result.resize(cols.size());
             size_t num_rows = reader->readRows(single_range.start_mark, 0, false, single_range.row_num, result);
+            Search::DenseBitmapPtr row_exists = std::make_shared<Search::DenseBitmap>(num_rows, true);
+
             if (num_rows == 0)
             {
                 LOG_WARNING(log, "Part: {}, no data read for column {}", part->name, cols.back().name);
@@ -1028,23 +1026,14 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     {
         while (num_rows_read < total_rows_to_read)
         {
-            size_t remaining_size = total_rows_to_read - num_rows_read;
-            size_t max_read_row = std::min(remaining_size, default_read_num);
+            size_t max_read_row = std::min((total_rows_to_read - num_rows_read), default_read_num);
             Columns result;
             result.resize(cols.size());
             size_t num_rows = reader->readRows(current_mark, 0, continue_read, max_read_row, result);
+            current_mark ++;
 
             continue_read = true;
 
-            for (size_t mask = 0; mask < total_mask - 1; ++mask)
-            {
-                if (index_granularity.getMarkStartingRow(mask) >= num_rows_read
-                    && index_granularity.getMarkStartingRow(mask + 1) < num_rows_read)
-                {
-                    current_mark = mask;
-                }
-            }
-
             LOG_DEBUG(log, "Part: {}, read num_rows: {}, col size: {}", part->name, num_rows, cols.size());
 
             if (num_rows == 0)
@@ -1059,7 +1048,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
             const ColumnArray::Offsets & offsets = array->getOffsets();
             const ColumnFloat32 * src_data_concrete = checkAndGetColumn<ColumnFloat32>(&src_data);
             const PaddedPODArray<Float32> & src_vec = src_data_concrete->getData();
-            // size_t size = offsets.size();
+
             if (src_vec.empty())
             {
                 num_rows_read += num_rows;
@@ -1084,6 +1073,8 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
             LOG_DEBUG(log, "Part: {}, raw_data size: {}", part->name, vector_raw_data.size());
 
             int deleted_row_num = 0;
+            Search::DenseBitmapPtr row_exists = std::make_shared<Search::DenseBitmap>(offsets.size(), true);
+
             if (part->storage.hasLightweightDeletedMask())
             {
                 LOG_DEBUG(log, "Try to get row exists col, result size: {}", result.size());
@@ -1145,7 +1136,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
         for (size_t label = 0; label < k * nq; ++label)
         {
             UInt32 vector_id = label / k;
-            if (final_id[label] > -1 && row_exists->is_member(final_id[label]))
+            if (final_id[label] > -1)
             {
                 label_column->insert(final_id[label]);
                 vector_id_column->insert(vector_id);
@@ -1161,7 +1152,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     {
         for (size_t label = 0; label < k * nq; ++label)
         {
-            if (final_id[label] > -1 && row_exists->is_member(final_id[label]))
+            if (final_id[label] > -1)
             {
                 LOG_DEBUG(log, "Label: {}, distance: {}", final_id[label], final_distance[label]);
                 label_column->insert(final_id[label]);
diff --git a/tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.reference b/tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.reference
new file mode 100644
index 0000000000..7704e5de0c
--- /dev/null
+++ b/tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.reference
@@ -0,0 +1,34 @@
+0
+0
+0	2023-03-01	5
+1	2023-03-01	14
+2	2023-03-01	29
+3	2023-03-01	50
+4	2023-03-01	77
+5	2023-03-01	110
+6	2023-03-01	149
+7	2023-03-01	194
+8	2023-03-01	245
+9	2023-03-01	302
+10	2023-03-01	365
+11	2023-03-01	434
+12	2023-03-01	509
+13	2023-03-01	590
+14	2023-03-01	677
+15	2023-03-01	770
+16	2023-03-01	869
+17	2023-03-01	974
+18	2023-03-01	1085
+19	2023-03-01	1202
+0
+0
+0	1	2023-03-01	5
+1	1	2023-04-01	29
+2	1	2023-03-01	29
+3	1	2023-04-01	77
+4	1	2023-03-01	77
+5	1	2023-04-01	149
+6	1	2023-03-01	149
+7	1	2023-04-01	245
+8	1	2023-03-01	245
+9	1	2023-04-01	365
diff --git a/tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.sql b/tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.sql
new file mode 100644
index 0000000000..7bbf26566c
--- /dev/null
+++ b/tests/queries/2_vector_search/00031_mqvs_support_replacing_merge_tree.sql
@@ -0,0 +1,89 @@
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS replacing_test SYNC;
+CREATE TABLE replacing_test(
+    id Float32, 
+    vector Array(Float32),
+    date Date,
+    CONSTRAINT check_length CHECK length(vector) = 3
+    ) engine ReplacingMergeTree
+    ORDER BY id;
+
+ALTER TABLE replacing_test ADD VECTOR INDEX mstg vector TYPE MSTG;
+
+INSERT INTO replacing_test SELECT
+    number,
+    [number + 4, number + 4, number + 4],
+    toDate('2023-04-01', 'UTC')
+FROM numbers(1000);
+
+INSERT INTO replacing_test SELECT
+    number,
+    [number + 3, number + 3, number + 3],
+    toDate('2023-03-01', 'UTC')
+FROM numbers(1000);
+
+SELECT sleep(2);
+
+OPTIMIZE TABLE replacing_test FINAL;
+
+SELECT sleep(2);
+
+SELECT
+    id,
+    date,
+    distance(vector, [1., 2., 3.]) AS dist
+FROM replacing_test
+ORDER BY dist ASC
+LIMIT 10;
+
+delete from replacing_test where id < 10;
+
+SELECT
+    id,
+    date,
+    distance(vector, [1., 2., 3.]) AS dist
+FROM replacing_test
+ORDER BY dist ASC
+LIMIT 10;
+
+DROP TABLE IF EXISTS replacing_test SYNC;
+CREATE TABLE replacing_test(
+    id Float32, 
+    vector Array(Float32),
+    date Date,
+    ver UInt8,
+    CONSTRAINT check_length CHECK length(vector) = 3
+    ) engine ReplacingMergeTree(ver)
+    ORDER BY id;
+
+ALTER TABLE replacing_test ADD VECTOR INDEX mstg vector TYPE MSTG;
+
+INSERT INTO replacing_test SELECT
+    number,
+    [number + 4, number + 4, number + 4],
+    toDate('2023-04-01', 'UTC'),
+    number%2
+FROM numbers(1000);
+
+INSERT INTO replacing_test SELECT
+    number,
+    [number + 3, number + 3, number + 3],
+    toDate('2023-03-01', 'UTC'),
+    (number+1)%2
+FROM numbers(1000);
+
+SELECT sleep(2);
+
+OPTIMIZE TABLE replacing_test FINAL;
+
+SELECT sleep(2);
+
+SELECT
+    id,
+    ver,
+    date,
+    distance(vector, [1., 2., 3.]) AS dist
+FROM replacing_test
+ORDER BY dist ASC
+LIMIT 10;
\ No newline at end of file
-- 
2.32.1 (Apple Git-133)

