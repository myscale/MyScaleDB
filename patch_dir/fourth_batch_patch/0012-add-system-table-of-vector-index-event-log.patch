From 1a426a103896e0ac17bcecd4312d606f05dec7d4 Mon Sep 17 00:00:00 2001
From: Shanfeng Pang <shanfengp@moqi.ai>
Date: Thu, 11 May 2023 08:59:07 +0000
Subject: [PATCH 12/49] add system table of vector index event log

---
 programs/server/Server.cpp                    |   2 +
 src/Common/LRUResourceCache.h                 |  17 +-
 src/Common/SystemLogBase.cpp                  |   1 +
 src/Common/SystemLogBase.h                    |   4 +-
 src/Interpreters/Context.cpp                  |  25 ++-
 src/Interpreters/Context.h                    |   8 +
 src/Interpreters/InterpreterDropQuery.cpp     |   2 +
 src/Interpreters/SystemLog.cpp                |   5 +
 src/Interpreters/SystemLog.h                  |   3 +
 src/Interpreters/VectorIndexEventLog.cpp      | 202 ++++++++++++++++++
 src/Interpreters/VectorIndexEventLog.h        | 115 ++++++++++
 src/Interpreters/executeQuery.cpp             |  79 +++++++
 src/Storages/MergeTree/IMergeTreeDataPart.cpp |  14 ++
 src/Storages/MergeTree/MergeTreeData.cpp      |  31 ++-
 .../MergeTreeVectorIndexBuilderUpdater.cpp    |  15 +-
 src/VectorIndex/CacheManager.cpp              |  57 ++++-
 src/VectorIndex/CacheManager.h                |   5 +-
 src/VectorIndex/SegmentId.h                   |  32 +++
 src/VectorIndex/VectorSegmentExecutor.cpp     |  68 +++++-
 .../config.d/vector_index_event_log_test.xml  |   9 +
 tests/config/install.sh                       |   1 +
 .../00030_mqvs_vector_event_log.reference     |  41 ++++
 .../00030_mqvs_vector_event_log.sql           |  56 +++++
 23 files changed, 778 insertions(+), 14 deletions(-)
 create mode 100644 src/Interpreters/VectorIndexEventLog.cpp
 create mode 100644 src/Interpreters/VectorIndexEventLog.h
 create mode 100644 tests/config/config.d/vector_index_event_log_test.xml
 create mode 100644 tests/queries/2_vector_search/00030_mqvs_vector_event_log.reference
 create mode 100644 tests/queries/2_vector_search/00030_mqvs_vector_event_log.sql

diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp
index e8be2e47ed..6171d68ff6 100644
--- a/programs/server/Server.cpp
+++ b/programs/server/Server.cpp
@@ -1665,6 +1665,8 @@ if (ThreadFuzzer::instance().isEffective())
 
         async_metrics.stop();
 
+        global_context->flushAllVectorIndexWillUnload();
+
         /** Ask to cancel background jobs all table engines,
           *  and also query_log.
           * It is important to do early, not in destructor of Context, because
diff --git a/src/Common/LRUResourceCache.h b/src/Common/LRUResourceCache.h
index aad06677ec..709919542e 100644
--- a/src/Common/LRUResourceCache.h
+++ b/src/Common/LRUResourceCache.h
@@ -79,9 +79,9 @@ public:
     }
 
     template <typename LoadFunc>
-    MappedHolderPtr getOrSet(const Key & key, LoadFunc && load_func)
+    MappedHolderPtr getOrSet(const Key & key, LoadFunc && load_func, std::function<void()> release_callback = {})
     {
-        auto mapped_ptr = getImpl(key, load_func);
+        auto mapped_ptr = getImpl(key, load_func, release_callback);
         if (!mapped_ptr)
             return nullptr;
         return std::make_unique<MappedHolder>(this, key, mapped_ptr);
@@ -139,6 +139,12 @@ private:
         LRUQueueIterator queue_iterator;
         size_t reference_count = 0;
         bool expired = false;
+        std::function<void()> release_callback;
+        ~Cell()
+        {
+            if (release_callback)
+                release_callback();
+        }
     };
 
     using Cells = std::unordered_map<Key, Cell, HashFunction>;
@@ -221,7 +227,7 @@ private:
 
     /// Returns nullptr when there is no more space for the new value or the old value is in used.
     template <typename LoadFunc>
-    MappedPtr getImpl(const Key & key, LoadFunc && load_func)
+    MappedPtr getImpl(const Key & key, LoadFunc && load_func, std::function<void()> release_callback = {})
     {
         InsertTokenHolder token_holder;
         {
@@ -264,7 +270,7 @@ private:
         Cell * cell_ptr = nullptr;
         if (token_it != insert_tokens.end() && token_it->second.get() == token)
         {
-            cell_ptr = set(key, token->value);
+            cell_ptr = set(key, token->value, release_callback);
         }
         else
         {
@@ -346,7 +352,7 @@ private:
     }
 
     // key mustn't be in the cache
-    Cell * set(const Key & insert_key, MappedPtr value)
+    Cell * set(const Key & insert_key, MappedPtr value, std::function<void()> release_callback = {})
     {
         size_t weight = value ? weight_function(*value) : 0;
         size_t queue_size = cells.size() + 1;
@@ -404,6 +410,7 @@ private:
         new_cell.value = value;
         new_cell.weight = weight;
         new_cell.queue_iterator = queue.insert(queue.end(), insert_key);
+        new_cell.release_callback = release_callback;
         return &new_cell;
     }
 };
diff --git a/src/Common/SystemLogBase.cpp b/src/Common/SystemLogBase.cpp
index 41925c571c..d8e72f56e1 100644
--- a/src/Common/SystemLogBase.cpp
+++ b/src/Common/SystemLogBase.cpp
@@ -11,6 +11,7 @@
 #include <Interpreters/TraceLog.h>
 #include <Interpreters/ZooKeeperLog.h>
 #include <Interpreters/TransactionsInfoLog.h>
+#include <Interpreters/VectorIndexEventLog.h>
 
 #include <Common/MemoryTrackerBlockerInThread.h>
 #include <Common/SystemLogBase.h>
diff --git a/src/Common/SystemLogBase.h b/src/Common/SystemLogBase.h
index faf3217553..dbc843bc09 100644
--- a/src/Common/SystemLogBase.h
+++ b/src/Common/SystemLogBase.h
@@ -25,7 +25,9 @@
     M(TraceLogElement) \
     M(TransactionsInfoLogElement) \
     M(ZooKeeperLogElement) \
-    M(TextLogElement)
+    M(TextLogElement) \
+    M(VectorIndexEventLogElement)
+
 
 namespace Poco
 {
diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp
index 7f588255c7..729d216838 100644
--- a/src/Interpreters/Context.cpp
+++ b/src/Interpreters/Context.cpp
@@ -64,6 +64,7 @@
 #include <Interpreters/InterserverIOHandler.h>
 #include <Interpreters/SystemLog.h>
 #include <Interpreters/SessionLog.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <Interpreters/Context.h>
 #include <Interpreters/DDLWorker.h>
 #include <Interpreters/DDLTask.h>
@@ -94,7 +95,7 @@
 #include <Interpreters/ClusterDiscovery.h>
 #include <Interpreters/TransactionLog.h>
 #include <filesystem>
-
+#include <VectorIndex/CacheManager.h>
 
 namespace fs = std::filesystem;
 
@@ -1667,6 +1668,11 @@ void Context::dropMarkCache() const
         shared->mark_cache->reset();
 }
 
+void Context::flushAllVectorIndexWillUnload() const
+{
+    VectorIndex::CacheManager::flushWillUnloadLog();
+}
+
 
 void Context::setIndexUncompressedCache(size_t max_size_in_bytes)
 {
@@ -2465,6 +2471,19 @@ std::shared_ptr<TransactionsInfoLog> Context::getTransactionsInfoLog() const
     return shared->system_logs->transactions_info_log;
 }
 
+std::shared_ptr<VectorIndexEventLog> Context::getVectorIndexEventLog(const String & part_database) const
+{
+    auto lock = getLock();
+
+    if (!shared->system_logs)
+        return {};
+    
+    if (part_database == DatabaseCatalog::SYSTEM_DATABASE)
+        return {};
+
+    return shared->system_logs->vector_index_event_log;
+}
+
 CompressionCodecPtr Context::chooseCompressionCodec(size_t part_size, double part_size_ratio) const
 {
     auto lock = getLock();
@@ -2751,6 +2770,10 @@ void Context::shutdown()
     shared->shutdown();
 }
 
+bool Context::isShutdown() const
+{
+    return shared->shutdown_called;
+}
 
 Context::ApplicationType Context::getApplicationType() const
 {
diff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h
index e622d4ba8d..f2554149ba 100644
--- a/src/Interpreters/Context.h
+++ b/src/Interpreters/Context.h
@@ -87,6 +87,7 @@ class OpenTelemetrySpanLog;
 class ZooKeeperLog;
 class SessionLog;
 class TransactionsInfoLog;
+class VectorIndexEventLog;
 struct MergeTreeSettings;
 class StorageS3Settings;
 class IDatabase;
@@ -309,6 +310,7 @@ private:
 
     /// A flag, used to distinguish between user query and internal query to a database engine (MaterializedPostgreSQL).
     bool is_internal_query = false;
+    bool is_detach_query = false;
 
     inline static ContextPtr global_context_instance;
 
@@ -736,6 +738,8 @@ public:
     std::shared_ptr<MarkCache> getMarkCache() const;
     void dropMarkCache() const;
 
+    void flushAllVectorIndexWillUnload() const;
+
     /// Create a cache of index uncompressed blocks of specified size. This can be done only once.
     void setIndexUncompressedCache(size_t max_size_in_bytes);
     std::shared_ptr<UncompressedCache> getIndexUncompressedCache() const;
@@ -809,6 +813,7 @@ public:
     std::shared_ptr<ZooKeeperLog> getZooKeeperLog() const;
     std::shared_ptr<SessionLog> getSessionLog() const;
     std::shared_ptr<TransactionsInfoLog> getTransactionsInfoLog() const;
+    std::shared_ptr<VectorIndexEventLog> getVectorIndexEventLog(const String & part_database = {}) const;
 
     /// Returns an object used to log operations with parts if it possible.
     /// Provide table name to make required checks.
@@ -849,9 +854,12 @@ public:
     void reloadConfig() const;
 
     void shutdown();
+    bool isShutdown() const;
 
     bool isInternalQuery() const { return is_internal_query; }
     void setInternalQuery(bool internal) { is_internal_query = internal; }
+    bool isDetachQuery() const { return  is_detach_query; }
+    void setDetachQuery(bool detach) { is_detach_query = detach; }
 
     bool applyDeletedMask() const { return apply_deleted_mask; }
     void setApplyDeletedMask(bool apply) { apply_deleted_mask = apply; }
diff --git a/src/Interpreters/InterpreterDropQuery.cpp b/src/Interpreters/InterpreterDropQuery.cpp
index 5563e7fe69..170e8f451c 100644
--- a/src/Interpreters/InterpreterDropQuery.cpp
+++ b/src/Interpreters/InterpreterDropQuery.cpp
@@ -140,6 +140,7 @@ BlockIO InterpreterDropQuery::executeToTableImpl(ContextPtr context_, ASTDropQue
         bool is_replicated_ddl_query = typeid_cast<DatabaseReplicated *>(database.get()) &&
                                        !context_->getClientInfo().is_replicated_database_internal &&
                                        !is_drop_or_detach_database;
+        getContext()->setDetachQuery(false);
 
         AccessFlags drop_storage;
 
@@ -167,6 +168,7 @@ BlockIO InterpreterDropQuery::executeToTableImpl(ContextPtr context_, ASTDropQue
         if (query.kind == ASTDropQuery::Kind::Detach)
         {
             context_->checkAccess(drop_storage, table_id);
+            getContext()->setDetachQuery(true);
 
             if (table->isDictionary())
             {
diff --git a/src/Interpreters/SystemLog.cpp b/src/Interpreters/SystemLog.cpp
index f165025282..5180784ccb 100644
--- a/src/Interpreters/SystemLog.cpp
+++ b/src/Interpreters/SystemLog.cpp
@@ -11,6 +11,7 @@
 #include <Interpreters/TraceLog.h>
 #include <Interpreters/ZooKeeperLog.h>
 #include <Interpreters/TransactionsInfoLog.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <Interpreters/InterpreterCreateQuery.h>
 #include <Interpreters/InterpreterRenameQuery.h>
 #include <Interpreters/InterpreterInsertQuery.h>
@@ -152,6 +153,8 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf
     session_log = createSystemLog<SessionLog>(global_context, "system", "session_log", config, "session_log");
     transactions_info_log = createSystemLog<TransactionsInfoLog>(
         global_context, "system", "transactions_info_log", config, "transactions_info_log");
+    vector_index_event_log = createSystemLog<VectorIndexEventLog>(
+        global_context, "system", "vector_index_event_log", config, "vector_index_event_log");
 
     if (query_log)
         logs.emplace_back(query_log.get());
@@ -179,6 +182,8 @@ SystemLogs::SystemLogs(ContextPtr global_context, const Poco::Util::AbstractConf
         logs.emplace_back(session_log.get());
     if (transactions_info_log)
         logs.emplace_back(transactions_info_log.get());
+    if (vector_index_event_log)
+        logs.emplace_back(vector_index_event_log.get());
 
     try
     {
diff --git a/src/Interpreters/SystemLog.h b/src/Interpreters/SystemLog.h
index 655bb29ceb..caa91b4846 100644
--- a/src/Interpreters/SystemLog.h
+++ b/src/Interpreters/SystemLog.h
@@ -44,6 +44,7 @@ class QueryViewsLog;
 class ZooKeeperLog;
 class SessionLog;
 class TransactionsInfoLog;
+class VectorIndexEventLog;
 
 /// System logs should be destroyed in destructor of the last Context and before tables,
 ///  because SystemLog destruction makes insert query while flushing data into underlying tables
@@ -73,6 +74,8 @@ struct SystemLogs
     std::shared_ptr<SessionLog> session_log;
     /// Events related to transactions
     std::shared_ptr<TransactionsInfoLog> transactions_info_log;
+    /// Vector index event log
+    std::shared_ptr<VectorIndexEventLog> vector_index_event_log;
     std::vector<ISystemLog *> logs;
 };
 
diff --git a/src/Interpreters/VectorIndexEventLog.cpp b/src/Interpreters/VectorIndexEventLog.cpp
new file mode 100644
index 0000000000..ae38d923be
--- /dev/null
+++ b/src/Interpreters/VectorIndexEventLog.cpp
@@ -0,0 +1,202 @@
+#include <Columns/ColumnsNumber.h>
+#include <DataTypes/DataTypeArray.h>
+#include <DataTypes/DataTypesNumber.h>
+#include <DataTypes/DataTypeDateTime.h>
+#include <DataTypes/DataTypeDateTime64.h>
+#include <DataTypes/DataTypeDate.h>
+#include <DataTypes/DataTypeString.h>
+#include <DataTypes/DataTypeEnum.h>
+#include <Storages/MergeTree/IMergeTreeDataPart.h>
+#include <Storages/MergeTree/MergeTreeData.h>
+#include <Interpreters/VectorIndexEventLog.h>
+#include <Interpreters/Context.h>
+#include <Interpreters/executeQuery.h>
+#include <Processors/Executors/PullingPipelineExecutor.h>
+
+#include <Common/CurrentThread.h>
+
+namespace DB
+{
+
+NamesAndTypesList VectorIndexEventLogElement::getNamesAndTypes()
+{
+    auto event_type_datatype = std::make_shared<DataTypeEnum8>(
+        DataTypeEnum8::Values
+        {
+            {"DefinitionCreated",       static_cast<Int8>(DEFINITION_CREATED)},
+            {"DefinitionDroped",    static_cast<Int8>(DEFINITION_DROPPED)},
+            {"DefinitionError",    static_cast<Int8>(DEFINITION_ERROR)},
+            {"BuildStart",  static_cast<Int8>(BUILD_START)},
+            {"BuildSucceed",    static_cast<Int8>(BUILD_SUCCEED)},
+            {"BuildError",    static_cast<Int8>(BUILD_ERROR)},
+            {"BuildCanceld",      static_cast<Int8>(BUILD_CANCELD)},
+            {"LoadStart",      static_cast<Int8>(LOAD_START)},
+            {"LoadSucceed",      static_cast<Int8>(LOAD_SUCCEED)},
+            {"LoadCanceled",      static_cast<Int8>(LOAD_CANCELD)},
+            {"LoadFailed",    static_cast<Int8>(LOAD_FAILED)},
+            {"LoadError",    static_cast<Int8>(LOAD_ERROR)},
+            {"Unload",      static_cast<Int8>(UNLOAD)},
+            {"WillUnload",      static_cast<Int8>(WILLUNLOAD)},
+            {"Cleared",      static_cast<Int8>(CLEARED)},
+        }
+    );
+    // ColumnsWithTypeAndName columns_with_type_and_name;
+
+    return {
+        {"database", std::make_shared<DataTypeString>()},
+        {"table", std::make_shared<DataTypeString>()},
+        {"part_name", std::make_shared<DataTypeString>()},
+        {"partition_id", std::make_shared<DataTypeString>()},
+
+        {"event_type", std::move(event_type_datatype)},
+        {"event_date", std::make_shared<DataTypeDate>()},
+        {"event_time", std::make_shared<DataTypeDateTime>()},
+        {"event_time_microseconds", std::make_shared<DataTypeDateTime64>(6)},
+
+        {"error", std::make_shared<DataTypeUInt16>()},
+        {"exception", std::make_shared<DataTypeString>()},
+    };
+};
+
+void VectorIndexEventLogElement::appendToBlock(MutableColumns & columns) const
+{
+    size_t i = 0;
+
+    columns[i++]->insert(database_name);
+    columns[i++]->insert(table_name);
+    columns[i++]->insert(part_name);
+    columns[i++]->insert(partition_id);
+
+    columns[i++]->insert(event_type);
+    columns[i++]->insert(DateLUT::instance().toDayNum(event_time).toUnderType());
+    columns[i++]->insert(event_time);
+    columns[i++]->insert(event_time_microseconds);
+
+    columns[i++]->insert(error_code);
+    columns[i++]->insert(exception);
+};
+
+void VectorIndexEventLog::addEventLog(
+    VectorIndexEventLogPtr log_entry, 
+    const String & db_name,
+    const String & table_name,
+    const String & part_name,
+    const String & partition_id,
+    VectorIndexEventLogElement::Type event_type,
+    const ExecutionStatus & execution_status)
+{
+    if (!log_entry) return;
+    VectorIndexEventLogElement elem;
+    elem.database_name = db_name;
+    elem.table_name = table_name;
+    elem.part_name = part_name;
+    elem.partition_id = partition_id;
+    elem.event_type = event_type;
+    const auto time_now = std::chrono::system_clock::now();
+
+    elem.event_time = time_in_seconds(time_now);
+    elem.event_time_microseconds = time_in_microseconds(time_now);
+
+    elem.error_code = static_cast<UInt16>(execution_status.code);
+    elem.exception = execution_status.message;
+
+    log_entry->add(elem);
+}
+
+void VectorIndexEventLog::addEventLog(
+    ContextPtr current_context,
+    const String & db_name,
+    const String & table_name,
+    const String & part_name,
+    const String & partition_id,
+    VectorIndexEventLogElement::Type event_type,
+    const ExecutionStatus & execution_status)
+{
+    VectorIndexEventLogPtr log_entry = current_context->getVectorIndexEventLog();
+
+    try
+    {
+        if (log_entry)
+            addEventLog(log_entry, db_name,
+                        table_name, part_name,
+                        partition_id, event_type,
+                        execution_status);
+    }
+    catch (...)
+    {
+        tryLogCurrentException(log_entry ? log_entry->log : &Poco::Logger::get("VectorIndexEventLog"), __PRETTY_FUNCTION__);
+    }
+}
+
+void VectorIndexEventLog::addEventLog(
+    ContextPtr current_context,
+    const DB::MergeTreeDataPartPtr & data_part,
+    VectorIndexEventLogElement::Type event_type,
+    const ExecutionStatus & execution_status)
+{
+    VectorIndexEventLogPtr log_entry = current_context->getVectorIndexEventLog();
+
+    try
+    {
+        if(log_entry)
+            addEventLog(log_entry, 
+                        data_part->storage.getStorageID().database_name,
+                        data_part->storage.getStorageID().table_name, 
+                        data_part->name,
+                        data_part->info.partition_id,
+                        event_type,
+                        execution_status);
+    }
+    catch (...)
+    {
+        tryLogCurrentException(log_entry ? log_entry->log : &Poco::Logger::get("VectorIndexEventLog"), __PRETTY_FUNCTION__);
+    }
+}
+
+void VectorIndexEventLog::addEventLog(
+    ContextPtr current_context,
+    const String & table_uuid,
+    const String & part_name,
+    const String & partition_id,
+    VectorIndexEventLogElement::Type event_type,
+    const ExecutionStatus & execution_status)
+{
+    VectorIndexEventLogPtr log_entry = current_context->getVectorIndexEventLog();
+    
+    try
+    {
+        if(log_entry)
+        {
+            UUID tb_uuid = VectorIndexEventLog::parseUUID(table_uuid);
+            auto ret = getDbAndTableNameFromUUID(tb_uuid);
+            if (ret.has_value())
+                addEventLog(log_entry, 
+                            ret->first,
+                            ret->second,
+                            part_name,
+                            partition_id,
+                            event_type,
+                            execution_status);
+        }
+    }
+    catch (...)
+    {
+        tryLogCurrentException(log_entry ? log_entry->log : &Poco::Logger::get("VectorIndexEventLog"), __PRETTY_FUNCTION__);
+    }
+}
+
+std::optional<std::pair<String, String>> VectorIndexEventLog::getDbAndTableNameFromUUID(const UUID & table_uuid)
+{
+    if (!DatabaseCatalog::instance().tryGetByUUID(table_uuid).second)
+        return std::nullopt;
+    auto table_id = DatabaseCatalog::instance().tryGetByUUID(table_uuid).second->getStorageID();
+    if (table_id)
+    {
+        String database_name = table_id.database_name;
+        String table_name = table_id.table_name;
+        return std::make_pair(database_name, table_name);
+    }
+    return std::nullopt;
+}
+
+}
diff --git a/src/Interpreters/VectorIndexEventLog.h b/src/Interpreters/VectorIndexEventLog.h
new file mode 100644
index 0000000000..4416db2b5e
--- /dev/null
+++ b/src/Interpreters/VectorIndexEventLog.h
@@ -0,0 +1,115 @@
+#pragma once
+#include <optional>
+#include <Interpreters/SystemLog.h>
+#include <Core/NamesAndTypes.h>
+#include <Core/NamesAndAliases.h>
+#include <Storages/MergeTree/IMergeTreeDataPart.h>
+#include <IO/ReadBufferFromMemory.h>
+#include <IO/ReadHelpers.h>
+
+namespace DB
+{
+
+struct VectorIndexEventLogElement
+{
+    enum Type
+    {
+        DEFINITION_CREATED = 1,
+        DEFINITION_DROPPED = 2,
+        DEFINITION_ERROR = 3,
+
+        BUILD_START = 4,
+        BUILD_SUCCEED = 5,
+        BUILD_ERROR = 6,
+        BUILD_CANCELD = 7,
+
+        LOAD_START = 8,
+        LOAD_SUCCEED = 9,
+        LOAD_CANCELD = 10,
+        LOAD_FAILED = 11,
+        LOAD_ERROR = 12,
+        UNLOAD = 13,
+        WILLUNLOAD = 14,
+        CLEARED = 15,
+        DEFAULT = 16,
+    };
+    String database_name;
+    String table_name;
+    String part_name;
+    String partition_id;
+
+    Type event_type = DEFAULT;
+    time_t event_time = 0;
+    Decimal64 event_time_microseconds = 0;
+
+    UInt16 error_code = 0;
+    String exception;
+
+    static std::string name() { return "VectorIndexEventLog"; }
+
+    static NamesAndTypesList getNamesAndTypes();
+    static NamesAndAliases getNamesAndAliases() { return {}; }
+    void appendToBlock(MutableColumns & columns) const; 
+};
+
+class VectorIndexEventLog : public SystemLog<VectorIndexEventLogElement>
+{
+    using SystemLog<VectorIndexEventLogElement>::SystemLog;
+    using VectorIndexEventLogPtr = std::shared_ptr<VectorIndexEventLog>;
+
+public:
+    static void addEventLog(
+        VectorIndexEventLogPtr log_entry, 
+        const String & db_name,
+        const String & table_name,
+        const String & part_name,
+        const String & partition_id,
+        VectorIndexEventLogElement::Type event_type,
+        const ExecutionStatus & execution_status = {});
+    
+    static void addEventLog(
+        ContextPtr current_context,
+        const String & db_name,
+        const String & table_name,
+        const String & part_name,
+        const String & partition_id,
+        VectorIndexEventLogElement::Type event_type,
+        const ExecutionStatus & execution_status = {});
+    
+    static void addEventLog(
+        ContextPtr current_context,
+        const DB::MergeTreeDataPartPtr & data_part,
+        VectorIndexEventLogElement::Type event_type,
+        const ExecutionStatus & execution_status = {});
+
+    static void addEventLog(
+        ContextPtr current_context,
+        const String & table_uuid,
+        const String & part_name,
+        const String & partition_id,
+        VectorIndexEventLogElement::Type event_type,
+        const ExecutionStatus & execution_status = {});
+
+    static std::optional<std::pair<String, String>> getDbAndTableNameFromUUID(const UUID & table_uuid);
+
+    static inline UInt64 time_in_microseconds(std::chrono::time_point<std::chrono::system_clock> timepoint)
+    {
+        return std::chrono::duration_cast<std::chrono::microseconds>(timepoint.time_since_epoch()).count();
+    }
+
+    static inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock> timepoint)
+    {
+        return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();
+    }
+
+    static inline UUID parseUUID(const String & table_uuid)
+    {
+        UUID uuid = UUIDHelpers::Nil;
+        auto buffer = ReadBufferFromMemory(table_uuid.data(), table_uuid.length());
+        readUUIDText(uuid, buffer);
+        return uuid;
+    }
+
+};
+
+}
diff --git a/src/Interpreters/executeQuery.cpp b/src/Interpreters/executeQuery.cpp
index b4e24f34eb..b0a9afe72a 100644
--- a/src/Interpreters/executeQuery.cpp
+++ b/src/Interpreters/executeQuery.cpp
@@ -52,6 +52,7 @@
 #include <Interpreters/OpenTelemetrySpanLog.h>
 #include <Interpreters/ProcessList.h>
 #include <Interpreters/QueryLog.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <Interpreters/ReplaceQueryParameterVisitor.h>
 #include <Interpreters/SelectIntersectExceptQueryVisitor.h>
 #include <Interpreters/SelectQueryOptions.h>
@@ -263,6 +264,34 @@ inline UInt64 time_in_seconds(std::chrono::time_point<std::chrono::system_clock>
     return std::chrono::duration_cast<std::chrono::seconds>(timepoint.time_since_epoch()).count();
 }
 
+VectorIndexEventLogElement::Type getQueryWithVectorType(ASTPtr ast)
+{
+    if(ast)
+    {
+        auto * create_query = ast->as<ASTCreateQuery>();
+        auto * alter_query = ast->as<ASTAlterQuery>();
+        if (create_query && 
+            !create_query->attach && 
+            create_query->columns_list && 
+            create_query->columns_list->vec_indices && 
+            !create_query->columns_list->vec_indices->children.empty())
+        {
+            return VectorIndexEventLogElement::DEFINITION_CREATED;
+        }
+        else if (alter_query)
+        {
+            for (const auto & command : alter_query->command_list->children)
+            {
+                if ( command->as<ASTAlterCommand&>().type == ASTAlterCommand::ADD_VECTOR_INDEX )
+                    return VectorIndexEventLogElement::DEFINITION_CREATED;
+                else if (command->as<ASTAlterCommand&>().type == ASTAlterCommand::DROP_VECTOR_INDEX)
+                    return VectorIndexEventLogElement::DEFINITION_DROPPED;
+            }
+        }
+    }
+    return VectorIndexEventLogElement::DEFAULT;
+}
+
 static void onExceptionBeforeStart(const String & query_for_logging, ContextPtr context, UInt64 current_time_us, ASTPtr ast)
 {
     /// Exception before the query execution.
@@ -273,6 +302,19 @@ static void onExceptionBeforeStart(const String & query_for_logging, ContextPtr
 
     /// Log the start of query execution into the table if necessary.
     QueryLogElement elem;
+    VectorIndexEventLogElement vec_elem;
+    auto current_event_type = getQueryWithVectorType(ast);
+    if(current_event_type != VectorIndexEventLogElement::DEFAULT &&
+       current_event_type != VectorIndexEventLogElement::DEFINITION_DROPPED)
+        vec_elem.event_type = VectorIndexEventLogElement::DEFINITION_ERROR;
+    vec_elem.part_name = "";
+    vec_elem.partition_id = "";
+    vec_elem.event_time = current_time_us / 1000000;
+    vec_elem.event_time_microseconds = current_time_us;
+    if (const auto * query_with_table_output = dynamic_cast<const ASTQueryWithTableAndOutput *>(ast.get()))
+    {
+        vec_elem.table_name = query_with_table_output->getTable();
+    }
 
     elem.type = QueryLogElementType::EXCEPTION_BEFORE_START;
 
@@ -285,6 +327,7 @@ static void onExceptionBeforeStart(const String & query_for_logging, ContextPtr
     elem.query_start_time_microseconds = current_time_us;
 
     elem.current_database = context->getCurrentDatabase();
+    vec_elem.database_name = elem.current_database;
     elem.query = query_for_logging;
     elem.normalized_query_hash = normalizedQueryHash<false>(query_for_logging);
 
@@ -299,7 +342,9 @@ static void onExceptionBeforeStart(const String & query_for_logging, ContextPtr
     // We don't calculate databases, tables and columns when the query isn't able to start
 
     elem.exception_code = getCurrentExceptionCode();
+    vec_elem.error_code = getCurrentExceptionCode();
     elem.exception = getCurrentExceptionMessage(false);
+    vec_elem.exception = getCurrentExceptionMessage(false);
 
     elem.client_info = context->getClientInfo();
 
@@ -317,6 +362,10 @@ static void onExceptionBeforeStart(const String & query_for_logging, ContextPtr
     /// Update performance counters before logging to query_log
     CurrentThread::finalizePerformanceCounters();
 
+    if (auto vector_index_event_log = context->getVectorIndexEventLog())
+        if (vec_elem.event_type != VectorIndexEventLogElement::DEFAULT)
+            vector_index_event_log->add(vec_elem);
+
     if (settings.log_queries && elem.type >= settings.log_queries_min_type && !settings.log_queries_min_query_duration_ms.totalMilliseconds())
         if (auto query_log = context->getQueryLog())
             query_log->add(elem);
@@ -775,6 +824,19 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
         /// Everything related to query log.
         {
             QueryLogElement elem;
+            VectorIndexEventLogElement vec_elem;
+            
+            vec_elem.part_name = "";
+            vec_elem.partition_id = "";
+            vec_elem.event_time = time_in_seconds(current_time);
+            vec_elem.event_time_microseconds = time_in_microseconds(current_time);
+            vec_elem.event_type = VectorIndexEventLogElement::DEFAULT;
+            if (query_database == "")
+                vec_elem.database_name = context->getCurrentDatabase();
+            else
+                vec_elem.database_name = query_database;
+            vec_elem.table_name = query_table;
+            vec_elem.event_type = getQueryWithVectorType(ast);
 
             elem.type = QueryLogElementType::QUERY_START; //-V1048
 
@@ -879,6 +941,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
 
             /// Also make possible for caller to log successful query finish and exception during execution.
             auto finish_callback = [elem,
+                                    vec_elem,
                                     context,
                                     session_context,
                                     ast,
@@ -909,6 +972,13 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                 elem.event_time = time_in_seconds(finish_time);
                 elem.event_time_microseconds = time_in_microseconds(finish_time);
                 status_info_to_query_log(elem, info, ast, context);
+                if (vec_elem.event_type != VectorIndexEventLogElement::DEFAULT)
+                {
+                    if (auto vec_index_event_log = context->getVectorIndexEventLog())
+                    {
+                        vec_index_event_log->add(vec_elem);
+                    }
+                }
 
                 if (pulling_pipeline)
                 {
@@ -989,6 +1059,7 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
             };
 
             auto exception_callback = [elem,
+                                       vec_elem,
                                        context,
                                        session_context,
                                        ast,
@@ -1015,6 +1086,14 @@ static std::tuple<ASTPtr, BlockIO> executeQueryImpl(
                 // event_time and event_time_microseconds are being constructed from the same time point
                 // to ensure that both the times will be equal up to the precision of a second.
                 const auto time_now = std::chrono::system_clock::now();
+                if (vec_elem.event_type != VectorIndexEventLogElement::DEFAULT)
+                {
+                    vec_elem.event_type = VectorIndexEventLogElement::DEFINITION_ERROR;
+                    if (auto vec_index_event_log = context->getVectorIndexEventLog())
+                    {
+                        vec_index_event_log->add(vec_elem);
+                    }
+                }
 
                 elem.event_time = time_in_seconds(time_now);
                 elem.event_time_microseconds = time_in_microseconds(time_now);
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
index ded510932f..f5f5e0cac6 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
@@ -12,6 +12,7 @@
 #include <IO/WriteHelpers.h>
 #include <Interpreters/MergeTreeTransaction.h>
 #include <Interpreters/TransactionLog.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <Parsers/ExpressionElementParsers.h>
 #include <Parsers/parseQuery.h>
 #include <Parsers/queryToString.h>
@@ -1131,6 +1132,7 @@ void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const Stri
     /// No need to check metadata of table, because for drop index, the metadata has erased it.
     /// Remove all the files which end with .vidx2
     auto disk = volume->getDisk();
+    bool with_vector_index_file_remove = false;
 
     for (auto it = disk->iterateDirectory(getFullRelativePath()); it->isValid(); it->next())
     {
@@ -1139,9 +1141,21 @@ void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const Stri
         if (!endsWith(file_name, VECTOR_INDEX_FILE_SUFFIX) || (skip_decouple && startsWith(file_name, "merged-")))
             continue;
 
+        with_vector_index_file_remove = true;
         disk->removeFileIfExists(fs::path(getFullRelativePath()) / file_name);
     }
 
+    if (with_vector_index_file_remove)
+    {
+        /// add vector index cleared event
+        auto table_id = storage.getStorageID();
+        VectorIndexEventLog::addEventLog(storage.getContext(),
+                                         table_id.database_name,
+                                         table_id.table_name,
+                                         name,
+                                         info.partition_id,
+                                         VectorIndexEventLogElement::CLEARED);
+    }
     /// Clear from metadata
     if (containVectorIndex(index_name, col_name))
     {
diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp
index 353772c9e1..55c4082154 100644
--- a/src/Storages/MergeTree/MergeTreeData.cpp
+++ b/src/Storages/MergeTree/MergeTreeData.cpp
@@ -39,6 +39,7 @@
 #include <Interpreters/TransactionLog.h>
 #include <Interpreters/evaluateConstantExpression.h>
 #include <Interpreters/convertFieldToType.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <Parsers/ASTFunction.h>
 #include <Parsers/ASTLiteral.h>
 #include <Parsers/ASTNameTypePair.h>
@@ -1751,7 +1752,6 @@ void MergeTreeData::removePartsFinally(const MergeTreeData::DataPartsVector & pa
             part_log_elem.part_name = part->name;
             part_log_elem.bytes_compressed_on_disk = part->getBytesOnDisk();
             part_log_elem.rows = part->rows_count;
-
             part_log->add(part_log_elem);
         }
     }
@@ -1911,6 +1911,19 @@ void MergeTreeData::clearPartsFromFilesystem(const DataPartsVector & parts_to_re
 {
     clearPrimaryKeyCache(parts_to_remove);
     clearCachedVectorIndex(parts_to_remove, false);
+    auto table_id = getStorageID();
+    VectorIndexEventLogElement vec_elem;
+    bool detach = getContext()->isDetachQuery();
+    auto vec_event_log = getContext()->getVectorIndexEventLog(table_id.database_name);
+    if (vec_event_log && !detach)
+    {
+        vec_elem.event_type = VectorIndexEventLogElement::CLEARED;
+        const auto time_now = std::chrono::system_clock::now();
+        vec_elem.event_time = time_in_seconds(time_now);
+        vec_elem.event_time_microseconds = time_in_microseconds(time_now);
+        vec_elem.database_name = table_id.database_name;
+        vec_elem.table_name = table_id.table_name;
+    }
 
     const auto settings = getSettings();
     if (parts_to_remove.size() > 1 && settings->max_part_removal_threads > 1 && parts_to_remove.size() > settings->concurrent_part_removal_threshold)
@@ -1923,6 +1936,14 @@ void MergeTreeData::clearPartsFromFilesystem(const DataPartsVector & parts_to_re
         /// NOTE: Under heavy system load you may get "Cannot schedule a task" from ThreadPool.
         for (const DataPartPtr & part : parts_to_remove)
         {
+            if (part->containAnyVectorIndex() &&
+                vec_event_log &&
+                vec_elem.event_type != VectorIndexEventLogElement::DEFAULT)
+            {
+                vec_elem.part_name = part->name;
+                vec_elem.partition_id = part->info.partition_id;
+                vec_event_log->add(vec_elem);
+            }
             pool.scheduleOrThrowOnError([&, thread_group = CurrentThread::getGroup()]
             {
                 if (thread_group)
@@ -1939,6 +1960,14 @@ void MergeTreeData::clearPartsFromFilesystem(const DataPartsVector & parts_to_re
     {
         for (const DataPartPtr & part : parts_to_remove)
         {
+            if (part->containAnyVectorIndex() &&
+                vec_event_log &&
+                vec_elem.event_type != VectorIndexEventLogElement::DEFAULT)
+            {
+                vec_elem.part_name = part->name;
+                vec_elem.partition_id = part->info.partition_id;
+                vec_event_log->add(vec_elem);
+            }
             LOG_DEBUG(log, "Removing part from filesystem {}", part->name);
             part->remove();
         }
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
index 45ce57d005..334ecf1178 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
@@ -3,6 +3,7 @@
 #include <DataTypes/DataTypeArray.h>
 #include <Storages/MergeTree/MergeTreeData.h>
 #include <VectorIndex/DiskIOReader.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <VectorIndex/PartReader.h>
 #include <VectorIndex/VectorIndexCommon.h>
 #include <VectorIndex/VectorSegmentExecutor.h>
@@ -264,6 +265,7 @@ MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(const StorageMetadataPtr &
         if (part->vector_index_build_cancelled)
         {
             LOG_INFO(log, "The index build job for Part {} has been cancelled", part_name);
+            VectorIndexEventLog::addEventLog(data.getContext(),part,VectorIndexEventLogElement::BUILD_CANCELD);
             return BuildVectorIndexStatus::BUILD_FAIL;
         }
 
@@ -280,6 +282,7 @@ MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(const StorageMetadataPtr &
         if (failed_count >= maxBuildRetryCount)
         {
             part->setBuildError();
+            VectorIndexEventLog::addEventLog(data.getContext(),part,VectorIndexEventLogElement::BUILD_ERROR, ExecutionStatus(ErrorCodes::MEMORY_LIMIT_EXCEEDED, "part = " + part->name + ", has MEMORY_LIMIT_EXCEEDED for max retry times " + std::to_string(failed_count)));
             throw Exception(ErrorCodes::MEMORY_LIMIT_EXCEEDED, "part = {}, has MEMORY_LIMIT_EXCEEDED for max retry times {}", part->name, failed_count);
         }
 
@@ -301,10 +304,12 @@ MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(const StorageMetadataPtr &
                 status = BuildVectorIndexStatus::BUILD_FAIL;
                 int temp_value = counter.increaseAndGet(part->getFullRelativePath());
                 LOG_WARNING(log, "Vector index build task for part {} has MEMORY_LIMIT_EXCEEDED for {} times", part->name, temp_value);
+                VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_ERROR, ExecutionStatus::fromCurrentException());
                 mem_limit_happened = true;
             }
             else
             {
+                VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_ERROR, ExecutionStatus::fromCurrentException());
                 throw;
             }
         }
@@ -388,6 +393,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 else
                 {
                     LOG_WARNING(log, "Found column {} in part and VectorIndexDescription, but not in metadata snapshot.", col);
+                    VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_ERROR, ExecutionStatus(ErrorCodes::ABORTED, "Found column " + col + " in part and VectorIndexDescription, but not in metadata snapshot"));
                     return BuildVectorIndexStatus::META_ERROR;
                 }
             }
@@ -400,6 +406,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 vec_index_desc.name,
                 part->name);
             part->addVectorIndex(vec_index_desc.name + "_" + vec_index_desc.column);
+            VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_SUCCEED);
             return BuildVectorIndexStatus::SUCCESS;
         }
 
@@ -461,6 +468,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                     if (!future_part)
                     {
                         LOG_WARNING(log, "Failed to find future part for part {}, leave the temporary directory", part->name);
+                        VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_CANCELD);
                         return BuildVectorIndexStatus::SUCCESS;
                     }
                 }
@@ -478,6 +486,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 /// else future part will pick up later at the next time when index built for it.
             }
 
+            VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_SUCCEED);
             return BuildVectorIndexStatus::SUCCESS;
         }
 
@@ -513,6 +522,8 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
             data.getSettings()->default_mstg_disk_mode);
         size_t max_build_index_add_block_size = data.getContext()->getSettingsRef().max_build_index_add_block_size;
         size_t max_build_index_train_block_size = data.getContext()->getSettingsRef().max_build_index_train_block_size;
+
+        VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_START);
         vec_index_builder->buildIndex(&part_reader, slow_mode, max_build_index_train_block_size, max_build_index_add_block_size);
 
         const auto empty_ids = part_reader.emptyIds();
@@ -529,7 +540,6 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
             {
                 /// Remove temporay directory
                 disk->removeRecursive(vector_tmp_relative_path);
-
                 throw Exception(seri_status.getCode(), seri_status.getMessage());
             }
 
@@ -547,6 +557,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 if (!future_part)
                 {
                     LOG_WARNING(log, "Failed to find future part for part {}, leave the temporary directory", part->name);
+                    VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_CANCELD);
                     return BuildVectorIndexStatus::SUCCESS;
                 }
             }
@@ -559,6 +570,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                 {
                     LOG_INFO(log, "Vector index has been dropped, no need to build it.");
                     disk->removeRecursive(vector_tmp_relative_path);
+                    VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_CANCELD);
                     return BuildVectorIndexStatus::SUCCESS;
                 }
 
@@ -595,6 +607,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
 
     LOG_DEBUG(log, "Vector index build complete");
 
+    VectorIndexEventLog::addEventLog(data.getContext(), part, VectorIndexEventLogElement::BUILD_SUCCEED);
     return BuildVectorIndexStatus::SUCCESS;
 }
 
diff --git a/src/VectorIndex/CacheManager.cpp b/src/VectorIndex/CacheManager.cpp
index 802d0d2698..4ef0b929cf 100644
--- a/src/VectorIndex/CacheManager.cpp
+++ b/src/VectorIndex/CacheManager.cpp
@@ -2,6 +2,7 @@
 #include <VectorIndex/CacheManager.h>
 
 #include <VectorIndex/IndexException.h>
+#include <Interpreters/VectorIndexEventLog.h>
 
 namespace DB::ErrorCodes
 {
@@ -45,8 +46,56 @@ void CacheManager::put(const CacheKey & cache_key, IndexWithMetaPtr index)
         throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "cache not allocated");
     }
     LOG_INFO(log, "Put into cache: cache_key = {}", cache_key.toString());
+    auto global_context = DB::Context::getGlobalContextInstance();
+    auto release_callback = [cache_key, global_context]()
+    {
+        if (!global_context->isShutdown())
+            DB::VectorIndexEventLog::addEventLog(global_context,
+                                                 cache_key.getTableUUID(),
+                                                 cache_key.getPartName(),
+                                                 cache_key.getPartitionID(),
+                                                 DB::VectorIndexEventLogElement::UNLOAD);
+    };
+    DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                         cache_key.getTableUUID(),
+                                         cache_key.getPartName(),
+                                         cache_key.getPartitionID(),
+                                         DB::VectorIndexEventLogElement::LOAD_START);
+    if (!cache->getOrSet(cache_key, [&]() { return index; }, release_callback))
+    {
+        LOG_DEBUG(log, "Put into cache: {} failed", cache_key.toString());
+        DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                             cache_key.getTableUUID(),
+                                             cache_key.getPartName(),
+                                             cache_key.getPartitionID(),
+                                             DB::VectorIndexEventLogElement::LOAD_FAILED);
+    }
+    else
+    {
+        DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                             cache_key.getTableUUID(),
+                                             cache_key.getPartName(),
+                                             cache_key.getPartitionID(),
+                                             DB::VectorIndexEventLogElement::LOAD_SUCCEED);
+    }
 
-    cache->getOrSet(cache_key, [&]() { return index; });
+}
+
+void CacheManager::flushWillUnloadLog()
+{
+    auto cache_mgr = getInstance();
+    auto cache_items = cache_mgr->cache->getCacheList();
+    for(auto item : cache_items)
+    {
+        auto context_ = DB::Context::getGlobalContextInstance();
+        auto cache_key = item.first;
+        if (context_)
+            DB::VectorIndexEventLog::addEventLog(context_,
+                                                 cache_key.getTableUUID(),
+                                                 cache_key.getPartName(),
+                                                 cache_key.getPartitionID(),
+                                                 DB::VectorIndexEventLogElement::WILLUNLOAD);
+    }
 }
 
 size_t CacheManager::countItem() const
@@ -60,7 +109,9 @@ void CacheManager::forceExpire(const CacheKey & cache_key)
     return cache->tryRemove(cache_key);
 }
 
-IndexWithMetaHolderPtr CacheManager::load(const CacheKey & cache_key, std::function<IndexWithMetaPtr()> load_func)
+IndexWithMetaHolderPtr CacheManager::load(const CacheKey & cache_key, 
+                                          std::function<IndexWithMetaPtr()> load_func,
+                                          std::function<void()> release_callback)
 {
     if (!cache)
     {
@@ -68,7 +119,7 @@ IndexWithMetaHolderPtr CacheManager::load(const CacheKey & cache_key, std::funct
     }
     LOG_INFO(log, "Start loading cache: cache_key = {}", cache_key.toString());
 
-    return cache->getOrSet(cache_key, load_func);
+    return cache->getOrSet(cache_key, load_func, release_callback);
 }
 
 void CacheManager::setCacheSize(size_t size_in_bytes)
diff --git a/src/VectorIndex/CacheManager.h b/src/VectorIndex/CacheManager.h
index 3e0684e2a8..601751ffce 100644
--- a/src/VectorIndex/CacheManager.h
+++ b/src/VectorIndex/CacheManager.h
@@ -83,11 +83,14 @@ public:
     IndexWithMetaHolderPtr get(const CacheKey & cache_key);
     size_t countItem() const;
     void forceExpire(const CacheKey & cache_key);
-    IndexWithMetaHolderPtr load(const CacheKey & cache_key, std::function<IndexWithMetaPtr()> load_func);
+    IndexWithMetaHolderPtr load(const CacheKey & cache_key, 
+                                std::function<IndexWithMetaPtr()> load_func,
+                                std::function<void()> release_callback = {});
     std::list<std::pair<CacheKey, Search::Parameters>> getAllItems();
 
     static CacheManager * getInstance();
     static void setCacheSize(size_t size_in_bytes);
+    static void flushWillUnloadLog();
 
 protected:
     mutable std::unique_ptr<VectorIndexCache> cache;
diff --git a/src/VectorIndex/SegmentId.h b/src/VectorIndex/SegmentId.h
index 2c35ffbe69..0144937d1d 100644
--- a/src/VectorIndex/SegmentId.h
+++ b/src/VectorIndex/SegmentId.h
@@ -17,6 +17,9 @@ namespace VectorIndex
 {
 
 String cutMutVer(const String & part_name);
+String cutPartitionID(const String & part_name);
+String cutTableUUIDFromCacheKey(const String & cache_key);
+String cutPartNameFromCacheKey(const String & cache_key);
 
 struct CacheKey
 {
@@ -32,6 +35,35 @@ struct CacheKey
     }
 
     String toString() const { return table_path + "/" + part_name_no_mutation + "/" + vector_index_name + "-" + column_name; }
+
+    static String getTableUUIDFromCacheKey(const String & cache_key)
+    {
+        return cutTableUUIDFromCacheKey(cache_key);
+    }
+
+    static String getPartNameFromCacheKey(const String & cache_key)
+    {
+        return cutPartNameFromCacheKey(cache_key);
+    }
+
+    static String getPartitionIDFromCacheKey(const String & cache_key)
+    {
+        String part_name = cutPartNameFromCacheKey(cache_key);
+        return cutPartitionID(cache_key);
+    }
+
+    String getTableUUID()  const
+    {
+        fs::path full_path(table_path);
+        return full_path.stem().string();
+    }
+
+    String getPartName() const { return part_name_no_mutation; }
+
+    String getPartitionID() const 
+    {
+        return cutPartitionID(part_name_no_mutation);
+    }
 };
 
 struct SegmentId
diff --git a/src/VectorIndex/VectorSegmentExecutor.cpp b/src/VectorIndex/VectorSegmentExecutor.cpp
index 4e0ecc6d16..6d881822af 100644
--- a/src/VectorIndex/VectorSegmentExecutor.cpp
+++ b/src/VectorIndex/VectorSegmentExecutor.cpp
@@ -17,7 +17,9 @@
 #include <Common/getNumberOfPhysicalCPUCores.h>
 #include <Common/MemoryStatisticsOS.h>
 
+#include <Interpreters/Context.h>
 #include <Interpreters/OpenTelemetrySpanLog.h>
+#include <Interpreters/VectorIndexEventLog.h>
 #include <VectorIndex/BruteForceSearch.h>
 #include <VectorIndex/CacheManager.h>
 #include <VectorIndex/DiskIOReader.h>
@@ -132,6 +134,26 @@ String cutMutVer(const String & part_name)
 
 std::once_flag VectorSegmentExecutor::once;
 int VectorSegmentExecutor::max_threads = 0;
+String cutPartitionID(const String & part_name)
+{
+    std::vector<String> tokens;
+    boost::split(tokens, part_name, boost::is_any_of("_"));
+    return tokens[0];
+}
+
+String cutTableUUIDFromCacheKey(const String & cache_key)
+{
+    std::vector<String> tokens;
+    boost::split(tokens, cache_key, boost::is_any_of("/"));
+    return tokens[tokens.size() - 3];
+}
+
+String cutPartNameFromCacheKey(const String & cache_key)
+{
+    std::vector<String> tokens;
+    boost::split(tokens, cache_key, boost::is_any_of("/"));
+    return tokens[tokens.size() - 2];
+}
 
 void VectorSegmentExecutor::init()
 {
@@ -401,6 +423,11 @@ Status VectorSegmentExecutor::load()
         /// We don't want multiple execution engines loading index concurrently, so we use getOrSet method of LRUResourceCache
         /// to ensure that only one execution engine may read from disk at any time.
         LOG_DEBUG(log, "Num of item before cache {}", mgr->countItem());
+        DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                             cache_key.getTableUUID(),
+                                             cache_key.getPartName(),
+                                             cache_key.getPartitionID(),
+                                             DB::VectorIndexEventLogElement::LOAD_START);
 
         auto load_func = [&]() -> IndexWithMetaPtr
         {
@@ -476,10 +503,20 @@ Status VectorSegmentExecutor::load()
                 throw e;
             }
         };
+        auto global_context = DB::Context::getGlobalContextInstance();
+        auto release_callback = [cache_key, global_context]()
+        {
+            if (!global_context->isShutdown())
+                DB::VectorIndexEventLog::addEventLog(global_context,
+                                                     cache_key.getTableUUID(),
+                                                     cache_key.getPartName(),
+                                                     cache_key.getPartitionID(),
+                                                     DB::VectorIndexEventLogElement::UNLOAD);
+        };
 
         try
         {
-            index_holder = mgr->load(cache_key, load_func);
+            index_holder = mgr->load(cache_key, load_func, release_callback);
             LOG_DEBUG(log, "Num of item after cache {}", mgr->countItem());
             if (index_holder)
             {
@@ -489,21 +526,50 @@ Status VectorSegmentExecutor::load()
                 delete_bitmap = new_index.getDeleteBitmap();
                 des = new_index.des;
                 fallback_to_flat = new_index.fallback_to_flat;
+
+                DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                                     cache_key.getTableUUID(),
+                                                     cache_key.getPartName(),
+                                                     cache_key.getPartitionID(),
+                                                     DB::VectorIndexEventLogElement::LOAD_SUCCEED);
                 return Status();
             }
         }
         catch (const IndexException & e)
         {
+            DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                                 cache_key.getTableUUID(),
+                                                 cache_key.getPartName(),
+                                                 cache_key.getPartitionID(),
+                                                 DB::VectorIndexEventLogElement::LOAD_ERROR,
+                                                 DB::ExecutionStatus(e.code(), e.message()));
             return Status(e.code(), e.message());
         }
         catch (const DB::Exception & e)
         {
+            DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                                 cache_key.getTableUUID(),
+                                                 cache_key.getPartName(),
+                                                 cache_key.getPartitionID(),
+                                                 DB::VectorIndexEventLogElement::LOAD_ERROR,
+                                                 DB::ExecutionStatus(e.code(), e.message()));
             return Status(e.code(), e.message());
         }
         catch (const std::exception & e)
         {
+            DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                                 cache_key.getTableUUID(),
+                                                 cache_key.getPartName(),
+                                                 cache_key.getPartitionID(),
+                                                 DB::VectorIndexEventLogElement::LOAD_ERROR,
+                                                 DB::ExecutionStatus(DB::ErrorCodes::STD_EXCEPTION, e.what()));
             return Status(DB::ErrorCodes::STD_EXCEPTION, e.what());
         }
+        DB::VectorIndexEventLog::addEventLog(DB::Context::getGlobalContextInstance(),
+                                             cache_key.getTableUUID(),
+                                             cache_key.getPartName(),
+                                             cache_key.getPartitionID(),
+                                             DB::VectorIndexEventLogElement::LOAD_FAILED);
 
         return Status(2, "Load failed");
     }
diff --git a/tests/config/config.d/vector_index_event_log_test.xml b/tests/config/config.d/vector_index_event_log_test.xml
new file mode 100644
index 0000000000..48ef5bd2b1
--- /dev/null
+++ b/tests/config/config.d/vector_index_event_log_test.xml
@@ -0,0 +1,9 @@
+<clickhouse>
+    <vector_index_event_log>
+        <database>system</database>
+        <table>vector_index_event_log</table>
+        <partition_by>toYYYYMM(event_date)</partition_by>
+        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
+        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
+    </vector_index_event_log>
+</clickhouse>
diff --git a/tests/config/install.sh b/tests/config/install.sh
index 4e8252f32e..df95c3f487 100755
--- a/tests/config/install.sh
+++ b/tests/config/install.sh
@@ -40,6 +40,7 @@ ln -sf $SRC_PATH/config.d/CORS.xml $DEST_SERVER_PATH/config.d/
 ln -sf $SRC_PATH/config.d/zookeeper_log.xml $DEST_SERVER_PATH/config.d/
 ln -sf $SRC_PATH/config.d/logger.xml $DEST_SERVER_PATH/config.d/
 ln -sf $SRC_PATH/config.d/named_collection.xml $DEST_SERVER_PATH/config.d/
+ln -sf $SRC_PATH/config.d/vector_index_event_log_test.xml $DEST_SERVER_PATH/config.d/
 ln -sf $SRC_PATH/users.d/log_queries.xml $DEST_SERVER_PATH/users.d/
 ln -sf $SRC_PATH/users.d/readonly.xml $DEST_SERVER_PATH/users.d/
 ln -sf $SRC_PATH/users.d/access_management.xml $DEST_SERVER_PATH/users.d/
diff --git a/tests/queries/2_vector_search/00030_mqvs_vector_event_log.reference b/tests/queries/2_vector_search/00030_mqvs_vector_event_log.reference
new file mode 100644
index 0000000000..2ded0d26bc
--- /dev/null
+++ b/tests/queries/2_vector_search/00030_mqvs_vector_event_log.reference
@@ -0,0 +1,41 @@
+0
+2	2.69
+3	3.8899999
+1	7.49
+4	11.089999
+0	18.29
+5	24.289999
+6	43.49
+7	68.69
+8	99.89
+9	137.09
+0
+0
+0
+0
+0
+0
+test_vector_event_log	DefinitionCreated
+test_vector_event_log	BuildStart
+test_vector_event_log	LoadStart
+test_vector_event_log	LoadSucceed
+test_vector_event_log	BuildSucceed
+test_vector_event_log	Unload
+test_vector_event_log	LoadStart
+test_vector_event_log	LoadSucceed
+test_vector_event_log	DefinitionDroped
+test_vector_event_log	Unload
+test_vector_event_log	Cleared
+test_vector_event_log	DefinitionCreated
+test_vector_event_log	BuildStart
+test_vector_event_log	LoadStart
+test_vector_event_log	LoadSucceed
+test_vector_event_log	BuildSucceed
+test_vector_event_log	Unload
+test_vector_event_log	Cleared
+test_vector_event_log	BuildStart
+test_vector_event_log	LoadStart
+test_vector_event_log	LoadSucceed
+test_vector_event_log	BuildSucceed
+test_vector_event_log	Unload
+test_vector_event_log	Cleared
diff --git a/tests/queries/2_vector_search/00030_mqvs_vector_event_log.sql b/tests/queries/2_vector_search/00030_mqvs_vector_event_log.sql
new file mode 100644
index 0000000000..31a1494a0c
--- /dev/null
+++ b/tests/queries/2_vector_search/00030_mqvs_vector_event_log.sql
@@ -0,0 +1,56 @@
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS test_vector_event_log SYNC;
+TRUNCATE TABLE system.vector_index_event_log SYNC;
+CREATE TABLE test_vector_event_log
+(
+    id    UInt32,
+    vector  Array(Float32),
+    CONSTRAINT check_length CHECK length(vector) = 3
+)
+engine = MergeTree 
+ORDER BY id;
+
+INSERT INTO test_vector_event_log SELECT number, [number,number,number] FROM numbers(1000);
+
+ALTER TABLE test_vector_event_log ADD VECTOR INDEX vec_ind vector TYPE HNSWFLAT;
+
+SELECT sleep(2);
+
+DETACH TABLE test_vector_event_log SYNC;
+
+ATTACH TABLE test_vector_event_log;
+
+select id, distance(vector, [1.2, 2.3, 3.4]) as dist from test_vector_event_log order by dist limit 10;
+
+SELECT sleep(2);
+
+ALTER TABLE test_vector_event_log DROP VECTOR INDEX vec_ind;
+
+ALTER TABLE test_vector_event_log ADD VECTOR INDEX vec_ind vector TYPE HNSWFLAT;
+
+SELECT sleep(2);
+
+TRUNCATE TABLE test_vector_event_log SYNC;
+
+SELECT sleep(2);
+
+INSERT INTO test_vector_event_log SELECT number, [number,number,number] FROM numbers(1000);
+
+SELECT sleep(2);
+
+DROP TABLE test_vector_event_log SYNC;
+
+SELECT sleep(3);
+
+SELECT sleep(3);
+
+SYSTEM FLUSH LOGS;
+
+SELECT table, event_type 
+FROM system.vector_index_event_log 
+WHERE table = 'test_vector_event_log'
+ORDER BY event_time_microseconds;
+
+
+
-- 
2.32.1 (Apple Git-133)

