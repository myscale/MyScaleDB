From 20ae84477ca4f999b027b161fe0d5392b3274435 Mon Sep 17 00:00:00 2001
From: Zhuo Qiu <qiu_z@moqi.ai>
Date: Tue, 25 Apr 2023 13:11:30 +0000
Subject: [PATCH 01/49] integrate search-index (including MSTG)

---
 .gitlab-ci-functional-test.yml                |    2 +-
 .gitmodules                                   |   14 +-
 annoy                                         |    1 -
 contrib/CMakeLists.txt                        |   10 +-
 contrib/abseil-cpp                            |    2 +-
 contrib/faiss                                 |    1 -
 contrib/hnswlib                               |    1 -
 contrib/s2geometry                            |    2 +-
 contrib/search-index                          |    1 +
 docker/mqdb/server.conf/config.xml            |    5 +
 docker/mqdb/server.conf/users.xml             |    7 +-
 docker/test/mqdb_run_stateless/run.sh         |    4 +-
 docker/test/mqdb_test_script/clickhouse-test  |    2 +-
 programs/server/Server.cpp                    |   28 +-
 src/CMakeLists.txt                            |   11 +-
 src/Core/Settings.h                           |    7 +-
 src/Interpreters/Context.cpp                  |   16 +
 src/Interpreters/Context.h                    |    2 +
 .../QueryPlan/ReadWithVectorScan.cpp          |   21 +-
 src/Storages/MergeTree/IMergeTreeDataPart.cpp |   89 +-
 src/Storages/MergeTree/IMergeTreeDataPart.h   |    2 +-
 src/Storages/MergeTree/MergeTask.cpp          |   40 +-
 .../MergeTreeBaseSelectProcessor.cpp          |   21 +-
 .../MergeTree/MergeTreeBlockReadUtils.h       |    6 +-
 src/Storages/MergeTree/MergeTreeData.cpp      |    6 +-
 src/Storages/MergeTree/MergeTreeSettings.h    |    6 +-
 .../MergeTreeVectorIndexBuilderUpdater.cpp    |  415 ++-----
 .../MergeTreeVectorIndexBuilderUpdater.h      |   10 +-
 .../MergeTree/MergeTreeVectorScanManager.cpp  |  224 ++--
 .../MergeTree/MergeTreeVectorScanManager.h    |   31 +-
 .../MergeTree/MergeTreeVectorScanUtils.cpp    |    4 +-
 src/Storages/MergeTree/MutateTask.cpp         |   23 +-
 .../MergeTree/PrimaryKeyCacheManager.cpp      |    1 -
 .../MergeTree/ReplicatedVectorIndexTask.cpp   |    2 +-
 .../MergeTree/ReplicatedVectorIndexTask.h     |    2 +-
 .../MergeTree/VectorIndexMergeTreeTask.cpp    |    6 +-
 .../MergeTree/VectorIndexMergeTreeTask.h      |    2 +-
 src/Storages/StorageMergeTree.cpp             |   38 +-
 src/Storages/VectorIndexCommands.cpp          |    2 +-
 src/Storages/VectorIndicesDescription.cpp     |   10 +-
 src/VectorIndex/Autotuner.cpp                 |  134 ---
 src/VectorIndex/Autotuner.h                   |   69 --
 src/VectorIndex/Binary.h                      |   26 -
 src/VectorIndex/BruteForceSearch.cpp          |   22 +-
 src/VectorIndex/BruteForceSearch.h            |   16 +-
 src/VectorIndex/CMakeLists.txt                |   22 +-
 src/VectorIndex/CacheManager.cpp              |    6 +-
 src/VectorIndex/CacheManager.h                |   16 +-
 src/VectorIndex/CompositeIndexReader.cpp      |  140 ---
 src/VectorIndex/CompositeIndexReader.h        |   32 -
 src/VectorIndex/Dataset.h                     |   25 +-
 src/VectorIndex/FaissIndex.cpp                |  138 ---
 src/VectorIndex/FaissIndex.h                  |   38 -
 src/VectorIndex/FlatIndex.cpp                 |  101 --
 src/VectorIndex/FlatIndex.h                   |   60 -
 src/VectorIndex/GeneralBitMap.h               |   74 --
 src/VectorIndex/HNSWIndex.cpp                 |  238 ----
 src/VectorIndex/HNSWIndex.h                   |   76 --
 src/VectorIndex/HNSWPQ.cpp                    |  242 ----
 src/VectorIndex/HNSWPQ.h                      |   79 --
 src/VectorIndex/HNSWSQ.cpp                    |  277 -----
 src/VectorIndex/HNSWSQ.h                      |   72 --
 src/VectorIndex/IVFFlatIndex.cpp              |  296 -----
 src/VectorIndex/IVFFlatIndex.h                |   58 -
 src/VectorIndex/IVFPQIndex.cpp                |  195 ---
 src/VectorIndex/IVFPQIndex.h                  |   51 -
 src/VectorIndex/IVFSQIndex.cpp                |  226 ----
 src/VectorIndex/IVFSQIndex.h                  |   55 -
 src/VectorIndex/IndexException.h              |   15 +-
 src/VectorIndex/IndexReader.cpp               |   21 -
 src/VectorIndex/IndexReader.h                 |   25 -
 src/VectorIndex/IndexWriter.cpp               |   39 -
 src/VectorIndex/IndexWriter.h                 |   27 -
 src/VectorIndex/MergeUtils.h                  |   46 +-
 src/VectorIndex/Metadata.cpp                  |  146 +++
 src/VectorIndex/Metadata.h                    |   48 +
 src/VectorIndex/PartReader.cpp                |  183 +++
 src/VectorIndex/PartReader.h                  |   73 ++
 src/VectorIndex/SegmentId.h                   |  116 +-
 src/VectorIndex/Status.h                      |    4 +-
 src/VectorIndex/VectorIndex.h                 |  150 ---
 src/VectorIndex/VectorIndexCommon.h           |  300 ++---
 src/VectorIndex/VectorIndexFactory.cpp        |  199 ---
 src/VectorIndex/VectorIndexFactory.h          |   19 -
 src/VectorIndex/VectorSegmentExecutor.cpp     | 1070 +++++++----------
 src/VectorIndex/VectorSegmentExecutor.h       |  248 ++--
 src/VectorIndex/test/CMakeLists.txt           |    2 -
 src/VectorIndex/test/testExecutionEngine.cpp  |  106 --
 tests/clickhouse-test                         |    2 +-
 ...0003_mqvs_distance_with_prewhere.reference |    2 +-
 .../00003_mqvs_distance_with_prewhere.sh      |    2 +-
 .../00005_mqvs_build_ivfflat_index.sh         |    1 +
 .../00006_mqvs_build_hnswflat_index.sh        |    1 +
 .../00008_mqvs_empty_vector.reference         |    4 +-
 .../00013_mqvs_distance_ivfsq.reference       |   40 +-
 ..._mqvs_distance_cosine_bruteforce.reference |    5 +
 .../00014_mqvs_distance_cosine_bruteforce.sql |   10 +
 .../00014_mqvs_distance_cosine_hnsw.reference |    4 +-
 ...00014_mqvs_distance_cosine_ivfpq.reference |   20 +-
 ...00014_mqvs_distance_cosine_ivfsq.reference |   20 +-
 ..._mqvs_lightweight_delete_with_decouple.sql |    2 +-
 ...cated_lightweight_delete_with_decouple.sql |    4 +-
 .../00018_mqvs_drop_index_mergetree.reference |    2 +-
 ...dd_fail_status_in_vector_indices.reference |    4 +-
 ...mqvs_add_fail_status_in_vector_indices.sql |    4 +-
 ...dd_fail_status_in_vector_indices.reference |    4 +-
 ...ated_add_fail_status_in_vector_indices.sql |    4 +-
 ..._refactor_support_prewhere_where.reference |   10 +-
 ...qvs_replicated_merge_with_vector_index.sql |    2 +-
 ...23_mqvs_mutation_can_reuse_vector_index.sh |    6 +-
 ...028_mqvs_index_mstg_build_search.reference |   14 +
 .../00028_mqvs_index_mstg_build_search.sql    |   22 +
 .../00029_mqvs_fallback_to_flat.reference     |   12 +
 .../00029_mqvs_fallback_to_flat.sql           |   15 +
 114 files changed, 1838 insertions(+), 5076 deletions(-)
 delete mode 160000 annoy
 delete mode 160000 contrib/faiss
 delete mode 160000 contrib/hnswlib
 create mode 160000 contrib/search-index
 delete mode 100644 src/VectorIndex/Autotuner.cpp
 delete mode 100644 src/VectorIndex/Autotuner.h
 delete mode 100644 src/VectorIndex/Binary.h
 delete mode 100644 src/VectorIndex/CompositeIndexReader.cpp
 delete mode 100644 src/VectorIndex/CompositeIndexReader.h
 delete mode 100644 src/VectorIndex/FaissIndex.cpp
 delete mode 100644 src/VectorIndex/FaissIndex.h
 delete mode 100644 src/VectorIndex/FlatIndex.cpp
 delete mode 100644 src/VectorIndex/FlatIndex.h
 delete mode 100644 src/VectorIndex/GeneralBitMap.h
 delete mode 100644 src/VectorIndex/HNSWIndex.cpp
 delete mode 100644 src/VectorIndex/HNSWIndex.h
 delete mode 100644 src/VectorIndex/HNSWPQ.cpp
 delete mode 100644 src/VectorIndex/HNSWPQ.h
 delete mode 100644 src/VectorIndex/HNSWSQ.cpp
 delete mode 100644 src/VectorIndex/HNSWSQ.h
 delete mode 100644 src/VectorIndex/IVFFlatIndex.cpp
 delete mode 100644 src/VectorIndex/IVFFlatIndex.h
 delete mode 100644 src/VectorIndex/IVFPQIndex.cpp
 delete mode 100644 src/VectorIndex/IVFPQIndex.h
 delete mode 100644 src/VectorIndex/IVFSQIndex.cpp
 delete mode 100644 src/VectorIndex/IVFSQIndex.h
 delete mode 100644 src/VectorIndex/IndexReader.cpp
 delete mode 100644 src/VectorIndex/IndexReader.h
 delete mode 100644 src/VectorIndex/IndexWriter.cpp
 delete mode 100644 src/VectorIndex/IndexWriter.h
 create mode 100644 src/VectorIndex/Metadata.cpp
 create mode 100644 src/VectorIndex/Metadata.h
 create mode 100644 src/VectorIndex/PartReader.cpp
 create mode 100644 src/VectorIndex/PartReader.h
 delete mode 100644 src/VectorIndex/VectorIndex.h
 delete mode 100644 src/VectorIndex/VectorIndexFactory.cpp
 delete mode 100644 src/VectorIndex/VectorIndexFactory.h
 delete mode 100644 src/VectorIndex/test/CMakeLists.txt
 delete mode 100644 src/VectorIndex/test/testExecutionEngine.cpp
 create mode 100644 tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.reference
 create mode 100644 tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.sql
 create mode 100644 tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.reference
 create mode 100644 tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.sql
 create mode 100644 tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.reference
 create mode 100644 tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.sql

diff --git a/.gitlab-ci-functional-test.yml b/.gitlab-ci-functional-test.yml
index 5696de8325..78caeed528 100644
--- a/.gitlab-ci-functional-test.yml
+++ b/.gitlab-ci-functional-test.yml
@@ -94,4 +94,4 @@ stateful_test:
     - docker/builder/tools/stateful-test.sh
     - if [[ ${ARCH} == "amd64" ]];then docker/builder/tools/check_job_states.sh mqdb_run_stateful; fi
   rules:
-    - if: '$CI_TEST_IN_K8S == "false"'
\ No newline at end of file
+    - if: '$CI_TEST_IN_K8S == "false"'
diff --git a/.gitmodules b/.gitmodules
index 23ad152843..d4559690b4 100644
--- a/.gitmodules
+++ b/.gitmodules
@@ -237,7 +237,7 @@
 	url = https://github.com/azadkuh/sqlite-amalgamation
 [submodule "contrib/s2geometry"]
 	path = contrib/s2geometry
-	url = https://github.com/ClickHouse/s2geometry.git
+	url = git@git.moqi.ai:mqdb/s2geometry.git
 [submodule "contrib/bzip2"]
 	path = contrib/bzip2
 	url = https://github.com/ClickHouse/bzip2.git
@@ -266,12 +266,6 @@
 	path = contrib/annoy
 	url = https://github.com/ClickHouse/annoy.git
 	branch = ClickHouse-master
-[submodule "contrib/faiss"]
-	path = contrib/faiss
-	url = git@git.moqi.ai:mqdb/faiss.git
-[submodule "contrib/hnswlib"]
-	path = contrib/hnswlib
-	url = git@git.moqi.ai:mqdb/hnswlib.git
-[submodule "annoy"]
-	path = annoy
-	url = https://github.com/ClickHouse/annoy.git
+[submodule "contrib/search-index"]
+	path = contrib/search-index
+	url = git@git.moqi.ai:mqdb/search-index.git
diff --git a/annoy b/annoy
deleted file mode 160000
index ebaa60e5c8..0000000000
--- a/annoy
+++ /dev/null
@@ -1 +0,0 @@
-Subproject commit ebaa60e5c83d140901b9719471eb47800e5744ac
diff --git a/contrib/CMakeLists.txt b/contrib/CMakeLists.txt
index 2b2e7b71a9..7e200f7485 100644
--- a/contrib/CMakeLists.txt
+++ b/contrib/CMakeLists.txt
@@ -150,9 +150,13 @@ add_contrib (s2geometry-cmake s2geometry)
 
 add_contrib (annoy-cmake annoy)
 
-set(FAISS_OPT_LEVEL avx2)
-add_subdirectory (faiss)
-add_subdirectory (hnswlib)
+set(ENABLE_FAISS ON)
+set(ENABLE_SCANN ON)
+set(ENABLE_DISKANN OFF)
+set(MYSCALE_MODE ON)
+set(SI_PYBIND OFF)
+set(SCANN_PYBIND OFF)
+add_contrib (search-index)
 # Put all targets defined here and in subdirectories under "contrib/<immediate-subdir>" folders in GUI-based IDEs.
 # Some of third-party projects may override CMAKE_FOLDER or FOLDER property of their targets, so they would not appear
 # in "contrib/..." as originally planned, so we workaround this by fixing FOLDER properties of all targets manually,
diff --git a/contrib/abseil-cpp b/contrib/abseil-cpp
index 215105818d..8c0b94e793 160000
--- a/contrib/abseil-cpp
+++ b/contrib/abseil-cpp
@@ -1 +1 @@
-Subproject commit 215105818dfde3174fe799600bb0f3cae233d0bf
+Subproject commit 8c0b94e793a66495e0b1f34a5eb26bd7dc672db0
diff --git a/contrib/faiss b/contrib/faiss
deleted file mode 160000
index c679689cf1..0000000000
--- a/contrib/faiss
+++ /dev/null
@@ -1 +0,0 @@
-Subproject commit c679689cf10eff6043b1333f2d8b764746dd9e7c
diff --git a/contrib/hnswlib b/contrib/hnswlib
deleted file mode 160000
index 90fe3a1119..0000000000
--- a/contrib/hnswlib
+++ /dev/null
@@ -1 +0,0 @@
-Subproject commit 90fe3a11192af08f0207a354a5b0e3a9fd177f2c
diff --git a/contrib/s2geometry b/contrib/s2geometry
index 471fe9dc93..a5f0cdda8c 160000
--- a/contrib/s2geometry
+++ b/contrib/s2geometry
@@ -1 +1 @@
-Subproject commit 471fe9dc931a4bb560333545186e9b5da168ac83
+Subproject commit a5f0cdda8cfe4735ec6f921810cb67404d08a9db
diff --git a/contrib/search-index b/contrib/search-index
new file mode 160000
index 0000000000..f9b53b9465
--- /dev/null
+++ b/contrib/search-index
@@ -0,0 +1 @@
+Subproject commit f9b53b9465a96d4b6be6de1505beb4fe22dd2dad
diff --git a/docker/mqdb/server.conf/config.xml b/docker/mqdb/server.conf/config.xml
index 38ccc58fbf..1139d0c89f 100644
--- a/docker/mqdb/server.conf/config.xml
+++ b/docker/mqdb/server.conf/config.xml
@@ -148,4 +148,9 @@
             <replace>\1(???)</replace>
         </rule>
     </query_masking_rules>
+
+    <merge_tree>
+        <enable_primary_key_cache>true</enable_primary_key_cache>
+        <min_bytes_to_build_vector_index>10485760</min_bytes_to_build_vector_index>
+    </merge_tree>
 </clickhouse>
diff --git a/docker/mqdb/server.conf/users.xml b/docker/mqdb/server.conf/users.xml
index c3888940e6..f5741cdb8d 100644
--- a/docker/mqdb/server.conf/users.xml
+++ b/docker/mqdb/server.conf/users.xml
@@ -4,13 +4,9 @@
     <profiles>
         <default>
             <max_memory_usage>8000000000</max_memory_usage>
-            <serialized_index_segment_max_byte>50000000</serialized_index_segment_max_byte>
             <load_balancing>random</load_balancing>
             <log_queries>1</log_queries>
             <allow_experimental_lightweight_delete>true</allow_experimental_lightweight_delete>
-            <!-- <mutations_sync>0</mutations_sync> -->
-            <!-- <replication_alter_partitions_sync>1</replication_alter_partitions_sync> -->
-            <!-- <insert_distributed_sync>1</insert_distributed_sync> -->
             <optimize_move_to_prewhere>1</optimize_move_to_prewhere>
             <max_query_size>262144000</max_query_size>
             <connect_timeout_with_failover_ms>5000</connect_timeout_with_failover_ms>
@@ -21,8 +17,7 @@
             <readonly>0</readonly>
             <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
             <parallel_view_processing>1</parallel_view_processing>
-            <vector_index_cache_size>4</vector_index_cache_size>
-            <incremental_build_index_ratio>0.4</incremental_build_index_ratio>
+            <use_uncompressed_cache>1</use_uncompressed_cache>
         </default>
         <readonly>
             <profile>default</profile>
diff --git a/docker/test/mqdb_run_stateless/run.sh b/docker/test/mqdb_run_stateless/run.sh
index cc0a0100c8..4e21d31642 100644
--- a/docker/test/mqdb_run_stateless/run.sh
+++ b/docker/test/mqdb_run_stateless/run.sh
@@ -135,7 +135,9 @@ function run_tests() {
         01658_read_file_to_stringcolumn 01600_detach_permanently 01527_clickhouse_local_optimize \
         02047 01039 00993 02207 02117 02226 01606_git_import \
         01154_move_partition_long 01076_parallel_alter_replicated_zookeeper 01172_transaction_counters \
-        01079_parallel_alter_detach_table_zookeeper 01193_metadata_loading 2>&1 |
+        01079_parallel_alter_detach_table_zookeeper 01193_metadata_loading \
+        01103_check_cpu_instructions_at_startup \
+        2>&1 |
         ts '%Y-%m-%d %H:%M:%S' |
         tee -a test_output/test_result.txt
     set -e
diff --git a/docker/test/mqdb_test_script/clickhouse-test b/docker/test/mqdb_test_script/clickhouse-test
index 695ae3a97d..3547c85835 100644
--- a/docker/test/mqdb_test_script/clickhouse-test
+++ b/docker/test/mqdb_test_script/clickhouse-test
@@ -307,7 +307,7 @@ class FailureReason(enum.Enum):
     SERVER_DIED = "server died"
     EXIT_CODE = "return code: "
     STDERR = "having stderror: "
-    EXCEPTION = "having having exception in stdout: "
+    EXCEPTION = "having exception in stdout: "
     RESULT_DIFF = "result differs with reference: "
     TOO_LONG = "Test runs too long (> 60s). Make it faster."
 
diff --git a/programs/server/Server.cpp b/programs/server/Server.cpp
index 474d82c883..e8be2e47ed 100644
--- a/programs/server/Server.cpp
+++ b/programs/server/Server.cpp
@@ -94,10 +94,9 @@
 #include <Compression/CompressionCodecEncrypted.h>
 #include <filesystem>
 
-#include "config_core.h"
-#include "Common/config_version.h"
-#include <VectorIndex/Autotuner.h>
 #include <VectorIndex/VectorSegmentExecutor.h>
+#include "Common/config_version.h"
+#include "config_core.h"
 
 
 #if defined(OS_LINUX)
@@ -546,7 +545,7 @@ std::string getHexDigest(const std::string & content)
 {
     std::string salt_content = content + STRING_SUFFIX_FOR_DIGEST;
     unsigned char digest[33];
-    SHA256((unsigned char *)salt_content.c_str(), salt_content.size(), digest);
+    SHA256(reinterpret_cast<const uint8_t *>(salt_content.c_str()), salt_content.size(), digest);
     int len = 32;
     std::string result;
     result.resize(2 * len);
@@ -635,9 +634,9 @@ bool checkLicenseSign(const std::string & public_key_path, const std::string & c
         LOG_DEBUG(log, "Read license public key failed.");
         return false;
     }
-    char digest[33];
-    SHA256((unsigned char *)content.c_str(), content.size(), (unsigned char *)digest);
-    int result = RSA_verify(NID_sha256, (unsigned char *)digest, 32, (unsigned char *)sign.c_str(), sign.size(), rsa_public_key);
+    uint8_t digest[33];
+    SHA256(reinterpret_cast<const uint8_t *>(content.c_str()), content.size(), digest);
+    int result = RSA_verify(NID_sha256, digest, 32, reinterpret_cast<const uint8_t *>(sign.c_str()), sign.size(), rsa_public_key);
     RSA_free(rsa_public_key);
     return result == 1;
 }
@@ -733,7 +732,7 @@ void checkLicenseImpl(
         }
 
         std::string cpu_count_xml = license_doc->getNodeByPath(CPU_COUNT_PATH_XML)->innerText();
-        if (cpu_count <= std::stoi(cpu_count_xml))
+        if (cpu_count <= std::stoul(cpu_count_xml))
         {
             LOG_INFO(log, "The number of CPU is checked: {}, MAX: {}.", cpu_count, cpu_count_xml);
         }
@@ -1275,6 +1274,12 @@ if (ThreadFuzzer::instance().isEffective())
         fs::create_directories(user_scripts_path);
     }
 
+    {
+        std::string vector_index_cache_path = config().getString("vector_index_cache_path", path / "vector_index_cache/");
+        global_context->setVectorIndexCachePath(vector_index_cache_path);
+        fs::create_directories(vector_index_cache_path);
+    }
+
     /// top_level_domains_lists
     {
         const std::string & top_level_domains_path = config().getString("top_level_domains_path", path / "top_level_domains/");
@@ -1749,13 +1754,6 @@ if (ThreadFuzzer::instance().isEffective())
     LOG_INFO(log, "vector_index_cache_max_size_in_bytes = {}", vector_index_cache_max_size_in_bytes);
     VectorIndex::VectorSegmentExecutor::setCacheManagerSizeInBytes(vector_index_cache_max_size_in_bytes);
 
-    size_t max_permitted = global_context->getSettingsRef().serialized_index_segment_max_byte;
-    LOG_INFO(log, "max size of serializaed segment of vector index set to {}", max_permitted);
-    VectorIndex::VectorSegmentExecutor::setSerializeSegmentSize(max_permitted);
-    ///To turn on autotuner, turn it on here.
-//        VectorIndex::Autotuner* tuner = VectorIndex::Autotuner::getInstance();
-//        tuner->start();
-
     LOG_INFO(log, "Loading metadata from {}", path_str);
 
     try
diff --git a/src/CMakeLists.txt b/src/CMakeLists.txt
index 2475a08edd..d1a73a251a 100644
--- a/src/CMakeLists.txt
+++ b/src/CMakeLists.txt
@@ -71,6 +71,7 @@ add_subdirectory (Formats)
 add_subdirectory (Compression)
 add_subdirectory (Server)
 add_subdirectory (Coordination)
+add_subdirectory (VectorIndex)
 
 
 set(dbms_headers)
@@ -174,9 +175,6 @@ list (APPEND dbms_headers
     Dictionaries/DictionaryStructure.h
     Dictionaries/getDictionaryConfigurationFromAST.h)
 
-add_headers_and_sources(dbms VectorIndex)
-set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fopenmp")
-
 if (NOT ENABLE_SSL)
     list (REMOVE_ITEM clickhouse_common_io_sources Common/OpenSSLHelpers.cpp)
     list (REMOVE_ITEM clickhouse_common_io_headers Common/OpenSSLHelpers.h)
@@ -392,6 +390,7 @@ dbms_target_link_libraries (
         Poco::JSON
         Poco::MongoDB
         string_utils
+        clickhouse_vector_index
     PUBLIC
         boost::system
         clickhouse_common_io
@@ -509,13 +508,10 @@ if (TARGET ch_contrib::datasketches)
 endif ()
 
 target_link_libraries (clickhouse_common_io PRIVATE ch_contrib::lz4)
-dbms_target_include_directories(PUBLIC "${ClickHouse_SOURCE_DIR}/contrib/faiss")
-dbms_target_include_directories(PUBLIC "${ClickHouse_SOURCE_DIR}/contrib/hnswlib")
 dbms_target_include_directories(PUBLIC "${ClickHouse_SOURCE_DIR}/contrib/rapidjson/include")
 dbms_target_include_directories(PUBLIC "${ClickHouse_SOURCE_DIR}/contrib/lz4/lib")
 
 dbms_target_link_libraries(PRIVATE _boost_context)
-dbms_target_link_libraries(PUBLIC faiss)
 
 if (ENABLE_NLP)
     dbms_target_link_libraries (PUBLIC ch_contrib::stemmer)
@@ -546,8 +542,7 @@ if (TARGET ch_contrib::annoy)
     dbms_target_link_libraries(PUBLIC ch_contrib::annoy)
 endif()
 
-find_package(OpenMP REQUIRED)
-dbms_target_link_libraries(PUBLIC OpenMP::OpenMP_CXX)
+dbms_target_link_libraries(PUBLIC ch_contrib::search_index)
 
 include ("${ClickHouse_SOURCE_DIR}/cmake/add_check.cmake")
 
diff --git a/src/Core/Settings.h b/src/Core/Settings.h
index 42f079183e..6cae503b43 100644
--- a/src/Core/Settings.h
+++ b/src/Core/Settings.h
@@ -165,14 +165,9 @@ class IColumn;
     M(UInt64, background_common_pool_size, 8, "Number of threads for some lightweight tasks for replicated tables (like cleaning old parts etc.). Only has meaning at server startup.", 0) \
     M(UInt64, background_vector_pool_size, 1, "Number of threads for vector index building", 0)      \
     M(UInt64, background_slow_mode_vector_pool_size, 3, "Number of threads for slow mode vector index building", 0)      \
-    M(UInt64, vector_index_cache_size, 100, "number of vector index to cache", 0)      \
     M(Float, vector_index_cache_size_ratio_of_memory, 1.0, "vector_index_cache_size_ratio_of_memory", 0) \
-    M(Float, incremental_build_index_ratio, 0.1, "the ratio which data in a datapart is being added to vector index, also is the ratio of data being used for training index", 0)   \
-    M(UInt64, max_build_index_block, 100000, "number of rows to build index in one round", 0)     \
-    M(UInt64, max_build_index_block_size_rows, 160000, "number of rows to build index in one round", 0) \
-    M(UInt64, min_build_index_train_block_size, 100 * 1024 * 1024, "Minimum block size in bytes for training in build index", 0) \
+    M(UInt64, max_build_index_train_block_size, 100 * 1024 * 1024, "Maximum block size in bytes for training in build index", 0) \
     M(UInt64, max_build_index_add_block_size, 10 * 1024 * 1024, "Maximum block size in bytes for adding vectors in one round of build index", 0) \
-    M(UInt64, serialized_index_segment_max_byte, 50000000, "Segment size in bytes for vector index serialization", 0) \
     M(Bool, optimize_move_to_prewhere_for_vector_search, true, "Enables or disables special PREWHERE optimization for vector search in SELECT queries which move all viable WHERE to PREWHERE.", 0) \
     M(UInt64, background_schedule_pool_size, 128, "Number of threads performing background tasks for replicated tables, dns cache updates. Only has meaning at server startup.", 0) \
     M(UInt64, background_message_broker_schedule_pool_size, 16, "Number of threads performing background tasks for message streaming. Only has meaning at server startup.", 0) \
diff --git a/src/Interpreters/Context.cpp b/src/Interpreters/Context.cpp
index 7655e824c1..7f588255c7 100644
--- a/src/Interpreters/Context.cpp
+++ b/src/Interpreters/Context.cpp
@@ -181,6 +181,7 @@ struct ContextSharedPart
     String user_files_path;                                 /// Path to the directory with user provided files, usable by 'file' table function.
     String dictionaries_lib_path;                           /// Path to the directory with user provided binaries and libraries for external dictionaries.
     String user_scripts_path;                               /// Path to the directory with user provided scripts.
+    String vector_index_cache_path;                         /// Path to the directory of vector index cache for MSTG disk mode
     ConfigurationPtr config;                                /// Global configuration settings.
 
     String tmp_path;                                        /// Path to the temporary files that occur when processing the request.
@@ -573,6 +574,12 @@ String Context::getUserScriptsPath() const
     return shared->user_scripts_path;
 }
 
+String Context::getVectorIndexCachePath() const
+{
+    auto lock = getLock();
+    return shared->vector_index_cache_path;
+}
+
 Strings Context::getWarnings() const
 {
     Strings common_warnings;
@@ -618,6 +625,9 @@ void Context::setPath(const String & path)
 
     if (shared->user_scripts_path.empty())
         shared->user_scripts_path = shared->path + "user_scripts/";
+
+    if (shared->vector_index_cache_path.empty())
+        shared->vector_index_cache_path = shared->path + "vector_index_cache/";
 }
 
 VolumePtr Context::setTemporaryStorage(const String & path, const String & policy_name)
@@ -672,6 +682,12 @@ void Context::setUserScriptsPath(const String & path)
     shared->user_scripts_path = path;
 }
 
+void Context::setVectorIndexCachePath(const String & path)
+{
+    auto lock = getLock();
+    shared->vector_index_cache_path = path;
+}
+
 void Context::addWarningMessage(const String & msg)
 {
     auto lock = getLock();
diff --git a/src/Interpreters/Context.h b/src/Interpreters/Context.h
index fc565bc302..e622d4ba8d 100644
--- a/src/Interpreters/Context.h
+++ b/src/Interpreters/Context.h
@@ -369,6 +369,7 @@ public:
     String getUserFilesPath() const;
     String getDictionariesLibPath() const;
     String getUserScriptsPath() const;
+    String getVectorIndexCachePath() const;
 
     /// A list of warnings about server configuration to place in `system.warnings` table.
     Strings getWarnings() const;
@@ -380,6 +381,7 @@ public:
     void setUserFilesPath(const String & path);
     void setDictionariesLibPath(const String & path);
     void setUserScriptsPath(const String & path);
+    void setVectorIndexCachePath(const String & path);
 
     void addWarningMessage(const String & msg);
 
diff --git a/src/Processors/QueryPlan/ReadWithVectorScan.cpp b/src/Processors/QueryPlan/ReadWithVectorScan.cpp
index 3883db7e47..f121cbd994 100644
--- a/src/Processors/QueryPlan/ReadWithVectorScan.cpp
+++ b/src/Processors/QueryPlan/ReadWithVectorScan.cpp
@@ -192,9 +192,24 @@ Pipe ReadWithVectorScan::readFromParts(
         if (part->index_granularity.getMarksCount())
             ranges.emplace_back(0, part->index_granularity.getMarksCount());
 
-        auto source = std::make_shared<MergeTreeSelectWithVectorScanProcessor>(data, storage_snapshot, part, max_block_size, 
-            preferred_block_size_bytes, preferred_max_column_in_block_size_bytes, required_columns, ranges, use_uncompressed_cache, prewhere_info,
-            actions_settings, reader_settings, virt_column_names, (size_t)0, false, std::move(extension), vector_scan_manager);
+        auto source = std::make_shared<MergeTreeSelectWithVectorScanProcessor>(
+            data,
+            storage_snapshot,
+            part,
+            max_block_size,
+            preferred_block_size_bytes,
+            preferred_max_column_in_block_size_bytes,
+            required_columns,
+            ranges,
+            use_uncompressed_cache,
+            prewhere_info,
+            actions_settings,
+            reader_settings,
+            virt_column_names,
+            0UL,
+            false,
+            std::move(extension),
+            vector_scan_manager);
         pipes.emplace_back(Pipe(std::move(source)));
     }
 
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
index 7d3f1c1149..ded510932f 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
@@ -2,35 +2,35 @@
 
 #include <optional>
 #include <string_view>
+#include <Compression/getCompressionCodecForFile.h>
 #include <Core/Defines.h>
+#include <DataTypes/DataTypeAggregateFunction.h>
+#include <DataTypes/NestedUtils.h>
 #include <IO/HashingWriteBuffer.h>
 #include <IO/ReadBufferFromString.h>
 #include <IO/ReadHelpers.h>
 #include <IO/WriteHelpers.h>
+#include <Interpreters/MergeTreeTransaction.h>
+#include <Interpreters/TransactionLog.h>
+#include <Parsers/ExpressionElementParsers.h>
+#include <Parsers/parseQuery.h>
+#include <Parsers/queryToString.h>
 #include <Storages/MergeTree/MergeTreeData.h>
-#include <Storages/MergeTree/localBackup.h>
-#include <Storages/MergeTree/checkDataPart.h>
 #include <Storages/MergeTree/PrimaryKeyCacheManager.h>
+#include <Storages/MergeTree/checkDataPart.h>
+#include <Storages/MergeTree/localBackup.h>
 #include <Storages/StorageReplicatedMergeTree.h>
-#include <Common/StringUtils/StringUtils.h>
-#include <Common/escapeForFileName.h>
-#include <Common/ZooKeeper/ZooKeeper.h>
+#include <VectorIndex/CacheManager.h>
+#include <VectorIndex/DiskIOReader.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
+#include <base/JSON.h>
+#include <base/logger_useful.h>
 #include <Common/CurrentMetrics.h>
 #include <Common/FieldVisitorsAccurateComparison.h>
 #include <Common/MemoryTrackerBlockerInThread.h>
-#include <base/JSON.h>
-#include <base/logger_useful.h>
-#include <Compression/getCompressionCodecForFile.h>
-#include <Parsers/parseQuery.h>
-#include <Parsers/queryToString.h>
-#include <Parsers/ExpressionElementParsers.h>
-#include <DataTypes/NestedUtils.h>
-#include <DataTypes/DataTypeAggregateFunction.h>
-#include <VectorIndex/VectorSegmentExecutor.h>
-#include <VectorIndex/CacheManager.h>
-#include <VectorIndex/DiskIOReader.h>
-#include <Interpreters/MergeTreeTransaction.h>
-#include <Interpreters/TransactionLog.h>
+#include <Common/StringUtils/StringUtils.h>
+#include <Common/ZooKeeper/ZooKeeper.h>
+#include <Common/escapeForFileName.h>
 
 
 namespace CurrentMetrics
@@ -1129,7 +1129,7 @@ void IMergeTreeDataPart::loadColumns(bool require)
 void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const String & col_name, bool skip_decouple) const
 {
     /// No need to check metadata of table, because for drop index, the metadata has erased it.
-    /// Remove all the files which end with .vidx
+    /// Remove all the files which end with .vidx2
     auto disk = volume->getDisk();
 
     for (auto it = disk->iterateDirectory(getFullRelativePath()); it->isValid(); it->next())
@@ -1184,52 +1184,11 @@ void IMergeTreeDataPart::loadSimpleVectorIndexMetadata() const
     for (const auto & vec_index_desc : metadata_snapshot->vec_indices)
         index_name_to_verify.emplace_back(vec_index_desc.name + "_" + vec_index_desc.column);
 
-    String read_file_path = getFullPath() + "vector_index_ready" + VECTOR_INDEX_FILE_SUFFIX;
-
-    VectorIndex::DiskIOReader reader;
-    std::unordered_map<std::string, VectorIndex::Parameters> para;
-    std::unordered_map<String, int64_t> sizes = VectorIndex::readVectorIndexReadyFile(reader, read_file_path, index_name_to_verify, para);
-
-    if (sizes.empty())
-        return;
-
     for (const auto & vec_index_desc : metadata_snapshot->vec_indices)
     {
         String index_name = vec_index_desc.name + "_" + vec_index_desc.column;
-        auto index_size = sizes.find(index_name);
-        if (index_size != sizes.end())
-        {
-            int64_t size = index_size->second;
-            // this index is in metadata and found in vector_index_ready
-            if (size != -1)
-            {
-                LOG_TRACE(storage.log, "Read from vector_index_ready:{},{}", index_name, size);
-                VectorIndex::Parameters & single_params_from_record = para.find(index_name)->second;
-                ///there are two cases, one, there are parameters, in which case we compare the one in metadata with the one on disk.
-                if (!single_params_from_record.empty())
-                {
-                    VectorIndex::IndexType t
-                            = VectorIndex::VectorIndexFactory::createIndexType(single_params_from_record.find("type")->second);
-                    single_params_from_record.erase("type");
-
-                    if (VectorIndex::VectorSegmentExecutor::compareVectorIndexParameters(
-                            t,
-                            single_params_from_record,
-                            VectorIndex::VectorIndexFactory::createIndexType(vec_index_desc.type),
-                            VectorIndex::convertPocoJsonToMap(vec_index_desc.parameters)))
-                    {
-                        LOG_DEBUG(storage.log, "Index {} is built for part {}", index_name, name);
-                        addVectorIndex(index_name);
-                    }
-                }
-                // second, there are no parameters, in which case we simple admit the correctness of index. this is legacy adaptation.
-                else
-                {
-                    LOG_DEBUG(storage.log, "Index {} is built for part {}", index_name, name);
-                    addVectorIndex(index_name);
-                }
-            }
-        }
+        LOG_DEBUG(storage.log, "Index {} is built for part {}", index_name, name);
+        addVectorIndex(index_name);
     }
 }
 
@@ -1254,7 +1213,7 @@ void IMergeTreeDataPart::loadDecoupledVectorIndexMetadata() const
         if (!endsWith(file_name, ready_file_name))
             continue;
 
-        /// Found merged files, merged-0-<part name>-vector_index_ready.vidx
+        /// Found merged files, merged-0-<part name>-vector_index_ready.vidx2
         Strings tokens;
         boost::algorithm::split(tokens, file_name, boost::is_any_of("-"));
         if (tokens.size() != 4)
@@ -1646,7 +1605,7 @@ void IMergeTreeDataPart::onLightweightDelete() const
     /// currently only consider one vector index
     auto vec_index_desc = metadata_snapshot->vec_indices[0];
 
-    VectorIndex::SegmentId segment_id(getFullPath(), name, name, vec_index_desc.name, vec_index_desc.column, 0);
+    VectorIndex::SegmentId segment_id(volume, getFullPath(), name, vec_index_desc.name, vec_index_desc.column, "");
     VectorIndex::VectorSegmentExecutor vec_executor(segment_id);
 
     /// Update vector index deleted bitmap for the part on disk and cache if exists.
@@ -1703,7 +1662,7 @@ void IMergeTreeDataPart::onDecoupledLightWeightDelete() const
     const auto old_parts = getMergedSourceParts();
     for (const auto & old_part : old_parts)
     {
-        VectorIndex::SegmentId segment_id(data_path, name, old_part.name, vec_index_desc.name, vec_index_desc.column, old_part.id);
+        VectorIndex::SegmentId segment_id(volume, data_path, name, old_part.name, vec_index_desc.name, vec_index_desc.column, "", old_part.id);
         VectorIndex::VectorSegmentExecutor vec_executor(segment_id);
         /// Update merged deleted bitmap for the old part on disk and cache if exists.
         vec_executor.updateMergedBitMap(new_del_ids);
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h
index ea2da84d93..e608856fe6 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.h
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h
@@ -522,7 +522,7 @@ public:
 
     static inline constexpr auto TXN_VERSION_METADATA_FILE_NAME = "txn_version.txt";
 
-    static inline constexpr auto VECTOR_INDEX_FILE_EXTENSION = ".vidx";
+    static inline constexpr auto VECTOR_INDEX_FILE_EXTENSION = ".vidx2";
 
     /// One of part files which is used to check how many references (I'd like
     /// to say hardlinks, but it will confuse even more) we have for the part
diff --git a/src/Storages/MergeTree/MergeTask.cpp b/src/Storages/MergeTree/MergeTask.cpp
index 2e13d55498..f05df9bf60 100644
--- a/src/Storages/MergeTree/MergeTask.cpp
+++ b/src/Storages/MergeTree/MergeTask.cpp
@@ -9,27 +9,27 @@
 
 #include <DataTypes/ObjectUtils.h>
 #include <DataTypes/Serializations/SerializationInfo.h>
-#include <Storages/MergeTree/MergeTreeData.h>
-#include <Storages/MergeTree/IMergeTreeDataPart.h>
-#include <Storages/MergeTree/MergeTreeSequentialSource.h>
-#include <Storages/MergeTree/FutureMergedMutatedPart.h>
-#include <Storages/MergeTree/MergeTreeDataMergerMutator.h>
-#include <Storages/MergeTree/MergeTreeInOrderSelectProcessor.h>
-#include <Processors/Transforms/ExpressionTransform.h>
-#include <Processors/Transforms/MaterializingTransform.h>
-#include <Processors/Transforms/FilterTransform.h>
-#include <Processors/Merges/MergingSortedTransform.h>
+#include <IO/WriteIntText.h>
+#include <Processors/Merges/AggregatingSortedTransform.h>
 #include <Processors/Merges/CollapsingSortedTransform.h>
-#include <Processors/Merges/SummingSortedTransform.h>
-#include <Processors/Merges/ReplacingSortedTransform.h>
 #include <Processors/Merges/GraphiteRollupSortedTransform.h>
-#include <Processors/Merges/AggregatingSortedTransform.h>
+#include <Processors/Merges/MergingSortedTransform.h>
+#include <Processors/Merges/ReplacingSortedTransform.h>
+#include <Processors/Merges/SummingSortedTransform.h>
 #include <Processors/Merges/VersionedCollapsingTransform.h>
-#include <Processors/Transforms/TTLTransform.h>
-#include <Processors/Transforms/TTLCalcTransform.h>
 #include <Processors/Transforms/DistinctSortedTransform.h>
+#include <Processors/Transforms/ExpressionTransform.h>
+#include <Processors/Transforms/FilterTransform.h>
+#include <Processors/Transforms/MaterializingTransform.h>
+#include <Processors/Transforms/TTLCalcTransform.h>
+#include <Processors/Transforms/TTLTransform.h>
+#include <Storages/MergeTree/FutureMergedMutatedPart.h>
+#include <Storages/MergeTree/IMergeTreeDataPart.h>
+#include <Storages/MergeTree/MergeTreeData.h>
+#include <Storages/MergeTree/MergeTreeDataMergerMutator.h>
+#include <Storages/MergeTree/MergeTreeInOrderSelectProcessor.h>
+#include <Storages/MergeTree/MergeTreeSequentialSource.h>
 #include <VectorIndex/MergeUtils.h>
-#include <IO/WriteIntText.h>
 
 namespace DB
 {
@@ -285,7 +285,7 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::prepare()
         global_ctx->inverted_row_ids_map_buf = std::make_unique<CompressedWriteBuffer>(*global_ctx->inverted_row_ids_map_uncompressed_buf);
 
         /// create row ids map for each old part
-        for (int i = 0; i < global_ctx->future_part->parts.size(); ++i)
+        for (size_t i = 0; i < global_ctx->future_part->parts.size(); ++i)
         {
             auto row_ids_map_file = createTemporaryFile(ctx->tmp_disk->getPath());
             auto row_ids_map_uncompressed_buf = ctx->tmp_disk->writeFile(fileName(row_ids_map_file->path()));
@@ -509,7 +509,7 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
     }
 
     /// write row_ids_map_bufs
-    for (int source_num = 0; source_num < old_parts_num; source_num++)
+    for (size_t source_num = 0; source_num < old_parts_num; source_num++)
     {
         UInt64 old_row_id = 0;
         while (old_row_id < global_ctx->future_part->parts[source_num]->rows_count)
@@ -534,7 +534,7 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
         ctx->rows_sources_uncompressed_write_buf.reset();
     }
 
-    for (int i = 0; i < global_ctx->future_part->parts.size(); ++i)
+    for (size_t i = 0; i < global_ctx->future_part->parts.size(); ++i)
     {
         global_ctx->row_ids_map_bufs[i]->next();
         global_ctx->row_ids_map_uncompressed_bufs[i]->next();
@@ -827,7 +827,7 @@ bool MergeTask::MergeProjectionsStage::finalizeProjectionsAndWholeMerge() const
     /// finalize row ids map info to new data part dir
     if (!global_ctx->row_ids_map_files.empty())
     {
-        for (int i = 0; i < global_ctx->future_part->parts.size(); ++i)
+        for (size_t i = 0; i < global_ctx->future_part->parts.size(); ++i)
         {
             auto& row_ids_map_tmp_file = global_ctx->row_ids_map_files[i]->path();
             /// move and rename row ids map file to new dir
diff --git a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp
index 22cb0e98e1..406d410eb1 100644
--- a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp
+++ b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp
@@ -23,9 +23,8 @@
 #include <Processors/Transforms/AggregatingTransform.h>
 #include <base/logger_useful.h>
 
-#include <VectorIndex/VectorSegmentExecutor.h>
-#include <VectorIndex/VectorIndexFactory.h>
 #include <VectorIndex/Status.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
 
 #include <city.h>
 
@@ -740,15 +739,15 @@ bool MergeTreeBaseSelectProcessor::readPrimaryKeyBin(Columns & out_columns)
         buffered_columns[i] = primary_key.data_types[i]->createColumn();
     }
 
-    MergeTreeReaderPtr reader = task->data_part->getReader(
-            cols,
-            storage_snapshot->metadata,
-            MarkRanges{MarkRange(0, task->data_part->getMarksCount())},
-            nullptr,
-            storage.getContext()->getMarkCache().get(),
-            reader_settings);
+    MergeTreeReaderPtr pk_reader = task->data_part->getReader(
+        cols,
+        storage_snapshot->metadata,
+        MarkRanges{MarkRange(0, task->data_part->getMarksCount())},
+        nullptr,
+        storage.getContext()->getMarkCache().get(),
+        reader_settings);
 
-    if (!reader)
+    if (!pk_reader)
     {
         LOG_ERROR(log, "Failed to get reader");
         return false;
@@ -774,7 +773,7 @@ bool MergeTreeBaseSelectProcessor::readPrimaryKeyBin(Columns & out_columns)
         Columns result;
         result.resize(cols_size);
 
-        size_t num_rows = reader->readRows(current_mark, 0, continue_read, remaining_size, result);
+        size_t num_rows = pk_reader->readRows(current_mark, 0, continue_read, remaining_size, result);
 
         continue_read = true;
         num_rows_read += num_rows;
diff --git a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h
index f5863e862f..1300faf393 100644
--- a/src/Storages/MergeTree/MergeTreeBlockReadUtils.h
+++ b/src/Storages/MergeTree/MergeTreeBlockReadUtils.h
@@ -6,11 +6,11 @@
 
 #include <optional>
 #include <Core/NamesAndTypes.h>
-#include <Storages/MergeTree/RangesInDataPart.h>
 #include <Storages/MergeTree/MergeTreeRangeReader.h>
-#include <Common/VectorScanUtils.h>
-
+#include <Storages/MergeTree/MergeTreeVectorScanManager.h>
+#include <Storages/MergeTree/RangesInDataPart.h>
 #include <Storages/MergeTree/VectorScanResult.h>
+#include <Common/VectorScanUtils.h>
 
 namespace DB
 {
diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp
index 84251b7f56..d04e98f47c 100644
--- a/src/Storages/MergeTree/MergeTreeData.cpp
+++ b/src/Storages/MergeTree/MergeTreeData.cpp
@@ -90,10 +90,10 @@
 #include <unordered_set>
 #include <filesystem>
 
-#include <VectorIndex/VectorSegmentExecutor.h>
-#include <VectorIndex/VectorIndexCommon.h>
 #include <VectorIndex/DiskIOReader.h>
 #include <VectorIndex/MergeUtils.h>
+#include <VectorIndex/VectorIndexCommon.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
 
 namespace fs = std::filesystem;
 
@@ -1824,7 +1824,7 @@ void MergeTreeData::clearPrimaryKeyCache(const DataPartsVector & parts)
     }
 }
 
-void MergeTreeData::regularClearCachedIndex(const DataPartsVector & parts)
+void MergeTreeData::regularClearCachedIndex(const DataPartsVector & /* parts */)
 {
 //    StorageMetadataPtr meta_snapshot = getInMemoryMetadataPtr();
 //    for (const auto & part : parts)
diff --git a/src/Storages/MergeTree/MergeTreeSettings.h b/src/Storages/MergeTree/MergeTreeSettings.h
index f9c5ce3c84..8ca6243d77 100644
--- a/src/Storages/MergeTree/MergeTreeSettings.h
+++ b/src/Storages/MergeTree/MergeTreeSettings.h
@@ -144,11 +144,13 @@ struct Settings;
     /** Vector Search */ \
     M(Bool, enable_primary_key_cache, false, "Enable primary key cache when do vector search.", 0) \
     M(Bool, enable_decouple_vector_index_rebuild_from_merge, true, "Enable use old vector indices during merge.", 0) \
-    M(Bool, distable_rebuild_for_decouple, false, "(Test only) Disable rebuild of new vector indices for decouple.", 0) \
+    M(Bool, disable_rebuild_for_decouple, false, "(Test only) Disable rebuild of new vector indices for decouple.", 0) \
     M(UInt64, min_rows_to_build_vector_index, 0, "The minimum row size of data part to build vector index", 0) \
-    M(String, vector_search_metric_type, "L2", "default metric type for brute force search", 0) \
+    M(UInt64, min_bytes_to_build_vector_index, 0, "The minimum byte size of data part to build vector index", 0) \
+    M(String, vector_search_metric_type, "L2", "Default metric type for brute force search", 0) \
     M(UInt64, max_rows_for_slow_mode_single_vector_index_build, 100000, "The max row number of data part to build vector index using slow mode", 0) \
     M(Bool, enforce_fixed_vector_length_constraint, true, "Stricter length constraint check on columns with vector index.", 0) \
+    M(Bool, default_mstg_disk_mode, false, "Default disk mode value for MSTG.", 0) \
     \
     /** Obsolete settings. Kept for backward compatibility only. */ \
     M(UInt64, min_relative_delay_to_yield_leadership, 120, "Obsolete setting, does nothing.", 0) \
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
index 4955b31a39..151458c459 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
@@ -1,15 +1,16 @@
+#include <Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h>
+
 #include <DataTypes/DataTypeArray.h>
 #include <Storages/MergeTree/MergeTreeData.h>
-#include <Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h>
 #include <VectorIndex/DiskIOReader.h>
-#include <VectorIndex/VectorSegmentExecutor.h>
+#include <VectorIndex/PartReader.h>
 #include <VectorIndex/VectorIndexCommon.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
 #include <Common/ProfileEvents.h>
 #include <Common/Stopwatch.h>
+#include <Common/ActionBlocker.h>
 #include <Common/StringUtils/StringUtils.h>
 
-/// #define build_fail_test
-
 namespace ProfileEvents
 {
 extern const Event VectorIndexBuildFailEvents;
@@ -70,7 +71,7 @@ void MergeTreeVectorIndexBuilderUpdater::removeDroppedVectorIndices(const Storag
     last_cache_check_time = now;
 
     ///check existing parts to see if any cached vector index need cleaning
-    std::list<std::pair<VectorIndex::CacheKey, VectorIndex::Parameters>> cached_item_list
+    std::list<std::pair<VectorIndex::CacheKey, Search::Parameters>> cached_item_list
         = VectorIndex::VectorSegmentExecutor::getAllCacheNames();
 
     /// getRelativeDataPath() contains '/' in the tail, but table_path in cache key doesn't have.
@@ -101,22 +102,12 @@ void MergeTreeVectorIndexBuilderUpdater::removeDroppedVectorIndices(const Storag
                 (part && (part->containVectorIndex(cache_item.first.vector_index_name, cache_item.first.column_name) || part->containRowIdsMaps())))
             {
                 LOG_DEBUG(log, "Find Vector Index in metadata");
-                VectorIndex::Parameters params = cache_item.second;
-                VectorIndex::IndexType t = VectorIndex::VectorIndexFactory::createIndexType(params.find("type")->second);
-                params.erase("type");
+                Search::Parameters params = cache_item.second;
 
                 LOG_DEBUG(log, "Params: {}, desc params: {}", VectorIndex::ParametersToString(params),
                     VectorIndex::ParametersToString(VectorIndex::convertPocoJsonToMap(vec_index_desc.parameters)));
-                
-                if (VectorIndex::VectorSegmentExecutor::compareVectorIndexParameters(
-                        t,
-                        params,
-                        VectorIndex::VectorIndexFactory::createIndexType(vec_index_desc.type),
-                        VectorIndex::convertPocoJsonToMap(vec_index_desc.parameters)))
-                {
-                    LOG_DEBUG(log, "Vector Index parameters match!");
-                    existed = true;
-                }
+
+                existed = true;
             }
         }
 
@@ -199,7 +190,7 @@ VectorIndexEntryPtr MergeTreeVectorIndexBuilderUpdater::selectPartToBuildVectorI
         if (is_replicated && data.partIsAssignedToBackgroundOperation(part))
             continue;
 
-        if (part->containRowIdsMaps() && data.getSettings()->distable_rebuild_for_decouple)
+        if (part->containRowIdsMaps() && data.getSettings()->disable_rebuild_for_decouple)
             continue;
 
         /// Since building vector index doesn't block mutation on the part, the new part need to check if any covered part is building vindex.
@@ -252,8 +243,8 @@ VectorIndexEntryPtr MergeTreeVectorIndexBuilderUpdater::selectPartToBuildVectorI
     return {};
 }
 
-BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(
-    const StorageMetadataPtr & metadata_snapshot, const String & part_name, bool tune, bool slow_mode)
+BuildVectorIndexStatus
+MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(const StorageMetadataPtr & metadata_snapshot, const String & part_name, bool slow_mode)
 {
     if (part_name.empty())
     {
@@ -277,20 +268,20 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(
         MergeTreeDataPartPtr part = data.getActiveContainingPart(part_name);
         if (!part)
         {
-            LOG_INFO(log, "[buildVectorIndex] part:{} is not active, no need to build index", part_name);
+            LOG_INFO(log, "Part {} is not active, no need to build index", part_name);
             return BuildVectorIndexStatus::SUCCESS;
         }
 
         if (part->vector_index_build_cancelled)
         {
-            LOG_INFO(log, "Part: {}, build index job has been cancelled", part->name);
+            LOG_INFO(log, "The index build job for Part {} has been cancelled", part_name);
             return BuildVectorIndexStatus::BUILD_FAIL;
         }
 
         /// Check latest metadata
         if (part->storage.getInMemoryMetadataPtr()->vec_indices.empty())
         {
-            LOG_INFO(log, "Vector index has been dropped, no need to build it");
+            LOG_INFO(log, "Skip build for cancelled vector index {}.", metadata_snapshot->vec_indices[0].name);
             return BuildVectorIndexStatus::SUCCESS;
         }
 
@@ -311,7 +302,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(
             if (BuildIndexHelpers::checkOperationIsNotCanceled(builds_blocker))
             {
                 LOG_INFO(log, "Build vector index for one part {}", part->name);
-                status = buildVectorIndexForOnePart(metadata_snapshot, part, tune, slow_mode);
+                status = buildVectorIndexForOnePart(metadata_snapshot, part, slow_mode);
             }
         }
         catch (Exception & e)
@@ -363,16 +354,12 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndex(
     watch.stop();
     LOG_INFO(log, "Vector index build task for {} finished in {} sec, slow_mode: {}", part_name, watch.elapsedSeconds(), slow_mode);
 
-#ifdef build_fail_test
-    LOG_INFO(log, "Vector index build task increment VectorIndexBuildFailEvents.");
-    ProfileEvents::increment(ProfileEvents::VectorIndexBuildFailEvents);
-#endif
     // TODO: handle fail case
     return BuildVectorIndexStatus::SUCCESS;
 }
 
 BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOnePart(
-    const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part, bool tune, bool slow_mode)
+    const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part, bool slow_mode)
 {
     LOG_TRACE(log, "Start checking for build index for part {}", part->name);
 
@@ -384,7 +371,7 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
         NamesAndTypesList cols;
 
         /// only one column to build vector index, using a large dimension as default value.
-        int dim = 960;
+        int dim = 0;
 
         /// read all the columns which are marked as having vector index from the part
         /// there should only be one column here
@@ -440,6 +427,8 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
         String vector_tmp_relative_path = data.getRelativeDataPath() + "vector_tmp_" + part_name_prefix + "/";
         String vector_tmp_full_path = data.getFullPathOnDisk(disk) + "vector_tmp_" + part_name_prefix + "/";
 
+        String vector_index_cache_prefix = fs::path(data.getContext()->getVectorIndexCachePath()) / data.getRelativeDataPath() / part_name_prefix / "";
+
         /// Since the vector index is stored in a temporary directory, add check for it too.
         if (disk->exists(part->getFullRelativePath() + vector_index_ready_file_name))
             read_file_path = part->getFullPath() + vector_index_ready_file_name;
@@ -461,326 +450,88 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
             }
         }
 
-        VectorIndex::Parameters parameters = VectorIndex::convertPocoJsonToMap(vec_index_desc.parameters);
-        std::unordered_map<std::string, VectorIndex::Parameters> params_from_record;
-        VectorIndex::DiskIOReader disk_reader;
-        std::vector<String> index_names;
-        std::string index_name = vec_index_desc.name + "_" + vec_index_desc.column;
-        index_names.emplace_back(index_name);
+        Search::Parameters parameters = VectorIndex::convertPocoJsonToMap(vec_index_desc.parameters);
 
         if (!read_file_path.empty())
         {
-            std::unordered_map<String, int64_t> original_binary_sizes
-                    = readVectorIndexReadyFile(disk_reader, read_file_path, index_names, params_from_record);
-
-            if (!original_binary_sizes.empty())
-            {
-                VectorIndex::Parameters & single_params_from_record = params_from_record.find(index_name)->second;
-                if (!single_params_from_record.empty() && original_binary_sizes.find(index_name)->second != -1)
-                {
-                    VectorIndex::IndexType t = VectorIndex::VectorIndexFactory::createIndexType(single_params_from_record.find("type")->second);
-                    single_params_from_record.erase("type");
-                    if (VectorIndex::VectorSegmentExecutor::compareVectorIndexParameters(
-                            t, single_params_from_record, VectorIndex::VectorIndexFactory::createIndexType(vec_index_desc.type), parameters))
-                    {
-                        if (from_part)
-                        {
-                            LOG_DEBUG(log, "Vector index is built for part: {}", part->name);
-                            part->addVectorIndex(vec_index_desc.name + "_" + vec_index_desc.column);
-                        }
-                        else /// Need to move built vector index files to the part.
-                        {
-                            LOG_DEBUG(log, "Vector index is built for part: {} and stored in temporary directory {}", part->name, vector_tmp_full_path);
-                            MergeTreeDataPartPtr future_part = nullptr;
-                            if (part->getState() == IMergeTreeDataPart::State::Active)
-                                future_part = part;
-                            else
-                            {
-                                /// Find future active part
-                                future_part = data.getActiveContainingPart(part->name);
-                                if (!future_part)
-                                {
-                                    LOG_WARNING(log, "Failed to find future part for part {}, leave the temporary directory", part->name);
-                                    return BuildVectorIndexStatus::SUCCESS;
-                                }
-                            }
-
-                            if (future_part && !future_part->getPartIsMutating())
-                            {
-                                moveVectorIndexFilesToFuturePart(metadata_snapshot, vector_tmp_relative_path, future_part);
-
-                                if (future_part->containRowIdsMaps())
-                                {
-                                    auto lock = data.lockParts();
-                                    VectorIndex::removeRowIdsMaps(future_part, log);
-                                }
-                            }
-                            /// else future part will pick up later at the next time when index built for it.
-                        }
-
-                        return BuildVectorIndexStatus::SUCCESS;
-                    }
-                }
-            }
-        }
-
-        MergeTreeReaderSettings reader_settings;
-        auto reader = part->getReader(
-            cols,
-            metadata_snapshot,
-            MarkRanges{MarkRange(0, part->getMarksCount())},
-            /* uncompressed_cache = */ nullptr,
-            data.getContext()->getMarkCache().get(),
-            reader_settings);
-
-        size_t num_rows_read = 0;
-        /// max read block rows for each round
-        /// size_t read_block_rows_num = std::max(max_build_index_block_size_rows, static_cast<size_t>(part->rows_count * incremental_ratio));
-
-        /// try to control memory usage only use max_build_index_add_block_size and min_build_index_train_block_size
-        size_t max_build_index_add_block_size = data.getContext()->getSettingsRef().max_build_index_add_block_size;
-        size_t min_build_index_train_block_size = data.getContext()->getSettingsRef().min_build_index_train_block_size;
-        if (min_build_index_train_block_size < max_build_index_add_block_size)
-        {
-            LOG_DEBUG(log, "min_build_index_train_block_size {} is smaller than max_build_index_add_block_size {}, will be updated",
-                          min_build_index_train_block_size, max_build_index_add_block_size);
-            min_build_index_train_block_size = max_build_index_add_block_size;
-        }
-
-        /// never divide a zero
-        size_t read_block_rows_num = max_build_index_add_block_size / 4 / std::max(1, dim);
-        size_t train_block_rows_num = min_build_index_train_block_size / 4 / std::max(1, dim);
-        LOG_DEBUG(log, "Set read_block_rows_num to {}, train_block_rows_num to {}", read_block_rows_num, train_block_rows_num);
-
-        bool continue_read = false;
-        bool training = true;
-
-        VectorIndex::VectorDatasetPtr vec_data;
-        VectorIndex::VectorSegmentExecutorPtr vec_index_builder;
-        std::vector<int64_t> empty_ids;
-        size_t current_round_start_row = 0;
-
-        size_t current_mask = 0;
-        size_t total_mask = part->getMarksCount();
-
-        auto & index_granularity = part->index_granularity;
-
-        size_t num_rows_train = 0;
-        int32_t dataset_offsets_size_train = 0;
-        std::vector<float> vector_raw_data_train;
-
-        /// process data block by block
-        while (BuildIndexHelpers::checkOperationIsNotCanceled(builds_blocker) && num_rows_read < part->rows_count)
-        {
-            if (part->vector_index_build_cancelled)
-            {
-                throw Exception(ErrorCodes::LOGICAL_ERROR, "Vector index build is cancelled for part {}", part->name);
-            }
-
-            auto & latest_vec_indices = part->storage.getInMemoryMetadataPtr()->vec_indices;
-            if (latest_vec_indices.empty() || !latest_vec_indices.has(vec_index_desc))
-            {
-                LOG_INFO(log, "Vector index has been dropped, no need to build it.");
-                disk->removeRecursive(vector_tmp_relative_path);
-                return BuildVectorIndexStatus::SUCCESS;
-            }
-
-            /// traning size is bigger than add vector size, may call several times before training.
-            if (!training)
-                empty_ids.clear();
-
-            size_t remaining_size = part->rows_count - num_rows_read;
-            size_t max_read_row = std::min(remaining_size, read_block_rows_num);
-
-            Columns result(cols.size());
-            size_t num_rows = reader->readRows(current_mask, 0, continue_read, max_read_row, result);
-
-            continue_read = true;
-
-            num_rows_read += num_rows;
-
-            for (size_t mask = current_mask; mask < total_mask - 1; ++mask)
-            {
-                if (index_granularity.getMarkStartingRow(mask) >= num_rows_read
-                    && index_granularity.getMarkStartingRow(mask + 1) < num_rows_read)
-                {
-                    current_mask = mask;
-                }
-            }
-
-            LOG_DEBUG(log, "Part: {}, read num_rows: {}, col size: {}", part->name, num_rows, cols.size());
-
-            if (num_rows == 0)
-            {
-                LOG_WARNING(log, "Part: {}, no data read for column {}", part->name, cols.back().name);
-                part->addVectorIndex(vec_index_desc.name + "_" + vec_index_desc.column);
-                break;
-            }
-
-            const auto & one_column = result.back();
-            const ColumnArray * array = checkAndGetColumn<ColumnArray>(one_column.get());
-            if (!array)
+            if (from_part)
             {
-                throw Exception(ErrorCodes::LOGICAL_ERROR, "Vector column type is not Array in part {}", part->name);
-            }
-
-            const IColumn & src_data = array->getData();
-            const ColumnArray::Offsets & offsets = array->getOffsets();
-            const ColumnFloat32 * src_data_concrete = checkAndGetColumn<ColumnFloat32>(&src_data);
-            if (!src_data_concrete)
-            {
-                throw Exception(ErrorCodes::LOGICAL_ERROR, "Vector column inner type in Array is not Float32 in part {}", part->name);
-            }
-
-            const PaddedPODArray<Float32> & src_vec = src_data_concrete->getData();
-            if (enforce_fixed_array && src_vec.size() != dim * offsets.size())
-            {
-                throw Exception(
-                    ErrorCodes::INCORRECT_DATA,
-                    "Part: {}, vector column data length does not meet constraint",
-                    part->name);
-            }
-            if (src_vec.empty())
-            {
-                LOG_WARNING(log, "Part:{}, no data read for column {}", part->name, cols.back().name);
+                LOG_DEBUG(log, "Vector index is built for part: {}", part->name);
                 part->addVectorIndex(vec_index_desc.name + "_" + vec_index_desc.column);
-                return BuildVectorIndexStatus::SUCCESS;
             }
-
-            size_t i = 0;
-
-            /// skip empty arrays, to compute dimension of vector data
-            /// offsets.size(): vector data number
-            while (i < offsets.size() && offsets[i] == 0)
-            {
-                ++i;
-            }
-
-            /// the real dimension created from data
-            int32_t dim = static_cast<int32_t>(offsets[i]);
-
-            std::vector<float> vector_raw_data(dim * offsets.size(), 0.0);
-            current_round_start_row = num_rows_read - num_rows;
-
-            for (size_t row = 0; row < offsets.size(); ++row)
+            else /// Need to move built vector index files to the part.
             {
-                size_t vec_start_offset = row != 0 ? offsets[row - 1] : 0;
-                size_t vec_end_offset = offsets[row];
-                if (enforce_fixed_array && vec_end_offset - vec_start_offset != dim)
-                    throw Exception(
-                        ErrorCodes::INCORRECT_DATA,
-                        "Part: {}, vector column data length does not meet constraint",
-                        part->name);
-                if (vec_start_offset != vec_end_offset)
+                LOG_DEBUG(log, "Vector index is built for part: {} and stored in temporary directory {}", part->name, vector_tmp_full_path);
+                MergeTreeDataPartPtr future_part = nullptr;
+                if (part->getState() == IMergeTreeDataPart::State::Active)
+                    future_part = part;
+                else
                 {
-                    for (size_t offset = vec_start_offset; offset < vec_end_offset && offset < vec_start_offset + dim; ++offset)
+                    /// Find future active part
+                    future_part = data.getActiveContainingPart(part->name);
+                    if (!future_part)
                     {
-                        vector_raw_data[row * dim + offset - vec_start_offset] = src_vec[offset];
+                        LOG_WARNING(log, "Failed to find future part for part {}, leave the temporary directory", part->name);
+                        return BuildVectorIndexStatus::SUCCESS;
                     }
                 }
-                else
-                {
-                    /// add this read round empty ids
-                    empty_ids.emplace_back(current_round_start_row + row);
-                }
-            }
-
-            LOG_DEBUG(
-                log,
-                "Part:{}, raw_data size: {}, empty_ids size: {}",
-                part->name,
-                vector_raw_data.size(),
-                empty_ids.size());
-
-            /// Checks for read rows >= minimum rows for training
-            if (training)
-            {
-                num_rows_train += num_rows;
-                dataset_offsets_size_train += offsets.size();
-                vector_raw_data_train.insert(vector_raw_data_train.end(), vector_raw_data.begin(), vector_raw_data.end());
-
-                if (num_rows_train < train_block_rows_num && part->rows_count - num_rows_read > 0)
-                    continue;
-                else
-                {
-                    vec_data = std::make_shared<VectorIndex::VectorDataset>(
-                        static_cast<int32_t>(dataset_offsets_size_train), static_cast<int32_t>(dim), std::move(vector_raw_data_train));
-                }
-            }
-            else /// Normal add vectors after training
-            {
-                vec_data = std::make_shared<VectorIndex::VectorDataset>(
-                    static_cast<int32_t>(offsets.size()), static_cast<int32_t>(dim), std::move(vector_raw_data));
-            }
-
-            /// only run in the first read round
-            if (training)
-            {
-                LOG_DEBUG(
-                    log,
-                    "Train vector index: part_name: {}, num_rows_train: {}, vector index name: {}, path: {}",
-                    part->name,
-                    num_rows_train,
-                    vec_index_desc.name,
-                    vector_tmp_relative_path + index_name);
 
-                /// Create temp directory before serialize.
-                if (disk->exists(vector_tmp_relative_path))
+                if (future_part && !future_part->getPartIsMutating())
                 {
-                    LOG_DEBUG(log, "The temporary directory to store vector index files already exists, will be removed {}", vector_tmp_relative_path);
-                    disk->removeRecursive(vector_tmp_relative_path);
-                }
+                    moveVectorIndexFilesToFuturePart(metadata_snapshot, vector_tmp_relative_path, future_part);
 
-                disk->createDirectories(vector_tmp_relative_path);
-
-                VectorIndex::SegmentId segment_id(vector_tmp_full_path, part->name, part->name, vec_index_desc.name, vec_index_desc.column, 0);
-
-                vec_index_builder = std::make_shared<VectorIndex::VectorSegmentExecutor>(
-                    VectorIndex::VectorIndexFactory::createIndexType(vec_index_desc.type),
-                    segment_id,
-                    parameters,
-                    dim);
-                VectorIndex::Status build_status = vec_index_builder->buildIndex(vec_data, part->rows_count, slow_mode);
-
-                if (!build_status.fine())
-                {
-                    LOG_ERROR(log, "Failed to build vector index for part {}", part->name);
-                    disk->removeRecursive(vector_tmp_relative_path);
-                    throw Exception(build_status.getCode(), build_status.getMessage());
+                    if (future_part->containRowIdsMaps())
+                    {
+                        auto lock = data.lockParts();
+                        VectorIndex::removeRowIdsMaps(future_part, log);
+                    }
                 }
-                training = false;
+                /// else future part will pick up later at the next time when index built for it.
             }
 
-            LOG_DEBUG(log, "Add vectors to index: read vector num: {}", vec_data->getVectorNum());
-            vec_index_builder->addVectors(vec_data);
-
-            if (!empty_ids.empty())
-                vec_index_builder->removeByIds(empty_ids.size(), empty_ids.data());
-
-            LOG_DEBUG(log, "After adding vectors: read vector num: {}", vec_data->getVectorNum());
+            return BuildVectorIndexStatus::SUCCESS;
         }
 
-        if (num_rows_read == 0 && part->rows_count == 0)
-        {
-            LOG_WARNING(log, "Part {} is empty", part->name);
-            continue;
-        }
-        else if (num_rows_read < part->rows_count)
+        /// Create temp directory before serialize.
+        if (disk->exists(vector_tmp_relative_path))
         {
-            LOG_ERROR(log, "Failed to build vector index for part {}", part->name);
+            LOG_DEBUG(
+                log, "The temporary directory to store vector index files already exists, will be removed {}", vector_tmp_relative_path);
             disk->removeRecursive(vector_tmp_relative_path);
-            return BuildVectorIndexStatus::BUILD_FAIL;
         }
 
+        disk->createDirectories(vector_tmp_relative_path);
+
+        VectorIndex::SegmentId segment_id(
+            part->volume,
+            vector_tmp_full_path,
+            part->name,
+            vec_index_desc.name,
+            vec_index_desc.column,
+            vector_index_cache_prefix);
+        VectorIndex::PartReader part_reader(
+            builds_blocker, part, cols, metadata_snapshot, data.getContext()->getMarkCache().get(), dim, enforce_fixed_array);
+        Search::IndexType index_type = VectorIndex::getIndexType(vec_index_desc.type);
+        Search::Metric metric = VectorIndex::getMetric(parameters.extractParam("metric_type", std::string("L2")));
+        VectorIndex::VectorSegmentExecutorPtr vec_index_builder = std::make_shared<VectorIndex::VectorSegmentExecutor>(
+            segment_id,
+            index_type,
+            metric,
+            dim,
+            part->rows_count,
+            parameters,
+            data.getSettings()->min_bytes_to_build_vector_index,
+            data.getSettings()->default_mstg_disk_mode);
+        size_t max_build_index_add_block_size = data.getContext()->getSettingsRef().max_build_index_add_block_size;
+        size_t max_build_index_train_block_size = data.getContext()->getSettingsRef().max_build_index_train_block_size;
+        vec_index_builder->buildIndex(&part_reader, slow_mode, max_build_index_train_block_size, max_build_index_add_block_size);
+
+        const auto empty_ids = part_reader.emptyIds();
+        if (!empty_ids.empty())
+            vec_index_builder->removeByIds(empty_ids.size(), empty_ids.data());
+
         if (!part->vector_index_build_cancelled && BuildIndexHelpers::checkOperationIsNotCanceled(builds_blocker))
         {
-            if (tune)
-            {
-                vec_index_builder->dispathAutoTuneTask(vec_data);
-            }
-            /// zili's profiler tuning logic
-            vec_index_builder->tune(vec_data, empty_ids, current_round_start_row);
-
             /// remove empty vectors
             LOG_DEBUG(log, "Serialize vector index");
             VectorIndex::Status seri_status = vec_index_builder->serialize();
@@ -827,8 +578,14 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
 
                 /// Second, update delete bitmap in memory in currently builder, which will be put in cache.
                 /// Update segment id with correct part name and path.
-                VectorIndex::SegmentId segment_id(future_part->getFullPath(), future_part->name, future_part->name, vec_index_desc.name, vec_index_desc.column, 0);
-                vec_index_builder->updateSegmentId(segment_id);
+                VectorIndex::SegmentId future_segment(
+                    future_part->volume,
+                    future_part->getFullPath(),
+                    future_part->name,
+                    vec_index_desc.name,
+                    vec_index_desc.column,
+                    vector_index_cache_prefix);
+                vec_index_builder->updateSegmentId(future_segment);
 
                 /// Need to reload delete bitmap from disk. The delete_bitmap in vec_index_builder doesn't contain rows deleted by lightweight.
                 if (future_part->hasLightweightDelete())
@@ -859,7 +616,7 @@ void MergeTreeVectorIndexBuilderUpdater::undoBuildVectorIndexForOnePart(
     {
         String index_name = vec_index_desc.name + "_" + vec_index_desc.column;
         part->removeVectorIndex(vec_index_desc.name, vec_index_desc.column, true);
-        VectorIndex::SegmentId segment_id(part->getFullPath(), part->name, vec_index_desc.name, vec_index_desc.column, 0);
+        VectorIndex::SegmentId segment_id(part->volume, part->getFullPath(), part->name, vec_index_desc.name, vec_index_desc.column, "");
         VectorIndex::VectorSegmentExecutor::removeFromCache(segment_id.getCacheKey());
     }
     auto disk = part->volume->getDisk();
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h
index 880cd5402b..9721416b0f 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h
@@ -17,10 +17,9 @@
 #include <Storages/MergeTree/VectorIndexEntry.h>
 #include <Storages/VectorIndexCommands.h>
 #include <VectorIndex/Dataset.h>
-#include <VectorIndex/VectorSegmentExecutor.h>
-#include <VectorIndex/Status.h>
-#include <VectorIndex/VectorIndexFactory.h>
 #include <VectorIndex/MergeUtils.h>
+#include <VectorIndex/Status.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
 #include <base/logger_useful.h>
 #include <Common/ActionBlocker.h>
 
@@ -54,8 +53,7 @@ public:
     void removeDroppedVectorIndices(const StorageMetadataPtr & metadata_snapshot);
 
     /// handle build index task
-    BuildVectorIndexStatus
-    buildVectorIndex(const StorageMetadataPtr & metadata_snapshot, const String & part_name, bool tune, bool slow_mode);
+    BuildVectorIndexStatus buildVectorIndex(const StorageMetadataPtr & metadata_snapshot, const String & part_name, bool slow_mode);
 
     /** Is used to cancel all index builds. On cancel() call all currently running actions will throw exception soon.
       * All new attempts to start a vector index build will throw an exception until all 'LockHolder' objects will be destroyed.
@@ -86,7 +84,7 @@ private:
     time_t last_cache_check_time = 0;
 
     BuildVectorIndexStatus
-    buildVectorIndexForOnePart(const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part, bool tune, bool slow_mode);
+    buildVectorIndexForOnePart(const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part, bool slow_mode);
 
     /// Move build vector index files from temporary directory to data part directory, and apply lightweight delete if needed.
     bool moveVectorIndexFilesToFuturePart(const StorageMetadataPtr & metadata_snapshot, const  String & vector_tmp_relative_path, const MergeTreeDataPartPtr & dest_part);
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index 25aef5786a..305747fb35 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -14,12 +14,10 @@
 
 #include <Storages/MergeTree/IMergeTreeReader.h>
 #include <VectorIndex/BruteForceSearch.h>
-#include <VectorIndex/VectorSegmentExecutor.h>
+#include <VectorIndex/MergeUtils.h>
 #include <VectorIndex/Status.h>
-#include <VectorIndex/VectorIndexFactory.h>
 #include <VectorIndex/VectorIndexCommon.h>
-#include <VectorIndex/MergeUtils.h>
-#include <VectorIndex/VectorIndex.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
 
 #include <memory>
 
@@ -34,7 +32,7 @@ namespace ErrorCodes
 }
 
 template <typename FloatType>
-std::vector<float> getQueryVector(const IColumn * query_vector_column, int dim, bool is_batch)
+std::vector<float> getQueryVector(const IColumn * query_vector_column, size_t dim, bool is_batch)
 {
     const auto * query_data_concrete = checkAndGetColumn<ColumnVector<FloatType>>(query_vector_column);
 
@@ -67,7 +65,7 @@ std::vector<float> getQueryVector(const IColumn * query_vector_column, int dim,
     return query_new_data;
 }
 
-std::vector<float> getQueryVectorInBatch(const IColumn * query_vectors_column, const int dim, int & query_vector_num)
+std::vector<float> getQueryVectorInBatch(const IColumn * query_vectors_column, const size_t dim, int & query_vector_num)
 {
     const ColumnArray * query_vectors_col = checkAndGetColumn<ColumnArray>(query_vectors_column);
 
@@ -119,7 +117,7 @@ void MergeTreeVectorScanManager::eraseResult()
 VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(bool is_batch, const VectorScanDescription& desc)
 {
     auto & query_column = desc.query_column;
-    int dim = desc.search_column_dim;
+    auto dim = desc.search_column_dim;
 
     if (!query_column)
         throw Exception("Wrong query column type", ErrorCodes::LOGICAL_ERROR); 
@@ -138,11 +136,8 @@ VectorIndex::VectorDatasetPtr MergeTreeVectorScanManager::generateVectorDataset(
         std::vector<float> query_new_data = getQueryVectorInBatch(&query_data, dim, query_vector_num);
 
         // default value
-        VectorIndex::Parameters vec_parameters = VectorIndex::convertPocoJsonToMap(desc.vector_parameters);
-        int k = 50;
-        if (desc.topk > 0)
-            k = desc.topk;
-
+        Search::Parameters search_params = VectorIndex::convertPocoJsonToMap(desc.vector_parameters);
+        int k = desc.topk > 0 ? desc.topk : VectorIndex::DEFAULT_TOPK;
         LOG_DEBUG(log, "Set k to {}, dim to {}", k, dim);
 
         return std::make_shared<VectorIndex::VectorDataset>(
@@ -243,15 +238,15 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
     auto vec_data = generateVectorDataset(is_batch, desc);
 
     UInt64 dim = desc.search_column_dim;
-    VectorIndex::Parameters vec_parameters = VectorIndex::convertPocoJsonToMap(desc.vector_parameters);
+    Search::Parameters search_params = VectorIndex::convertPocoJsonToMap(desc.vector_parameters);
+    LOG_DEBUG(log, "Search parameters: {}", search_params.toString());
 
-    int k = 50;
-    if (desc.topk > 0)
-        k = desc.topk;
+    int k = desc.topk > 0 ? desc.topk : VectorIndex::DEFAULT_TOPK;
+    search_params.erase("metric_type");
 
     LOG_DEBUG(log, "Set k to {}, dim to {}", k, dim);
 
-    String metrics_str = data_part->storage.getSettings()->vector_search_metric_type;
+    String metric_str = data_part->storage.getSettings()->vector_search_metric_type;
 
     std::vector<VectorIndex::SegmentId> segment_ids;
     for (auto & v_index : vector_indices)
@@ -260,7 +255,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         {
             if (v_index.parameters && v_index.parameters->has("metric_type"))
             {
-                metrics_str = v_index.parameters->getValue<String>("metric_type");
+                metric_str = v_index.parameters->getValue<String>("metric_type");
             }
             
             if (data_part->containVectorIndex(v_index.name, v_index.column))
@@ -277,7 +272,9 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
                 }
                 else
                 {
-                    VectorIndex::SegmentId segment_id(data_path, data_part->name, data_part->name, index.name, index.column, 0);
+                    String vector_index_cache_prefix
+                        = fs::path(data_part->storage.getContext()->getVectorIndexCachePath()) / data_part->storage.getRelativeDataPath() / data_part->info.getPartNameWithoutMutation() / "";
+                    VectorIndex::SegmentId segment_id(data_part->volume, data_path, data_part->name, index.name, index.column, vector_index_cache_prefix);
                     segment_ids.emplace_back(std::move(segment_id));
 
                     LOG_DEBUG(log, "Index found, because current data part contains it");
@@ -301,18 +298,21 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         }
     }
 
-    VectorIndex::Metrics metrics = VectorIndex::VectorIndexFactory::createIndexMetrics(metrics_str);
+    Search::Metric metric = VectorIndex::getMetric(metric_str);
 
     if (find_index)
     {
         LOG_DEBUG(log, "Find index, segment_ids size: {}", segment_ids.size());
-        DB::OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan::find_index");
-        span.addAttribute("vectorScan.segment_ids", segment_ids.size());
+        Search::IndexType index_type = VectorIndex::getIndexType(index.type);
+        Search::Parameters index_params = VectorIndex::convertPocoJsonToMap(index.parameters);
+        index_params.erase("metric_type");
+        DB::OpenTelemetrySpanHolder span2("MergeTreeVectorScanManager::vectorScan::find_index");
+        span2.addAttribute("vectorScan.segment_ids", segment_ids.size());
 
         std::vector<uint64_t> selected_row_ids;
         if (filter)
         {
-            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::proc_filter");
+            OpenTelemetrySpanHolder span3("MergeTreeVectorScanManager::vectorScan()::find_index::proc_filter");
             auto & filter_data = filter->getData();
             int range_index = 0;
             size_t start_pos = read_ranges[range_index].start_row;
@@ -336,12 +336,12 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
                 ++offset;
             }
             LOG_DEBUG(log, "Filter size: {}, read_range size: {}", filter_data_size, read_ranges.size());
-            span.addAttribute("vectorScan.filter_sizes", filter_data_size);
-            span.addAttribute("vectorScan.read_ranges", read_ranges.size());
+            span3.addAttribute("vectorScan.filter_sizes", filter_data_size);
+            span3.addAttribute("vectorScan.read_ranges", read_ranges.size());
         }
         else if (!read_ranges.empty()) /// having prewhere, but this read round does not generate a filter
         {
-            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::generate_row_ids");
+            OpenTelemetrySpanHolder span3("MergeTreeVectorScanManager::vectorScan()::find_index::generate_row_ids");
             size_t start_pos = read_ranges[0].start_row;
             size_t read_row_num = read_ranges[0].row_num;
             for (size_t i = start_pos; i < start_pos + read_row_num; ++i)
@@ -355,14 +355,21 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         bool brute_force = false;
         bool is_shutdown = false;
 
+        size_t min_bytes_to_build_vector_index = data_part->storage.getSettings()->min_bytes_to_build_vector_index;
+        bool default_mstg_disk_mode = data_part->storage.getSettings()->default_mstg_disk_mode;
         for (VectorIndex::SegmentId & segment_id : segment_ids)
         {
             LOG_DEBUG(log, "Create vector segment executor for : {}", segment_id.getFullPath());
+            // FIXME (qliu): rows_count is wrong for decoupled parts
             VectorIndex::VectorSegmentExecutorPtr vec_executor = std::make_shared<VectorIndex::VectorSegmentExecutor>(
-                VectorIndex::VectorIndexFactory::createIndexType(index.type),
                 segment_id,
-                vec_parameters,
-                dim);
+                index_type,
+                metric,
+                dim,
+                data_part->rows_count,
+                index_params,
+                min_bytes_to_build_vector_index,
+                default_mstg_disk_mode);
             is_shutdown = data_part->storage.isShutdown();
             if (!is_shutdown)
             {
@@ -401,7 +408,9 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             segment_ids.clear();
             if (data_part->containVectorIndex(index.name, index.column))
             {
-                VectorIndex::SegmentId segment_id(data_path, data_part->name, data_part->name, index.name, index.column, 0);
+                String vector_index_cache_prefix = fs::path(data_part->storage.getContext()->getVectorIndexCachePath())
+                    / data_part->storage.getRelativeDataPath() / data_part->info.getPartNameWithoutMutation() / "";
+                VectorIndex::SegmentId segment_id(data_part->volume, data_path, data_part->name, index.name, index.column, vector_index_cache_prefix);
                 segment_ids.emplace_back(std::move(segment_id));
             }
 
@@ -409,10 +418,14 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             {
                 LOG_DEBUG(log, "Create vector segment executor for : {}", segment_ids[0].getFullPath());
                 VectorIndex::VectorSegmentExecutorPtr vec_executor = std::make_shared<VectorIndex::VectorSegmentExecutor>(
-                    VectorIndex::VectorIndexFactory::createIndexType(index.type),
                     segment_ids[0],
-                    vec_parameters,
-                    dim);
+                    index_type,
+                    metric,
+                    dim,
+                    data_part->rows_count,
+                    index_params,
+                    min_bytes_to_build_vector_index,
+                    default_mstg_disk_mode);
                 is_shutdown = data_part->storage.isShutdown();
                 if (!is_shutdown)
                 {
@@ -445,34 +458,28 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
         }
 
         if (brute_force)
-            return vectorScanWithoutIndex(data_part, read_ranges, filter, vec_data, search_column_name, dim, k, is_batch, metrics);
+            return vectorScanWithoutIndex(data_part, read_ranges, filter, vec_data, search_column_name, dim, k, is_batch, metric);
 
         for (VectorIndex::VectorSegmentExecutorPtr & vec_executor : vec_executors)
         {
-            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan::build_bitmap_search_segment");
-            // remove deleted vector
-            /// TODO: to be optimized, not support for decouple case right now
-            /// data_part->onLightweightDelete();
-            int64_t base_vector_size = vec_executor->getRawDataSize();
-
-            VectorIndex::GeneralBitMapPtr bits;
+            OpenTelemetrySpanHolder span3("MergeTreeVectorScanManager::vectorScan::build_bitmap_search_segment");
+            Search::DenseBitmapPtr bits;
 
             /// have no filter
             if (selected_row_ids.empty() && read_ranges.empty())
             {
-                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_set_empty_bitmap");
-                bits = std::make_shared<VectorIndex::GeneralBitMap>(base_vector_size);
-                memset(bits->bitmap, 255, (base_vector_size / 8) + 1);
+                OpenTelemetrySpanHolder span4("MergeTreeVectorScanManager::vectorScan()::find_index::segment_set_empty_bitmap");
+                bits = nullptr;
             }
             else 
             {
-                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_get_real_bitmap");
+                OpenTelemetrySpanHolder span4("MergeTreeVectorScanManager::vectorScan()::find_index::segment_get_real_bitmap");
                 /// handle filter case
                 bits = vec_executor->getRealBitMap(selected_row_ids);
-                span.addAttribute("selected_row_ids.size", selected_row_ids.size());
+                span4.addAttribute("selected_row_ids.size", selected_row_ids.size());
             }
 
-            if (!bits->any())
+            if (bits != nullptr && !bits->any())
             {
                 /// don't perform vector search if the segment is completely filtered out
                 continue;
@@ -485,7 +492,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             float * distance_data = per_distance.data();
             int64_t * id_data = per_id.data();
 
-            auto search_status = vec_executor->search(vec_data, k, distance_data, id_data, bits, vec_parameters);
+            auto search_status = vec_executor->search(vec_data, k, distance_data, id_data, bits, search_params);
             if (search_status.getCode() == 10)
             {
                 throw Exception("Wrong dimension parameter", ErrorCodes::LOGICAL_ERROR);
@@ -502,8 +509,8 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
 
             if (is_batch)
             {
-                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_batch_generate_results");
-                for (size_t label = 0; label < k * vec_data->getVectorNum(); ++label)
+                OpenTelemetrySpanHolder span4("MergeTreeVectorScanManager::vectorScan()::find_index::segment_batch_generate_results");
+                for (int64_t label = 0; label < k * vec_data->getVectorNum(); ++label)
                 {
                     UInt32 vector_id = label / k;
                     if (per_id[label] > -1)
@@ -517,8 +524,8 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
             }
             else
             {
-                OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::segment_generate_results");
-                for (size_t label = 0; label < k; ++label)
+                OpenTelemetrySpanHolder span4("MergeTreeVectorScanManager::vectorScan()::find_index::segment_generate_results");
+                for (int64_t label = 0; label < k; ++label)
                 {
                     if (per_id[label] > -1)
                     {
@@ -531,14 +538,14 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
 
         if (is_batch)
         {
-            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::data_part_batch_generate_results");
+            OpenTelemetrySpanHolder span3("MergeTreeVectorScanManager::vectorScan()::find_index::data_part_batch_generate_results");
             tmp_vector_scan_result->query_vector_num = vec_data->getVectorNum();
             tmp_vector_scan_result->result_columns[1] = std::move(vector_id_column);
             tmp_vector_scan_result->result_columns[2] = std::move(distance_column);
         }
         else
         {
-            OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScan()::find_index::data_part_generate_results");
+            OpenTelemetrySpanHolder span3("MergeTreeVectorScanManager::vectorScan()::find_index::data_part_generate_results");
             tmp_vector_scan_result->query_vector_num = 1;
             tmp_vector_scan_result->result_columns[1] = std::move(distance_column);
         }
@@ -552,7 +559,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
     }
     else
     {
-        return vectorScanWithoutIndex(data_part, read_ranges, filter, vec_data, search_column_name, dim, k, is_batch, metrics);
+        return vectorScanWithoutIndex(data_part, read_ranges, filter, vec_data, search_column_name, dim, k, is_batch, metric);
     }
 }
 
@@ -573,14 +580,14 @@ void MergeTreeVectorScanManager::mergeBatchVectorScanResult(
     Columns & pre_result,
     size_t & read_rows,
     const ReadRanges & read_ranges,
-    VectorScanResultPtr vector_scan_result,
+    VectorScanResultPtr tmp_result,
     const ColumnUInt8 * filter,
     const ColumnUInt64 * part_offset)
 {
     OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::mergeBatchVectorScanResult()");
-    const ColumnUInt32 * label_column = checkAndGetColumn<ColumnUInt32>(vector_scan_result->result_columns[0].get());
-    const ColumnUInt32 * vector_id_column = checkAndGetColumn<ColumnUInt32>(vector_scan_result->result_columns[1].get());
-    const ColumnFloat32 * distance_column = checkAndGetColumn<ColumnFloat32>(vector_scan_result->result_columns[2].get());
+    const ColumnUInt32 * label_column = checkAndGetColumn<ColumnUInt32>(tmp_result->result_columns[0].get());
+    const ColumnUInt32 * vector_id_column = checkAndGetColumn<ColumnUInt32>(tmp_result->result_columns[1].get());
+    const ColumnFloat32 * distance_column = checkAndGetColumn<ColumnFloat32>(tmp_result->result_columns[2].get());
 
     auto final_vector_id_column = DataTypeUInt32().createColumn();
     auto final_distance_column = DataTypeFloat32().createColumn();
@@ -616,13 +623,12 @@ void MergeTreeVectorScanManager::mergeBatchVectorScanResult(
                     /// start_pos + offset equals to the real row id
                     if (label_column->getUInt(ind) == start_pos + offset)
                     {
-                        /// LOG_DEBUG(log, "merge result: ind: {}, current_column_pos: {}, filter_id: {}", ind, current_column_pos, i + start_offset);
                         /// for each result column
-                        for (size_t i = 0; i < final_result.size(); ++i)
+                        for (size_t j = 0; j < final_result.size(); ++j)
                         {
                             Field field;
-                            pre_result[i]->get(current_column_pos, field);
-                            final_result[i]->insert(field);
+                            pre_result[j]->get(current_column_pos, field);
+                            final_result[j]->insert(field);
                         }
                         final_vector_id_column->insert(vector_id_column->getUInt(ind));
                         final_distance_column->insert(distance_column->getFloat32(ind));
@@ -736,13 +742,13 @@ void MergeTreeVectorScanManager::mergeVectorScanResult(
     Columns & pre_result,
     size_t & read_rows,
     const ReadRanges & read_ranges,
-    VectorScanResultPtr vector_scan_result,
+    VectorScanResultPtr tmp_result,
     const ColumnUInt8 * filter,
     const ColumnUInt64 * part_offset)
 {
     OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::mergeVectorScanResult()");
-    const ColumnUInt32 * label_column = checkAndGetColumn<ColumnUInt32>(vector_scan_result->result_columns[0].get());
-    const ColumnFloat32 * distance_column = checkAndGetColumn<ColumnFloat32>(vector_scan_result->result_columns[1].get());
+    const ColumnUInt32 * label_column = checkAndGetColumn<ColumnUInt32>(tmp_result->result_columns[0].get());
+    const ColumnFloat32 * distance_column = checkAndGetColumn<ColumnFloat32>(tmp_result->result_columns[1].get());
 
     if (!label_column)
     {
@@ -892,7 +898,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     int dim,
     int k,
     bool is_batch,
-    const VectorIndex::Metrics& metrics)
+    const Search::Metric & metric)
 {
     OpenTelemetrySpanHolder span("MergeTreeVectorScanManager::vectorScanWithoutIndex()");
     NamesAndTypesList cols;
@@ -913,9 +919,8 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     {
         cols.emplace_back(LightweightDeleteDescription::FILTER_COLUMN);
     }
-    
-    VectorIndex::GeneralBitMapPtr row_exists = std::make_shared<VectorIndex::GeneralBitMap>(part->rows_count);
-    memset(row_exists->bitmap, 255, (part->rows_count / 8) + 1);
+
+    Search::DenseBitmapPtr row_exists = std::make_shared<Search::DenseBitmap>(part->rows_count, true);
 
     VectorScanResultPtr tmp_vector_scan_result = std::make_shared<VectorScanResult>();
     tmp_vector_scan_result->result_columns.resize(is_batch ? 3 : 2);
@@ -955,7 +960,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     bool continue_read = false;
 
     std::vector<float> final_distance;
-    if (metrics == VectorIndex::Metrics::IP)
+    if (metric == Search::Metric::IP)
     {
         final_distance = std::vector<float>(k * nq, std::numeric_limits<float>().min());
     }
@@ -970,7 +975,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     {
         LOG_TRACE(log, "with filter");
         /// for debug
-        for (int i = 0; i < read_ranges.size(); i++)
+        for (size_t i = 0; i < read_ranges.size(); i++)
         {
             LOG_TRACE(
                 log,
@@ -1018,14 +1023,6 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
                 continue;
             }
 
-            size_t i = 0;
-            size_t start_row = 0;
-            /// skip empty arrays
-            while (i < offsets.size() && offsets[i] == start_row)
-            {
-                ++i;
-            }
-
             //std::vector<float> vector_raw_data(dim * offsets.size(), std::numeric_limits<float>().max());
             std::vector<float> vector_raw_data;
             vector_raw_data.reserve(single_range.row_num);
@@ -1073,7 +1070,20 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
             auto base_data = std::make_shared<VectorIndex::VectorDataset>(
                 static_cast<int32_t>(actual_id_in_range.size()), static_cast<int32_t>(dim), const_cast<float *>(vector_raw_data.data()));
 
-            searchWrapper(true, query_vector, base_data, k, dim, nq, single_range.start_row, final_id, final_distance, actual_id_in_range, metrics, row_exists, 0);
+            searchWrapper(
+                true,
+                query_vector,
+                base_data,
+                k,
+                dim,
+                nq,
+                single_range.start_row,
+                final_id,
+                final_distance,
+                actual_id_in_range,
+                metric,
+                row_exists,
+                0);
 
             LOG_DEBUG(
                 log,
@@ -1127,14 +1137,6 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
                 continue;
             }
 
-            size_t i = 0;
-            size_t start_row = 0;
-            /// skip empty arrays
-            while (i < offsets.size() && offsets[i] == start_row)
-            {
-                ++i;
-            }
-
             std::vector<float> vector_raw_data(dim * offsets.size(), std::numeric_limits<float>().max());
 
             for (size_t row = 0; row < offsets.size(); ++row)
@@ -1162,7 +1164,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
                     const ColumnUInt8 * col = checkAndGetColumn<ColumnUInt8>(row_exists_col.get());
                     const auto & col_data = col->getData();
                     LOG_DEBUG(log, "Col data size: {}", col_data.size());
-                    for (int i = 0; i < col_data.size(); i++)
+                    for (size_t i = 0; i < col_data.size(); i++)
                     {
                         if (!col_data[i])
                         {
@@ -1178,9 +1180,22 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
                 static_cast<int32_t>(offsets.size()), static_cast<int32_t>(dim), const_cast<float *>(vector_raw_data.data()));
 
             std::vector<size_t> place_holder;
-            searchWrapper(false, query_vector, base_data, k, dim, nq, num_rows_read, final_id, final_distance, place_holder, metrics, row_exists, deleted_row_num);
+            searchWrapper(
+                false,
+                query_vector,
+                base_data,
+                k,
+                dim,
+                nq,
+                num_rows_read,
+                final_id,
+                final_distance,
+                place_holder,
+                metric,
+                row_exists,
+                deleted_row_num);
+
 
-            
             num_rows_read += num_rows;
 
             LOG_DEBUG(
@@ -1201,7 +1216,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
         for (size_t label = 0; label < k * nq; ++label)
         {
             UInt32 vector_id = label / k;
-            if (final_id[label] > -1 && row_exists->test(final_id[label]))
+            if (final_id[label] > -1 && row_exists->is_member(final_id[label]))
             {
                 /// LOG_DEBUG(log, "[vectorScan] label: {}, distance: {}", final_id[label], final_distance[label]);
                 label_column->insert(final_id[label]);
@@ -1218,7 +1233,7 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScanWithoutIndex(
     {
         for (size_t label = 0; label < k * nq; ++label)
         {
-            if (final_id[label] > -1 && row_exists->test(final_id[label]))
+            if (final_id[label] > -1 && row_exists->is_member(final_id[label]))
             {
                 LOG_DEBUG(log, "Label: {}, distance: {}", final_id[label], final_distance[label]);
                 label_column->insert(final_id[label]);
@@ -1239,19 +1254,19 @@ void MergeTreeVectorScanManager::searchWrapper(
     VectorIndex::VectorDatasetPtr & query_vector,
     VectorIndex::VectorDatasetPtr & base_data,
     int k,
-    int dim,
+    int /* dim */,
     int nq,
     int num_rows_read,
     std::vector<int64_t> & final_id,
     std::vector<float> & final_distance,
     std::vector<size_t> & actual_id_in_range,
-    const VectorIndex::Metrics& metrics,
-    VectorIndex::GeneralBitMapPtr& row_exists,
+    const Search::Metric & metric,
+    Search::DenseBitmapPtr & row_exists,
     int delete_id_num)
 {
     std::vector<float> per_distance;
     std::vector<float> tmp_per_distance;
-    if (metrics == VectorIndex::Metrics::IP)
+    if (metric == Search::Metric::IP)
     {
         per_distance = std::vector<float>(k * nq, std::numeric_limits<float>().min());
         if (delete_id_num > 0)
@@ -1284,7 +1299,8 @@ void MergeTreeVectorScanManager::searchWrapper(
 
     LOG_TRACE(log, "the base data length:{}", base_data->getVectorNum());
 
-    auto s = VectorIndex::VectorSegmentExecutor::searchWithoutIndex(query_vector, base_data, k + delete_id_num, distance_data, id_data, metrics);
+    auto s = VectorIndex::VectorSegmentExecutor::searchWithoutIndex(
+        query_vector, base_data, k + delete_id_num, distance_data, id_data, metric);
     if (!s.fine())
     {
         throw Exception("brute force search failed", ErrorCodes::LOGICAL_ERROR);
@@ -1304,7 +1320,7 @@ void MergeTreeVectorScanManager::searchWrapper(
                 {
                     LOG_ERROR(log, "tmp_id: {}, num_rows_read: {}", tmp_id, num_rows_read);
                 }
-                else if (tmp_id >= 0 && row_exists->test(tmp_id + num_rows_read))
+                else if (tmp_id >= 0 && row_exists->is_member(tmp_id + num_rows_read))
                 {
                     per_id[i * k + curr_pos] = tmp_per_id[i * (k + delete_id_num) + tmp_curr_pos];
                     per_distance[i * k + curr_pos] = tmp_per_distance[i * (k + delete_id_num) + tmp_curr_pos];
@@ -1336,16 +1352,16 @@ void MergeTreeVectorScanManager::searchWrapper(
         }
     }
 
-    for (size_t q = 0; q < nq; q++)
+    for (int q = 0; q < nq; q++)
     {
         size_t current_result_offset = q * k;
 
         size_t j = current_result_offset;
         size_t z = current_result_offset;
-        for (size_t i = 0; i < k; i++)
+        for (int i = 0; i < k; i++)
         {
-            if ((metrics != VectorIndex::Metrics::IP && final_distance[j] > per_distance[z]) 
-                || (metrics == VectorIndex::Metrics::IP && final_distance[j] < per_distance[z]))
+            if ((metric != Search::Metric::IP && final_distance[j] > per_distance[z])
+                || (metric == Search::Metric::IP && final_distance[j] < per_distance[z]))
             {
                 intermediate_distance.emplace_back(per_distance[z]);
                 intermediate_ids.emplace_back(per_id[z] + num_rows_read);
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.h b/src/Storages/MergeTree/MergeTreeVectorScanManager.h
index d69e54740b..f3d1dfd77e 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.h
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.h
@@ -9,10 +9,17 @@
 #include <Storages/MergeTree/VectorScanResult.h>
 #include <Storages/SelectQueryInfo.h>
 #include <Storages/StorageInMemoryMetadata.h>
-#include <VectorIndex/VectorSegmentExecutor.h>
 
 #include <base/logger_useful.h>
 
+#include <VectorIndex/Dataset.h>
+
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wnon-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wunused-parameter"
+#include <SearchIndex/VectorIndex.h>
+#pragma GCC diagnostic pop
+
 namespace DB
 {
 
@@ -91,11 +98,23 @@ private:
         int dim,
         int k,
         bool is_batch,
-        const VectorIndex::Metrics& metrics);
+        const Search::Metric & metric);
 
-    void mergeBatchVectorScanResult(Columns & pre_result, size_t & read_rows, const ReadRanges & read_ranges = ReadRanges(), VectorScanResultPtr vector_scan_result = nullptr, const ColumnUInt8 * filter = nullptr, const ColumnUInt64 * part_offset = nullptr);
+    void mergeBatchVectorScanResult(
+        Columns & pre_result,
+        size_t & read_rows,
+        const ReadRanges & read_ranges = ReadRanges(),
+        VectorScanResultPtr tmp_result = nullptr,
+        const ColumnUInt8 * filter = nullptr,
+        const ColumnUInt64 * part_offset = nullptr);
 
-    void mergeVectorScanResult(Columns & pre_result, size_t & read_rows, const ReadRanges & read_ranges = ReadRanges(), VectorScanResultPtr vector_scan_result = nullptr, const ColumnUInt8 * filter = nullptr, const ColumnUInt64 * part_offset = nullptr);
+    void mergeVectorScanResult(
+        Columns & pre_result,
+        size_t & read_rows,
+        const ReadRanges & read_ranges = ReadRanges(),
+        VectorScanResultPtr tmp_result = nullptr,
+        const ColumnUInt8 * filter = nullptr,
+        const ColumnUInt64 * part_offset = nullptr);
 
     void searchWrapper(
         bool prewhere,
@@ -108,8 +127,8 @@ private:
         std::vector<int64_t> & final_id,
         std::vector<float> & final_distance,
         std::vector<size_t> & actual_id_in_range,
-        const VectorIndex::Metrics& metrics,
-        VectorIndex::GeneralBitMapPtr& row_exists,
+        const Search::Metric & metric,
+        Search::DenseBitmapPtr & row_exists,
         int delete_id_nums);
 };
 
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp b/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp
index 9384b2a1dc..747912386a 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanUtils.cpp
@@ -127,7 +127,7 @@ void filterMarkRangesByVectorScanResult(MergeTreeData::DataPartPtr part, MergeTr
         part->index_granularity_info.fixed_index_granularity,
         part->index_granularity_info.index_granularity_bytes);
 
-    auto need_this_range = [&](MergeTreeData::DataPartPtr part, MergeTreeVectorScanManagerPtr vector_scan_mgr, MarkRanges & mark_ranges, MarkRange & range)
+    auto need_this_range = [&](MarkRange & range)
     {
         auto begin = range.begin;
         auto end = range.end;
@@ -166,7 +166,7 @@ void filterMarkRangesByVectorScanResult(MergeTreeData::DataPartPtr part, MergeTr
 
         steps++;
 
-        if (!need_this_range(part, vector_scan_mgr, mark_ranges, range))
+        if (!need_this_range(range))
             continue;
 
         if (range.end == range.begin + 1)
diff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp
index 3568406d1e..d599c40989 100644
--- a/src/Storages/MergeTree/MutateTask.cpp
+++ b/src/Storages/MergeTree/MutateTask.cpp
@@ -1,24 +1,25 @@
 #include <Storages/MergeTree/MutateTask.h>
 
-#include <base/logger_useful.h>
-#include <Common/escapeForFileName.h>
 #include <Columns/ColumnsNumber.h>
-#include <Parsers/queryToString.h>
-#include <Interpreters/SquashingTransform.h>
 #include <Interpreters/MergeTreeTransaction.h>
-#include <Processors/Transforms/TTLTransform.h>
-#include <Processors/Transforms/TTLCalcTransform.h>
-#include <Processors/Transforms/DistinctSortedTransform.h>
-#include <Processors/Transforms/ColumnGathererTransform.h>
+#include <Interpreters/SquashingTransform.h>
+#include <Parsers/queryToString.h>
+#include <Processors/Executors/PullingPipelineExecutor.h>
 #include <Processors/Sources/SourceFromSingleChunk.h>
+#include <Processors/Transforms/ColumnGathererTransform.h>
+#include <Processors/Transforms/DistinctSortedTransform.h>
 #include <Processors/Transforms/ExpressionTransform.h>
 #include <Processors/Transforms/MaterializingTransform.h>
-#include <Processors/Executors/PullingPipelineExecutor.h>
-#include <Storages/MergeTree/StorageFromMergeTreeDataPart.h>
+#include <Processors/Transforms/TTLCalcTransform.h>
+#include <Processors/Transforms/TTLTransform.h>
+#include <Storages/MergeTree/MergeTreeDataMergerMutator.h>
 #include <Storages/MergeTree/MergeTreeDataWriter.h>
+#include <Storages/MergeTree/StorageFromMergeTreeDataPart.h>
 #include <Storages/MutationCommands.h>
-#include <Storages/MergeTree/MergeTreeDataMergerMutator.h>
+#include <VectorIndex/VectorIndexCommon.h>
+#include <base/logger_useful.h>
 #include <boost/algorithm/string/replace.hpp>
+#include <Common/escapeForFileName.h>
 
 
 namespace CurrentMetrics
diff --git a/src/Storages/MergeTree/PrimaryKeyCacheManager.cpp b/src/Storages/MergeTree/PrimaryKeyCacheManager.cpp
index 374ece018c..f841ac93b4 100644
--- a/src/Storages/MergeTree/PrimaryKeyCacheManager.cpp
+++ b/src/Storages/MergeTree/PrimaryKeyCacheManager.cpp
@@ -35,7 +35,6 @@ std::optional<Columns> PrimaryKeyCacheManager::getPartPkCache(String cache_key)
 
 void PrimaryKeyCacheManager::removeFromPKCache(const String & cache_key)
 {
-    LOG_INFO(log, "PrimaryKeyCache remove cache_key={}", cache_key);
     return cache_ex.remove(cache_key);
 }
 
diff --git a/src/Storages/MergeTree/ReplicatedVectorIndexTask.cpp b/src/Storages/MergeTree/ReplicatedVectorIndexTask.cpp
index 8a56d358fa..5a8654643d 100644
--- a/src/Storages/MergeTree/ReplicatedVectorIndexTask.cpp
+++ b/src/Storages/MergeTree/ReplicatedVectorIndexTask.cpp
@@ -59,7 +59,7 @@ bool ReplicatedVectorIndexTask::executeStep()
         {
             try
             {
-                build_status = builder.buildVectorIndex(metadata_snapshot, source_part->name, false, entry.slow_mode);
+                build_status = builder.buildVectorIndex(metadata_snapshot, source_part->name, entry.slow_mode);
                 storage.updateVectorIndexBuildStatus(entry.source_parts[0], true, "");
 
                 /// For memory limit failure, try to run build 3 times.
diff --git a/src/Storages/MergeTree/ReplicatedVectorIndexTask.h b/src/Storages/MergeTree/ReplicatedVectorIndexTask.h
index 5c55240d1a..67bf29db9f 100644
--- a/src/Storages/MergeTree/ReplicatedVectorIndexTask.h
+++ b/src/Storages/MergeTree/ReplicatedVectorIndexTask.h
@@ -39,7 +39,7 @@ public:
 
     bool executeStep() override;
     StorageID getStorageID() override;
-    UInt64 getPriority() override { return priority; };
+    UInt64 getPriority() override { return priority; }
     void onCompleted() override;
 
     ~ReplicatedVectorIndexTask() override;
diff --git a/src/Storages/MergeTree/VectorIndexMergeTreeTask.cpp b/src/Storages/MergeTree/VectorIndexMergeTreeTask.cpp
index 751802cff3..d3c6c37811 100644
--- a/src/Storages/MergeTree/VectorIndexMergeTreeTask.cpp
+++ b/src/Storages/MergeTree/VectorIndexMergeTreeTask.cpp
@@ -21,16 +21,16 @@ bool VectorIndexMergeTreeTask::executeStep()
 {
     if (vector_index_entry != nullptr)
     {
-        LOG_DEBUG(log, "Execute vector index build for : {} slow_mode: {}", vector_index_entry->part_name, slow_mode);
+        LOG_DEBUG(log, "Execute vector index build for {}, slow_mode: {}", vector_index_entry->part_name, slow_mode);
         try
         {
-            builder.buildVectorIndex(metadata_snapshot, vector_index_entry->part_name, false, slow_mode);
+            builder.buildVectorIndex(metadata_snapshot, vector_index_entry->part_name, slow_mode);
             storage.updateVectorIndexBuildStatus(vector_index_entry->part_name, true, "");
         }
         catch (...)
         {
             String exception_message = getCurrentExceptionMessage(false);
-            LOG_ERROR(log, "Something went wrong during index building: {}", exception_message);
+            LOG_ERROR(log, "Something went wrong for {} during index building: {}", vector_index_entry->part_name, exception_message);
             storage.updateVectorIndexBuildStatus(vector_index_entry->part_name, false, exception_message);
 
             auto part = storage.getActiveContainingPart(vector_index_entry->part_name);
diff --git a/src/Storages/MergeTree/VectorIndexMergeTreeTask.h b/src/Storages/MergeTree/VectorIndexMergeTreeTask.h
index 4503b90ee7..98a245d4d6 100644
--- a/src/Storages/MergeTree/VectorIndexMergeTreeTask.h
+++ b/src/Storages/MergeTree/VectorIndexMergeTreeTask.h
@@ -37,7 +37,7 @@ public:
         , slow_mode(slow_mode_)
         , log(&Poco::Logger::get("VectorIndexMergeTreeTask"))
     {
-        LOG_INFO(log, "Create VectorIndexMergeTreeTask, slow mode: {}", slow_mode);
+        LOG_DEBUG(log, "Create VectorIndexMergeTreeTask for {}, slow mode: {}", vector_index_entry->part_name, slow_mode);
     }
 
     bool executeStep() override;
diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp
index a8702bb9b9..d2573583ad 100644
--- a/src/Storages/StorageMergeTree.cpp
+++ b/src/Storages/StorageMergeTree.cpp
@@ -9,39 +9,39 @@
 #include <base/sort.h>
 
 #include <Databases/IDatabase.h>
-#include <Common/escapeForFileName.h>
-#include <Common/typeid_cast.h>
-#include <Common/ThreadPool.h>
+#include <IO/copyData.h>
+#include <Interpreters/Context.h>
 #include <Interpreters/InterpreterAlterQuery.h>
-#include <Interpreters/PartLog.h>
 #include <Interpreters/MutationsInterpreter.h>
-#include <Interpreters/Context.h>
+#include <Interpreters/PartLog.h>
 #include <Interpreters/TransactionLog.h>
-#include <IO/copyData.h>
 #include <Parsers/ASTCheckQuery.h>
 #include <Parsers/ASTFunction.h>
 #include <Parsers/ASTLiteral.h>
 #include <Parsers/ASTPartition.h>
 #include <Parsers/ASTSetQuery.h>
-#include <Parsers/queryToString.h>
 #include <Parsers/formatAST.h>
-#include <Storages/MergeTree/MergeTreeData.h>
-#include <Storages/MergeTree/ActiveDataPartSet.h>
+#include <Parsers/queryToString.h>
+#include <Processors/QueryPlan/BuildQueryPipelineSettings.h>
+#include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>
+#include <Processors/QueryPlan/QueryPlan.h>
+#include <QueryPipeline/Pipe.h>
 #include <Storages/AlterCommands.h>
-#include <Storages/PartitionCommands.h>
-#include <Storages/MergeTree/MergeTreeSink.h>
-#include <Storages/MergeTree/MergeTreeDataPartInMemory.h>
+#include <Storages/MergeTree/ActiveDataPartSet.h>
+#include <Storages/MergeTree/MergeList.h>
 #include <Storages/MergeTree/MergePlainMergeTreeTask.h>
-#include <Storages/MergeTree/VectorIndexMergeTreeTask.h>
+#include <Storages/MergeTree/MergeTreeData.h>
+#include <Storages/MergeTree/MergeTreeDataPartInMemory.h>
+#include <Storages/MergeTree/MergeTreeSink.h>
 #include <Storages/MergeTree/PartitionPruner.h>
-#include <Storages/MergeTree/MergeList.h>
+#include <Storages/MergeTree/VectorIndexMergeTreeTask.h>
 #include <Storages/MergeTree/checkDataPart.h>
-#include <QueryPipeline/Pipe.h>
-#include <Processors/QueryPlan/QueryPlan.h>
-#include <Processors/QueryPlan/BuildQueryPipelineSettings.h>
-#include <Processors/QueryPlan/Optimizations/QueryPlanOptimizationSettings.h>
-#include <VectorIndex/VectorIndexCommon.h>
+#include <Storages/PartitionCommands.h>
 #include <VectorIndex/MergeUtils.h>
+#include <VectorIndex/VectorIndexCommon.h>
+#include <Common/ThreadPool.h>
+#include <Common/escapeForFileName.h>
+#include <Common/typeid_cast.h>
 
 namespace DB
 {
diff --git a/src/Storages/VectorIndexCommands.cpp b/src/Storages/VectorIndexCommands.cpp
index e72c5978bc..e2b55f9325 100644
--- a/src/Storages/VectorIndexCommands.cpp
+++ b/src/Storages/VectorIndexCommands.cpp
@@ -37,7 +37,7 @@ std::optional<VectorIndexCommand> VectorIndexCommand::parse(ASTAlterCommand * co
         res.index_name = command->vec_index_decl->as<ASTIdentifier &>().name();
         res.column_name = getIdentifierName(command->column);
         res.index_type = Poco::toUpper(command->vec_index_decl->as<ASTVectorIndexDeclaration>()->type->name);
-        LOG_DEBUG(log, "Aadd vector index: name: {}, index_type: {}", res.index_name, res.index_type);
+        LOG_DEBUG(log, "Add vector index: name: {}, index_type: {}", res.index_name, res.index_type);
         return res;
     }
     else if (command->type == ASTAlterCommand::DROP_VECTOR_INDEX)
diff --git a/src/Storages/VectorIndicesDescription.cpp b/src/Storages/VectorIndicesDescription.cpp
index fe6c11b76b..73e1769b9e 100644
--- a/src/Storages/VectorIndicesDescription.cpp
+++ b/src/Storages/VectorIndicesDescription.cpp
@@ -13,7 +13,7 @@
 #include <Storages/VectorIndicesDescription.h>
 #include <Common/quoteString.h>
 
-#include <VectorIndex/VectorIndexFactory.h>
+#include <VectorIndex/VectorIndexCommon.h>
 
 namespace DB
 {
@@ -97,12 +97,8 @@ VectorIndexDescription VectorIndexDescription::getVectorIndexFromAST(const ASTPt
     result.name = vec_index_definition->name;
     result.column = vec_index_definition->column;
     result.data_type = columns.get(result.column).type;
-
-    result.type = Poco::toUpper(vec_index_definition->type->name);
-    if (!VectorIndex::VectorIndexFactory::typeExist(result.type)) {
-        throw Exception("Index type " + result.type + " is unknown", ErrorCodes::INCORRECT_QUERY);
-    }
-
+    result.type = vec_index_definition->type->name;
+    VectorIndex::getIndexType(result.type);
 
     /// currently not used
     const auto & definition_arguments = vec_index_definition->type->arguments;
diff --git a/src/VectorIndex/Autotuner.cpp b/src/VectorIndex/Autotuner.cpp
deleted file mode 100644
index d2f6f1c8c3..0000000000
--- a/src/VectorIndex/Autotuner.cpp
+++ /dev/null
@@ -1,134 +0,0 @@
-#include <VectorIndex/Autotuner.h>
-#include <thread>
-#include <faiss/AutoTune.h>
-#include <VectorIndex/DiskIOWriter.h>
-#include <VectorIndex/VectorIndexCommon.h>
-
-namespace VectorIndex
-{
-
-void Autotuner::start()
-{
-    thread = ThreadFromGlobalPool(&Autotuner::run, this);
-}
-
-void Autotuner::run()
-{
-    go = true;
-    LOG_INFO(log, "Start index autotuner");
-    while (true)
-    {
-        if (quit)
-        {
-            return;
-        }
-        if (!tuning_task_queue.empty())
-        {
-            current = tuning_task_queue.begin();
-            Execute(current->first, current->second);
-            serializeResult(current->first);
-        }
-        else
-        {
-            std::this_thread::sleep_for(std::chrono::seconds(1));
-        }
-    }
-}
-
-void Autotuner::addTask(std::string segment_id, TuningPackPtr tuningPack)
-{
-    tuning_task_queue.insert(std::make_pair(segment_id, tuningPack));
-}
-
-void Autotuner::pause()
-{
-    LOG_TRACE(log, "pausing autotuner");
-    go = false;
-}
-
-void Autotuner::resume()
-{
-    LOG_TRACE(log, "resuming autotuner");
-    go = true;
-    pause_c.notify_one();
-}
-
-void Autotuner::Execute(std::string segment_id, TuningPackPtr tuning)
-{
-    int query_size = tuning->query_size;
-    int topK = tuning->topK;
-    int64_t * gt = tuning->gt->data();
-    float * query = tuning->query->data();
-    bool one_recall = tuning->oneRecall;
-    LOG_INFO(log, "{} entering auto tune area", segment_id);
-    AccParametersPack result
-        = tuning->index->exploreTask(query, gt, topK, query_size, one_recall, std::ref(pause_m), std::ref(pause_c), std::ref(go), log);
-    finished_tunes.insert(std::make_pair(segment_id, result));
-}
-
-void Autotuner::serializeResult(std::string segment_id)
-{
-    LOG_INFO(log, "{} write op points to persistent", segment_id);
-    AccParametersPack map;
-    if (finished_tunes.contains(segment_id))
-    {
-        map = finished_tunes[segment_id];
-    }
-    else
-    {
-        return;
-    }
-    if (map.empty())
-    {
-        LOG_INFO(log, "{} can't find any op point, finish autotune with no result", segment_id);
-    }
-    else
-    {
-        std::string to_be_written = AccParametersPackToString(map);
-        char * data = to_be_written.data();
-        int64_t size = to_be_written.size();
-        DiskIOWriter diskwriter;
-        diskwriter.open(segment_id + PARAMETER_PACK_NAME, false);
-        diskwriter.write(&size, sizeof(size));
-        diskwriter.write(data, size);
-        diskwriter.close();
-    }
-    removeTask(segment_id);
-}
-
-bool Autotuner::removeTask(std::string segment_id)
-{
-    bool removed = false;
-    if (finished_tunes.contains(segment_id))
-    {
-        finished_tunes.erase(segment_id);
-        if (tuning_task_queue.contains(segment_id))
-        {
-            tuning_task_queue.erase(segment_id);
-        }
-        removed = true;
-    }
-    return removed;
-}
-
-Autotuner * Autotuner::getInstance()
-{
-    static Autotuner autotuner;
-    return &autotuner;
-}
-
-Autotuner::~Autotuner()
-{
-    try
-    {
-        quit = true;
-        if (thread.joinable())
-            thread.join();
-    }
-    catch (...)
-    {
-        DB::tryLogCurrentException(__PRETTY_FUNCTION__);
-    }
-}
-
-}
diff --git a/src/VectorIndex/Autotuner.h b/src/VectorIndex/Autotuner.h
deleted file mode 100644
index e35d0d8718..0000000000
--- a/src/VectorIndex/Autotuner.h
+++ /dev/null
@@ -1,69 +0,0 @@
-#pragma once
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wreserved-identifier"
-
-#include <string>
-#include <thread>
-#include <unordered_map>
-#include <base/logger_useful.h>
-#include <Common/ThreadPool.h>
-#include <VectorIndex/Status.h>
-#include <VectorIndex/VectorIndex.h>
-
-namespace VectorIndex
-{
-struct TuningPack
-{
-    TuningPack(
-        VectorIndexPtr & index_, std::vector<float> * query_, std::vector<int64_t> * gt_, int topK_, int query_size_, bool oneRecall_)
-        : index(index_), query(query_), gt(gt_), topK(topK_), query_size(query_size_), oneRecall(oneRecall_)
-    {
-    }
-    VectorIndexPtr index;
-    std::vector<float> * query;
-    std::vector<int64_t> * gt;
-    int topK;
-    int query_size;
-    bool oneRecall;
-
-    ~TuningPack()
-    {
-        free(query);
-        free(gt);
-    }
-};
-
-using TuningPackPtr = std::shared_ptr<TuningPack>;
-using Autotune_queue = std::unordered_map<std::string, TuningPackPtr>;
-
-class Autotuner
-{
-public:
-    Autotuner() { log = &Poco::Logger::get("AutoTuner"); }
-    void addTask(std::string segment_id, TuningPackPtr tuningPack);
-    void resume();
-    void pause();
-    void start();
-    void run();
-    void serializeResult(std::string segment_id);
-    bool removeTask(std::string segment_id);
-    static Autotuner * getInstance();
-    ~Autotuner();
-
-private:
-    void Execute(std::string, TuningPackPtr);
-
-    std::unordered_map<std::string, TuningPackPtr>::iterator current;
-    std::mutex pause_m;
-    std::condition_variable pause_c;
-    bool go;
-    ///segment_id : TuningPack
-    Autotune_queue tuning_task_queue;
-    ///segment_id: (accuracy : parameters...)
-    std::unordered_map<std::string, AccParametersPack> finished_tunes;
-    Poco::Logger * log;
-    ThreadFromGlobalPool thread;
-    std::atomic<bool> quit{false};
-};
-using AutotunerPtr = std::shared_ptr<Autotuner>;
-}
diff --git a/src/VectorIndex/Binary.h b/src/VectorIndex/Binary.h
deleted file mode 100644
index 31fa33eb0f..0000000000
--- a/src/VectorIndex/Binary.h
+++ /dev/null
@@ -1,26 +0,0 @@
-#pragma once
-
-#include <base/logger_useful.h>
-
-namespace VectorIndex
-{
-struct Binary
-{
-    //a tuple class containing binary representation of anything, used to handle IO
-public:
-    uint8_t * data;
-    int64_t size;
-
-    Poco::Logger * const log;
-
-    Binary():data(nullptr),size(0),log(&Poco::Logger::get("Binary"))
-    {}
-
-    ~Binary() noexcept
-    {
-        delete []data;
-    }
-};
-using BinaryPtr = std::shared_ptr<Binary>;
-
-}
diff --git a/src/VectorIndex/BruteForceSearch.cpp b/src/VectorIndex/BruteForceSearch.cpp
index ae9a64494e..fd60777faa 100644
--- a/src/VectorIndex/BruteForceSearch.cpp
+++ b/src/VectorIndex/BruteForceSearch.cpp
@@ -5,27 +5,29 @@ namespace VectorIndex
 {
 
 Status tryBruteForceSearch(
-    const float * x, const float * y, size_t d, size_t k, size_t nx, size_t ny, int64_t * result_id, float * distance, const Metrics & m)
+    const float * x,
+    const float * y,
+    size_t d,
+    size_t k,
+    size_t nx,
+    size_t ny,
+    int64_t * result_id,
+    float * distance,
+    const Search::Metric & m)
 {
-    Poco::Logger * log = &Poco::Logger::get("bruteforce");
-    if (m == IP)
+    Poco::Logger * log = &Poco::Logger::get("BruteForce");
+    if (m == Search::Metric::IP)
     {
         LOG_DEBUG(log, "Metric is IP");
         faiss::float_minheap_array_t res = {size_t(nx), size_t(k), result_id, distance};
         faiss::knn_inner_product(x, y, d, nx, ny, &res, nullptr);
     }
-    else if (m == L2)
+    else if (m == Search::Metric::L2)
     {
         LOG_DEBUG(log, "Metric is L2");
         faiss::float_maxheap_array_t res = {size_t(nx), size_t(k), result_id, distance};
         faiss::knn_L2sqr(x, y, d, nx, ny, &res, nullptr);
     }
-    else if (m == Cosine)
-    {
-        LOG_DEBUG(log, "Metric is Cosine");
-        faiss::float_maxheap_array_t res = {size_t(nx), size_t(k), result_id, distance};
-        faiss::knn_cosine(x, y, d, nx, ny, &res, nullptr);
-    }
     else
     {
         return Status(8, "Metric not implemented in brute force search");
diff --git a/src/VectorIndex/BruteForceSearch.h b/src/VectorIndex/BruteForceSearch.h
index 1fd58a2636..1a1d3c0371 100644
--- a/src/VectorIndex/BruteForceSearch.h
+++ b/src/VectorIndex/BruteForceSearch.h
@@ -4,9 +4,11 @@
 #pragma GCC diagnostic ignored "-Wunused-function"
 #include <faiss/utils/distances.h>
 #pragma GCC diagnostic pop
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wunused-parameter"
+#include <SearchIndex/VectorIndex.h>
+#pragma GCC diagnostic pop
 #include <VectorIndex/Status.h>
-#include <VectorIndex/VectorIndex.h>
-#include "GeneralBitMap.h"
 
 namespace VectorIndex
 {
@@ -16,5 +18,13 @@ namespace VectorIndex
 /// k is the top k we desired after distance calculation.
 
 Status tryBruteForceSearch(
-    const float * x, const float * y, size_t d, size_t k, size_t nx, size_t ny, int64_t * result_id, float * distance, const Metrics & m);
+    const float * x,
+    const float * y,
+    size_t d,
+    size_t k,
+    size_t nx,
+    size_t ny,
+    int64_t * result_id,
+    float * distance,
+    const Search::Metric & m);
 }
diff --git a/src/VectorIndex/CMakeLists.txt b/src/VectorIndex/CMakeLists.txt
index 35bebb1027..b80e306114 100644
--- a/src/VectorIndex/CMakeLists.txt
+++ b/src/VectorIndex/CMakeLists.txt
@@ -1,12 +1,10 @@
-#cmake_minimum_required(VERSION 3.17)
-#project(
-#VectorIndex
-#VERSION 0.0.1
-#)
-#set(CMAKE_CXX_STANDARD 17)
-#file(GLOB SRCS *.cpp *.h)
-#add_library(VectorIndex ${SRCS})
-#target_compile_options(faiss PRIVATE - Wall - Wextra)
-#
-#add_subdirectory(test)
-#target_link_libraries(VectorIndex libfaiss.a)
+add_headers_and_sources(clickhouse_vector_index .)
+add_library(clickhouse_vector_index ${clickhouse_vector_index_sources})
+include_directories(${ClickHouse_SOURCE_DIR}/contrib/search-index/contrib/google-research/scann/contrib/tensorflow/include)
+include_directories(${ClickHouse_SOURCE_DIR}/contrib/search-index/contrib/google-research/scann/contrib/tensorflow/include/src)
+target_link_libraries(clickhouse_vector_index
+    PUBLIC
+	dbms
+    PRIVATE
+	ch_contrib::search_index
+)
\ No newline at end of file
diff --git a/src/VectorIndex/CacheManager.cpp b/src/VectorIndex/CacheManager.cpp
index bc4c7577fc..802d0d2698 100644
--- a/src/VectorIndex/CacheManager.cpp
+++ b/src/VectorIndex/CacheManager.cpp
@@ -1,5 +1,5 @@
-#include <VectorIndex/CacheManager.h>
 #include <memory>
+#include <VectorIndex/CacheManager.h>
 
 #include <VectorIndex/IndexException.h>
 
@@ -77,9 +77,9 @@ void CacheManager::setCacheSize(size_t size_in_bytes)
     m = true;
 }
 
-std::list<std::pair<CacheKey, Parameters>> CacheManager::getAllItems()
+std::list<std::pair<CacheKey, Search::Parameters>> CacheManager::getAllItems()
 {
-    std::list<std::pair<CacheKey, Parameters>> result;
+    std::list<std::pair<CacheKey, Search::Parameters>> result;
 
     std::list<std::pair<CacheKey, std::shared_ptr<IndexWithMeta>>> cache_list = cache->getCacheList();
 
diff --git a/src/VectorIndex/CacheManager.h b/src/VectorIndex/CacheManager.h
index 67d6aaaf4e..3e0684e2a8 100644
--- a/src/VectorIndex/CacheManager.h
+++ b/src/VectorIndex/CacheManager.h
@@ -1,24 +1,20 @@
 #pragma once
 
+#include <functional>
+#include <list>
 #include <memory>
 #include <string>
-#include <list>
-#include <functional>
 
 #include <Common/LRUResourceCache.h>
 
-#include <VectorIndex/VectorIndex.h>
 #include <VectorIndex/VectorSegmentExecutor.h>
 
 namespace std
 {
-template<>
+template <>
 struct hash<VectorIndex::CacheKey>
 {
-    std::size_t operator()(VectorIndex::CacheKey const& key) const noexcept
-    {
-        return std::hash<std::string>{}(key.toString());
-    }
+    std::size_t operator()(VectorIndex::CacheKey const & key) const noexcept { return std::hash<std::string>{}(key.toString()); }
 };
 }
 
@@ -33,7 +29,7 @@ class IndexWithMetaWeightFunc
 public:
     size_t operator()(const IndexWithMeta & index_meta) const
     {
-        return index_meta.index->sizeInBytes();
+        return index_meta.index->getResourceUsage().memory_usage_bytes;
     }
 };
 
@@ -88,7 +84,7 @@ public:
     size_t countItem() const;
     void forceExpire(const CacheKey & cache_key);
     IndexWithMetaHolderPtr load(const CacheKey & cache_key, std::function<IndexWithMetaPtr()> load_func);
-    std::list<std::pair<CacheKey, Parameters>> getAllItems();
+    std::list<std::pair<CacheKey, Search::Parameters>> getAllItems();
 
     static CacheManager * getInstance();
     static void setCacheSize(size_t size_in_bytes);
diff --git a/src/VectorIndex/CompositeIndexReader.cpp b/src/VectorIndex/CompositeIndexReader.cpp
deleted file mode 100644
index 87d39912f5..0000000000
--- a/src/VectorIndex/CompositeIndexReader.cpp
+++ /dev/null
@@ -1,140 +0,0 @@
-#include <Compression/LZ4_decompress_faster.h>
-#include <VectorIndex/CompositeIndexReader.h>
-#include <VectorIndex/DiskIOReader.h>
-
-namespace DB::ErrorCodes
-{
-extern const int CORRUPTED_DATA;
-}
-
-namespace VectorIndex
-{
-const static UInt32 COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER = LZ4::ADDITIONAL_BYTES_AT_END_OF_BUFFER;
-
-uint32_t compressWithCheckSum(uint8_t cmb, uint8_t * source, size_t size, BinaryPtr des)
-{
-    DB::CompressionCodecPtr codec = DB::CompressionCodecFactory::instance().get(cmb);
-    size_t decompressed_size = size;
-    des->data = new uint8_t[codec->getCompressedReserveSize(decompressed_size) + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
-    /// the reserved size might be much larger than actual compressed size
-    uint32_t size_compressed
-        = codec->compress(reinterpret_cast<const char *>(source), decompressed_size, reinterpret_cast<char *>(des->data));
-    des->size = size_compressed;
-    return size_compressed;
-}
-
-/// Take the compreseed binary of index file, check the checksum, them decompress it using
-/// method provided in header to des.
-uint32_t validateAndDecompress(const BinaryPtr source, size_t uncompressed_size, uint8_t * des)
-{
-    uint8_t method = DB::ICompressionCodec::readMethod(reinterpret_cast<const char *>(source->data));
-    DB::CompressionCodecPtr codec = DB::CompressionCodecFactory::instance().get(method);
-
-    uint32_t size_decompressed
-        = codec->decompress(reinterpret_cast<const char *>(source->data), source->size, reinterpret_cast<char *>(des));
-
-    if (uncompressed_size != size_decompressed)
-    {
-        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "vector index on disk is corrupted");
-    }
-    return size_decompressed;
-}
-
-CompositeIndexReader::CompositeIndexReader(SegmentId segment_id_, int64_t original_binary_size_)
-    : segment_id(segment_id_), original_binary_size(original_binary_size_)
-{
-}
-
-void CompositeIndexReader::read_part()
-{
-    if (final_mark)
-        return;
-
-    String path = segment_id.getFullPath() + "_" + ItoS(part_count++) + VECTOR_INDEX_FILE_SUFFIX;
-    DiskIOReader reader;
-    if (!reader.open(path))
-    {
-        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "failed to open " + path);
-    }
-    BinaryPtr index_binary_compressed = std::make_shared<Binary>();
-    /// first 8 bytes is final mark, deciding if this is the last segment
-    reader.read(&final_mark, sizeof(final_mark));
-
-    /// second 8 bytes are meta recording compressed binary size of index
-    reader.seekg(sizeof(int64_t));
-    int64_t binary_length;
-    reader.read(&binary_length, sizeof(binary_length));
-    LOG_DEBUG(log, "Compressed data size: {}", binary_length);
-
-    /// third 8 bytes are meta recording uncompressed binary size of index
-    reader.seekg(sizeof(int64_t) * 2);
-    int64_t binary_length_original;
-    reader.read(&binary_length_original, sizeof(binary_length_original));
-    buffer.resize(binary_length_original + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER);
-    LOG_DEBUG(log, "Uncompressed data size: {}", binary_length_original);
-
-    /// fourth 8 bytes records total vectors stored, this is repeated many times. Could be d, or not.
-    reader.seekg(sizeof(int64_t) * 3);
-    int64_t total_vec_bin;
-    reader.read(&total_vec_bin, sizeof(total_vec_bin));
-    LOG_DEBUG(log, "Total vectors: {}", total_vec_bin);
-
-    /// finally we have the compressed binaries
-    reader.seekg(sizeof(int64_t) * 4);
-    index_binary_compressed->data = new uint8_t[binary_length + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
-    index_binary_compressed->size = binary_length;
-
-    reader.read(index_binary_compressed->data, binary_length);
-
-    validateAndDecompress(index_binary_compressed, binary_length_original, buffer.data());
-
-    current_buffer_start = current_loaded_size;
-    current_loaded_size += binary_length_original;
-    LOG_DEBUG(log, "current_buffer_start: {}, current_loaded_size: {}", current_buffer_start, current_loaded_size);
-
-    if (final_mark && current_loaded_size != original_binary_size)
-    {
-        LOG_ERROR(log, "current_loaded_size {} != original_binary_size {}", current_loaded_size, original_binary_size);
-        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "current_loaded_size != original_binary_size");
-    }
-}
-
-size_t CompositeIndexReader::operator()(void * ptr, size_t size, size_t nitems)
-{
-    size_t to_read = size * nitems;
-    size_t ret = 0;
-
-    if (to_read == 0)
-        return 0;
-
-    while (offset + to_read > static_cast<size_t>(current_loaded_size))
-    {
-        if (offset < static_cast<size_t>(current_loaded_size))
-        {
-            size_t len = current_loaded_size - offset;
-            memcpy(ptr, &buffer[offset - current_buffer_start], len);
-            offset += len;
-            ret += len;
-            to_read -= len;
-            ptr = static_cast<char *>(ptr) + len;
-        }
-        read_part();
-        if (final_mark)
-            break;
-    }
-
-    if (offset + to_read <= static_cast<size_t>(current_loaded_size))
-    {
-        memcpy(ptr, &buffer[offset - current_buffer_start], to_read);
-        offset += to_read;
-        ret += to_read;
-    }
-    if (ret == size * nitems)
-        return nitems;
-    else
-    {
-        LOG_WARNING(log, "ret {} != size {} * nitems {}", ret, size, nitems);
-        return ret / size;
-    }
-}
-}
diff --git a/src/VectorIndex/CompositeIndexReader.h b/src/VectorIndex/CompositeIndexReader.h
deleted file mode 100644
index 1215d2d112..0000000000
--- a/src/VectorIndex/CompositeIndexReader.h
+++ /dev/null
@@ -1,32 +0,0 @@
-#pragma once
-
-#include <VectorIndex/IndexReader.h>
-#include <VectorIndex/SegmentId.h>
-
-namespace VectorIndex
-{
-
-/// Put a checksum of 12 bytes at the head of binary, then append the compressed bytes.
-/// this only compress and checksum the binary index file, not including the metadata.
-uint32_t compressWithCheckSum(uint8_t cmb, uint8_t * source, size_t size, BinaryPtr des);
-
-uint32_t validateAndDecompress(const BinaryPtr source, size_t uncompressed_size, uint8_t * des);
-
-/// CompositeIndexReader reads from multiple compressed .vidx files.
-struct CompositeIndexReader : IndexReader
-{
-    SegmentId segment_id;
-    int64_t original_binary_size;
-    size_t offset = 0;
-    int part_count = 0;
-    int64_t current_buffer_start = 0;
-    int64_t current_loaded_size = 0;
-    bool final_mark = false;
-    Poco::Logger * log = &Poco::Logger::get("CompositeIndexReader");
-    std::vector<uint8_t> buffer;
-
-    CompositeIndexReader(SegmentId segment_id_, int64_t original_binary_size_);
-    void read_part();
-    size_t operator()(void * ptr, size_t size, size_t nitems) override;
-};
-}
diff --git a/src/VectorIndex/Dataset.h b/src/VectorIndex/Dataset.h
index f1f0580be7..4260548269 100644
--- a/src/VectorIndex/Dataset.h
+++ b/src/VectorIndex/Dataset.h
@@ -10,7 +10,10 @@ namespace VectorIndex
 struct VectorDataset
 {
 public:
-    VectorDataset(int64_t total_vectors_, int64_t dimension_, std::vector<float> && data): total_vectors(total_vectors_), dimension(dimension_), vec_data(std::move(data)) {}
+    VectorDataset(int64_t total_vectors_, int64_t dimension_, std::vector<float> && data)
+        : total_vectors(total_vectors_), dimension(dimension_), vec_data(std::move(data))
+    {
+    }
 
     VectorDataset(int64_t total_vectors_, int64_t dimension_, float * data_) : total_vectors(total_vectors_), dimension(dimension_)
     {
@@ -45,6 +48,26 @@ public:
         return result;
     }
 
+    void normalize()
+    {
+        for (int idx = 0; idx < total_vectors; idx++)
+        {
+            float sum = 0;
+            float * ptr = static_cast<float *>(getData() + idx * dimension);
+            for (int d = 0; d < dimension; d++)
+            {
+                sum += ptr[d] * ptr[d];
+            }
+            if (sum < std::numeric_limits<float>::epsilon())
+                continue;
+            sum = std::sqrt(sum);
+            for (int d = 0; d < dimension; d++)
+            {
+                ptr[d] /= sum;
+            }
+        }
+    }
+
 private:
     int64_t total_vectors; //size of a dataset, number of vectors
     int64_t dimension; //dimension of each vector
diff --git a/src/VectorIndex/FaissIndex.cpp b/src/VectorIndex/FaissIndex.cpp
deleted file mode 100644
index 5ab0b21654..0000000000
--- a/src/VectorIndex/FaissIndex.cpp
+++ /dev/null
@@ -1,138 +0,0 @@
-#pragma GCC diagnostic ignored "-Wreserved-identifier"
-#include "FaissIndex.h"
-#include <iostream>
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-#include "faiss/AutoTune.h"
-#include "faiss/impl/AuxIndexStructures.h"
-#include "faiss/index_io.h"
-
-namespace DB::ErrorCodes
-{
-extern const int EMPTY_DATA_PASSED;
-extern const int STD_EXCEPTION;
-extern const int INCORRECT_DISK_INDEX;
-}
-namespace VectorIndex
-{
-BinaryPtr FaissIndex::serialize(size_t max_bytes, bool & finished)
-{
-    BufferIndexWriter writer;
-    faiss::write_index_incremental(index.get(), &writer, max_bytes, finished);
-    index_size += writer.actual_size;
-    return convertStructToBinary(writer.data, writer.actual_size);
-}
-
-void FaissIndex::load(IndexReader & reader)
-{
-    try
-    {
-        index.reset(faiss::read_index(&reader));
-    }
-    catch (const std::runtime_error & e)
-    {
-        throw IndexException(DB::ErrorCodes::STD_EXCEPTION, e.what());
-    }
-    catch (const faiss::FaissException & e)
-    {
-        throw IndexException(DB::ErrorCodes::INCORRECT_DISK_INDEX, e.what());
-    }
-}
-
-void * FaissIndex::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-{
-    /// handle this pointer carefully! remember to deconstruct it somewhere
-    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
-    return new_map;
-}
-
-BinaryPtr FaissIndex::convertStructToBinary(uint8_t * index_data, uint64_t written_size)
-{
-    BinaryPtr serial_index = std::make_shared<Binary>();
-    serial_index->data = index_data;
-    serial_index->size = written_size;
-    return serial_index;
-}
-
-Parameters FaissIndex::convertParamsToMap(std::string keys)
-{
-    Parameters params;
-    std::vector<std::string> first_process;
-    std::istringstream f(keys);
-    std::string s;
-    std::string s2;
-    while (getline(f, s, ','))
-    {
-        std::istringstream f2(s);
-        while (getline(f2, s2, '='))
-        {
-            first_process.push_back(s2);
-        }
-        params.insert(std::make_pair(first_process[0], first_process[1]));
-        first_process.clear();
-    }
-    return params;
-}
-
-AccParametersPack FaissIndex::exploreTask(
-    const float * query_data,
-    const int64_t * gt,
-    int topK,
-    int query_size,
-    bool oneRecall,
-    std::mutex & m,
-    std::condition_variable & cv,
-    bool & go,
-    Poco::Logger * log)
-{
-    LOG_INFO(
-        log,
-        "Preparing auto-tune criterion {} at top {}"
-        ", with nq={}\n",
-        oneRecall ? "one Recall" : "intersection Recall",
-        topK,
-        query_size);
-
-    std::shared_ptr<faiss::AutoTuneCriterion> criterion;
-    if (oneRecall)
-    {
-        criterion = std::make_shared<faiss::OneRecallAtRCriterion>(query_size, topK);
-    }
-    else
-    {
-        criterion = std::make_shared<faiss::IntersectionCriterion>(query_size, topK);
-    }
-    criterion->set_groundtruth(topK, nullptr, gt);
-    criterion->nnn = topK;
-
-    faiss::ParameterSpace param_space;
-    //params.min_test_duration = 1;
-    param_space.initialize(index.get());
-    LOG_INFO(log, "Auto-tuning over {} parameters ({} combinations)", param_space.parameter_ranges.size(), param_space.n_combinations());
-    faiss::OperatingPoints ops;
-    param_space.explore(index.get(), query_size, query_data, *criterion, &ops, std::ref(m), std::ref(cv), std::ref(go));
-    AccParametersPack result;
-    LOG_INFO(log, "found these optimal point:");
-    for (size_t i = 0; i < ops.optimal_pts.size(); i++)
-    {
-        if (ops.optimal_pts[i].perf <= 0.1)
-        {
-            LOG_INFO(log, "acc too low: {}, skipped", ops.optimal_pts[i].perf);
-            continue;
-        }
-        LOG_INFO(log, "{}, at acc {}", ops.optimal_pts[i].key, ops.optimal_pts[i].perf);
-        Parameters params = convertParamsToMap(ops.optimal_pts[i].key);
-        result.insert(std::make_pair(ops.optimal_pts[i].perf, params));
-    }
-    return result;
-}
-
-int64_t FaissIndex::removeWithIds(int64_t n, int64_t * ids)
-{
-    faiss::IDSelectorBatch batch_selector(n, ids);
-    int64_t removed = index->remove_ids(batch_selector);
-    return removed;
-}
-
-}
diff --git a/src/VectorIndex/FaissIndex.h b/src/VectorIndex/FaissIndex.h
deleted file mode 100644
index 04b573eb9f..0000000000
--- a/src/VectorIndex/FaissIndex.h
+++ /dev/null
@@ -1,38 +0,0 @@
-#pragma once
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#include <unordered_map>
-#include <faiss/Index.h>
-#include "VectorIndex.h"
-
-
-namespace VectorIndex
-{
-#define parallel_mode_4_threadhold 16
-#define min_centroid_size 39
-class FaissIndex : public VectorIndex
-{
-public:
-    FaissIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_) : VectorIndex(it_, im_, me_, dimension_) { }
-    virtual BinaryPtr serialize(size_t max_bytes, bool & finished) override;
-    void load(IndexReader & reader) override;
-    int64_t removeWithIds(int64_t n, int64_t * ids) override;
-    AccParametersPack exploreTask(
-        const float * query_data,
-        const int64_t * gt,
-        int topK,
-        int query_size,
-        bool oneRecall,
-        std::mutex & m,
-        std::condition_variable & cv,
-        bool & go,
-        Poco::Logger * log) override;
-    std::shared_ptr<faiss::Index> index = nullptr;
-
-protected:
-    void * convertInnerBitMap(GeneralBitMapPtr sharedPtr) override;
-    BinaryPtr convertStructToBinary(uint8_t * index_data, uint64_t written_size) override;
-    Parameters convertParamsToMap(std::string keys);
-};
-
-}
diff --git a/src/VectorIndex/FlatIndex.cpp b/src/VectorIndex/FlatIndex.cpp
deleted file mode 100644
index 4feae15e7f..0000000000
--- a/src/VectorIndex/FlatIndex.cpp
+++ /dev/null
@@ -1,101 +0,0 @@
-#include "FlatIndex.h"
-#include <base/logger_useful.h>
-#include "CacheManager.h"
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-#include "faiss/index_io.h"
-#include <VectorIndex/VectorIndexCommon.h>
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-}
-
-namespace VectorIndex
-{
-void FlatIndex::train(VectorDatasetPtr dataset, int64_t total)
-{
-    reinterpret_cast<faiss::IndexFlatFilter *>(index.get())->reserve(total);
-}
-
-void FlatIndex::addWithoutId(VectorDatasetPtr dataset)
-{
-    if (index != nullptr)
-    {
-        index->add(dataset->getVectorNum(), dataset->getData());
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-void FlatIndex::search(
-    const VectorDatasetPtr dataset,
-    const int32_t topK,
-    float * distances,
-    int64_t * result_id,
-    Parameters & /*param*/,
-    GeneralBitMapPtr filter)
-{
-    Poco::Logger * log = &Poco::Logger::get("FlatIndex");
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not intialized");
-    }
-    faiss::bitMapPtr inner_bit_map = std::shared_ptr<faiss::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<faiss::bitMap *>(convertInnerBitMap(filter)));
-
-    int32_t num_query = dataset->getVectorNum();
-    float * query_datas = dataset->getData();
-
-    LOG_DEBUG(log, "Raw data size: {}", reinterpret_cast<faiss::IndexFlatFilter *>(index.get())->xb.size());
-
-    reinterpret_cast<faiss::IndexFlatFilter *>(index.get())
-        ->search(num_query, query_datas, topK, distances, result_id, inner_bit_map.get());
-}
-
-VectorDatasetPtr FlatIndex::getInMemVectors()
-{
-    VectorDatasetPtr data = std::make_shared<VectorDataset>(
-        reinterpret_cast<faiss::IndexFlatFilter *>(index.get())->xb.size() / dimension,
-        dimension,
-        reinterpret_cast<faiss::IndexFlatFilter *>(index.get())->xb.data());
-    return data;
-}
-
-void FlatIndex::getMyParameters(Parameters params)
-{
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::FLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-
-bool FlatIndex::compare(const VectorIndex & other)
-{
-    const FlatIndex * other_p = dynamic_cast<const FlatIndex *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    return true;
-}
-/*
-void FlatIndex::remove(const int32_t * ids)
-{
-}
-*/
-
-}
diff --git a/src/VectorIndex/FlatIndex.h b/src/VectorIndex/FlatIndex.h
deleted file mode 100644
index 9cb21c4d08..0000000000
--- a/src/VectorIndex/FlatIndex.h
+++ /dev/null
@@ -1,60 +0,0 @@
-#pragma once
-
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#include <faiss/IndexFlatFilter.h>
-#include <faiss/index_io.h>
-#include <faiss/utils/bitMap.h>
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-#include "FaissIndex.h"
-#include "IndexException.h"
-
-namespace VectorIndex
-{
-class FlatIndex : public FaissIndex
-{
-public:
-    FlatIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters) : FaissIndex(it_, im_, me_, dimension_)
-    {
-        faiss::MetricType metrictype;
-        switch (me)
-        {
-            case Metrics::L2:
-                metrictype = faiss::METRIC_L2;
-                break;
-            case Metrics::IP:
-                metrictype = faiss::METRIC_INNER_PRODUCT;
-                break;
-            case Metrics::Cosine:
-                metrictype = faiss::METRIC_Cosine;
-        }
-        getMyParameters(parameters);
-        index = std::make_shared<faiss::IndexFlatFilter>(dimension_, metrictype);
-    }
-
-    void train(const VectorDatasetPtr dataset, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-        override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    void getMyParameters(Parameters params) override;
-
-    bool compare(const VectorIndex & other) override;
-};
-}
diff --git a/src/VectorIndex/GeneralBitMap.h b/src/VectorIndex/GeneralBitMap.h
deleted file mode 100644
index 9a737f138e..0000000000
--- a/src/VectorIndex/GeneralBitMap.h
+++ /dev/null
@@ -1,74 +0,0 @@
-#pragma once
-
-#include <cstring>
-#include <memory>
-#include <base/logger_useful.h>
-namespace VectorIndex
-{
-class GeneralBitMap
-{
-    /// The General form of bitmap which will be used by Clickhouse,
-    /// since any user-defined index form may have its own bitmap format,
-    /// the user shall define the convertInnerBitMap.
-    /// The bitmap marks available items as 1, unavailable items as 0.
-public:
-    GeneralBitMap() = default;
-
-    explicit GeneralBitMap(int64_t size_)
-    {
-        size = size_;
-        int bytes_count = (size >> 3) + 1; /// size/8 = bytes
-        bitmap = new char[bytes_count];
-        memset(bitmap, 0, bytes_count);
-    }
-
-    int32_t get_size() { return size; }
-
-    bool test(int32_t id)
-    {
-        // TODO should we verify id <=size ?
-        return (bitmap[id >> 3] & (0x1 << (id & 0x7)));
-    }
-
-    void set(int32_t id) { bitmap[id >> 3] |= (0x1 << (id & 0x7)); }
-
-    void unset(int64_t id) { bitmap[id >> 3] &= ~(0x1 << (id & 0x7)); }
-
-    bool any()
-    {
-        int bytes_count = (size >> 3) + 1; /// size/8 = bytes
-        for(int i = 0; i < bytes_count; ++i)
-        {
-            if (bitmap[i])
-                return true;
-        }
-        return false;
-    }
-
-    /// Set bit corresponding to a region, this is much faster than set(),
-    /// but can introduce up to 14 items been wrongly set at the margins.
-    void set_range(int64_t start_id, int64_t end_id)
-    {
-        int64_t range = (end_id - start_id) / 8 + 1;
-        int64_t start_byte = start_id / 8;
-        memset(bitmap + start_byte, 255, range);
-    }
-
-    /// There are two inner bitmap in faiss and hnsw, they mimic this
-    /// structure but don't free that char* at deallocation; rather, it's freed by this
-    /// bitmap at the outer layer.
-    ~GeneralBitMap()
-    {
-        if (bitmap)
-        {
-            LOG_DEBUG(&Poco::Logger::get("GeneralBitMap"), "delete bitmap");
-            delete[] bitmap;
-        }
-    }
-
-    char * bitmap;
-    int32_t size;
-};
-
-using GeneralBitMapPtr = std::shared_ptr<GeneralBitMap>;
-}
diff --git a/src/VectorIndex/HNSWIndex.cpp b/src/VectorIndex/HNSWIndex.cpp
deleted file mode 100644
index 2ce744445e..0000000000
--- a/src/VectorIndex/HNSWIndex.cpp
+++ /dev/null
@@ -1,238 +0,0 @@
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wint-to-pointer-cast"
-#pragma GCC diagnostic pop
-
-#include "HNSWIndex.h"
-#include <omp.h>
-#include <base/logger_useful.h>
-#include "IndexException.h"
-#include <VectorIndex/VectorIndexCommon.h>
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-extern const int EMPTY_DATA_PASSED;
-}
-
-namespace VectorIndex
-{
-void HNSWIndex::train(const VectorDatasetPtr dataset, int64_t total)
-{
-    hnswlib::SpaceInterface<float> * space;
-    switch (me)
-    {
-        case (Metrics::L2):
-            space = new hnswlib::L2Space(dimension);
-            break;
-        case (Metrics::IP):
-            space = new hnswlib::InnerProductSpace(dimension);
-            break;
-        case (Metrics::Cosine):
-            space = new hnswlib::CosineSpace(dimension);
-    }
-    //TODO configure this, dynamic max_element
-    max_element = total;
-    index = std::make_shared<hnswlib::HierarchicalNSW<float>>(space, max_element, neighbor, ef_c);
-}
-
-void HNSWIndex::addWithoutId(const VectorDatasetPtr dataset)
-{
-    if (index != nullptr)
-    {
-        int total_vectors = dataset->getVectorNum();
-        float * __restrict data_grid = dataset->getData();
-        int dim = dataset->getDimension();
-        //TODO add omp resource control
-        size_t current = index->cur_element_count;
-        LOG_TRACE(log, "current: {}", current);
-#pragma omp parallel for
-        for (int i = 0; i < total_vectors; i++)
-        {
-            index->addPoint(data_grid + i * dim, current + i);
-        }
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-void HNSWIndex::search(
-    const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-{
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not initialized");
-    }
-    int total_vectors = dataset->getVectorNum();
-    float * __restrict data_grid = dataset->getData();
-    int dim = dataset->getDimension();
-    hnswlib::bitMapPtr inner_bit_map = std::shared_ptr<hnswlib::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<hnswlib::bitMap *>(convertInnerBitMap(filter)));
-    //TODO add omp resource control
-    LOG_DEBUG(log, "Current element count:{}, max:{}", index->cur_element_count, index->max_elements_);
-    int ef_s = 50;
-    if (params.contains("ef_s"))
-    {
-        ef_s = StoI(params.find("ef_s")->second);
-        params.erase("ef_s");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::HNSWFLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-    int num_thread = 1;
-    if (total_vectors > 1)
-    {
-        num_thread = std::max(1, (num_thread_for_vector / count.load()));
-    }
-#pragma omp parallel for schedule(dynamic) num_threads(num_thread)
-    for (int i = 0; i < total_vectors; ++i)
-    {
-        //TODO might not need to be closer first here
-        auto result = index->searchKnnCloserFirst(data_grid + i * dim, topK, ef_s, inner_bit_map.get());
-        // size_t missing_k = topK - result.size();
-        //this part fills correct results
-        for (size_t j = 0; j < result.size(); ++j)
-        {
-            distances[i * topK + j] = result[j].first;
-            result_id[i * topK + j] = result[j].second;
-        }
-        //this part fills missing results if result size < kzw
-        for (size_t j = result.size(); j < topK; j++)
-        {
-            distances[i * topK + j] = -1;
-            result_id[i * topK + j] = -1;
-        }
-    }
-}
-
-BinaryPtr HNSWIndex::serialize(size_t max_bytes_to_serialize, bool & finished)
-{
-    BufferIndexWriter writer;
-    index->saveIndex(writer, max_bytes_to_serialize, finished);
-    index_size += writer.actual_size;
-    return convertStructToBinary(writer.data, writer.actual_size);
-}
-
-
-void HNSWIndex::load(IndexReader & reader)
-{
-    hnswlib::SpaceInterface<float> * space;
-    switch (me)
-    {
-        case (Metrics::L2):
-            space = new hnswlib::L2Space(dimension);
-            break;
-        case (Metrics::IP):
-            space = new hnswlib::InnerProductSpace(dimension);
-            break;
-        case (Metrics::Cosine):
-            space = new hnswlib::CosineSpace(dimension);
-    }
-    index = std::make_shared<hnswlib::HierarchicalNSW<float>>(space);
-    index->loadIndex(reader, space);
-}
-
-void * HNSWIndex::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-{
-    /// handle this pointer carefully! remember to deconstruct it somewhere
-    hnswlib::bitMap * new_map = new hnswlib::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
-    return new_map;
-}
-
-BinaryPtr HNSWIndex::convertStructToBinary(uint8_t * index_data, uint64_t written_size)
-{
-    BinaryPtr serial_index = std::make_shared<Binary>();
-    serial_index->data = index_data;
-    serial_index->size = written_size;
-    return serial_index;
-}
-
-VectorDatasetPtr HNSWIndex::getInMemVectors()
-{
-    return nullptr;
-}
-
-AccParametersPack HNSWIndex::exploreTask(
-    const float * query_data,
-    const int64_t * gt,
-    int topK,
-    int query_size,
-    bool oneRecall,
-    std::mutex & m,
-    std::condition_variable & cv,
-    bool & go,
-    Poco::Logger * log)
-{
-    ///TODO implement
-    return AccParametersPack();
-}
-
-void HNSWIndex::getMyParameters(Parameters params)
-{
-    if (params.contains("m"))
-    {
-        neighbor = StoI(params.find("m")->second);
-        params.erase("m");
-    }
-    if (params.contains("ef_c"))
-    {
-        ef_c = StoI(params.find("ef_c")->second);
-        params.erase("ef_c");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::HNSWFLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-
-int64_t HNSWIndex::removeWithIds(int64_t n, int64_t * ids)
-{
-#pragma omp parallel for
-    for (int64_t i = 0; i < n; i++)
-    {
-        index->markDelete(ids[i]);
-    }
-    /// HNSW does mark for delete, so it will delete required number of items
-    return n;
-}
-
-bool HNSWIndex::compare(const VectorIndex & other)
-{
-    const HNSWIndex * other_p = dynamic_cast<const HNSWIndex *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->ef_c != ef_c)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->neighbor != neighbor)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    return true;
-}
-
-}
diff --git a/src/VectorIndex/HNSWIndex.h b/src/VectorIndex/HNSWIndex.h
deleted file mode 100644
index a7311c03e0..0000000000
--- a/src/VectorIndex/HNSWIndex.h
+++ /dev/null
@@ -1,76 +0,0 @@
-#pragma once
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#pragma GCC diagnostic ignored "-Wint-to-pointer-cast"
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-#include "VectorIndex.h"
-#include "hnswlib/hnswalg.h"
-
-namespace VectorIndex
-{
-class HNSWIndex : public VectorIndex
-{
-public:
-    HNSWIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters) : VectorIndex(it_, im_, me_, dimension_)
-    {
-        getMyParameters(parameters);
-    }
-
-    void train(const VectorDatasetPtr, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & param, GeneralBitMapPtr filter)
-        override;
-
-    int64_t removeWithIds(int64_t n, int64_t * ids) override;
-
-    BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override;
-
-    void load(IndexReader & reader) override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    /// When index is neither held by an explicit pointer or held in cache,
-    /// it'll destruct automatically.
-    std::shared_ptr<hnswlib::HierarchicalNSW<float>> index = nullptr;
-
-    void getMyParameters(Parameters params) override;
-
-    AccParametersPack exploreTask(
-        const float * query_data,
-        const int64_t * gt,
-        int topK,
-        int query_size,
-        bool oneRecall,
-        std::mutex & m,
-        std::condition_variable & cv,
-        bool & go,
-        Poco::Logger * log) override;
-
-    bool compare(const VectorIndex & other) override;
-
-
-private:
-    int max_element;
-    int neighbor = 16;
-    int ef_c = 100;
-
-    Poco::Logger * log = &Poco::Logger::get("HNSW");
-
-    void * convertInnerBitMap(GeneralBitMapPtr sharedPtr) override;
-    BinaryPtr convertStructToBinary(uint8_t * index_data, uint64_t written_size) override;
-};
-}
diff --git a/src/VectorIndex/HNSWPQ.cpp b/src/VectorIndex/HNSWPQ.cpp
deleted file mode 100644
index 3ec54fe3bd..0000000000
--- a/src/VectorIndex/HNSWPQ.cpp
+++ /dev/null
@@ -1,242 +0,0 @@
-#include "HNSWPQ.h"
-#include <faiss/index_io.h>
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-#include <VectorIndex/VectorIndexCommon.h>
-
-namespace VectorIndex
-{
-HNSWpq::HNSWpq(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters) : VectorIndex(it_, im_, me_, dimension_)
-{
-    faiss::MetricType metrictype;
-
-    getMyParameters(parameters);
-    switch (me)
-    {
-        case (Metrics::L2):
-            metrictype = faiss::METRIC_L2;
-            break;
-        case (Metrics::IP):
-            metrictype = faiss::METRIC_INNER_PRODUCT;
-            break;
-        case (Metrics::Cosine):
-            metrictype = faiss::METRIC_Cosine;
-    }
-
-    if (dimension == -1)
-    {
-        dimension = pq_m;
-    }
-    index = std::make_shared<faiss::IndexHNSWfastPQ>(dimension, pq_m, bit_size, neighbor, metrictype);
-    index->hnsw.efConstruction = ef_c;
-    index->own_fields = true;
-}
-
-void HNSWpq::train(const VectorDatasetPtr dataset, int64_t total)
-{
-    if (index != nullptr)
-    {
-        index->init_hnsw(total);
-        index->train(dataset->getVectorNum(), dataset->getData());
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "train: index not intialized");
-    }
-}
-
-void HNSWpq::addWithoutId(VectorDatasetPtr dataset)
-{
-    if (index != nullptr)
-    {
-        index->add(dataset->getVectorNum(), dataset->getData());
-        total_vector += dataset->getVectorNum();
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-void HNSWpq::search(
-    const VectorDatasetPtr dataset,
-    const int32_t topK,
-    float * distances,
-    int64_t * result_id,
-    Parameters & params,
-    GeneralBitMapPtr filter)
-{
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not intialized");
-    }
-
-    faiss::bitMapPtr inner_bit_map = std::shared_ptr<faiss::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<faiss::bitMap *>(convertInnerBitMap(filter)));
-    int32_t num_query = dataset->getVectorNum();
-    float * query_datas = dataset->getData();
-
-    //TODO make dynamic or user defined
-    int64_t ef_s = topK;
-    if (params.contains("ef_s"))
-    {
-        ef_s = std::max(ef_s, StoI(params.find("ef_s")->second));
-        params.erase("ef_s");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::HNSWPQ);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-    int num_thread = 1;
-    if (num_query > 1)
-    {
-        num_thread = std::max(1, (num_thread_for_vector / count.load()));
-    }
-    omp_set_num_threads(num_thread);
-    index->search(num_query, query_datas, topK, distances, result_id, ef_s, inner_bit_map.get());
-    //distance might not be useful in many cases
-}
-
-BinaryPtr HNSWpq::serialize(size_t max_bytes_to_serialize, bool & finished)
-{
-    BufferIndexWriter writer;
-    faiss::write_index_incremental(index.get(), &writer, max_bytes_to_serialize, finished);
-    index_size += writer.actual_size;
-    return convertStructToBinary(writer.data, writer.actual_size);
-}
-
-void HNSWpq::load(IndexReader & reader)
-{
-    try
-    {
-        index.reset(reinterpret_cast<faiss::IndexHNSWfastPQ *>(faiss::read_index(&reader)));
-    }
-    catch (const std::runtime_error & e)
-    {
-        throw IndexException(DB::ErrorCodes::STD_EXCEPTION, e.what());
-    }
-    catch (const faiss::FaissException & e)
-    {
-        throw IndexException(DB::ErrorCodes::INCORRECT_DISK_INDEX, e.what());
-    }
-}
-
-void * HNSWpq::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-{
-    /// handle this pointer carefully! remember to deconstruct it somewhere
-    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
-    return new_map;
-}
-
-BinaryPtr HNSWpq::convertStructToBinary(uint8_t * index_data, uint64_t written_size)
-{
-    BinaryPtr serial_index = std::make_shared<Binary>();
-    serial_index->data = index_data;
-    serial_index->size = written_size;
-    return serial_index;
-}
-
-void HNSWpq::getMyParameters(Parameters p)
-{
-    if (p.contains("ef_c"))
-    {
-        ef_c = StoI(p.find("ef_c")->second);
-        p.erase("ef_c");
-    }
-    if (p.contains("pq_m"))
-    {
-        pq_m = StoI(p.find("pq_m")->second);
-        p.erase("pq_m");
-    }
-    if (p.contains("m"))
-    {
-        neighbor = StoI(p.find("m")->second);
-        p.erase("m");
-    }
-    if (p.contains("bit_size"))
-    {
-        bit_size = StoI(p.find("bit_size")->second);
-        p.erase("bit_size");
-    }
-    if (p.contains("metric_type"))
-    {
-        p.erase("metric_type");
-    }
-    if (!p.empty())
-    {
-        std::string message = generateUnsupportedParameters(p, IndexType::HNSWPQ);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-VectorDatasetPtr HNSWpq::getInMemVectors()
-{
-    return nullptr;
-}
-
-AccParametersPack HNSWpq::exploreTask(
-    const float * query_data,
-    const int64_t * gt,
-    int topK,
-    int query_size,
-    bool oneRecall,
-    std::mutex & m,
-    std::condition_variable & cv,
-    bool & go,
-    Poco::Logger * log)
-{
-    (void)query_data;
-    (void)gt;
-    (void)topK;
-    (void)query_size;
-    (void)oneRecall;
-    (void)m;
-    (void)cv;
-    (void)go;
-    (void)log;
-    return AccParametersPack();
-}
-
-int64_t HNSWpq::removeWithIds(int64_t n, int64_t * ids)
-{
-    faiss::IDSelectorBatch batch_selector(n, ids);
-    int64_t removed = index->remove_ids(batch_selector);
-    return removed;
-}
-
-bool HNSWpq::compare(const VectorIndex & other)
-{
-    const HNSWpq * other_p = dynamic_cast<const HNSWpq *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->bit_size != bit_size)
-    {
-        return false;
-    }
-    if (other_p->pq_m != pq_m)
-    {
-        return false;
-    }
-    if (other_p->ef_c != ef_c)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    return true;
-}
-
-}
diff --git a/src/VectorIndex/HNSWPQ.h b/src/VectorIndex/HNSWPQ.h
deleted file mode 100644
index 839fdc07e1..0000000000
--- a/src/VectorIndex/HNSWPQ.h
+++ /dev/null
@@ -1,79 +0,0 @@
-#pragma once
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#include <faiss/IndexHNSWfast.h>
-#include "IndexException.h"
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-#include "VectorIndex.h"
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-extern const int EMPTY_DATA_PASSED;
-extern const int STD_EXCEPTION;
-extern const int INCORRECT_DISK_INDEX;
-}
-
-namespace VectorIndex
-{
-class HNSWpq : public VectorIndex
-{
-public:
-    HNSWpq(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters);
-
-    void train(const VectorDatasetPtr, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    int64_t removeWithIds(int64_t n, int64_t * ids) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & param, GeneralBitMapPtr filter)
-        override;
-
-    BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override;
-
-    void load(IndexReader & reader) override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    /// When index is neither held by an explicit pointer or held in cache,
-    /// it'll destruct automatically.
-    std::shared_ptr<faiss::IndexHNSWfastPQ> index = nullptr;
-
-    void getMyParameters(Parameters p) override;
-
-    AccParametersPack exploreTask(
-        const float * query_data,
-        const int64_t * gt,
-        int topK,
-        int query_size,
-        bool oneRecall,
-        std::mutex & m,
-        std::condition_variable & cv,
-        bool & go,
-        Poco::Logger * log) override;
-
-    bool compare(const VectorIndex & other) override;
-
-private:
-    int neighbor = 16;
-    int ef_c = 100;
-    int pq_m = 8;
-    int bit_size = 8;
-    void * convertInnerBitMap(GeneralBitMapPtr sharedPtr) override;
-    BinaryPtr convertStructToBinary(uint8_t * index_data, uint64_t written_size) override;
-};
-}
diff --git a/src/VectorIndex/HNSWSQ.cpp b/src/VectorIndex/HNSWSQ.cpp
deleted file mode 100644
index e672637c6c..0000000000
--- a/src/VectorIndex/HNSWSQ.cpp
+++ /dev/null
@@ -1,277 +0,0 @@
-#include "HNSWSQ.h"
-#include <VectorIndex/VectorIndexCommon.h>
-#include <faiss/index_io.h>
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-extern const int EMPTY_DATA_PASSED;
-extern const int STD_EXCEPTION;
-extern const int INCORRECT_DISK_INDEX;
-}
-
-namespace VectorIndex
-{
-HNSWsq::HNSWsq(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters) : VectorIndex(it_, im_, me_, dimension_)
-{
-    faiss::MetricType metrictype;
-
-    getMyParameters(parameters);
-    switch (me)
-    {
-        case (Metrics::L2):
-            metrictype = faiss::METRIC_L2;
-            break;
-        case (Metrics::IP):
-            metrictype = faiss::METRIC_INNER_PRODUCT;
-            break;
-        case (Metrics::Cosine):
-            // metrictype = faiss::METRIC_Cosine;
-            throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, "unsupported metric_type COSINE");
-    }
-    index = std::make_shared<faiss::IndexHNSWfastSQ>(dimension, quantizer, neighbor, metrictype);
-    index->hnsw.efConstruction = ef_c;
-    index->own_fields = true;
-}
-
-void HNSWsq::train(const VectorDatasetPtr dataset, int64_t total)
-{
-    if (index != nullptr)
-    {
-        index->init_hnsw(total);
-        index->train(dataset->getVectorNum(), dataset->getData());
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "train: index not intialized");
-    }
-}
-
-void HNSWsq::addWithoutId(VectorDatasetPtr dataset)
-{
-    if (index != nullptr)
-    {
-        index->add(dataset->getVectorNum(), dataset->getData());
-        total_vector += dataset->getVectorNum();
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-void HNSWsq::search(
-    const VectorDatasetPtr dataset,
-    const int32_t topK,
-    float * distances,
-    int64_t * result_id,
-    Parameters & params,
-    GeneralBitMapPtr filter)
-{
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not intialized");
-    }
-
-    faiss::bitMapPtr inner_bit_map = std::shared_ptr<faiss::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<faiss::bitMap *>(convertInnerBitMap(filter)));
-    int32_t num_query = dataset->getVectorNum();
-    float * query_datas = dataset->getData();
-
-    //TODO make dynamic or user defined
-    int64_t ef_s = topK;
-    if (params.contains("ef_s"))
-    {
-        ef_s = std::max(ef_s, StoI(params.find("ef_s")->second));
-        params.erase("ef_s");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::HNSWSQ);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-    int num_thread = 1;
-    if (num_query > 1)
-    {
-        num_thread = std::max(1, (num_thread_for_vector / count.load()));
-    }
-    omp_set_num_threads(num_thread);
-    index->search(num_query, query_datas, topK, distances, result_id, ef_s, inner_bit_map.get());
-    //distance might not be useful in many cases
-}
-
-BinaryPtr HNSWsq::serialize(size_t max_bytes_to_serialize, bool & finished)
-{
-    BufferIndexWriter writer;
-    faiss::write_index_incremental(index.get(), &writer, max_bytes_to_serialize, finished);
-    index_size += writer.actual_size;
-    return convertStructToBinary(writer.data, writer.actual_size);
-}
-
-
-void HNSWsq::load(IndexReader & reader)
-{
-    try
-    {
-        index.reset(reinterpret_cast<faiss::IndexHNSWfastSQ *>(faiss::read_index(&reader)));
-    }
-    catch (const std::runtime_error & e)
-    {
-        throw IndexException(DB::ErrorCodes::STD_EXCEPTION, e.what());
-    }
-    catch (const faiss::FaissException & e)
-    {
-        throw IndexException(DB::ErrorCodes::INCORRECT_DISK_INDEX, e.what());
-    }
-}
-
-void * HNSWsq::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-{
-    /// handle this pointer carefully! remember to deconstruct it somewhere
-    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
-    return new_map;
-}
-
-BinaryPtr HNSWsq::convertStructToBinary(uint8_t * index_data, uint64_t written_size)
-{
-    BinaryPtr serial_index = std::make_shared<Binary>();
-    serial_index->data = index_data;
-    serial_index->size = written_size;
-    return serial_index;
-}
-
-void HNSWsq::getMyParameters(Parameters p)
-{
-    if (p.contains("ef_c"))
-    {
-        ef_c = StoI(p.find("ef_c")->second);
-        p.erase("ef_c");
-    }
-    if (p.contains("m"))
-    {
-        neighbor = StoI(p.find("m")->second);
-        p.erase("m");
-    }
-    if (p.contains("bit_size"))
-    {
-        String bits = p.find("bit_size")->second;
-        quantizer = parse_SQ_string(bits);
-        p.erase("bit_size");
-    }
-    if (p.contains("metric_type"))
-    {
-        p.erase("metric_type");
-    }
-    if (!p.empty())
-    {
-        std::string message = generateUnsupportedParameters(p, IndexType::HNSWSQ);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-VectorDatasetPtr HNSWsq::getInMemVectors()
-{
-    return nullptr;
-}
-
-AccParametersPack HNSWsq::exploreTask(
-    const float * query_data,
-    const int64_t * gt,
-    int topK,
-    int query_size,
-    bool oneRecall,
-    std::mutex & m,
-    std::condition_variable & cv,
-    bool & go,
-    Poco::Logger * log)
-{
-    (void)query_data;
-    (void)gt;
-    (void)topK;
-    (void)query_size;
-    (void)oneRecall;
-    (void)m;
-    (void)cv;
-    (void)go;
-    (void)log;
-    return AccParametersPack();
-}
-faiss::ScalarQuantizer::QuantizerType HNSWsq::parse_SQ_string(String bits)
-{
-    if (bits == "8bit")
-    {
-        return faiss::ScalarQuantizer::QT_8bit;
-    }
-    else if (bits == "6bit")
-    {
-        return faiss::ScalarQuantizer::QT_6bit;
-    }
-    else if (bits == "4bit")
-    {
-        return faiss::ScalarQuantizer::QT_4bit;
-    }
-    else if (bits == "8bit_uniform")
-    {
-        return faiss::ScalarQuantizer::QT_8bit_uniform;
-    }
-    //    else if (bits == "8bit_direct")
-    //    {
-    //        return faiss::ScalarQuantizer::QT_8bit_direct;
-    //    }
-    else if (bits == "4bit_uniform")
-    {
-        return faiss::ScalarQuantizer::QT_4bit_uniform;
-    }
-    else if (bits == "QT_fp16")
-    {
-        return faiss::ScalarQuantizer::QT_fp16;
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, "unsupported QT bit size in HNSWSQ: {}", bits);
-    }
-}
-
-int64_t HNSWsq::removeWithIds(int64_t n, int64_t * ids)
-{
-    faiss::IDSelectorBatch batch_selector(n, ids);
-    int64_t removed = index->remove_ids(batch_selector);
-    return removed;
-}
-
-bool HNSWsq::compare(const VectorIndex & other)
-{
-    const HNSWsq * other_p = dynamic_cast<const HNSWsq *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->quantizer != quantizer)
-    {
-        return false;
-    }
-    if (other_p->ef_c != ef_c)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    return true;
-}
-
-
-}
diff --git a/src/VectorIndex/HNSWSQ.h b/src/VectorIndex/HNSWSQ.h
deleted file mode 100644
index 5df28f36b4..0000000000
--- a/src/VectorIndex/HNSWSQ.h
+++ /dev/null
@@ -1,72 +0,0 @@
-#pragma once
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#include <faiss/IndexHNSWfast.h>
-#include "IndexException.h"
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-#include "IndexException.h"
-#include "VectorIndex.h"
-
-namespace VectorIndex
-{
-class HNSWsq : public VectorIndex
-{
-public:
-    HNSWsq(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters);
-
-    void train(const VectorDatasetPtr, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    int64_t removeWithIds(int64_t n, int64_t * ids) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & param, GeneralBitMapPtr filter)
-        override;
-
-    BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) override; //searilize index
-
-    void load(IndexReader & reader) override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    /// When index is neither held by an explicit pointer or held in cache,
-    /// it'll destruct automatically.
-    std::shared_ptr<faiss::IndexHNSWfastSQ> index = nullptr;
-
-    void getMyParameters(Parameters params) override;
-
-    AccParametersPack exploreTask(
-        const float * query_data,
-        const int64_t * gt,
-        int topK,
-        int query_size,
-        bool oneRecall,
-        std::mutex & m,
-        std::condition_variable & cv,
-        bool & go,
-        Poco::Logger * log) override;
-
-    bool compare(const VectorIndex & other) override;
-
-private:
-    int neighbor = 16;
-    int ef_c = 100;
-    faiss::ScalarQuantizer::QuantizerType quantizer = faiss::ScalarQuantizer::QT_8bit;
-
-    void * convertInnerBitMap(GeneralBitMapPtr sharedPtr) override;
-    BinaryPtr convertStructToBinary(uint8_t * index_data, uint64_t written_size) override;
-    faiss::ScalarQuantizer::QuantizerType parse_SQ_string(String bits);
-};
-}
diff --git a/src/VectorIndex/IVFFlatIndex.cpp b/src/VectorIndex/IVFFlatIndex.cpp
deleted file mode 100644
index 5564c7987a..0000000000
--- a/src/VectorIndex/IVFFlatIndex.cpp
+++ /dev/null
@@ -1,296 +0,0 @@
-#include "IVFFlatIndex.h"
-#include <iostream>
-#include <omp.h>
-#include <base/logger_useful.h>
-#include "BruteForceSearch.h"
-#include "CacheManager.h"
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-#include "faiss/impl/AuxIndexStructures.h"
-#include "faiss/index_io.h"
-#include "faiss/profile.h"
-#include <VectorIndex/VectorIndexCommon.h>
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-extern const int INCORRECT_INDEX;
-}
-
-namespace VectorIndex
-{
-
-void IVFFlatIndex::train(const VectorDatasetPtr dataset, int64_t total)
-{
-    faiss::MetricType metrictype;
-    switch (me)
-    {
-        case Metrics::L2:
-            metrictype = faiss::METRIC_L2;
-            break;
-        case Metrics::IP:
-            metrictype = faiss::METRIC_INNER_PRODUCT;
-            break;
-        case Metrics::Cosine:
-            metrictype = faiss::METRIC_Cosine;
-    }
-    faiss::IndexFlat * coarse_quantizer = new faiss::IndexFlat(dimension, metrictype);
-    int nlist = ncentroids > dataset->getVectorNum() / min_centroid_size ? dataset->getVectorNum() / min_centroid_size : ncentroids;
-    nlist = std::max(1, nlist);
-    LOG_DEBUG(log, "Train index: nlist: {}", nlist);
-    index = std::make_shared<faiss::IndexIVFFlatFilter>(coarse_quantizer, dimension, nlist, metrictype);
-    faiss::IndexIVFFlatFilter * ivfflat = reinterpret_cast<faiss::IndexIVFFlatFilter *>(index.get());
-    ivfflat->own_fields = true;
-    if (profiler)
-    {
-        ivfflat->set_tune_mode();
-        ivfflat->train(dataset->getVectorNum(), dataset->getData());
-        ivfflat->set_tune_off();
-    }
-    else
-    {
-        LOG_DEBUG(log, "Profiler is false, vector num: {}", dataset->getVectorNum());
-        ivfflat->train(dataset->getVectorNum(), dataset->getData());
-    }
-}
-
-void IVFFlatIndex::addWithoutId(VectorDatasetPtr dataset)
-{
-    /// we skip the first add in IVFFlat, becuase we did it already in training.
-    if (index != nullptr)
-    {
-        int64_t * ids = new int64_t[dataset->getVectorNum()];
-        for (int i = 0; i < dataset->getVectorNum(); i++)
-        {
-            ids[i] = total_vector + i;
-        }
-        index->add_with_ids(dataset->getVectorNum(), dataset->getData(), ids);
-        total_vector += dataset->getVectorNum();
-        delete[] ids;
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-
-void IVFFlatIndex::search(
-    const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-{
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not intialized");
-    }
-    auto * index_real = reinterpret_cast<faiss::IndexIVFFlatFilter *>(index.get());
-
-    faiss::bitMapPtr inner_bit_map = std::shared_ptr<faiss::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<faiss::bitMap *>(convertInnerBitMap(filter)));
-    int32_t num_query = dataset->getVectorNum();
-    float * query_datas = dataset->getData();
-
-    int nprobe = 1;
-    float acc = -1;
-    if (params.contains("nprobe"))
-    {
-        nprobe = StoI(params.find("nprobe")->second);
-        params.erase("nprobe");
-        /// TODO: we want to scale down the nprobe by the proportion of nlist scale down.
-        /// nprobe = std::max(1, static_cast<int>(nprobe * (static_cast<float>(index_real->nlist) / ncentroids)));
-    }
-    /// we can only have one of nprobe or acc, not both.
-    else if (params.contains("acc"))
-    {
-        acc = StoF(params.find("acc")->second);
-        params.erase("acc");
-        if (!index_real->tuned)
-        {
-            throw IndexException(DB::ErrorCodes::INCORRECT_INDEX, "autotune is off, turn on profiler and rebuild index");
-        }
-        if (acc < 0 || acc > 1)
-        {
-            throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, "invalid acc {} for autotune", acc);
-        }
-        if (!index_real->tuned)
-        {
-            LOG_WARNING(log, "The index is too small to be tuned, not using accuracy bounding.");
-            nprobe = INT32_MAX; ///since the datapart is too small, we might just search its entirety.
-        }
-    } 
-    if (params.contains("metric_type"))
-    {
-        /// simply ignore it
-        params.erase("metric_type");
-    }
-    
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::IVFFLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-    faiss::IVFSearchParameters ivf_params;
-    int current_running_task = count.load(std::memory_order_relaxed);
-    /// when we don't have acc bounding to do, we follow normal search route.
-    if (acc == -1 || !index_real->tuned)
-    {
-        ivf_params.nprobe = nprobe;
-        /// we have two ways to optimize parallelizations for IVF.
-        /// first case, when we have very few connections, each sending a vector scan request that contains a single query vector.
-        /// In this case, we parallelize over centroids.
-        if (num_query <= num_thread_for_vector)
-        {
-            ivf_params.parallel_mode = 1;
-        }
-        /// experimental feature, parallelize over centroids with probes grouped together to use fast blas distance.
-        /// please see the implementation for detail.
-        else if (num_query * nprobe >= index_real->nlist * parallel_mode_4_threadhold)
-        {
-            ivf_params.parallel_mode = 4;
-        }
-        /// otherwise, which are when we have large number of connections,
-        /// we follow the default parallel mode which is parallel by query.
-        else
-        {
-            ivf_params.parallel_mode = 0;
-        }
-        omp_set_num_threads(std::max(1, (num_thread_for_vector / current_running_task)));
-        LOG_DEBUG(
-            log,
-            "Index search: nprobe: {}, parallel mode: {}, num_t: {}",
-            nprobe,
-            ivf_params.parallel_mode,
-            num_thread_for_vector);
-        index_real->search(num_query, query_datas, topK, distances, result_id, &ivf_params, inner_bit_map.get());
-    }
-    else
-    {
-        /// this is acc bounded search route
-        ivf_params.acc = acc;
-        omp_set_num_threads(std::max(1, (num_thread_for_vector / current_running_task)));
-        LOG_DEBUG(
-            log,
-            "Index search: acc requirement: {}, parallel mode: {}, num_t: {}",
-            acc,
-            ivf_params.parallel_mode,
-            num_thread_for_vector);
-        faiss::Error_sys profiled_index(index.get());
-        profiled_index.search(num_query, query_datas, topK, distances, result_id, &ivf_params, inner_bit_map.get());
-    }
-
-    //distance might not be useful in many cases
-}
-
-VectorDatasetPtr IVFFlatIndex::getInMemVectors()
-{
-    return nullptr;
-}
-
-void IVFFlatIndex::getMyParameters(Parameters params)
-{
-    if (params.contains("ncentroids"))
-    {
-        ncentroids = StoI(params.find("ncentroids")->second);
-        params.erase("ncentroids");
-    }
-    if (params.contains("profiler"))
-    {
-        profiler = str_toupper(params.find("profiler")->second) == "TRUE";
-        params.erase("profiler");
-    }
-    if (params.contains("std_m"))
-    {
-        std_m = StoF(params.find("std_m")->second);
-        params.erase("std_m");
-    }
-    if (params.contains("multiplier"))
-    {
-        multiplier = StoF(params.find("multiplier")->second);
-        params.erase("multiplier");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-    
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::IVFFLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-
-bool IVFFlatIndex::compare(const VectorIndex & other)
-{
-    const IVFFlatIndex * other_p = dynamic_cast<const IVFFlatIndex *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->ncentroids != ncentroids)
-    {
-        return false;
-    }
-    if (other_p->std_m != std_m)
-    {
-        return false;
-    }
-    if (other_p->multiplier != multiplier)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    return true;
-}
-
-void IVFFlatIndex::tune(VectorDatasetPtr base, int topK)
-{
-    if (!profiler)
-    {
-        return;
-    }
-    if (auto * index_real = reinterpret_cast<faiss::IndexIVFFlatFilter *>(index.get()))
-    {
-        int default_query_size = base->getVectorNum();
-        int default_topk = topK;
-        std::vector<float> query(default_query_size * dimension);
-        memcpy(query.data(), base->getData(), sizeof(float) * default_query_size * default_topk);
-        std::vector<float> gt_dis(default_topk * default_query_size);
-        std::vector<int64_t> gt(default_topk * default_query_size);
-        LOG_DEBUG(log, "Get gt for {} queries", default_query_size);
-        faiss::bitMapPtr bits = std::make_shared<faiss::bitMap>(base->getVectorNum());
-        memset(bits->bitmap, 255, (base->getVectorNum() / 8) + 1);
-        faiss::IVFSearchParameters param;
-        param.nprobe = index_real->nlist;
-        param.parallel_mode = 4;
-        if(me==Metrics::Cosine){
-            index_real->metric_type = faiss::METRIC_INNER_PRODUCT;
-            index_real->quantizer->metric_type = faiss::METRIC_INNER_PRODUCT;
-            /// the relative distance of ip and cosine should be the same
-        }
-        index_real->search(default_query_size, query.data(), default_topk, gt_dis.data(), gt.data(), &param, bits.get());
-
-        faiss::Error_sys profiled_index(index_real, default_query_size, default_topk);
-        LOG_DEBUG(log, "Training profiler");
-        profiled_index.set_gt(gt_dis.data(), gt.data());
-        profiled_index.sys_train(default_query_size, query.data(), std_m, multiplier);
-        if(me==Metrics::Cosine){
-            index_real->metric_type = faiss::METRIC_Cosine;
-            index_real->quantizer->metric_type = faiss::METRIC_Cosine;
-        }
-        LOG_DEBUG(log, "Profiler train completed");
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "IVFFlat casting failed, this is logic error.");
-    }
-}
-}
diff --git a/src/VectorIndex/IVFFlatIndex.h b/src/VectorIndex/IVFFlatIndex.h
deleted file mode 100644
index ba117dbca0..0000000000
--- a/src/VectorIndex/IVFFlatIndex.h
+++ /dev/null
@@ -1,58 +0,0 @@
-#pragma once
-
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#include <faiss/IndexFlat.h>
-#include <faiss/IndexIVFFlatFilter.h>
-#include <faiss/index_io.h>
-#include <faiss/utils/bitMap.h>
-#include "FaissIndex.h"
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-
-namespace VectorIndex
-{
-class IVFFlatIndex : public FaissIndex
-{
-public:
-    IVFFlatIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters)
-        : FaissIndex(it_, im_, me_, dimension_), log(&Poco::Logger::get("IVFFlat"))
-    {
-        getMyParameters(parameters);
-    }
-
-    void train(const VectorDatasetPtr dataset, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-        override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    void getMyParameters(Parameters params) override;
-
-    bool compare(const VectorIndex & other) override;
-
-    void tune(VectorDatasetPtr base, int topK);
-
-private:
-    /// These are just default values, outside class shouldn't access them for reference.
-    int ncentroids = 1024;
-    float std_m = 6.0;
-    float multiplier = 1.3;
-    bool profiler = false;
-    Poco::Logger * log;
-};
-}
diff --git a/src/VectorIndex/IVFPQIndex.cpp b/src/VectorIndex/IVFPQIndex.cpp
deleted file mode 100644
index cc4189ecc1..0000000000
--- a/src/VectorIndex/IVFPQIndex.cpp
+++ /dev/null
@@ -1,195 +0,0 @@
-#include "IVFPQIndex.h"
-#include <omp.h>
-#include "CacheManager.h"
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-#include "faiss/IndexIVFPQFilter.h"
-#include "faiss/impl/AuxIndexStructures.h"
-#include <VectorIndex/VectorIndexCommon.h>
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-}
-
-namespace VectorIndex
-{
-void IVFPQIndex::train(VectorDatasetPtr dataset, int64_t total)
-{
-    faiss::MetricType metrictype;
-    switch (me)
-    {
-        case Metrics::L2:
-            metrictype = faiss::METRIC_L2;
-            break;
-        case Metrics::IP:
-            metrictype = faiss::METRIC_INNER_PRODUCT;
-            break;
-        case Metrics::Cosine:
-            metrictype = faiss::METRIC_Cosine;
-    }
-    faiss::IndexFlat * coarse_quantizer = new faiss::IndexFlat(dimension, metrictype);
-    int nlist = ncentroids > dataset->getVectorNum() / min_centroid_size ? dataset->getVectorNum() / min_centroid_size : ncentroids;
-    nlist = std::max(1, nlist);
-    index = std::make_shared<faiss::IndexIVFPQFilter>(coarse_quantizer, dimension, nlist, M, bit_size, metrictype);
-    reinterpret_cast<faiss::IndexIVFPQFilter *>(index.get())->own_fields = true;
-    index->train(dataset->getVectorNum(), dataset->getData());
-}
-
-void IVFPQIndex::addWithoutId(VectorDatasetPtr dataset)
-{
-    if (index != nullptr)
-    {
-        int64_t * ids = new int64_t[dataset->getVectorNum()];
-        for (int i = 0; i < dataset->getVectorNum(); i++)
-        {
-            ids[i] = total_vector + i;
-        }
-        index->add_with_ids(dataset->getVectorNum(), dataset->getData(), ids);
-        total_vector += dataset->getVectorNum();
-        delete[] ids;
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-void IVFPQIndex::search(
-    const VectorDatasetPtr dataset,
-    const int32_t topK,
-    float * distances,
-    int64_t * result_id,
-    Parameters & params,
-    GeneralBitMapPtr filter)
-{
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not intialized");
-    }
-
-    faiss::bitMapPtr inner_bit_map = std::shared_ptr<faiss::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<faiss::bitMap *>(convertInnerBitMap(filter)));
-    int32_t num_query = dataset->getVectorNum();
-    float * query_datas = dataset->getData();
-
-    int nprobe = 1;
-    if (params.contains("nprobe"))
-    {
-        nprobe = StoI(params.find("nprobe")->second);
-        params.erase("nprobe");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::IVFFLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-    faiss::IVFSearchParameters ivf_params;
-    ivf_params.nprobe = nprobe;
-
-    /// we have two ways to optimize parallelizations for IVF.
-    /// first case, when we have very few connections, each sending a vector scan request that contains a single query vector.
-    /// In this case, we parallelize over centroids.
-    int current_running_task = count.load(std::memory_order_relaxed);
-    if (num_query <= num_thread_for_vector)
-    {
-        ivf_params.parallel_mode = 1;
-    }
-    /// otherwise, which are when we have large number of connections,
-    /// we follow the default parallel mode which is parallel by query.
-    else
-    {
-        ivf_params.parallel_mode = 0;
-    }
-    omp_set_num_threads(std::max(1, (num_thread_for_vector / current_running_task)));
-    reinterpret_cast<faiss::IndexIVFPQFilter *>(index.get())
-        ->search(num_query, query_datas, topK, distances, result_id, &ivf_params, inner_bit_map.get());
-    //distance might not be useful in many cases
-}
-
-
-VectorDatasetPtr IVFPQIndex::getInMemVectors()
-{
-    return nullptr;
-}
-
-
-void IVFPQIndex::getMyParameters(Parameters params)
-{
-    if (params.contains("ncentroids"))
-    {
-        ncentroids = StoI(params.find("ncentroids")->second);
-        params.erase("ncentroids");
-    }
-    if (params.contains("M"))
-    {
-        M = StoI(params.find("M")->second);
-        params.erase("M");
-    }
-    if (params.contains("bit_size"))
-    {
-        bit_size = StoI(params.find("bit_size")->second);
-        params.erase("bit_size");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::IVFPQ);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-
-bool IVFPQIndex::compare(const VectorIndex & other)
-{
-    const IVFPQIndex * other_p = dynamic_cast<const IVFPQIndex *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->ncentroids != ncentroids)
-    {
-        return false;
-    }
-    if (other_p->M != M)
-    {
-        return false;
-    }
-    if (other_p->bit_size != bit_size)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    return true;
-}
-
-//std::unordered_map<std::string, std::string> IVFPQIndex::exploreTask(const float * query_data, const int64_t * gt, int topK, int query_size,
-//                                                                     bool oneReccall,std::mutex & m, std::condition_variable & cv, bool & go)
-//{
-//}
-
-
-/*
-void IVFPQIndex::remove(const int32_t * ids)
-{
-}
-*/
-
-}
diff --git a/src/VectorIndex/IVFPQIndex.h b/src/VectorIndex/IVFPQIndex.h
deleted file mode 100644
index c02704706c..0000000000
--- a/src/VectorIndex/IVFPQIndex.h
+++ /dev/null
@@ -1,51 +0,0 @@
-#pragma once
-
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#include <faiss/IndexFlat.h>
-#include <faiss/IndexIVFPQFilter.h>
-#include <faiss/index_io.h>
-#include <faiss/utils/bitMap.h>
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-#include "FaissIndex.h"
-
-namespace VectorIndex
-{
-class IVFPQIndex : public FaissIndex
-{
-public:
-    IVFPQIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters) : FaissIndex(it_, im_, me_, dimension_)
-    {
-        getMyParameters(parameters);
-    }
-
-    void train(const VectorDatasetPtr dataset, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-        override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    void getMyParameters(Parameters params) override;
-
-    bool compare(const VectorIndex & other) override;
-
-    int ncentroids = 1024;
-    int M = 16;
-    int bit_size = 8;
-};
-}
diff --git a/src/VectorIndex/IVFSQIndex.cpp b/src/VectorIndex/IVFSQIndex.cpp
deleted file mode 100644
index a579274284..0000000000
--- a/src/VectorIndex/IVFSQIndex.cpp
+++ /dev/null
@@ -1,226 +0,0 @@
-#include "IVFSQIndex.h"
-#include <omp.h>
-#include "CacheManager.h"
-#include "IndexException.h"
-#include "IndexReader.h"
-#include "IndexWriter.h"
-#include "faiss/IndexIVFSQFilter.h"
-#include "faiss/impl/AuxIndexStructures.h"
-#include <VectorIndex/VectorIndexCommon.h>
-#include <base/logger_useful.h>
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-extern const int UNSUPPORTED_PARAMETER;
-}
-
-namespace VectorIndex
-{
-void IVFSQIndex::train(VectorDatasetPtr dataset, int64_t total)
-{
-    faiss::MetricType metrictype;
-    switch (me)
-    {
-        case Metrics::L2:
-            metrictype = faiss::METRIC_L2;
-            break;
-        case Metrics::IP:
-            metrictype = faiss::METRIC_INNER_PRODUCT;
-            break;
-        case Metrics::Cosine:
-            metrictype = faiss::METRIC_Cosine;
-            //TODO conitnued
-    }
-    faiss::IndexFlat * coarse_quantizer = new faiss::IndexFlat(dimension, metrictype);
-    int nlist = ncentroids > dataset->getVectorNum() / min_centroid_size ? dataset->getVectorNum() / min_centroid_size : ncentroids;
-    nlist = std::max(1, nlist);
-    index = std::make_shared<faiss::IndexIVFSQFilter>(coarse_quantizer, dimension, nlist, quantizer, metrictype);
-    reinterpret_cast<faiss::IndexIVFSQFilter *>(index.get())->own_fields = true;
-    LOG_DEBUG(log, "Vector num: {}, raw data size: {}, dim: {}",
-        dataset->getVectorNum(), dataset->getRawVector().size(), dimension);
-    index->train(dataset->getVectorNum(), dataset->getData());
-}
-
-void IVFSQIndex::addWithoutId(VectorDatasetPtr dataset)
-{
-    if (index != nullptr)
-    {
-        int64_t * ids = new int64_t[dataset->getVectorNum()];
-        for (int i = 0; i < dataset->getVectorNum(); i++)
-        {
-            ids[i] = total_vector + i;
-        }
-        index->add_with_ids(dataset->getVectorNum(), dataset->getData(), ids);
-        total_vector += dataset->getVectorNum();
-        delete[] ids;
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "addWithoutId: index not intialized");
-    }
-}
-
-void IVFSQIndex::search(
-    const VectorDatasetPtr dataset,
-    const int32_t topK,
-    float * distances,
-    int64_t * result_id,
-    Parameters & params,
-    GeneralBitMapPtr filter)
-{
-    if (index == nullptr)
-    {
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "search: index not intialized");
-    }
-
-    faiss::bitMapPtr inner_bit_map = std::shared_ptr<faiss::bitMap>();
-    inner_bit_map.reset(reinterpret_cast<faiss::bitMap *>(convertInnerBitMap(filter)));
-    int32_t num_query = dataset->getVectorNum();
-    float * query_datas = dataset->getData();
-
-    int nprobe = 1;
-    if (params.contains("nprobe"))
-    {
-        nprobe = StoI(params.find("nprobe")->second);
-        params.erase("nprobe");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::IVFFLAT);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-    faiss::IVFSearchParameters ivf_params;
-    ivf_params.nprobe = nprobe;
-
-    /// we have two ways to optimize parallelizations for IVF.
-    /// first case, when we have very few connections, each sending a vector scan request that contains a single query vector.
-    /// In this case, we parallelize over centroids.
-    int current_running_task = count.load(std::memory_order_relaxed);
-    if (num_query <= num_thread_for_vector)
-    {
-        ivf_params.parallel_mode = 1;
-    }
-    /// otherwise, which are when we have large number of connections,
-    /// we follow the default parallel mode which is parallel by query.
-    else
-    {
-        ivf_params.parallel_mode = 0;
-    }
-    omp_set_num_threads(std::max(1, (num_thread_for_vector / current_running_task)));
-    reinterpret_cast<faiss::IndexIVFSQFilter *>(index.get())
-        ->search(num_query, query_datas, topK, distances, result_id, &ivf_params, inner_bit_map.get());
-    //distance might not be useful in many cases
-}
-
-
-VectorDatasetPtr IVFSQIndex::getInMemVectors()
-{
-    return nullptr;
-}
-
-
-void IVFSQIndex::getMyParameters(Parameters params)
-{
-    if (params.contains("ncentroids"))
-    {
-        ncentroids = StoI(params.find("ncentroids")->second);
-        params.erase("ncentroids");
-    }
-    if (params.contains("bit_size"))
-    {
-        String bits = params.find("bit_size")->second;
-        quantizer = parse_SQ_string(bits);
-        params.erase("bit_size");
-    }
-    if (params.contains("metric_type"))
-    {
-        params.erase("metric_type");
-    }
-    if (!params.empty())
-    {
-        std::string message = generateUnsupportedParameters(params, IndexType::IVFSQ);
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, message);
-    }
-}
-
-faiss::ScalarQuantizer::QuantizerType IVFSQIndex::parse_SQ_string(String bits)
-{
-    if (bits == "8bit")
-    {
-        return faiss::ScalarQuantizer::QT_8bit;
-    }
-    else if (bits == "6bit")
-    {
-        return faiss::ScalarQuantizer::QT_6bit;
-    }
-    else if (bits == "4bit")
-    {
-        return faiss::ScalarQuantizer::QT_4bit;
-    }
-    else if (bits == "8bit_uniform")
-    {
-        return faiss::ScalarQuantizer::QT_8bit_uniform;
-    }
-    else if (bits == "8bit_direct")
-    {
-        return faiss::ScalarQuantizer::QT_8bit_direct;
-    }
-    else if (bits == "4bit_uniform")
-    {
-        return faiss::ScalarQuantizer::QT_4bit_uniform;
-    }
-    else if (bits == "QT_fp16")
-    {
-        return faiss::ScalarQuantizer::QT_fp16;
-    }
-    else
-    {
-        throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, "unsupported QT bit size in IVFSQ: {}", bits);
-    }
-}
-
-bool IVFSQIndex::compare(const VectorIndex & other)
-{
-    const IVFSQIndex * other_p = dynamic_cast<const IVFSQIndex *>(&other);
-    if (other_p == nullptr)
-    {
-        return false;
-    }
-    if (other_p->ncentroids != ncentroids)
-    {
-        return false;
-    }
-    if (other_p->me != me)
-    {
-        return false;
-    }
-    if (other_p->dimension != dimension)
-    {
-        return false;
-    }
-    if (other_p->quantizer != quantizer)
-    {
-        return false;
-    }
-    return true;
-}
-
-//std::unordered_map<std::string, std::string> IVFSQIndex::exploreTask(const float * query_data, const int64_t * gt, int topK, int query_size,
-//                                                                     bool oneReccall,std::mutex & m, std::condition_variable & cv, bool & go)
-//{
-//}
-
-
-/*
-void IVFSQIndex::remove(const int32_t * ids)
-{
-}
-*/
-
-}
diff --git a/src/VectorIndex/IVFSQIndex.h b/src/VectorIndex/IVFSQIndex.h
deleted file mode 100644
index 601e72236e..0000000000
--- a/src/VectorIndex/IVFSQIndex.h
+++ /dev/null
@@ -1,55 +0,0 @@
-#pragma once
-
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wold-style-cast"
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#pragma GCC diagnostic ignored "-Wunused-parameter"
-#pragma GCC diagnostic ignored "-Wshadow-field"
-#pragma GCC diagnostic ignored "-Wdocumentation"
-#pragma GCC diagnostic ignored "-Wcast-qual"
-#pragma GCC diagnostic ignored "-Woverloaded-virtual"
-#pragma GCC diagnostic ignored "-Wcast-align"
-#pragma GCC diagnostic ignored "-Wsuggest-destructor-override"
-#include <faiss/IndexFlat.h>
-#include <faiss/IndexIVFSQFilter.h>
-#include <faiss/index_io.h>
-#include <faiss/utils/bitMap.h>
-#pragma GCC diagnostic pop
-
-#include <string>
-#include "Binary.h"
-#include "FaissIndex.h"
-
-namespace VectorIndex
-{
-class IVFSQIndex : public FaissIndex
-{
-public:
-    IVFSQIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_, Parameters parameters) : FaissIndex(it_, im_, me_, dimension_)
-    {
-        getMyParameters(parameters);
-    }
-
-    void train(const VectorDatasetPtr dataset, int64_t total) override;
-
-    void addWithoutId(const VectorDatasetPtr dataset) override;
-
-    void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-        override;
-
-    VectorDatasetPtr getInMemVectors() override;
-
-    void getMyParameters(Parameters params) override;
-
-    bool compare(const VectorIndex & other) override;
-
-private:
-    faiss::ScalarQuantizer::QuantizerType parse_SQ_string(String bits);
-
-    int ncentroids = 1024;
-    faiss::ScalarQuantizer::QuantizerType quantizer = faiss::ScalarQuantizer::QT_8bit;
-
-    Poco::Logger * log = &Poco::Logger::get("IVFSQ");
-};
-}
diff --git a/src/VectorIndex/IndexException.h b/src/VectorIndex/IndexException.h
index 107db33861..38d6f3fbe7 100644
--- a/src/VectorIndex/IndexException.h
+++ b/src/VectorIndex/IndexException.h
@@ -6,25 +6,14 @@ namespace VectorIndex
 class IndexException : public DB::Exception
 {
 public:
-    IndexException(int code_, const std::string & message_) : DB::Exception(code_, "[VectorIndex] " + message_) { }
-
-    /// Just record index status code and message, and wait for further processing.
-    IndexException(const std::string & message_, int code_) : status_code(code_), status_message(message_) { }
-
-    int statusCode() const { return status_code; }
-    String statusMessage() const { return status_message; }
+    IndexException(int code, const std::string & message) : DB::Exception(code, "[VectorIndex] " + message) { }
 
     // Format message with fmt::format, like the logging functions.
     template <typename... Args>
     IndexException(int code, const std::string & fmt, Args &&... args)
-        : DB::Exception(fmt::format(fmt::runtime("vector index: " + fmt), std::forward<Args>(args)...), code)
+        : DB::Exception(fmt::format(fmt::runtime("[VectorIndex] " + fmt), std::forward<Args>(args)...), code)
     {
     }
-
-private:
-    /// Record index status code and message
-    int status_code;
-    String status_message;
 };
 
 }
diff --git a/src/VectorIndex/IndexReader.cpp b/src/VectorIndex/IndexReader.cpp
deleted file mode 100644
index 7d057dac16..0000000000
--- a/src/VectorIndex/IndexReader.cpp
+++ /dev/null
@@ -1,21 +0,0 @@
-#include <VectorIndex/IndexException.h>
-#include <VectorIndex/IndexReader.h>
-
-namespace VectorIndex
-{
-
-size_t BufferIndexReader::operator()(void * ptr, size_t size, size_t nitems)
-{
-    if (rp >= total)
-        return 0;
-    size_t nremain = (total - rp) / size;
-    if (nremain < nitems)
-        nitems = nremain;
-    if (size * nitems > 0)
-    {
-        memcpy(ptr, data + rp, size * nitems);
-        rp += size * nitems;
-    }
-    return nitems;
-}
-}
diff --git a/src/VectorIndex/IndexReader.h b/src/VectorIndex/IndexReader.h
deleted file mode 100644
index 533346caea..0000000000
--- a/src/VectorIndex/IndexReader.h
+++ /dev/null
@@ -1,25 +0,0 @@
-#pragma once
-
-#include <vector>
-
-#include <base/logger_useful.h>
-
-#include "faiss/impl/io.h"
-
-namespace VectorIndex
-{
-
-struct IndexReader : faiss::IOReader
-{
-    size_t read(void * ptr, size_t size, size_t nitems = 1) { return operator()(ptr, size, nitems); }
-};
-
-struct BufferIndexReader : IndexReader
-{
-    uint8_t * data;
-    uint64_t total = 0;
-    uint64_t rp = 0;
-
-    size_t operator()(void * ptr, size_t size, size_t nitems) override;
-};
-}
diff --git a/src/VectorIndex/IndexWriter.cpp b/src/VectorIndex/IndexWriter.cpp
deleted file mode 100644
index e4e49daeff..0000000000
--- a/src/VectorIndex/IndexWriter.cpp
+++ /dev/null
@@ -1,39 +0,0 @@
-#include "IndexWriter.h"
-namespace VectorIndex
-{
-
-#define RESERVE 2
-
-size_t BufferIndexWriter::operator()(const void * ptr, size_t size, size_t nitems)
-{
-    if (ptr == nullptr || size == 0 || nitems == 0)
-        return 0;
-    size_t total_need = size * nitems + actual_size;
-    if (total_need > 0)
-    {
-        if (reserved_size == 0)
-        {
-            reserved_size = total_need * RESERVE;
-            actual_size = size * nitems;
-            data = new uint8_t[reserved_size];
-            memcpy(data, ptr, actual_size);
-        }
-        else if (reserved_size < total_need)
-        { //if reserved space if not enough
-            reserved_size = total_need * RESERVE;
-            auto * new_data = new uint8_t[reserved_size];
-            memcpy(new_data, data, actual_size); // copy old data to new data chunk
-            delete[] data;
-            data = new_data;
-            memcpy(data + actual_size, ptr, size * nitems); // copy increment to data
-            actual_size = total_need;
-        }
-        else
-        {
-            memcpy(data + actual_size, ptr, size * nitems); // if still got reserved space
-            actual_size = total_need;
-        }
-    }
-    return nitems;
-}
-}
diff --git a/src/VectorIndex/IndexWriter.h b/src/VectorIndex/IndexWriter.h
deleted file mode 100644
index 5906b58c74..0000000000
--- a/src/VectorIndex/IndexWriter.h
+++ /dev/null
@@ -1,27 +0,0 @@
-#pragma once
-
-#include <cstring>
-#include <memory>
-
-#pragma GCC diagnostic push
-#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
-#include "faiss/impl/io.h"
-#pragma GCC diagnostic pop
-
-namespace VectorIndex
-{
-struct IndexWriter : faiss::IOWriter
-{
-    size_t write(const void * ptr, size_t size, size_t nitems = 1) { return operator()(ptr, size, nitems); }
-};
-
-// in memory reader conforming to faiss IOwriter that's used to produce
-// a binary object
-struct BufferIndexWriter : IndexWriter
-{
-    uint8_t * data;
-    uint64_t actual_size = 0;
-    uint64_t reserved_size = 0;
-    size_t operator()(const void * ptr, size_t size, size_t nitems) override;
-};
-}
diff --git a/src/VectorIndex/MergeUtils.h b/src/VectorIndex/MergeUtils.h
index ab6d0b0772..ba710fd7d9 100644
--- a/src/VectorIndex/MergeUtils.h
+++ b/src/VectorIndex/MergeUtils.h
@@ -1,36 +1,44 @@
 #pragma once
+
+#include <filesystem>
 #include <fstream>
 #include <iostream>
-#include <filesystem>
+
 #include <boost/algorithm/string.hpp>
+
 #include <Disks/IDisk.h>
-#include <Storages/MergeTree/MergeTreeData.h>
 #include <Storages/MergeTree/IMergeTreeDataPart.h>
-#include <VectorIndex/VectorIndexCommon.h>
+#include <Storages/MergeTree/MergeTreeData.h>
+#include <base/logger_useful.h>
+
 #include <VectorIndex/SegmentId.h>
+#include <VectorIndex/VectorIndexCommon.h>
+#include <VectorIndex/VectorSegmentExecutor.h>
 
-#include <base/logger_useful.h>
+#pragma GCC diagnostic ignored "-Wunused-function"
 
 namespace VectorIndex
 {
 
 /// used to rename and move vector indices files of one old data part
 /// to new data part's path
-static inline void renameVectorIndexFiles(const String & part_id, const String & part_name, const String & old_path, const String & new_path)
+static inline void
+renameVectorIndexFiles(const String & part_id, const String & part_name, const String & old_path, const String & new_path)
 {
     /// first get all vector indices related files
     String ext(VECTOR_INDEX_FILE_SUFFIX);
-    for (auto &p : fs::recursive_directory_iterator(old_path))
+    for (auto & p : fs::recursive_directory_iterator(old_path))
     {
         if (p.path().extension() == ext)
         {
             String new_file_path = new_path + "merged-" + part_id + "-" + part_name + "-" + DB::fileName(p.path());
             fs::rename(p.path(), new_file_path);
         }
-    }   
+    }
 }
 
-static std::vector<SegmentId> getAllSegmentIds(const String & data_path, const DB::MergeTreeDataPartPtr & data_part, const String & index_name, const String & index_column)
+static std::vector<SegmentId> getAllSegmentIds(
+    const String & data_path, const DB::MergeTreeDataPartPtr & data_part, const String & index_name, const String & index_column)
 {
     std::vector<SegmentId> segment_ids;
 
@@ -41,14 +49,24 @@ static std::vector<SegmentId> getAllSegmentIds(const String & data_path, const D
     /// decide whether we have merged old data parts index files
     if (data_part->containRowIdsMaps())
     {
-        auto log = &Poco::Logger::get("getAllSegmentIds");
         auto old_parts = data_part->getMergedSourceParts();
 
         for (const auto & old_part : old_parts)
         {
-            LOG_DEBUG(log, "Segments: merged-{}-{}", old_part.id, old_part.name);
-
-            SegmentId segment_id(data_path, data_part->name, old_part.name, index_name, index_column, old_part.id);
+            String vector_index_cache_prefix = fs::path(data_part->storage.getContext()->getVectorIndexCachePath())
+                / data_part->storage.getRelativeDataPath()
+                / DB::MergeTreePartInfo::fromPartName(old_part.name, DB::MERGE_TREE_DATA_MIN_FORMAT_VERSION_WITH_CUSTOM_PARTITIONING)
+                      .getPartNameWithoutMutation()
+                / "";
+            SegmentId segment_id(
+                data_part->volume,
+                data_path,
+                data_part->name,
+                old_part.name,
+                index_name,
+                index_column,
+                vector_index_cache_prefix,
+                old_part.id);
             segment_ids.emplace_back(std::move(segment_id));
         }
     }
@@ -56,7 +74,9 @@ static std::vector<SegmentId> getAllSegmentIds(const String & data_path, const D
     /// If no merged old parts' index files, decide whether we have simple built vector index.
     if (segment_ids.empty() && data_part->containVectorIndex(index_name, index_column))
     {
-        SegmentId segment_id(data_path, data_part->name, data_part->name, index_name, index_column, 0);
+        String vector_index_cache_prefix = fs::path(data_part->storage.getContext()->getVectorIndexCachePath())
+            / data_part->storage.getRelativeDataPath() / data_part->info.getPartNameWithoutMutation() / "";
+        SegmentId segment_id(data_part->volume, data_path, data_part->name, index_name, index_column, vector_index_cache_prefix);
         segment_ids.emplace_back(std::move(segment_id));
     }
 
diff --git a/src/VectorIndex/Metadata.cpp b/src/VectorIndex/Metadata.cpp
new file mode 100644
index 0000000000..bcffbc70b3
--- /dev/null
+++ b/src/VectorIndex/Metadata.cpp
@@ -0,0 +1,146 @@
+#include <VectorIndex/Metadata.h>
+
+#include <IO/ReadHelpers.h>
+#include <IO/WriteHelpers.h>
+
+namespace VectorIndex
+{
+void Metadata::readText(DB::ReadBuffer & buf)
+{
+    DB::assertString("vector index metadata format version: 1\n", buf);
+    DB::assertString("num_segments: 1\n", buf);
+
+    DB::assertString("version: ", buf);
+    DB::readString(version, buf);
+    DB::assertChar('\n', buf);
+
+    DB::assertString("type: ", buf);
+    DB::String type_str;
+    DB::readString(type_str, buf);
+    Search::findEnumByName(type_str, type);
+    DB::assertChar('\n', buf);
+
+    DB::assertString("metric: ", buf);
+    DB::String metric_str;
+    DB::readString(metric_str, buf);
+    Search::findEnumByName(metric_str, metric);
+    DB::assertChar('\n', buf);
+
+    DB::assertString("dimension: ", buf);
+    DB::readIntText(dimension, buf);
+    DB::assertChar('\n', buf);
+
+    DB::assertString("total_vec: ", buf);
+    DB::readIntText(total_vec, buf);
+    DB::assertChar('\n', buf);
+
+    DB::assertString("fallback_to_flat: ", buf);
+    DB::readBoolText(fallback_to_flat, buf);
+    DB::assertChar('\n', buf);
+
+    DB::String current_part_name;
+    DB::assertString("current_part_name: ", buf);
+    DB::readString(current_part_name, buf);
+    DB::assertChar('\n', buf);
+
+    DB::String owner_part_name;
+    DB::assertString("owner_part_name: ", buf);
+    DB::readString(owner_part_name, buf);
+    DB::assertChar('\n', buf);
+
+    DB::String vector_index_name;
+    DB::assertString("vector_index_name: ", buf);
+    DB::readString(vector_index_name, buf);
+    DB::assertChar('\n', buf);
+
+    DB::String column_name;
+    DB::assertString("column_name: ", buf);
+    DB::readString(column_name, buf);
+    DB::assertChar('\n', buf);
+
+    UInt8 owner_part_id;
+    DB::assertString("owner_part_id: ", buf);
+    DB::readIntText(owner_part_id, buf);
+    DB::assertChar('\n', buf);
+
+    size_t num_params = 0;
+    DB::assertString("num_params: ", buf);
+    DB::readIntText(num_params, buf);
+    DB::assertChar('\n', buf);
+
+    String key;
+    String value;
+    for (size_t i = 0; i < num_params; i++)
+    {
+        readBackQuotedStringWithSQLStyle(key, buf);
+        assertChar(' ', buf);
+        readString(value, buf);
+        assertChar('\n', buf);
+        des.setParam(key, value);
+    }
+
+    assertEOF(buf);
+}
+
+void Metadata::writeText(DB::WriteBuffer & buf) const
+{
+    DB::writeString("vector index metadata format version: 1\n", buf);
+    DB::writeString("num_segments: 1\n", buf);
+
+    DB::writeString("version: ", buf);
+    DB::writeString(version, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("type: ", buf);
+    DB::writeString(Search::enumToString(type), buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("metric: ", buf);
+    DB::writeString(Search::enumToString(metric), buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("dimension: ", buf);
+    DB::writeIntText(dimension, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("total_vec: ", buf);
+    DB::writeIntText(total_vec, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("fallback_to_flat: ", buf);
+    DB::writeBoolText(fallback_to_flat, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("current_part_name: ", buf);
+    DB::writeString(segment_id.current_part_name, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("owner_part_name: ", buf);
+    DB::writeString(segment_id.owner_part_name, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("vector_index_name: ", buf);
+    DB::writeString(segment_id.vector_index_name, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("column_name: ", buf);
+    DB::writeString(segment_id.column_name, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("owner_part_id: ", buf);
+    DB::writeIntText(segment_id.owner_part_id, buf);
+    DB::writeChar('\n', buf);
+
+    DB::writeString("num_params: ", buf);
+    DB::writeIntText(des.size(), buf);
+    DB::writeChar('\n', buf);
+
+    for (const auto & it : des)
+    {
+        DB::writeBackQuotedString(it.first, buf);
+        DB::writeChar(' ', buf);
+        DB::writeString(it.second, buf);
+        DB::writeChar('\n', buf);
+    }
+}
+}
diff --git a/src/VectorIndex/Metadata.h b/src/VectorIndex/Metadata.h
new file mode 100644
index 0000000000..f7ae4f05c2
--- /dev/null
+++ b/src/VectorIndex/Metadata.h
@@ -0,0 +1,48 @@
+#pragma once
+
+#include <IO/ReadBuffer.h>
+#include <IO/WriteBuffer.h>
+
+#include <VectorIndex/VectorIndexCommon.h>
+#include <VectorIndex/SegmentId.h>
+
+namespace VectorIndex
+{
+class Metadata
+{
+public:
+    Metadata(const SegmentId & segment_id_) : segment_id(segment_id_) { }
+
+    Metadata(
+        const SegmentId & segment_id_,
+        DB::String version_,
+        Search::IndexType type_,
+        Search::Metric metric_,
+        size_t dimension_,
+        size_t total_vec_,
+        bool fallback_to_flat_,
+        Search::Parameters des_)
+        : segment_id(segment_id_)
+        , version(version_)
+        , type(type_)
+        , metric(metric_)
+        , dimension(dimension_)
+        , total_vec(total_vec_)
+        , fallback_to_flat(fallback_to_flat_)
+        , des(des_)
+    {
+    }
+
+    void readText(DB::ReadBuffer & buf);
+    void writeText(DB::WriteBuffer & buf) const;
+
+    const SegmentId & segment_id;
+    DB::String version;
+    Search::IndexType type;
+    Search::Metric metric;
+    size_t dimension;
+    size_t total_vec;
+    bool fallback_to_flat;
+    Search::Parameters des;
+};
+}
diff --git a/src/VectorIndex/PartReader.cpp b/src/VectorIndex/PartReader.cpp
new file mode 100644
index 0000000000..f7c0f4ffe0
--- /dev/null
+++ b/src/VectorIndex/PartReader.cpp
@@ -0,0 +1,183 @@
+#include <Columns/ColumnArray.h>
+#include <DataTypes/DataTypeArray.h>
+#include <VectorIndex/PartReader.h>
+
+namespace VectorIndex
+{
+PartReader::PartReader(
+    const DB::ActionBlocker & builds_blocker_,
+    const DB::MergeTreeDataPartPtr & part_,
+    const DB::NamesAndTypesList & cols_,
+    const DB::StorageMetadataPtr & metadata_snapshot_,
+    DB::MarkCache * mark_cache_,
+    size_t dimension_,
+    bool enforce_fixed_array_)
+    : builds_blocker(builds_blocker_)
+    , part(part_)
+    , cols(cols_)
+    , index_granularity(part->index_granularity)
+    , dimension(dimension_)
+    , total_mask(part->getMarksCount())
+    , enforce_fixed_array(enforce_fixed_array_)
+{
+    DB::MergeTreeReaderSettings reader_settings;
+    reader = part->getReader(
+        cols,
+        metadata_snapshot_,
+        DB::MarkRanges{DB::MarkRange(0, total_mask)},
+        /* uncompressed_cache = */ nullptr,
+        mark_cache_,
+        reader_settings);
+}
+
+std::shared_ptr<PartReader::DataChunk> merge(const std::vector<std::shared_ptr<PartReader::DataChunk>> & chunks)
+{
+    if (chunks.empty())
+        return nullptr;
+    auto dimension = chunks.back()->dimension();
+    size_t total = 0;
+    for (auto chunk : chunks)
+        total += chunk->numData();
+    float * data = new float[dimension * total]();
+    Search::idx_t * ids = new Search::idx_t[total]();
+    auto merged_chunk = std::make_shared<PartReader::DataChunk>(data, total, dimension, [=]() { delete[] data; });
+    merged_chunk->setDataID(ids, [=]() { delete[] ids; });
+    auto cur_data = data;
+    auto cur_ids = ids;
+    for (auto chunk : chunks)
+    {
+        auto chunk_data = chunk->getData();
+        auto chunk_ids = chunk->getDataID();
+        auto chunk_size = chunk->numData();
+        memcpy(cur_data, chunk_data, chunk_size * dimension * sizeof(float));
+        memcpy(cur_ids, chunk_ids, chunk_size * sizeof(Search::idx_t));
+        cur_data += chunk_size * dimension;
+        cur_ids += chunk_size;
+    }
+    return merged_chunk;
+}
+
+std::shared_ptr<PartReader::DataChunk> PartReader::sampleData(size_t n)
+{
+    LOG_DEBUG(logger, "Sample {} rows from part {}", n, part->name);
+    std::vector<std::shared_ptr<PartReader::DataChunk>> chunks;
+    size_t num_rows = 0;
+    while (num_rows < n)
+    {
+        auto chunk = readDataImpl(n - num_rows);
+        if (chunk == nullptr)
+            break;
+        num_rows += chunk->numData();
+        chunks.push_back(chunk);
+    }
+    reset();
+    return merge(chunks);
+}
+
+size_t PartReader::numDataRead() const
+{
+    return num_rows_read;
+}
+
+size_t PartReader::dataDimension() const
+{
+    return dimension;
+}
+
+bool PartReader::eof()
+{
+    return num_rows_read == part->rows_count;
+}
+
+std::shared_ptr<PartReader::DataChunk> PartReader::readDataImpl(size_t n)
+{
+    if (n == 0)
+        return nullptr;
+
+    if (builds_blocker.isCancelled() || part->vector_index_build_cancelled)
+        throw DB::Exception("Cancelled building vector index", DB::ErrorCodes::ABORTED);
+
+    size_t remaining_size = part->rows_count - num_rows_read;
+    size_t max_read_row = std::min(remaining_size, n);
+    DB::Columns result(cols.size());
+    LOG_DEBUG(logger, "Reading {} rows from part {} from row {}", max_read_row, part->name, num_rows_read);
+    LOG_DEBUG(logger, "Column size is {}", cols.size());
+    size_t num_rows = reader->readRows(current_mask, 0, continue_read, max_read_row, result);
+    LOG_DEBUG(logger, "Read {} rows from part {}", num_rows, part->name);
+    if (num_rows == 0)
+        return nullptr;
+    continue_read = true;
+    size_t current_round_start_row = num_rows_read;
+    num_rows_read += num_rows;
+    for (size_t mask = current_mask; mask < total_mask - 1; ++mask)
+    {
+        if (index_granularity.getMarkStartingRow(mask) >= num_rows_read && index_granularity.getMarkStartingRow(mask + 1) < num_rows_read)
+        {
+            current_mask = mask;
+        }
+    }
+    const auto & one_column = result.back();
+    const DB::ColumnArray * array = DB::checkAndGetColumn<DB::ColumnArray>(one_column.get());
+    if (!array)
+    {
+        throw DB::Exception(DB::ErrorCodes::LOGICAL_ERROR, "vector column type is not Array in part {}", part->name);
+    }
+    const DB::IColumn & src_data = array->getData();
+    const DB::ColumnArray::Offsets & offsets = array->getOffsets();
+    const DB::ColumnFloat32 * src_data_concrete = DB::checkAndGetColumn<DB::ColumnFloat32>(&src_data);
+    if (!src_data_concrete)
+    {
+        throw DB::Exception(DB::ErrorCodes::LOGICAL_ERROR, "vector column inner type in Array is not Float32 in part {}", part->name);
+    }
+
+    const DB::PaddedPODArray<DB::Float32> & src_vec = src_data_concrete->getData();
+
+    if (enforce_fixed_array && src_vec.size() != dimension * offsets.size())
+    {
+        throw DB::Exception(DB::ErrorCodes::INCORRECT_DATA, "Vector column data length does not meet constraint in part {}", part->name);
+    }
+
+    if (src_vec.empty())
+        return nullptr;
+
+    float * vector_raw_data = new float[dimension * offsets.size()]();
+    std::shared_ptr<PartReader::DataChunk> chunk
+        = std::make_shared<PartReader::DataChunk>(vector_raw_data, offsets.size(), dimension, [=]() { delete[] vector_raw_data; });
+    Search::idx_t * ids = new Search::idx_t[offsets.size()]();
+    chunk->setDataID(ids, [=]() { delete[] ids; });
+
+    for (size_t row = 0; row < offsets.size(); ++row)
+    {
+        /// get the start and end offset of the vector in the src_vec
+        size_t vec_start_offset = row != 0 ? offsets[row - 1] : 0;
+        size_t vec_end_offset = offsets[row];
+        if (enforce_fixed_array && vec_end_offset - vec_start_offset != dimension)
+            throw DB::Exception(
+                DB::ErrorCodes::INCORRECT_DATA, "Vector column data length does not meet constraint in part {}", part->name);
+        if (vec_start_offset != vec_end_offset)
+        {
+            /// this is a valid vector, copy it to the result
+            for (size_t i = 0; i < dimension && i < vec_end_offset - vec_start_offset; ++i)
+            {
+                vector_raw_data[row * dimension + i] = src_vec[vec_start_offset + i];
+            }
+            ids[row] = current_round_start_row + row;
+        }
+        else
+        {
+            /// this is an empty vector
+            empty_ids.emplace_back(current_round_start_row + row);
+        }
+    }
+
+    return chunk;
+}
+
+void PartReader::reset()
+{
+    num_rows_read = 0;
+    current_mask = 0;
+    continue_read = false;
+    empty_ids.clear();
+}
+}
diff --git a/src/VectorIndex/PartReader.h b/src/VectorIndex/PartReader.h
new file mode 100644
index 0000000000..d037cc5669
--- /dev/null
+++ b/src/VectorIndex/PartReader.h
@@ -0,0 +1,73 @@
+#pragma once
+
+#include <random>
+#include <Storages/MergeTree/IMergeTreeReader.h>
+#include <Storages/MergeTree/MergeTreeData.h>
+#include <base/logger_useful.h>
+#include <Common/Exception.h>
+
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wnon-virtual-dtor"
+#include <SearchIndex/VectorIndex.h>
+#pragma GCC diagnostic pop
+
+namespace DB::ErrorCodes
+{
+extern const int NOT_IMPLEMENTED;
+extern const int ABORTED;
+}
+
+namespace VectorIndex
+{
+
+class PartReader : public Search::IndexSourceDataReader<float>
+{
+public:
+    PartReader(
+        const DB::ActionBlocker & builds_blocker_,
+        const DB::MergeTreeDataPartPtr & part_,
+        const DB::NamesAndTypesList & cols_,
+        const DB::StorageMetadataPtr & metadata_snapshot_,
+        DB::MarkCache * mark_cache_,
+        size_t dimension_,
+        bool enforce_fixed_array);
+    ~PartReader() { }
+
+    std::shared_ptr<DataChunk> sampleData(size_t n) override;
+
+    size_t numDataRead() const override;
+
+    size_t dataDimension() const override;
+
+    bool eof() override;
+
+    void seekg(std::streamsize /* offset */, std::ios::seekdir /* dir */) override
+    {
+        throw DB::Exception(DB::ErrorCodes::NOT_IMPLEMENTED, "seekg() is not implemented in PartReader");
+    }
+
+    const std::vector<size_t> & emptyIds() const { return empty_ids; }
+
+protected:
+    std::shared_ptr<DataChunk> readDataImpl(size_t n) override;
+    void reset();
+
+private:
+    using MergeTreeReaderPtr = std::unique_ptr<DB::IMergeTreeReader>;
+
+    const Poco::Logger * logger = &Poco::Logger::get("PartReader");
+    const DB::ActionBlocker & builds_blocker;
+    const DB::MergeTreeDataPartPtr & part;
+    const DB::NamesAndTypesList & cols;
+    const DB::MergeTreeIndexGranularity & index_granularity;
+    const size_t dimension = 0;
+    const size_t total_mask;
+    const bool enforce_fixed_array;
+
+    MergeTreeReaderPtr reader;
+    std::vector<size_t> empty_ids;
+    size_t num_rows_read = 0;
+    bool continue_read = false;
+    size_t current_mask = 0;
+};
+};
diff --git a/src/VectorIndex/SegmentId.h b/src/VectorIndex/SegmentId.h
index b8a3da5df4..2c35ffbe69 100644
--- a/src/VectorIndex/SegmentId.h
+++ b/src/VectorIndex/SegmentId.h
@@ -1,12 +1,18 @@
 #pragma once
 #include <filesystem>
-#include <base/types.h>
 #include <VectorIndex/VectorIndexCommon.h>
+#include <base/types.h>
 
 #include <base/logger_useful.h>
 
 namespace fs = std::filesystem;
 
+namespace DB
+{
+class IVolume;
+using VolumePtr = std::shared_ptr<IVolume>;
+}
+
 namespace VectorIndex
 {
 
@@ -19,40 +25,66 @@ struct CacheKey
     String vector_index_name;
     String column_name;
 
-    bool operator==(const CacheKey& other) const {
-        return (table_path == other.table_path)
-        && (part_name_no_mutation == other.part_name_no_mutation)
-        && (vector_index_name == other.vector_index_name)
-        && (column_name == other.column_name);
-    }
-
-    String toString() const
+    bool operator==(const CacheKey & other) const
     {
-        return table_path + "/" + part_name_no_mutation + "/" + vector_index_name + "_" + column_name;
+        return (table_path == other.table_path) && (part_name_no_mutation == other.part_name_no_mutation)
+            && (vector_index_name == other.vector_index_name) && (column_name == other.column_name);
     }
+
+    String toString() const { return table_path + "/" + part_name_no_mutation + "/" + vector_index_name + "-" + column_name; }
 };
 
 struct SegmentId
 {
+    DB::VolumePtr volume;
     String data_part_path;
     String current_part_name;
     String owner_part_name;
     String vector_index_name;
     String column_name;
+    String vector_index_cache_prefix;
     UInt8 owner_part_id;
 
-    SegmentId(const String& data_part_path_, const String& current_part_name_, const String& owner_part_name_,
-              const String& vector_index_name_, const String& column_name_, UInt8 owner_part_id_): 
-              data_part_path(data_part_path_), current_part_name(current_part_name_), owner_part_name(owner_part_name_),
-              vector_index_name(vector_index_name_), column_name(column_name_), owner_part_id(owner_part_id_) {}
+    SegmentId(
+        DB::VolumePtr volume_,
+        const String & data_part_path_,
+        const String & current_part_name_,
+        const String & owner_part_name_,
+        const String & vector_index_name_,
+        const String & column_name_,
+        const String & vector_index_cache_prefix_,
+        UInt8 owner_part_id_)
+        : volume(volume_)
+        , data_part_path(data_part_path_)
+        , current_part_name(current_part_name_)
+        , owner_part_name(owner_part_name_)
+        , vector_index_name(vector_index_name_)
+        , column_name(column_name_)
+        , vector_index_cache_prefix(vector_index_cache_prefix_)
+        , owner_part_id(owner_part_id_)
+    {
+    }
 
 
-    SegmentId(const String& data_part_path_, const String& current_part_name_, 
-              const String& vector_index_name_, const String& column_name_, UInt8 owner_part_id_):
-              data_part_path(data_part_path_), current_part_name(current_part_name_), owner_part_name(current_part_name_),
-              vector_index_name(vector_index_name_), column_name(column_name_), owner_part_id(owner_part_id_) {}
+    SegmentId(
+        DB::VolumePtr volume_,
+        const String & data_part_path_,
+        const String & current_part_name_,
+        const String & vector_index_name_,
+        const String & column_name_,
+        const String & vector_index_cache_prefix_)
+        : volume(volume_)
+        , data_part_path(data_part_path_)
+        , current_part_name(current_part_name_)
+        , owner_part_name(current_part_name_)
+        , vector_index_name(vector_index_name_)
+        , column_name(column_name_)
+        , vector_index_cache_prefix(vector_index_cache_prefix_)
+        , owner_part_id(0)
+    {
+    }
 
-    String getPathSuffix() const
+    String getPathPrefix() const
     {
         /// normal vector index
         if (owner_part_name == current_part_name)
@@ -65,57 +97,35 @@ struct SegmentId
         }
     }
 
-    String getIndexNameWithColumn() const
-    {
-        return vector_index_name + "_" + column_name;
-    }
+    String getIndexNameWithColumn() const { return vector_index_name + "-" + column_name; }
 
-    String getFullPath() const
-    {
-        return getPathSuffix() + getIndexNameWithColumn();
-    }
+    String getFullPath() const { return getPathPrefix() + getIndexNameWithColumn() + "-"; }
 
     CacheKey getCacheKey() const
     {
         fs::path full_path(data_part_path);
-        /// use parent data path, need to call parent_path() twice, 
+        /// use parent data path, need to call parent_path() twice,
         /// according to https://en.cppreference.com/w/cpp/filesystem/path/parent_path
         return CacheKey{full_path.parent_path().parent_path().string(), cutMutVer(owner_part_name), vector_index_name, column_name};
     }
 
-    String getVectorReadyFilePath() const
-    {
-        return getPathSuffix() + VECTOR_INDEX_READY;
-    }
+    String getVectorReadyFilePath() const { return getPathPrefix() + VECTOR_INDEX_READY + VECTOR_INDEX_FILE_SUFFIX; }
 
-    String getBitMapFilePath() const
-    {
-        return getPathSuffix() + VECTOR_INDEX_BITMAP;
-    }
+    String getBitMapFilePath() const { return getPathPrefix() + VECTOR_INDEX_BITMAP + VECTOR_INDEX_FILE_SUFFIX; }
 
-    bool fromMergedParts()
-    {
-        return current_part_name != owner_part_name;
-    }
+    bool fromMergedParts() { return current_part_name != owner_part_name; }
 
-    String getRowIdsMapFilePath() const
-    {
-        return getPathSuffix() + "row_ids_map" + VECTOR_INDEX_FILE_SUFFIX;
-    }
+    String getRowIdsMapFilePath() const { return getPathPrefix() + "row_ids_map" + VECTOR_INDEX_FILE_SUFFIX; }
 
-    String getInvertedRowIdsMapFilePath() const
-    {
-        return data_part_path + "/" + "merged-inverted_row_ids_map" + VECTOR_INDEX_FILE_SUFFIX;
-    }
+    String getInvertedRowIdsMapFilePath() const { return data_part_path + "/" + "merged-inverted_row_ids_map" + VECTOR_INDEX_FILE_SUFFIX; }
 
     String getInvertedRowSourcesMapFilePath() const
     {
         return data_part_path + "/" + "merged-inverted_row_sources_map" + VECTOR_INDEX_FILE_SUFFIX;
-    }    
-
-    UInt8 getOwnPartId() const
-    {
-        return owner_part_id;
     }
+
+    String getVectorIndexCachePrefix() const { return vector_index_cache_prefix; }
+
+    UInt8 getOwnPartId() const { return owner_part_id; }
 };
 }
diff --git a/src/VectorIndex/Status.h b/src/VectorIndex/Status.h
index b6f1afaeab..e8689cb728 100644
--- a/src/VectorIndex/Status.h
+++ b/src/VectorIndex/Status.h
@@ -6,7 +6,7 @@ struct Status
 {
     Status() : code(0) { }
     Status(int c) : code(c) { }
-    Status(int c, const String& msg) : code(c), message(std::move(msg)) { }
+    Status(int c, const String & msg) : code(c), message(std::move(msg)) { }
 
     bool fine() { return code == 0; }
 
@@ -14,7 +14,7 @@ struct Status
 
     void setCode(int error) { code = error; }
 
-    void setMessage(const String& s) { message = s; }
+    void setMessage(const String & s) { message = s; }
 
     String getMessage() { return message; }
 
diff --git a/src/VectorIndex/VectorIndex.h b/src/VectorIndex/VectorIndex.h
deleted file mode 100644
index 4c6274294c..0000000000
--- a/src/VectorIndex/VectorIndex.h
+++ /dev/null
@@ -1,150 +0,0 @@
-#pragma once
-
-#include <memory>
-#include <unordered_map>
-#include <VectorIndex/Binary.h>
-#include <VectorIndex/Dataset.h>
-#include <VectorIndex/GeneralBitMap.h>
-#include <VectorIndex/IndexException.h>
-#include <VectorIndex/IndexReader.h>
-#include <base/logger_useful.h>
-
-namespace VectorIndex
-{
-enum IndexType
-{
-    IVFFLAT,
-    IVFPQ,
-    IVFSQ,
-    FLAT,
-    HNSWFLAT,
-    HNSWPQ,
-    HNSWSQ
-};
-
-enum IndexMode
-{
-    CPU,
-    GPU,
-    FPGA
-};
-
-enum Metrics
-{
-    L2,
-    IP,
-    Cosine
-};
-
-extern std::atomic_int count;
-extern int num_thread_for_vector;
-
-using Parameters = std::unordered_map<std::string, std::string>;
-using AccParametersPack = std::unordered_map<float, Parameters>;
-#define PARAMETER_PACK_NAME "_parameter"
-
-
-/// Interface for vector index definitions,
-/// user-defined vector index should implement all these methods.
-class VectorIndex
-{
-public:
-    VectorIndex() = default;
-    VectorIndex(IndexType it_, IndexMode im_, Metrics me_, int dimension_) : it(it_), me(me_), im(im_), dimension(dimension_) { }
-
-    /// Train vector index on a set of data. Should not insert the data.
-    virtual void train(const VectorDatasetPtr dataset, const int64_t total_vector_expected) = 0;
-
-    /// Adding data into index, the data is supposed to be stored with an <id, vector> mapping inside
-    /// the index such that id autoincrement and one can easily map from an id to the vector inserted.
-    virtual void addWithoutId(const VectorDatasetPtr dataset) = 0;
-
-    /// Remove vectors from index. This function is not used because we use
-    /// VectorSegmentExecutor::delete_bitmap to mark deletion.
-    virtual int64_t removeWithIds(int64_t n, int64_t * ids) = 0;
-
-    /// Search the index with the given dataset and a filter, returns id and distance of each result up to topK results.
-    virtual void search(
-        const VectorDatasetPtr dataset, int32_t topK, float * distances, int64_t * result_id, Parameters & params, GeneralBitMapPtr filter)
-        = 0;
-
-    /// Serialize index into binaries in memory, returns a pointer to that binary.
-    virtual BinaryPtr serialize(size_t max_bytes_to_serialize, bool & finished) = 0;
-
-    /// Load index from IndexReader into a usable index.
-    virtual void load(IndexReader & reader) = 0;
-
-    /// The type of index (IVFFLAT, HNSW, etc)
-    IndexType indexType() { return it; }
-
-    IndexMode indexMode() { return im; }
-
-    Metrics metrics() { return me; }
-
-    void setTrained() { trained = true; }
-
-    bool trainStatus() { return trained; }
-
-    void setIndexSize(size_t index_size_) { index_size = index_size_; }
-
-    size_t sizeInBytes() const { return index_size; }
-
-    /// If possible, get uncompressed vectors stored in memory
-    virtual VectorDatasetPtr getInMemVectors() = 0;
-
-    /// Set parameters for build and search
-    virtual void getMyParameters(Parameters params) = 0;
-
-    virtual AccParametersPack exploreTask(
-        const float * query_data,
-        const int64_t * gt,
-        int topK,
-        int query_size,
-        bool oneRecall,
-        std::mutex & m,
-        std::condition_variable & cv,
-        bool & go,
-        Poco::Logger * log)
-        = 0;
-
-    /// compare this vector index with another, see if all their parameters are the same.
-    virtual bool compare(const VectorIndex & other) = 0;
-
-
-    bool parseParameter(Parameters & param)
-    {
-        try
-        {
-            getMyParameters(param);
-        }
-        catch (const IndexException & e)
-        {
-            LOG_WARNING(&Poco::Logger::get("VectorIndex"), "failed to parse parameters: {}", e.what());
-            return false;
-        }
-        return true;
-    }
-
-    virtual ~VectorIndex() = default;
-
-protected:
-    IndexType it; // ivfpq, flat, hnsw
-    Metrics me; // L1, L2, IP, Cosine
-    IndexMode im; // cpu, gpu
-    int dimension; // dimension
-    bool trained = false; // searchabled
-    int64_t total_vector = 0;
-    size_t index_size = 0;
-
-protected:
-    virtual void * convertInnerBitMap(GeneralBitMapPtr sharedPtr) = 0; //TODO might be too expensive
-    virtual BinaryPtr convertStructToBinary(uint8_t * index_data, uint64_t written_size) = 0;
-
-private:
-    /// used to store old2new row id map for merge operation.
-    std::vector<int> row_ids_map;
-};
-
-using VectorIndexPtr = std::shared_ptr<VectorIndex>;
-
-}
diff --git a/src/VectorIndex/VectorIndexCommon.h b/src/VectorIndex/VectorIndexCommon.h
index c933a474f9..98774246a5 100644
--- a/src/VectorIndex/VectorIndexCommon.h
+++ b/src/VectorIndex/VectorIndexCommon.h
@@ -6,15 +6,14 @@
 #include <Poco/JSON/JSON.h>
 #include <Poco/JSON/Object.h>
 
-#include <Interpreters/OpenTelemetrySpanLog.h>
+#include <Common/Exception.h>
 #include <Compression/CompressedReadBuffer.h>
 #include <Compression/CompressedWriteBuffer.h>
+#include <Interpreters/OpenTelemetrySpanLog.h>
 
 #include <VectorIndex/BruteForceSearch.h>
-#include <VectorIndex/GeneralBitMap.h>
 #include <VectorIndex/IOReader.h>
 #include <VectorIndex/IOWriter.h>
-#include <VectorIndex/VectorIndexFactory.h>
 
 #pragma GCC diagnostic push
 #pragma GCC diagnostic ignored "-Wzero-as-null-pointer-constant"
@@ -23,36 +22,65 @@
 #include <rapidjson/writer.h>
 #pragma GCC diagnostic pop
 
-#define VECTOR_INDEX_FILE_SUFFIX ".vidx"
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wzero-as-null-pointer-constant"
+#pragma GCC diagnostic ignored "-Wunused-parameter"
+#pragma GCC diagnostic ignored "-Wextra-semi-stmt"
+#pragma GCC diagnostic ignored "-Wold-style-cast"
+#pragma GCC diagnostic ignored "-Wc++20-compat"
+#pragma GCC diagnostic ignored "-Walloca"
+#pragma GCC diagnostic ignored "-Wmissing-noreturn"
+#pragma GCC diagnostic ignored "-Wgcc-compat"
+#pragma GCC diagnostic ignored "-Wcovered-switch-default"
+#pragma GCC diagnostic ignored "-Wgnu-zero-variadic-macro-arguments"
+#pragma GCC diagnostic ignored "-Wextra-semi"
+#pragma GCC diagnostic ignored "-Wfinal-dtor-non-final-class"
+#pragma GCC diagnostic ignored "-Wundef"
+#pragma GCC diagnostic ignored "-Wsuggest-override"
+#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
+#pragma GCC diagnostic ignored "-Wdeprecated-copy-with-user-provided-dtor"
+#pragma GCC diagnostic ignored "-Wmismatched-tags"
+#pragma GCC diagnostic ignored "-Wundefined-reinterpret-cast"
+#pragma GCC diagnostic ignored "-Wsign-compare"
+#pragma GCC diagnostic ignored "-Wshadow-uncaptured-local"
+#pragma GCC diagnostic ignored "-Wunused-variable"
+#pragma GCC diagnostic ignored "-Wunused-private-field"
+#pragma GCC diagnostic ignored "-Wshadow-field"
+#pragma GCC diagnostic ignored "-Wdelete-non-abstract-non-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wshadow"
+#pragma GCC diagnostic ignored "-Wnon-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wrange-loop-bind-reference"
+#pragma GCC diagnostic ignored "-Wenum-compare-switch"
+#pragma GCC diagnostic ignored "-Wnewline-eof"
+#pragma GCC diagnostic ignored "-Wreorder-ctor"
+#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+#pragma GCC diagnostic ignored "-Wreserved-identifier"
+#include <SearchIndex/SearchIndexCommon.h>
+#include <SearchIndex/VectorIndex.h>
+#pragma GCC diagnostic pop
+
+#define VECTOR_INDEX_FILE_SUFFIX ".vidx2"
 #define MAX_BRUTE_FORCE_SEARCH_SIZE 50000
 #define MIN_SEGMENT_SIZE 1000000
 #define VECTOR_INDEX_READY "vector_index_ready"
-#define VECTOR_INDEX_BITMAP "vector_bitMap"
+#define VECTOR_INDEX_BITMAP "vector_bitmap"
 
-namespace VectorIndex
+namespace DB
 {
-///for now, we stick with std implementation
-static inline int64_t StoI(const String& text)
+namespace ErrorCodes
 {
-    return std::stoll(text);
+    extern const int BAD_ARGUMENTS;
 }
-
-static inline std::string ItoS(int64_t i)
-{
-    return std::to_string(i);
 }
-
-static inline float StoF(const String& text)
+namespace VectorIndex
 {
-    return std::stof(text);
-}
 
-static inline std::string FtoS(float f)
-{
-    return std::to_string(f);
-}
+const int DEFAULT_TOPK = 30;
 
-static inline std::string ParametersToString(const Parameters& params)
+using VectorIndexPtr = std::shared_ptr<
+    Search::VectorIndex<Search::AbstractIStream, Search::AbstractOStream, Search::DenseBitmap, Search::DataType::FloatVector>>;
+
+static inline std::string ParametersToString(const Search::Parameters & params)
 {
     rapidjson::StringBuffer strBuf;
     rapidjson::Writer<rapidjson::StringBuffer> writer(strBuf);
@@ -66,49 +94,9 @@ static inline std::string ParametersToString(const Parameters& params)
     return strBuf.GetString();
 }
 
-static inline std::string AccParametersPackToString(const AccParametersPack& pack)
+static inline Search::Parameters convertPocoJsonToMap(Poco::JSON::Object::Ptr json)
 {
-    rapidjson::StringBuffer strBuf;
-    rapidjson::Writer<rapidjson::StringBuffer> writer(strBuf);
-    writer.StartObject();
-    for (auto & pair : pack)
-    {
-        writer.Key(FtoS(pair.first).c_str());
-        writer.StartObject();
-        for (auto & para : pair.second)
-        {
-            writer.Key(para.first.c_str());
-            writer.String(para.second.c_str());
-        }
-        writer.EndObject();
-    }
-    writer.EndObject();
-    return strBuf.GetString();
-}
-
-static inline AccParametersPack StringToAccParametersPack(const String& raw, Poco::Logger * log)
-{
-    AccParametersPack pack;
-    rapidjson::Document doc;
-    doc.Parse(raw.c_str());
-    for (auto & m : doc.GetObject())
-    {
-        LOG_TRACE(log, "{}", m.name.GetString());
-        std::unordered_map<std::string, std::string> params;
-        for (auto m2 = m.value.MemberBegin(); m2 != m.value.MemberEnd(); m2++)
-        {
-            LOG_TRACE(log, "{}", m2->name.GetString());
-            LOG_TRACE(log, "{}", m2->value.GetString());
-            params.insert(std::make_pair(m2->name.GetString(), m2->value.GetString()));
-        }
-        pack.insert(std::make_pair(StoF(m.name.GetString()), params));
-    }
-    return pack;
-}
-
-static inline Parameters convertPocoJsonToMap(Poco::JSON::Object::Ptr json)
-{
-    Parameters params;
+    Search::Parameters params;
     if (json)
     {
         for (Poco::JSON::Object::ConstIterator it = json->begin(); it != json->end(); it++)
@@ -120,165 +108,37 @@ static inline Parameters convertPocoJsonToMap(Poco::JSON::Object::Ptr json)
     return params;
 }
 
-static inline std::string generateUnsupportedParameters(const Parameters& params, IndexType type)
-{
-    std::string message = "These parameters are not supported in Index type ";
-    message = message + VectorIndexFactory::typeToString(type) + " : ";
-    for (auto & each : params)
-    {
-        message = message + each.first + " : ";
-        message = message + each.second + ", ";
-    }
-    return message;
-}
-
-static inline std::unordered_map<String, int64_t> readVectorIndexReadyFile(
-    IOReader & reader, const String& ready_file, const std::vector<String>& index_name, std::unordered_map<String, Parameters> & index_parameters)
+inline Search::IndexType getIndexType(const std::string & type)
 {
-    std::unordered_map<String, int64_t> pair;
-    if (!reader.open(ready_file + VECTOR_INDEX_FILE_SUFFIX))
-    {
-        if (!reader.open(ready_file))
-        {
-            return pair;
-        }
-    }
-    std::unique_ptr<char[]> chars(new char[reader.length()]);
-    reader.read(chars.get(), reader.length());
-    String lines(chars.get(), reader.length());
-    std::stringstream stream(lines);
-    std::string aline;
-    while (std::getline(stream, aline))
-    {
-        int64_t original_index_size = -1;
-        for (auto & one_index_name : index_name)
-        {
-            if (static_cast<int>(aline.find(one_index_name)) != -1)
-            {
-                std::string temp_string;
-                std::string type;
-                int c = 0;
-                ///If there are multiple copies of one_index_name due to any reasons, use the last occurence.
-                index_parameters.insert_or_assign(one_index_name, Parameters());
-                std::stringstream inner_stream(aline);
-                while (std::getline(inner_stream, temp_string, ';'))
-                {
-                    if (static_cast<int>(temp_string.find(':')) != -1)
-                    {
-                        break;
-                    }
-                    if (c == 0)
-                    {
-                        type = temp_string;
-                        index_parameters.find(one_index_name)->second.insert(std::make_pair("type", type));
-                        c++;
-                    }
-                    else if (c == 1)
-                    {
-                        std::string para_string;
-                        std::string para_string2;
-                        bool even = true;
-                        std::stringstream innermost_stream(temp_string);
-                        while (std::getline(innermost_stream, para_string, ','))
-                        {
-                            if (even)
-                            {
-                                para_string2 = para_string;
-                                even = false;
-                            }
-                            else
-                            {
-                                index_parameters.find(one_index_name)->second.insert(std::make_pair(para_string2, para_string));
-                                even = true;
-                            }
-                        }
-                        c++;
-                    }
-                }
-                std::string length_string = aline.substr(aline.find(':') + 1, aline.length()); ///index_name:1234
-                original_index_size = StoI(length_string);
-                pair.insert_or_assign(one_index_name, original_index_size);
-                break;
-            }
-        }
-    }
-    reader.close();
-    return pair;
+    auto upper = Poco::toUpper(type);
+    if (upper == "IVFFLAT")
+        return Search::IndexType::IVFFLAT;
+    else if (upper == "IVFPQ")
+        return Search::IndexType::IVFPQ;
+    else if (upper == "IVFSQ")
+        return Search::IndexType::IVFSQ;
+    else if (upper == "FLAT")
+        return Search::IndexType::FLAT;
+    else if (upper == "HNSWFLAT" || upper == "HNSWFASTFLAT")
+        return Search::IndexType::HNSWfastFLAT;
+    else if (upper == "HNSWPQ" || upper == "HNSWFASTPQ")
+        return Search::IndexType::HNSWPQ;
+    else if (upper == "HNSWSQ" || upper == "HNSWFASTSQ")
+        return Search::IndexType::HNSWfastSQ;
+    else if (upper == "MSTG")
+        return Search::IndexType::MSTG;
+    throw DB::Exception("Unknown index type: " + type, DB::ErrorCodes::BAD_ARGUMENTS);
 }
 
-static inline GeneralBitMapPtr mergeBitMap(GeneralBitMapPtr left, GeneralBitMapPtr right)
+inline Search::Metric getMetric(const std::string & metric)
 {
-    DB::OpenTelemetrySpanHolder span("mergeBitMap");
-    int64_t vector_count = left->get_size();
-    GeneralBitMapPtr after_merge = std::make_shared<GeneralBitMap>();
-    char * bits = new char[(vector_count >> 3) + 1]; // size/8 = bytes
-    char * left_bits = left->bitmap;
-    char * right_bits = right->bitmap;
-    size_t bit_size = 0;
-    for (int64_t i = 0; i < (vector_count >> 3) + 1; ++i)
-    {
-        bits[i] = left_bits[i] & right_bits[i];
-        if (bits[i])
-        {
-            ++bit_size;
-        }
-    }
-    LOG_DEBUG(&Poco::Logger::get("mergeBitMap"), "mergeBitMap: bit size: {}, vector_count: {}", bit_size, vector_count);
-    after_merge->bitmap = bits;
-    after_merge->size = vector_count;
-    return after_merge;
+    auto upper = Poco::toUpper(metric);
+    if (upper == "L2")
+        return Search::Metric::L2;
+    else if (upper == "IP")
+        return Search::Metric::IP;
+    else if (upper == "COSINE")
+        return Search::Metric::Cosine;
+    throw DB::Exception("Unknown metric: " + metric, DB::ErrorCodes::BAD_ARGUMENTS);
 }
-
-static inline size_t compressBound(int64_t raw_size, uint8_t cmb)
-{
-    int64_t max_precompress_size = 0;
-    if (cmb == static_cast<UInt8>(DB::CompressionMethodByte::LZ4))
-    {
-        max_precompress_size = LZ4_MAX_INPUT_SIZE;
-    }
-    else if (cmb == static_cast<UInt8>(DB::CompressionMethodByte::NONE))
-    {
-        max_precompress_size = (1LL << 32) - 10;
-    }
-    return max_precompress_size < raw_size ? max_precompress_size : raw_size;
-}
-
-using rng_type = std::mt19937;
-static inline void getQueryandGt(
-    VectorDatasetPtr base, float * gt_dis, int64_t * gt, float * query, int default_topk, int default_query_size, Metrics default_metrics)
-{
-    std::vector<int64_t> query_ids;
-    query_ids.reserve(default_query_size);
-    ///might be fewer
-    GeneralBitMapPtr bits = std::make_shared<GeneralBitMap>(base->getVectorNum());
-    memset(bits->bitmap, 255, (base->getVectorNum() / 8) + 1);
-    ///might be fewer
-
-    float * base_data = base->getData();
-    std::uniform_int_distribution<> udist(0, base->getVectorNum());
-    rng_type rng;
-    int dimension = base->getDimension();
-    for (int i = 0; i < default_query_size; i++)
-    {
-        int index = udist(rng);
-        query_ids.emplace_back(index);
-        for (int k = 0; k < dimension; k++)
-        {
-            query[i * dimension + k] = base_data[index * dimension + k];
-        }
-    }
-    ///we extract query_size random vectors from base, use them as query to test against base so we can produce a ground truth table.
-    ///we are not using the ids of those query directly because some metric type will make a vector have greater distance with itself
-    ///than others (such as IP).
-    tryBruteForceSearch(query, base_data, dimension, default_topk, default_query_size, base->getVectorNum(), gt, gt_dis, default_metrics);
-}
-
-inline String str_toupper(String s)
-{
-    std::transform(
-        s.begin(), s.end(), s.begin(), [](unsigned char c) { return std::toupper(c); } // correct
-    );
-    return s;
-}
-
 }
diff --git a/src/VectorIndex/VectorIndexFactory.cpp b/src/VectorIndex/VectorIndexFactory.cpp
deleted file mode 100644
index e61a8bc73d..0000000000
--- a/src/VectorIndex/VectorIndexFactory.cpp
+++ /dev/null
@@ -1,199 +0,0 @@
-#include "VectorIndexFactory.h"
-#include "FlatIndex.h"
-#include "HNSWIndex.h"
-#include "HNSWPQ.h"
-#include "HNSWSQ.h"
-#include "IVFFlatIndex.h"
-#include "IVFPQIndex.h"
-#include "IVFSQIndex.h"
-#include "IndexException.h"
-
-namespace DB::ErrorCodes
-{
-extern const int LOGICAL_ERROR;
-}
-
-namespace VectorIndex
-{
-VectorIndexPtr VectorIndexFactory::createIndex(IndexType it, IndexMode im, Metrics me, int dimension, Parameters parameters)
-{
-    if (it == IndexType::IVFFLAT)
-    {
-        return std::make_shared<IVFFlatIndex>(it, im, me, dimension, parameters);
-    }
-    else if (it == IndexType::IVFPQ)
-    {
-        return std::make_shared<IVFPQIndex>(it, im, me, dimension, parameters);
-    }
-    else if (it == IndexType::IVFSQ)
-    {
-        return std::make_shared<IVFSQIndex>(it, im, me, dimension, parameters);
-    }
-    else if (it == IndexType::FLAT)
-    {
-        return std::make_shared<FlatIndex>(it, im, me, dimension, parameters);
-    }
-    else if (it == IndexType::HNSWFLAT)
-    {
-        return std::make_shared<HNSWIndex>(it, im, me, dimension, parameters);
-    }
-    else if (it == IndexType::HNSWPQ)
-    {
-        return std::make_shared<HNSWpq>(it, im, me, dimension, parameters);
-    }
-    else if (it == IndexType::HNSWSQ)
-    {
-        return std::make_shared<HNSWsq>(it, im, me, dimension, parameters);
-    }
-    return nullptr;
-}
-
-bool VectorIndexFactory::typeExist(std::string index_type)
-{
-    return (
-        index_type == "IVFFLAT" || index_type == "IVFPQ" || index_type == "IVFSQ" || index_type == "FLAT" || index_type == "HNSW"
-        || index_type == "HNSWFLAT" || index_type == "HNSWPQ" || index_type == "HNSWSQ");
-}
-
-IndexType VectorIndexFactory::createIndexType(std::string index_type)
-{
-    if (index_type == "IVFFLAT")
-    {
-        return IndexType::IVFFLAT;
-    }
-    if (index_type == "IVFPQ")
-    {
-        return IndexType::IVFPQ;
-    }
-    if (index_type == "IVFSQ")
-    {
-        return IndexType::IVFSQ;
-    }
-    if (index_type == "FLAT")
-    {
-        return IndexType::FLAT;
-    }
-    if (index_type == "HNSW" || index_type == "HNSWFLAT")
-    {
-        return IndexType::HNSWFLAT;
-    }
-    if (index_type == "HNSWPQ")
-    {
-        return IndexType::HNSWPQ;
-    }
-    if (index_type == "HNSWSQ")
-    {
-        return IndexType::HNSWSQ;
-    }
-    __builtin_unreachable();
-}
-
-std::string VectorIndexFactory::typeToString(IndexType it)
-{
-    if (it == IndexType::IVFFLAT)
-    {
-        return std::string("IVFFLAT");
-    }
-    else if (it == IndexType::IVFPQ)
-    {
-        return std::string("IVFPQ");
-    }
-    else if (it == IndexType::IVFSQ)
-    {
-        return std::string("IVFSQ");
-    }
-    else if (it == IndexType::FLAT)
-    {
-        return std::string("FLAT");
-    }
-    else if (it == IndexType::HNSWFLAT)
-    {
-        return std::string("HNSWFLAT");
-    }
-    else if (it == IndexType::HNSWPQ)
-    {
-        return std::string("HNSWPQ");
-    }
-    else if (it == IndexType::HNSWSQ)
-    {
-        return std::string("HNSWSQ");
-    }
-    return "";
-}
-std::string VectorIndexFactory::MetricToString(Metrics me)
-{
-    if (me == Metrics::L2)
-    {
-        return std::string("L2");
-    }
-    else if (me == Metrics::IP)
-    {
-        return std::string("IP");
-    }
-    else if (me == Metrics::Cosine)
-    {
-        return std::string("COSINE");
-    }
-    return "";
-}
-
-inline std::string str_toupper(std::string s)
-{
-    std::transform(
-        s.begin(), s.end(), s.begin(), [](unsigned char c) { return std::toupper(c); } // correct
-    );
-    return s;
-}
-
-Metrics VectorIndexFactory::createIndexMetrics(std::string index_metric)
-{
-    auto upper_case = str_toupper(index_metric);
-    if (upper_case == "L2")
-    {
-        return Metrics::L2;
-    }
-    if (upper_case == "IP")
-    {
-        return Metrics::IP;
-    }
-    if (upper_case == "COSINE")
-    {
-        return Metrics::Cosine;
-    }
-    throw IndexException(DB::ErrorCodes::UNSUPPORTED_PARAMETER, "unknown metric_type {}", index_metric);
-}
-
-std::string VectorIndexFactory::modeToString(IndexMode mode)
-{
-    if (mode == IndexMode::CPU)
-    {
-        return std::string("CPU");
-    }
-    else if (mode == IndexMode::GPU)
-    {
-        return std::string("GPU");
-    }
-    else if (mode == IndexMode::FPGA)
-    {
-        return std::string("FPGA");
-    }
-    return "";
-}
-
-IndexMode VectorIndexFactory::createIndexMode(std::string index_mode)
-{
-    if (index_mode == "CPU")
-    {
-        return IndexMode::CPU;
-    }
-    if (index_mode == "GPU")
-    {
-        return IndexMode::GPU;
-    }
-    if (index_mode == "FPGA")
-    {
-        return IndexMode::FPGA;
-    }
-    __builtin_unreachable();
-}
-}
diff --git a/src/VectorIndex/VectorIndexFactory.h b/src/VectorIndex/VectorIndexFactory.h
deleted file mode 100644
index 6a933a6f5a..0000000000
--- a/src/VectorIndex/VectorIndexFactory.h
+++ /dev/null
@@ -1,19 +0,0 @@
-#pragma once
-
-#include "VectorIndex.h"
-
-namespace VectorIndex
-{
-class VectorIndexFactory
-{
-public:
-    static bool typeExist(std::string index_type);
-    static IndexType createIndexType(std::string index_type);
-    static Metrics createIndexMetrics(std::string index_metric);
-    static IndexMode createIndexMode(std::string index_mode);
-    static VectorIndexPtr createIndex(IndexType it, IndexMode im, Metrics me, int dimension, Parameters parameters);
-    static std::string typeToString(IndexType it);
-    static std::string MetricToString(Metrics me);
-    static std::string modeToString(IndexMode mode);
-};
-}
diff --git a/src/VectorIndex/VectorSegmentExecutor.cpp b/src/VectorIndex/VectorSegmentExecutor.cpp
index 491168d0a5..fd7d833944 100644
--- a/src/VectorIndex/VectorSegmentExecutor.cpp
+++ b/src/VectorIndex/VectorSegmentExecutor.cpp
@@ -1,7 +1,9 @@
 #include <VectorIndex/VectorSegmentExecutor.h>
-#include <random>
+
 #include <thread>
+#include <sys/resource.h>
 #include <omp.h>
+
 #include <boost/algorithm/string/split.hpp>
 
 #include <Compression/CompressedReadBuffer.h>
@@ -10,18 +12,56 @@
 #include <IO/BufferWithOwnMemory.h>
 #include <IO/ReadBufferFromFile.h>
 #include <IO/WriteHelpers.h>
+#include <Common/Exception.h>
+#include <Common/HashTable/HashMap.h>
+#include <Common/getNumberOfPhysicalCPUCores.h>
+#include <Common/MemoryStatisticsOS.h>
+
 #include <Interpreters/OpenTelemetrySpanLog.h>
 #include <VectorIndex/BruteForceSearch.h>
 #include <VectorIndex/CacheManager.h>
-#include <VectorIndex/CompositeIndexReader.h>
 #include <VectorIndex/DiskIOReader.h>
 #include <VectorIndex/DiskIOWriter.h>
 #include <VectorIndex/IndexException.h>
 #include <VectorIndex/MergeUtils.h>
+#include <VectorIndex/Metadata.h>
 #include <VectorIndex/VectorIndexCommon.h>
-#include <VectorIndex/VectorIndexFactory.h>
-#include <Common/Exception.h>
-#include <Common/HashTable/HashMap.h>
+
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wzero-as-null-pointer-constant"
+#pragma GCC diagnostic ignored "-Wunused-parameter"
+#pragma GCC diagnostic ignored "-Wextra-semi-stmt"
+#pragma GCC diagnostic ignored "-Wold-style-cast"
+#pragma GCC diagnostic ignored "-Wc++20-compat"
+#pragma GCC diagnostic ignored "-Walloca"
+#pragma GCC diagnostic ignored "-Wmissing-noreturn"
+#pragma GCC diagnostic ignored "-Wgcc-compat"
+#pragma GCC diagnostic ignored "-Wcovered-switch-default"
+#pragma GCC diagnostic ignored "-Wgnu-zero-variadic-macro-arguments"
+#pragma GCC diagnostic ignored "-Wextra-semi"
+#pragma GCC diagnostic ignored "-Wfinal-dtor-non-final-class"
+#pragma GCC diagnostic ignored "-Wundef"
+#pragma GCC diagnostic ignored "-Wsuggest-override"
+#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
+#pragma GCC diagnostic ignored "-Wdeprecated-copy-with-user-provided-dtor"
+#pragma GCC diagnostic ignored "-Wmismatched-tags"
+#pragma GCC diagnostic ignored "-Wundefined-reinterpret-cast"
+#pragma GCC diagnostic ignored "-Wsign-compare"
+#pragma GCC diagnostic ignored "-Wshadow-uncaptured-local"
+#pragma GCC diagnostic ignored "-Wunused-variable"
+#pragma GCC diagnostic ignored "-Wunused-private-field"
+#pragma GCC diagnostic ignored "-Wshadow-field"
+#pragma GCC diagnostic ignored "-Wdelete-non-abstract-non-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wshadow"
+#pragma GCC diagnostic ignored "-Wnon-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wrange-loop-bind-reference"
+#pragma GCC diagnostic ignored "-Wenum-compare-switch"
+#pragma GCC diagnostic ignored "-Wnewline-eof"
+#pragma GCC diagnostic ignored "-Wreorder-ctor"
+#pragma GCC diagnostic ignored "-Wdeprecated-declarations"
+#include <SearchIndex/Common/Utils.h>
+#include <SearchIndex/IndexDataFileIO.h>
+#pragma GCC diagnostic pop
 
 #include <base/logger_useful.h>
 
@@ -33,13 +73,49 @@ extern const int CORRUPTED_DATA;
 
 namespace VectorIndex
 {
-std::once_flag once;
-std::shared_mutex mu;
-std::condition_variable_any cv;
-int num_thread_for_vector;
-std::atomic_int count;
 
-auto VectorSegmentExecutor::log = &Poco::Logger::get("VectorSegmentExecutor");
+void printMemoryInfo(const Poco::Logger * log, std::string msg)
+{
+#if defined(OS_LINUX) || defined(OS_FREEBSD)
+    struct rusage usage;
+    getrusage(RUSAGE_SELF, &usage);
+    DB::MemoryStatisticsOS memory_stat;
+    DB::MemoryStatisticsOS::Data data = memory_stat.get();
+    LOG_INFO(
+        log,
+        "{}: peak resident memory {} MB, resident memory {} MB, virtual memory {} MB",
+        msg,
+        usage.ru_maxrss / 1024,
+        data.resident / 1024 / 1024,
+        data.virt / 1024 / 1024);
+#endif
+}
+
+class SearchThreadLimiter
+{
+public:
+    SearchThreadLimiter(const Poco::Logger * log, int max_threads)
+    {
+        std::shared_lock<std::shared_mutex> lock(mutex);
+        cv.wait(lock, [&] { return count.load() < max_threads; });
+        count.fetch_add(1);
+        LOG_DEBUG(log, "Index search uses {}/{} threads", count.load(), max_threads);
+    }
+
+    ~SearchThreadLimiter()
+    {
+        count.fetch_sub(1);
+        cv.notify_one();
+    }
+private:
+    static std::shared_mutex mutex;
+    static std::condition_variable_any cv;
+    static std::atomic_int count;
+};
+
+std::shared_mutex SearchThreadLimiter::mutex;
+std::condition_variable_any SearchThreadLimiter::cv;
+std::atomic_int SearchThreadLimiter::count(0);
 
 String cutMutVer(const String & part_name)
 {
@@ -53,109 +129,100 @@ String cutMutVer(const String & part_name)
         return tokens[0] + "_" + tokens[1] + "_" + tokens[2] + "_" + tokens[3];
 }
 
-static String dumpBitmap(GeneralBitMapPtr bit_map_ptr)
-{
-    if (bit_map_ptr == nullptr)
-    {
-        return "";
-    }
-
-    String r;
-
-    const int size = bit_map_ptr->size;
-    for (int i = 0; i < 10 && i < size; ++i)
-    {
-        if (i > 0)
-        {
-            r += ",";
-        }
-        r += (bit_map_ptr->test(i) ? "1" : "0");
-    }
-
-    return r;
-}
+std::once_flag VectorSegmentExecutor::once;
+int VectorSegmentExecutor::max_threads = 0;
 
-/// TODO segment_id needs to be dynamic in the future
-VectorSegmentExecutor::VectorSegmentExecutor(IndexType type_, const SegmentId & segment_id_, Parameters des_, size_t dimension_)
-    : dimension(dimension_), type(type_), segment_id(segment_id_), des(des_)
+void VectorSegmentExecutor::init()
 {
-    std::call_once(once, [&] {
-        int num_threads = omp_get_max_threads();
-        if (num_threads <= 0)
+    std::call_once(
+        once,
+        [&]
         {
-            num_threads = 16;
-        }
-        num_thread_for_vector = num_threads;
-        omp_set_num_threads(num_thread_for_vector);
-        count.store(0);
-        LOG_DEBUG(log, "Set omp_num_threads to {}", num_threads);
-    });
+            max_threads = getNumberOfPhysicalCPUCores() * 2;
+            LOG_INFO(log, "Max threads for vector index: {}", max_threads);
+        });
+}
+
+VectorSegmentExecutor::VectorSegmentExecutor(
+    const SegmentId & segment_id_,
+    Search::IndexType type_,
+    Search::Metric metric_,
+    size_t dimension_,
+    size_t total_vec_,
+    Search::Parameters des_,
+    size_t min_bytes_to_build_vector_index_,
+    bool DEFAULT_DISK_MODE_)
+    : DEFAULT_DISK_MODE(DEFAULT_DISK_MODE_)
+    , segment_id(segment_id_)
+    , type(type_)
+    , metric(metric_)
+    , dimension(dimension_)
+    , total_vec(total_vec_)
+    , des(des_)
+    , min_bytes_to_build_vector_index(min_bytes_to_build_vector_index_)
+{
+    init();
 }
 
-VectorSegmentExecutor::VectorSegmentExecutor(const SegmentId & segment_id_)
-    : dimension(0)
-    , type(IndexType::FLAT)
-    , mode(IndexMode::CPU)
-    , me(Metrics::L2)
-    , segment_id(segment_id_)
+VectorSegmentExecutor::VectorSegmentExecutor(const SegmentId & segment_id_) : DEFAULT_DISK_MODE(false), segment_id(segment_id_)
 {
+    init();
 }
 
-Status VectorSegmentExecutor::buildIndex(VectorDatasetPtr data_set, int64_t total_vectors_expected, bool slow_mode)
+void VectorSegmentExecutor::buildIndex(PartReader * reader, bool slow_mode, size_t train_block_size, size_t add_block_size)
 {
-    Parameters para_copy = des;
-    try
-    {
-        if (!index)
-        {
-            LOG_DEBUG(log, "Index type actually created {}", VectorIndexFactory::typeToString(type));
-            if (para_copy.contains("metric_type"))
-            {
-                me = VectorIndexFactory::createIndexMetrics(para_copy.at("metric_type"));
-                para_copy.erase("metric_type");
-            }
-            if (para_copy.contains("mode"))
-            {
-                mode = VectorIndexFactory::createIndexMode(para_copy.at("mode"));
-                para_copy.erase("mode");
-            }
-            if (para_copy.contains("compression_scheme"))
-            {
-                cmb = DB::CompressionCodecFactory::instance().get(para_copy.find("compression_scheme")->second, {})->getMethodByte();
-                para_copy.erase("compression_scheme");
-            }
-            index = VectorIndexFactory::createIndex(type, mode, me, this->dimension, para_copy);
+    DB::OpenTelemetrySpanHolder span("VectorSegmentExecutor::buildIndex");
 
-            {
-                /// slow mode
-                if (slow_mode)
-                {
-                    int num_procs = omp_get_num_procs();
-                    /// only use half cores
-                    omp_set_num_threads(std::max(1, num_procs / 4));
-                    LOG_DEBUG(log, "Build index in slow mode, set num threads to {} with omp_get_num_procs {}", std::max(1, num_procs / 4), num_procs);
-                }
-            }
+    auto num_threads = max_threads;
+    if (slow_mode)
+        num_threads = num_threads / 2;
+    if (num_threads == 0)
+        num_threads = 1;
 
-            index->train(data_set, total_vectors_expected);
-            if (delete_bitmap == nullptr)
+    if (total_vec * dimension * sizeof(float) < min_bytes_to_build_vector_index)
+    {
+        fallback_to_flat = true;
+        type = Search::IndexType::FLAT;
+        std::erase_if(
+            des,
+            [](const auto & item)
             {
-                delete_bitmap = std::make_shared<GeneralBitMap>(total_vectors_expected);
-                memset(delete_bitmap->bitmap, 255, (total_vectors_expected / 8) + 1);
-            }
-            return Status();
-        }
-        else
-        {
-            /// maybe can never reach here
-            return Status(5, "vector index already built!");
-        }
+                auto const & [key, value] = item;
+                return key != "metric_type";
+            });
     }
-    catch (const IndexException & e)
+
+    try
+    {
+        configureDiskMode();
+        index = Search::
+            createVectorIndex<Search::AbstractIStream, Search::AbstractOStream, Search::DenseBitmap, Search::DataType::FloatVector>(
+                segment_id.getIndexNameWithColumn(),
+                type,
+                metric,
+                dimension,
+                total_vec,
+                des,
+                true,
+                vector_index_cache_prefix,
+                getDiskIOManager(),
+                true);
+        index->setTrainDataChunkSize(train_block_size);
+        index->setAddDataChunkSize(add_block_size);
+        printMemoryInfo(log, "Before build");
+        index->build(reader, num_threads);
+        printMemoryInfo(log, "After build");
+    }
+    catch (const SearchIndexException & e)
+    {
+        throw IndexException(e.getCode(), e.what());
+    }
+    catch (const DB::Exception & e)
     {
-        LOG_ERROR(log, "IndexException: {}, {}", e.code(), e.message());
-        return Status(e.code(), e.message());
+        throw e;
     }
+
+    delete_bitmap = std::make_shared<Search::DenseBitmap>(total_vec, true);
 }
 
 void VectorSegmentExecutor::updateCacheValueWithRowIdsMaps()
@@ -165,7 +232,7 @@ void VectorSegmentExecutor::updateCacheValueWithRowIdsMaps()
     {
         handleMergedMaps();
     }
-    catch(const DB::Exception & e)
+    catch (const DB::Exception & e)
     {
         LOG_DEBUG(log, "Failed to load inverted row ids map entries, error: {}", e.what());
         return;
@@ -180,10 +247,11 @@ void VectorSegmentExecutor::updateCacheValueWithRowIdsMaps()
     IndexWithMetaHolderPtr index_holder = mgr->get(cache_key);
     if (index_holder)
     {
-        IndexWithMeta & index = index_holder->value();
-        index.row_ids_map = this->row_ids_map;
-        index.inverted_row_ids_map = this->inverted_row_ids_map;
-        index.inverted_row_sources_map = this->inverted_row_sources_map;
+        IndexWithMeta & index_with_meta = index_holder->value();
+        index_with_meta.fallback_to_flat = fallback_to_flat;
+        index_with_meta.row_ids_map = this->row_ids_map;
+        index_with_meta.inverted_row_ids_map = this->inverted_row_ids_map;
+        index_with_meta.inverted_row_sources_map = this->inverted_row_sources_map;
     }
     /// not handle empty cache case here.
 }
@@ -197,13 +265,18 @@ Status VectorSegmentExecutor::cache()
         LOG_INFO(log, "{} index is null, not caching", segment_id.getCacheKey().toString());
         return Status(3);
     }
-    if (!des.contains("type"))
-    {
-        des.insert(std::make_pair("type", VectorIndexFactory::typeToString(type)));
-    }
     /// when cacheIndexAndMeta() is called, related files should have already been loaded.
-    IndexWithMetaPtr cache_item = std::make_shared<IndexWithMeta>(index, total_vec, op_points, delete_bitmap, des,
-        row_ids_map, inverted_row_ids_map, inverted_row_sources_map);
+    IndexWithMetaPtr cache_item = std::make_shared<IndexWithMeta>(
+        index,
+        total_vec,
+        delete_bitmap,
+        des,
+        row_ids_map,
+        inverted_row_ids_map,
+        inverted_row_sources_map,
+        disk_mode,
+        fallback_to_flat,
+        vector_index_cache_prefix);
 
     LOG_DEBUG(log, "Cache key: {}", segment_id.getCacheKey().toString());
     mgr->put(segment_id.getCacheKey(), cache_item);
@@ -213,147 +286,35 @@ Status VectorSegmentExecutor::cache()
 
 Status VectorSegmentExecutor::serialize()
 {
-    /// Serialization contains three steps:
-    /// 1. write vector_index_ready file to mark that we start writting
-    /// 2. incrementally write index file
-    /// 3. write vector_index_ready file to mark that we finished writting
-    ///    vector_index_ready file is a binary_log which can only be appended
-    ///    to but not altered
     try
     {
-        int64_t binary_total_size = 0;
-        bool last_part = false;
-        int segment_count = 0;
-        BinaryPtr index_binary;
-        startWrite();
-        while (!last_part)
-        {
-            /// Even though we set the max bytes to serialize for serialization,
-            /// it could exceed this amount by accident,then we need to handle the exceeded part.
-            LOG_DEBUG(log, "expected segment_size: {}", optimal_segment_size);
-            index_binary = index->serialize(optimal_segment_size, last_part);
-            if (index_binary->size <= 0)
-            {
-                break;
-            }
-            binary_total_size += index_binary->size;
-            LOG_DEBUG(log, "binary_total_size: {}", binary_total_size);
-            int64_t actual_all = index_binary->size;
-            int64_t written = 0;
-            while (actual_all > 0)
-            {
-                size_t max_allowed_per_write = compressBound(actual_all, cmb);
-                bool last_sub_part = (last_part & (max_allowed_per_write == actual_all));
-                /// write index loop, compress and write index in small parts
-                Status stat = writePart(last_sub_part, segment_count, index_binary->data + written, max_allowed_per_write);
-                if (!stat.fine())
-                {
-                    return stat;
-                }
-                segment_count++;
-                actual_all -= max_allowed_per_write;
-                written += max_allowed_per_write;
-            }
-        }
+        auto file_writer = Search::IndexDataFileWriter<Search::AbstractOStream>(
+            segment_id.getFullPath(),
+            [](const std::string & name, std::ios::openmode mode) { return std::make_shared<Search::FileBasedOStream>(name, mode); });
+
+        index->serialize(&file_writer);
+        index->saveDataID(&file_writer);
+        printMemoryInfo(log, "After serialization");
 
         writeBitMap();
-        return finishWrite(binary_total_size);
-    }
-    catch (const std::exception & e)
-    {
-        LOG_ERROR(log, "Failed to serialize due to {}", e.what());
-        return Status(1, e.what());
-    }
-}
 
-Status VectorSegmentExecutor::startWrite()
-{
-    DiskIOWriter ready_flag_writer;
-    String ready_file_path = segment_id.getVectorReadyFilePath();
-    String index_type = VectorIndexFactory::typeToString(type);
-    String paras = "";
-    String index_name = segment_id.getIndexNameWithColumn();
-    /// -1 means the index is invalid in disk
-    String binary_total_size_str = "-1";
-    String nextline = "\n";
-    
-    if (!ready_flag_writer.open(ready_file_path + VECTOR_INDEX_FILE_SUFFIX, true))
-    {
-        if (!ready_flag_writer.open(ready_file_path, true))
-        {
-            LOG_ERROR(log, "Fail to open {}", ready_file_path);
-            return Status(5, "not able to open ready flag for write!");
-        }
-    }
-    String all_string_together = index_type + ";" + paras + ";" + index_name + ":" + binary_total_size_str + nextline;
-    LOG_DEBUG(log, "{}, length: {}", all_string_together, all_string_together.length());
-    ready_flag_writer.seekp(0, seekdir::end);
-    ready_flag_writer.write((void *)all_string_together.c_str(), all_string_together.length());
-    ready_flag_writer.close();
-    return Status();
-}
+        std::string version = index->getVersion().toString();
+        Metadata metadata(segment_id, version, type, metric, dimension, total_vec, fallback_to_flat, des);
+        auto buf = segment_id.volume->getDisk()->writeFile(segment_id.getVectorReadyFilePath(), 4096);
+        metadata.writeText(*buf);
 
-Status VectorSegmentExecutor::writePart(bool final, int segment_count, uint8_t * index_segment_offset, size_t index_segment_size)
-{
-    std::string part_id = segment_id.getFullPath() + "_" + ItoS(segment_count) + VECTOR_INDEX_FILE_SUFFIX;
-    BinaryPtr index_binary_compressed = std::make_shared<Binary>();
-    LOG_DEBUG(log, "Size of binary before compress: {}", index_segment_size);
-    compressWithCheckSum(cmb, index_segment_offset, index_segment_size, index_binary_compressed);
-    LOG_DEBUG(log, "Size of binary after compress: {}", index_binary_compressed->size);
-    DiskIOWriter writer;
-    if (!writer.open(part_id, false))
-    {
-        LOG_ERROR(log, "fail to open {}", part_id);
-        return Status(5, "not able to open file!");
+        return Status(0);
     }
-    int64_t final_mark = final ? 1 : 0;
-    int64_t binary_length_compressed = index_binary_compressed->size;
-    int64_t binary_length_original = index_segment_size;
-    /// When this is the last part to write, the mark will be 1, else 0.
-    writer.write(&final_mark, sizeof(final_mark));
-    /// Compressed size of binaries of index
-    writer.write(&binary_length_compressed, sizeof(binary_length_compressed));
-    /// Uncompressed size of binaries of index
-    writer.write(&binary_length_original, sizeof(binary_length_original));
-    /// Total vector
-    writer.write(&total_vec, sizeof(total_vec));
-    /// Compressed binaries of index
-    writer.write(index_binary_compressed->data, binary_length_compressed);
-    writer.close();
-    /// After serializing the index, we write a ready flag to mark future
-    /// TODO with checksum, we can possiblly drop this
-    return Status();
-}
-
-Status VectorSegmentExecutor::finishWrite(int64_t binary_total_size)
-{
-    DiskIOWriter ready_flag_writer;
-    String ready_file_path = segment_id.getVectorReadyFilePath();
-    String index_type;
-    index_type = VectorIndexFactory::typeToString(type);
-    String paras;
-    for (auto & s : des)
+    catch (const SearchIndexException & e)
     {
-        paras = paras + s.first + ",";
-        paras = paras + s.second + ",";
+        LOG_ERROR(log, "SearchIndexException: {}", e.what());
+        return Status(e.getCode(), e.what());
     }
-    String index_name = segment_id.getIndexNameWithColumn();
-    String binary_total_size_str = ItoS(binary_total_size);
-    String nextline = "\n";
-    if (!ready_flag_writer.open(ready_file_path + VECTOR_INDEX_FILE_SUFFIX, true))
+    catch (const std::exception & e)
     {
-        if (!ready_flag_writer.open(ready_file_path, true))
-        {
-            LOG_ERROR(log, "Fail to open {}", ready_file_path);
-            return Status(5, "not able to open ready flag for write!");
-        }
+        LOG_ERROR(log, "Failed to serialize due to {}", e.what());
+        return Status(1, e.what());
     }
-    String all_string_together = index_type + ";" + paras + ";" + index_name + ":" + binary_total_size_str + nextline;
-    LOG_DEBUG(log, "{}, length: {}", all_string_together, all_string_together.length());
-    ready_flag_writer.seekp(0, seekdir::end);
-    ready_flag_writer.write((void *)all_string_together.c_str(), all_string_together.length());
-    ready_flag_writer.close();
-    return Status();
 }
 
 void VectorSegmentExecutor::handleMergedMaps()
@@ -366,9 +327,12 @@ void VectorSegmentExecutor::handleMergedMaps()
 
     try
     {
-        auto row_ids_map_buf = std::make_unique<DB::CompressedReadBufferFromFile>(std::make_unique<DB::ReadBufferFromFile>(segment_id.getRowIdsMapFilePath()));
-        auto inverted_row_ids_map_buf = std::make_unique<DB::CompressedReadBufferFromFile>(std::make_unique<DB::ReadBufferFromFile>(segment_id.getInvertedRowIdsMapFilePath()));
-        auto inverted_row_sources_map_buf = std::make_unique<DB::CompressedReadBufferFromFile>(std::make_unique<DB::ReadBufferFromFile>(segment_id.getInvertedRowSourcesMapFilePath()));
+        auto row_ids_map_buf = std::make_unique<DB::CompressedReadBufferFromFile>(
+            std::make_unique<DB::ReadBufferFromFile>(segment_id.getRowIdsMapFilePath()));
+        auto inverted_row_ids_map_buf = std::make_unique<DB::CompressedReadBufferFromFile>(
+            std::make_unique<DB::ReadBufferFromFile>(segment_id.getInvertedRowIdsMapFilePath()));
+        auto inverted_row_sources_map_buf = std::make_unique<DB::CompressedReadBufferFromFile>(
+            std::make_unique<DB::ReadBufferFromFile>(segment_id.getInvertedRowSourcesMapFilePath()));
 
         while (!inverted_row_sources_map_buf->eof())
         {
@@ -420,7 +384,7 @@ Status VectorSegmentExecutor::load()
     CacheKey cache_key = segment_id.getCacheKey();
     const String cache_key_str = cache_key.toString();
 
-    LOG_DEBUG(log, "segment_id.getPathSuffix() = {}", segment_id.getPathSuffix());
+    LOG_DEBUG(log, "segment_id.getPathPrefix() = {}", segment_id.getPathPrefix());
     LOG_DEBUG(log, "segment_id.getBitMapFilePath() = {}", segment_id.getBitMapFilePath());
     LOG_DEBUG(log, "cache_key_str = {}", cache_key_str);
 
@@ -434,106 +398,105 @@ Status VectorSegmentExecutor::load()
 
         auto load_func = [&]() -> IndexWithMetaPtr
         {
-            DiskIOReader reader;
-            /// TODO this is really funky... have to change it later
-            String ready_file_path = segment_id.getVectorReadyFilePath();
-            String index_name = segment_id.getIndexNameWithColumn();
-            std::vector<String> index_names{index_name};
-            std::unordered_map<std::string, Parameters> params;
-            std::unordered_map<String, int64_t> original_binary_sizes
-                = readVectorIndexReadyFile(reader, ready_file_path, index_names, params);
-            if (original_binary_sizes.find(index_name) == original_binary_sizes.end())
-            {
-                LOG_DEBUG(log, "Unable to parse the original index size {}", ready_file_path);
-                throw IndexException("Unable to parse the original index size " + ready_file_path, 5);
-            }
-            int64_t original_binary_size = original_binary_sizes.find(index_name)->second;
-            if (original_binary_size < 0)
-            {
-                throw IndexException("Unable to parse the original index size " + ready_file_path, 5);
-            }
-            des = params.at(index_name);
-
-            if (!readBitMap())
-            {
-                LOG_ERROR(log, "Failed to read vector index bitmap: {}", segment_id.getFullPath());
-                throw IndexException("Corrupted data: " + segment_id.getFullPath(), 5);
-            }
-
-            if (des.contains("metric_type"))
-            {
-                me = VectorIndexFactory::createIndexMetrics(des.at("metric_type"));
-            }
-            Parameters place_holder;
-            index = VectorIndexFactory::createIndex(type, mode, me, dimension, place_holder);
-            index->setIndexSize(original_binary_size);
-            LOG_DEBUG(log, "Start loading index: total_vec: {}", total_vec);
-            CompositeIndexReader index_reader(segment_id, original_binary_size);
             try
             {
-                index->load(index_reader);
-            }
-            catch (const IndexException & e)
-            {
-                LOG_ERROR(log, "failed to load index: {}", e.message());
-                throw;
-            }
-            index->setTrained();
-            des.erase("type");
-            index->parseParameter(des);
-            LOG_DEBUG(log, "Finish loading index");
-            if (auto_tune && getOps().getCode() != 0)
-            {
-                LOG_WARNING(log, "Index not autotuned");
-            }
+                Metadata metadata(segment_id);
+                auto buf = segment_id.volume->getDisk()->readFile(segment_id.getVectorReadyFilePath());
+                metadata.readText(*buf);
+                fallback_to_flat = metadata.fallback_to_flat;
+                if (fallback_to_flat)
+                {
+                    type = Search::IndexType::FLAT;
+                    std::erase_if(
+                        des,
+                        [](const auto & item)
+                        {
+                            auto const & [key, value] = item;
+                            return key != "metric_type";
+                        });
+                }
+                des.setParam("load_index_version", metadata.version);
+
+                configureDiskMode();
+                index = Search::
+                    createVectorIndex<Search::AbstractIStream, Search::AbstractOStream, Search::DenseBitmap, Search::DataType::FloatVector>(
+                        segment_id.getIndexNameWithColumn(),
+                        type,
+                        metric,
+                        dimension,
+                        total_vec,
+                        des,
+                        true,
+                        vector_index_cache_prefix,
+                        getDiskIOManager(),
+                        true);
+
+                LOG_INFO(log, "loading vector index from {}", segment_id.getFullPath());
+                auto file_reader = Search::IndexDataFileReader<Search::AbstractIStream>(
+                    segment_id.getFullPath(),
+                    [](const std::string & name, std::ios::openmode mode)
+                    { return std::make_shared<Search::FileBasedIStream>(name, mode); });
+                printMemoryInfo(log, "Before load");
+                index->load(&file_reader);
+                index->loadDataID(&file_reader);
+                printMemoryInfo(log, "After load");
+                total_vec = index->numData();
+                LOG_INFO(log, "load total_vec={}", total_vec);
+                readBitMap();
 
-            try
-            {
                 /// May failed to load merged row ids map due to background index build may remove them when finished.
                 handleMergedMaps();
-            }
-            catch (const DB::Exception & e)
-            {
-                LOG_DEBUG(log, "Failed to load inverted row ids map entries, error: {}", e.what());
-                throw IndexException(e.message(), e.code());
-            }
 
-            if (index == nullptr)
+                return std::make_shared<IndexWithMeta>(
+                    index,
+                    total_vec,
+                    delete_bitmap,
+                    des,
+                    row_ids_map,
+                    inverted_row_ids_map,
+                    inverted_row_sources_map,
+                    disk_mode,
+                    fallback_to_flat,
+                    vector_index_cache_prefix);
+            }
+            catch (const SearchIndexException & e)
             {
-                LOG_INFO(log, "{} index is null, not caching", segment_id.getCacheKey().toString());
-                throw IndexException(segment_id.getCacheKey().toString() + " index is null, not caching", 3);
+                LOG_ERROR(log, "SearchIndexException: {}", e.what());
+                throw IndexException(e.getCode(), e.what());
             }
-            if (!des.contains("type"))
+            catch (const DB::Exception & e)
             {
-                des.insert(std::make_pair("type", VectorIndexFactory::typeToString(type)));
+                LOG_DEBUG(log, "Failed to load inverted row ids map entries, error: {}", e.what());
+                throw e;
             }
-
-            return std::make_shared<IndexWithMeta>(
-                index, total_vec, op_points, delete_bitmap, des, row_ids_map, inverted_row_ids_map, inverted_row_sources_map);
         };
 
         try
         {
-            IndexWithMetaHolderPtr index_holder_ = mgr->load(cache_key, load_func);
+            index_holder = mgr->load(cache_key, load_func);
             LOG_DEBUG(log, "Num of item after cache {}", mgr->countItem());
-            if (index_holder_)
+            if (index_holder)
             {
-                IndexWithMeta & new_index = index_holder_->value();
+                IndexWithMeta & new_index = index_holder->value();
                 index = new_index.index;
                 total_vec = new_index.total_vec;
-                op_points = new_index.op_points;
                 delete_bitmap = new_index.getDeleteBitmap();
                 des = new_index.des;
-                if (auto_tune && getOps().getCode() != 0)
-                {
-                    LOG_WARNING(log, "Index not autotuned");
-                }
+                fallback_to_flat = new_index.fallback_to_flat;
                 return Status();
             }
         }
         catch (const IndexException & e)
         {
-            return Status(e.statusCode(), e.statusMessage());
+            return Status(e.code(), e.message());
+        }
+        catch (const DB::Exception & e)
+        {
+            return Status(e.code(), e.message());
+        }
+        catch (const std::exception & e)
+        {
+            return Status(DB::ErrorCodes::STD_EXCEPTION, e.what());
         }
 
         return Status(2, "Load failed");
@@ -544,7 +507,7 @@ Status VectorSegmentExecutor::load()
         IndexWithMeta & new_index = index_holder->value();
         index = new_index.index;
         total_vec = new_index.total_vec;
-        op_points = new_index.op_points;
+        fallback_to_flat = new_index.fallback_to_flat;
         delete_bitmap = new_index.getDeleteBitmap();
 
         des = new_index.des;
@@ -560,105 +523,103 @@ Status VectorSegmentExecutor::load()
             updateCacheValueWithRowIdsMaps();
         }
 
-        if (auto_tune && getOps().getCode() != 0)
-        {
-            LOG_WARNING(log, "Index not autotuned");
-        }
-
         return Status();
     }
 }
 
-Status VectorSegmentExecutor::addVectors(VectorDatasetPtr dataset)
-{
-    LOG_TRACE(log, "Adding {} vectors", dataset->getVectorNum());
-    index->addWithoutId(dataset);
-    total_vec += dataset->getVectorNum();
-    index->setTrained();
-    /// Index is only searchable after the first call to addVector.
-    /// this bypassed some concurrency problem.
-    return Status();
-}
-
 Status VectorSegmentExecutor::search(
-    VectorDatasetPtr dataset, int32_t k, float *& distances, int64_t *& labels, GeneralBitMapPtr filter, Parameters parameters)
+    VectorDatasetPtr dataset,
+    int32_t k,
+    float *& distances,
+    int64_t *& labels,
+    Search::DenseBitmapPtr & filter,
+    Search::Parameters & parameters)
 {
     DB::OpenTelemetrySpanHolder span("VectorSegmentExecutor::search()");
-    bool added = false;
-    try
+
+    // Check if the index is initialized and ready for searching
+    if (index == nullptr)
     {
-        if (index == nullptr)
-        {
-            return Status(3, "index not initialized before searching!");
-        }
-        if (!index->trainStatus())
-        {
-            return Status(7, "index not trained before searching!");
-        }
-        if (dataset->getDimension() != dimension)
-        {
-            return Status(10, "the dimension of searched index and input doesn't match.");
-        }
-        LOG_DEBUG(log, "{} vectors in engine {}", this->total_vec, this->segment_id.getFullPath());
-        Parameters params = parameters;
-        if (op_points != nullptr)
-        {
-            ///TODO pass acc_req in from user
-            float acc_req = 0.9;
-            bool satisfied = false;
-            for (auto & acc_parameters : *op_points)
-            {
-                LOG_DEBUG(log, "op point tested with acc {},", acc_parameters.first);
-                if (acc_parameters.first >= acc_req)
-                {
-                    params = acc_parameters.second->op_point;
-                    satisfied = true;
-                    break;
-                }
-            }
-            if (!satisfied)
-            {
-                LOG_WARNING(log, "Index can't satisfy the required accuracy, switching to brute force search.");
-                return Status(200);
-            }
-        }
+        return Status(3, "Index not initialized before searching!");
+    }
+    if (!index->ready())
+    {
+        return Status(7, "Index not ready before searching!");
+    }
 
-        filter = mergeBitMap(filter, this->getDeleteBitMap());
+    // Check if the dimensions of the searched index and input match
+    if (dataset->getDimension() != static_cast<int64_t>(dimension))
+    {
+        return Status(10, "The dimension of searched index and input doesn't match.");
+    }
 
-        std::shared_lock<std::shared_mutex> lock(mu);
-        cv.wait(lock, [] { return count.load() <= num_thread_for_vector; });
-        count.fetch_add(1);
-        added = true;
-        LOG_DEBUG(log, "Index search, num threads: {}", num_thread_for_vector);
-        /// a shared lock on a small number of concurrent threads, like 16. this is not hard limit so race is not a problem.
-        {
-            DB::OpenTelemetrySpanHolder span("VectorSegmentExecutor::search::vector_index_search");
-            span.addAttribute("vec_search.num_threads", num_thread_for_vector);
-            index->search(dataset, k, distances, labels, params, filter);
-        }
+    LOG_DEBUG(log, "Index {} has {} vectors", this->segment_id.getFullPath(), this->total_vec);
+
+    SearchThreadLimiter limiter(log, max_threads);
 
-        transferToNewRowIds(labels, k * dataset->getVectorNum());
+    // Merge filter and delete_bitmap
+    if (!delete_bitmap->all())
+        filter = Search::mergeDenseBitmap(filter, delete_bitmap);
+
+    // Perform the search and handle the results
+    try
+    {
+        if (fallback_to_flat)
+            parameters.clear();
+        performSearch(dataset, k, distances, labels, filter, parameters);
     }
-    catch (const IndexException & e)
+    catch (const SearchIndexException & e)
     {
-        LOG_ERROR(log, "IndexException: {}", e.message());
-        if (added)
-            count.fetch_sub(1);
-        cv.notify_one();
-        return Status(e.code(), e.message());
+        LOG_ERROR(log, "SearchIndexException: {}", e.what());
+        return Status(e.getCode(), e.what());
     }
-    if (added)
-        count.fetch_sub(1);
-    cv.notify_one();
+    catch (const std::exception & e)
+    {
+        return Status(DB::ErrorCodes::STD_EXCEPTION, e.what());
+    }
+
     return Status();
 }
 
+void VectorSegmentExecutor::performSearch(
+    VectorDatasetPtr dataset,
+    int32_t k,
+    float *& distances,
+    int64_t *& labels,
+    Search::DenseBitmapPtr & filter,
+    Search::Parameters & parameters)
+{
+    // Perform the actual search
+    {
+        DB::OpenTelemetrySpanHolder span2("VectorSegmentExecutor::search::vector_index_search");
+        span2.addAttribute("vec_search.max_threads", max_threads);
+        auto query_dataset = std::make_shared<Search::DataSet<float>>(dataset->getData(), dataset->getVectorNum(), dataset->getDimension());
+        index->search(query_dataset, k, distances, labels, parameters, false, filter.get());
+    }
+
+    // Transfer the results to newRowIds
+    transferToNewRowIds(labels, k * dataset->getVectorNum());
+}
+
+
 Status VectorSegmentExecutor::searchWithoutIndex(
-    VectorDatasetPtr query_data, VectorDatasetPtr base_data, int32_t k, float *& distances, int64_t *& labels, const Metrics& metrics)
+    VectorDatasetPtr query_data,
+    VectorDatasetPtr base_data,
+    int32_t k,
+    float *& distances,
+    int64_t *& labels,
+    const Search::Metric & metric)
 {
-    LOG_DEBUG(log, "Search without index: query_data {}", query_data->printVectors());
     omp_set_num_threads(1);
-    return tryBruteForceSearch(
+    auto metric2 = metric;
+    if (metric == Search::Metric::Cosine)
+    {
+        LOG_DEBUG(&Poco::Logger::get("VectorSegmentExecutor"), "Normalize vectors for cosine similarity brute force search");
+        metric2 = Search::Metric::IP;
+        query_data->normalize();
+        base_data->normalize();
+    }
+    auto status = tryBruteForceSearch(
         query_data->getData(),
         base_data->getData(),
         query_data->getDimension(),
@@ -667,16 +628,20 @@ Status VectorSegmentExecutor::searchWithoutIndex(
         base_data->getVectorNum(),
         labels,
         distances,
-        metrics);
-}
-
-IndexType VectorSegmentExecutor::indexType()
-{
-    return index->indexType();
+        metric2);
+    if (metric == Search::Metric::Cosine)
+    {
+        for (int64_t i = 0; i < k * query_data->getVectorNum(); i++)
+        {
+            distances[i] = 1 - distances[i];
+        }
+    }
+    return status;
 }
 
 Status VectorSegmentExecutor::removeFromCache(const CacheKey & cache_key)
 {
+    Poco::Logger * log = &Poco::Logger::get("VectorSegmentExecutor");
     CacheManager * mgr = CacheManager::getInstance();
     LOG_DEBUG(log, "Num of cache items before forceExpire {} ", mgr->countItem());
     mgr->forceExpire(cache_key);
@@ -689,164 +654,36 @@ int64_t VectorSegmentExecutor::getRawDataSize()
     return total_vec;
 }
 
-void VectorSegmentExecutor::setIndexParameters(Parameters p)
-{
-    index->getMyParameters(p);
-}
-
-
-Status VectorSegmentExecutor::dispathAutoTuneTask(VectorDatasetPtr base)
-{
-    if (base->getDimension() != dimension)
-    {
-        return Status(10, "dimension of base vector no matching index");
-    }
-    if (base->getVectorNum() < MAX_BRUTE_FORCE_SEARCH_SIZE)
-    {
-        return Status(0, "base too small, no need to tune, just brute force.");
-    }
-    ///TODO make this user-defined
-    int default_topk = 50;
-    int default_query_size = 1000 < base->getVectorNum() ? 1000 : base->getVectorNum();
-    Metrics default_metrics = me;
-    ///These two vectors are deconstrcuted by Autotuner
-    std::vector<float> * query = new std::vector<float>(default_query_size * dimension);
-    /// gt_dis here is just a place holder, we don't need the data.
-    std::vector<float> gt_dis(default_topk * default_query_size);
-    std::vector<int64_t> * gt = new std::vector<int64_t>(default_topk * default_query_size);
-    getQueryandGt(base, gt_dis.data(), gt->data(), query->data(), default_topk, default_query_size, default_metrics);
-    TuningPackPtr pack = std::make_shared<TuningPack>(index, query, gt, default_topk, default_query_size, false);
-    Autotuner * tuner = Autotuner::getInstance();
-    tuner->addTask(segment_id.getFullPath(), pack);
-    return Status();
-}
-
-/// base here is just used as query, not search base.
-Status VectorSegmentExecutor::tune(VectorDatasetPtr base, std::vector<int64_t> & empty_ids, size_t current_round_start_row)
-{
-    if (auto * ivfflat = dynamic_cast<IVFFlatIndex *>(index.get()))
-    {
-        int default_query_size = std::min(base->getVectorNum(), (int64_t)2000);
-        int default_topk = 50;
-        int dimension = base->getDimension();
-        if (default_query_size < 2000)
-        {
-            LOG_WARNING(log, "Not enough data points to train this data part.");
-            return Status();
-        }
-        std::vector<float> remove_empty;
-        size_t non_empty_size = 0;
-        auto empty_id = empty_ids.begin();
-        /// we need to filter out empty data because there are just 0.
-        for (int i = 0; i < default_query_size; i++)
-        {
-            if (empty_id != empty_ids.end() && i == *empty_id - current_round_start_row)
-            {
-                empty_id++;
-                continue;
-            }
-            remove_empty.insert(remove_empty.end(), base->getData() + i * dimension, base->getData() + (i + 1) * dimension);
-            non_empty_size++;
-        }
-
-        VectorDatasetPtr non_empty = std::make_shared<VectorDataset>(non_empty_size, dimension, remove_empty.data());
-        ivfflat->tune(non_empty, default_topk);
-    }
-    return Status();
-}
-
-
-/// If the autoTuning has finished, we try to get the points from the disk
-/// and load them into op_points
-Status VectorSegmentExecutor::getOps()
-{
-    if (op_points == nullptr)
-    {
-        DiskIOReader reader;
-        ///TODO this should be changed to checking hash of file
-        if (reader.open(segment_id.getFullPath() + PARAMETER_PACK_NAME))
-        {
-            op_points = std::make_shared<std::vector<std::pair<float, OperatingPointPtr>>>();
-            LOG_INFO(log, "{} successfully found the parameters pack", segment_id.getFullPath());
-            int64_t bin_size;
-            reader.read(&bin_size, sizeof(bin_size));
-            reader.seekg(sizeof(bin_size));
-            BinaryPtr ops_bin = std::make_shared<Binary>();
-            ops_bin->data = new uint8_t[bin_size];
-            ops_bin->size = bin_size;
-            reader.read(ops_bin->data, bin_size);
-            std::string params(reinterpret_cast<const char *>(ops_bin->data));
-            LOG_TRACE(log, "param: {}", params);
-            AccParametersPack pack = StringToAccParametersPack(params, log);
-            for (auto & m : pack)
-            {
-                OperatingPointPtr op = std::make_shared<OperatingPoint>();
-                for (auto & one_parameter : m.second)
-                {
-                    op->insertPoint(one_parameter.first, one_parameter.second);
-                }
-                LOG_INFO(log, "{} added op point {}", segment_id.getFullPath(), m.first);
-                op_points->emplace_back(std::make_pair(m.first, op));
-            }
-            std::sort(
-                op_points->begin(),
-                op_points->end(),
-                [](const std::pair<float, OperatingPointPtr> & a, const std::pair<float, OperatingPointPtr> & b) {
-                    return a.first < b.first;
-                });
-        }
-        else
-        {
-            LOG_WARNING(log, "The tuning for this index haven't finished.");
-        }
-    }
-    else
-    {
-        LOG_INFO(log, "op points already exist");
-    }
-    return Status();
-}
-
 Status VectorSegmentExecutor::cancelBuild()
 {
     /// TODO implement
     return Status();
 }
 
-Status VectorSegmentExecutor::removeByIds(int64_t n, int64_t * ids)
+Status VectorSegmentExecutor::removeByIds(size_t n, const size_t * ids)
 {
-    LOG_DEBUG(log, "Need to remove {} ids", n);
-    int64_t removed = 0;
-    for (int64_t i = 0; i < n; i++)
+    for (size_t i = 0; i < n; i++)
     {
-        if (delete_bitmap->test(ids[i]))
+        if (delete_bitmap->is_member(ids[i]))
         {
-            removed++;
             delete_bitmap->unset(ids[i]);
         }
     }
-    LOG_DEBUG(log, "Removed {} ids", removed);
-    if (removed == n)
-    {
-        return Status();
-    }
-    else
-    {
-        return Status(10, "error during remove by id, removed item num: " + ItoS(removed) + ", needed to remove num:" + ItoS(n));
-    }
+    return Status();
 }
 
 bool VectorSegmentExecutor::writeBitMap()
 {
     DiskIOWriter bit_map_writer;
-    String bitMap_path = segment_id.getBitMapFilePath() + VECTOR_INDEX_FILE_SUFFIX;
-    bit_map_writer.open(bitMap_path, false);
+    String bitmap_path = segment_id.getBitMapFilePath();
+    bit_map_writer.open(bitmap_path, false);
 
-    int64_t total_vec = delete_bitmap->size;
-    int64_t byte_count = (total_vec >> 3) + 1;
-    bit_map_writer.write(&byte_count, sizeof(int64_t));
+    if (delete_bitmap == nullptr)
+        delete_bitmap = std::make_shared<Search::DenseBitmap>(total_vec, true);
+    size_t size = delete_bitmap->get_size();
+    bit_map_writer.write(&size, sizeof(size_t));
 
-    bit_map_writer.write(delete_bitmap->bitmap, byte_count);
+    bit_map_writer.write(delete_bitmap->get_bitmap(), delete_bitmap->byte_size());
     bit_map_writer.close();
 
     return true;
@@ -854,32 +691,29 @@ bool VectorSegmentExecutor::writeBitMap()
 
 bool VectorSegmentExecutor::readBitMap()
 {
-    readTotalVec();
-
     DiskIOReader bit_map_reader;
     String read_file_path = segment_id.getBitMapFilePath();
 
-    if (!bit_map_reader.open(read_file_path + VECTOR_INDEX_FILE_SUFFIX))
+    if (!bit_map_reader.open(read_file_path))
     {
-        if (!bit_map_reader.open(read_file_path))
-        {
-            return false;
-        }
+        return false;
     }
 
-    int64_t bit_map_size;
-    bit_map_reader.read(&bit_map_size, sizeof(int64_t));
-    if (bit_map_size != (total_vec >> 3) + 1)
+    size_t size;
+    bit_map_reader.read(&size, sizeof(size_t));
+    if (delete_bitmap == nullptr)
+        delete_bitmap = std::make_shared<Search::DenseBitmap>(size);
+
+    size_t bit_map_size = delete_bitmap->byte_size();
+
+    if (total_vec != 0 && size != total_vec)
     {
-        LOG_ERROR(log, "Bitmap file {} is corrupted: bit_map_size {}, total_vec {}", read_file_path, bit_map_size, total_vec);
-        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "vector index bitmap on disk is corrupted");
+        LOG_ERROR(log, "Bitmap file {} is corrupted: size {}, total_vec {}", read_file_path, size, total_vec);
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "Vector index bitmap on disk is corrupted");
     }
 
-    if (delete_bitmap == nullptr)
-        delete_bitmap = std::make_shared<GeneralBitMap>(total_vec);
-
-    bit_map_reader.seekg(sizeof(int64_t));
-    bit_map_reader.read(delete_bitmap->bitmap, bit_map_size);
+    bit_map_reader.seekg(sizeof(size_t));
+    bit_map_reader.read(delete_bitmap->get_bitmap(), bit_map_size);
 
     return true;
 }
@@ -889,87 +723,13 @@ void VectorSegmentExecutor::setCacheManagerSizeInBytes(size_t size)
     CacheManager::setCacheSize(size);
 }
 
-void VectorSegmentExecutor::setSerializeSegmentSize(size_t size)
-{
-    optimal_segment_size = size > MIN_SEGMENT_SIZE ? size : MIN_SEGMENT_SIZE;
-}
-
-bool VectorSegmentExecutor::compareVectorIndexParameters(IndexType t1, Parameters p1, IndexType t2, Parameters p2)
-{
-    Metrics me = L2;
-    IndexMode mode = CPU;
-    char cmb = static_cast<uint8_t>(DB::CompressionMethodByte::LZ4);
-    if (p1.contains("metric_type"))
-    {
-        me = VectorIndexFactory::createIndexMetrics(p1.at("metric_type"));
-        p1.erase("metric_type");
-    }
-    if (p1.contains("mode"))
-    {
-        mode = VectorIndexFactory::createIndexMode(p1.at("mode"));
-        p1.erase("mode");
-    }
-    if (p1.contains("compression_scheme"))
-    {
-        cmb = DB::CompressionCodecFactory::instance().get(p1.at("compression_scheme"), {})->getMethodByte();
-        p1.erase("compression_scheme");
-    }
-
-    Metrics me2 = L2;
-    IndexMode mode2 = CPU;
-    char cmb2 = static_cast<uint8_t>(DB::CompressionMethodByte::LZ4);
-    if (p2.contains("metric_type"))
-    {
-        me2 = VectorIndexFactory::createIndexMetrics(p2.at("metric_type"));
-        p2.erase("metric_type");
-    }
-    if (p2.contains("mode"))
-    {
-        mode2 = VectorIndexFactory::createIndexMode(p2.at("mode"));
-        p2.erase("mode");
-    }
-    if (p2.contains("compression_scheme"))
-    {
-        cmb2 = DB::CompressionCodecFactory::instance().get(p2.at("compression_scheme"), {})->getMethodByte();
-        p2.erase("compression_scheme");
-    }
-
-    if (cmb != cmb2)
-    {
-        return false;
-    }
-    int dimension = 1;
-    if (VectorIndexFactory::typeToString(t1).find("PQ") != -1 || VectorIndexFactory::typeToString(t2).find("PQ") != -1)
-    {
-        dimension = -1;
-    }
-    VectorIndexPtr index1 = VectorIndexFactory::createIndex(t1, mode, me, dimension, p1);
-    VectorIndexPtr index2 = VectorIndexFactory::createIndex(t2, mode2, me2, dimension, p2);
-    return (index1->compare(*index2));
-}
-
-std::list<std::pair<CacheKey, Parameters>> VectorSegmentExecutor::getAllCacheNames()
+std::list<std::pair<CacheKey, Search::Parameters>> VectorSegmentExecutor::getAllCacheNames()
 {
     ///from this list, we get <segment_id, vectorindex description> pair
     return CacheManager::getInstance()->getAllItems();
 }
 
-void VectorSegmentExecutor::readTotalVec()
-{
-    DiskIOReader reader;
-    String path = segment_id.getFullPath() + "_" + ItoS(0) + VECTOR_INDEX_FILE_SUFFIX;
-    if (!reader.open(path))
-    {
-        LOG_ERROR(log, "Failed to open {}", path);
-        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "failed to open " + path);
-    }
-
-    reader.seekg(sizeof(int64_t) * 3);
-    reader.read(&total_vec, sizeof(total_vec));
-    LOG_DEBUG(log, "Total vectors read: {}", total_vec);
-}
-
-void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64>& deleted_row_ids)
+void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64> & deleted_row_ids)
 {
     if (segment_id.fromMergedParts())
         return;
@@ -985,7 +745,7 @@ void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64>& deleted_row_
     bool need_update = false;
     for (auto & del_row_id : deleted_row_ids)
     {
-        if (delete_bitmap->test(del_row_id))
+        if (delete_bitmap->is_member(del_row_id))
         {
             delete_bitmap->unset(del_row_id);
 
@@ -1009,7 +769,7 @@ void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64>& deleted_row_
         index_holder->value().setDeleteBitmap(delete_bitmap);
 }
 
-void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& deleted_row_ids)
+void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64> & deleted_row_ids)
 {
     if (!segment_id.fromMergedParts())
         return;
@@ -1030,7 +790,7 @@ void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& delete
     {
         handleMergedMaps();
     }
-    catch(const DB::Exception & e)
+    catch (const DB::Exception & e)
     {
         LOG_DEBUG(log, "Skip to update vector bitmap due to failure when read inverted row ids map entries, error: {}", e.what());
         return;
@@ -1043,7 +803,7 @@ void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& delete
         if (segment_id.getOwnPartId() == (*inverted_row_sources_map)[new_row_id])
         {
             UInt64 old_row_id = (*inverted_row_ids_map)[new_row_id];
-            if (delete_bitmap->test(old_row_id))
+            if (delete_bitmap->is_member(old_row_id))
             {
                 delete_bitmap->unset(old_row_id);
 
@@ -1068,5 +828,33 @@ void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& delete
         index_holder->value().setDeleteBitmap(delete_bitmap);
 }
 
+std::shared_ptr<Search::DiskIOManager> VectorSegmentExecutor::getDiskIOManager()
+{
+    static std::mutex mutex;
+    static std::shared_ptr<Search::DiskIOManager> io_manager = nullptr;
+
+    if (type != Search::IndexType::MSTG || !disk_mode)
+        return nullptr;
+
+    std::lock_guard<std::mutex> lock(mutex);
+    if (io_manager == nullptr)
+        io_manager = std::make_shared<Search::DiskIOManager>(4);
+    return io_manager;
+}
 
+void VectorSegmentExecutor::configureDiskMode()
+{
+    if (type == Search::IndexType::MSTG)
+    {
+        disk_mode = des.getParam("disk_mode", DEFAULT_DISK_MODE);
+        if (!des.contains("disk_mode"))
+            des.setParam("disk_mode", disk_mode);
+        if (disk_mode)
+        {
+            vector_index_cache_prefix = segment_id.getVectorIndexCachePrefix();
+            LOG_INFO(log, "vector_index_cache_prefix: {}", vector_index_cache_prefix);
+            fs::create_directories(vector_index_cache_prefix);
+        }
+    }
+}
 }
diff --git a/src/VectorIndex/VectorSegmentExecutor.h b/src/VectorIndex/VectorSegmentExecutor.h
index e899b6c82e..9f31c78129 100644
--- a/src/VectorIndex/VectorSegmentExecutor.h
+++ b/src/VectorIndex/VectorSegmentExecutor.h
@@ -1,64 +1,109 @@
 #pragma once
-#pragma GCC diagnostic ignored "-Wunused-function"
+
 #include <string>
 #include <Compression/CompressionInfo.h>
 #include <Storages/VectorIndicesDescription.h>
-#include <base/logger_useful.h>
+#include <VectorIndex/Dataset.h>
+#include <VectorIndex/IndexException.h>
+#include <VectorIndex/PartReader.h>
 #include <VectorIndex/SegmentId.h>
-#include <VectorIndex/Autotuner.h>
-#include <VectorIndex/FlatIndex.h>
-#include <VectorIndex/GeneralBitMap.h>
-#include <VectorIndex/HNSWIndex.h>
-#include <VectorIndex/IVFFlatIndex.h>
-#include <VectorIndex/IVFPQIndex.h>
 #include <VectorIndex/Status.h>
-#include <VectorIndex/IndexException.h>
+#include <base/logger_useful.h>
+
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wunused-function"
+#pragma GCC diagnostic ignored "-Wzero-as-null-pointer-constant"
+#pragma GCC diagnostic ignored "-Wunused-parameter"
+#pragma GCC diagnostic ignored "-Wextra-semi-stmt"
+#pragma GCC diagnostic ignored "-Wold-style-cast"
+#pragma GCC diagnostic ignored "-Wc++20-compat"
+#pragma GCC diagnostic ignored "-Walloca"
+#pragma GCC diagnostic ignored "-Wmissing-noreturn"
+#pragma GCC diagnostic ignored "-Wgcc-compat"
+#pragma GCC diagnostic ignored "-Wcovered-switch-default"
+#pragma GCC diagnostic ignored "-Wgnu-zero-variadic-macro-arguments"
+#pragma GCC diagnostic ignored "-Wextra-semi"
+#pragma GCC diagnostic ignored "-Wfinal-dtor-non-final-class"
+#pragma GCC diagnostic ignored "-Wundef"
+#pragma GCC diagnostic ignored "-Wsuggest-override"
+#pragma GCC diagnostic ignored "-Wshadow-field-in-constructor"
+#pragma GCC diagnostic ignored "-Wdeprecated-copy-with-user-provided-dtor"
+#pragma GCC diagnostic ignored "-Wmismatched-tags"
+#pragma GCC diagnostic ignored "-Wundefined-reinterpret-cast"
+#pragma GCC diagnostic ignored "-Wsign-compare"
+#pragma GCC diagnostic ignored "-Wshadow-uncaptured-local"
+#pragma GCC diagnostic ignored "-Wunused-variable"
+#pragma GCC diagnostic ignored "-Wunused-private-field"
+#pragma GCC diagnostic ignored "-Wshadow-field"
+#pragma GCC diagnostic ignored "-Wdelete-non-abstract-non-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wshadow"
+#pragma GCC diagnostic ignored "-Wnon-virtual-dtor"
+#pragma GCC diagnostic ignored "-Wrange-loop-bind-reference"
+#pragma GCC diagnostic ignored "-Wenum-compare-switch"
+#include <SearchIndex/VectorSearch.h>
+#pragma GCC diagnostic pop
 
 namespace VectorIndex
 {
-static size_t optimal_segment_size = (1LL << 32) - 10; // This is 2^32, or 4GB, we are not maxing it since compression introduce a header.
-
-struct OperatingPoint
+struct IndexWithMeta
 {
-    Parameters op_point;
-    String getPointAt(String index) { return (op_point[index]); }
+    IndexWithMeta() = delete;
+
+    IndexWithMeta(
+        VectorIndexPtr & index_,
+        uint64_t total_vec_,
+        Search::DenseBitmapPtr delete_bitmap_,
+        Search::Parameters des_,
+        std::shared_ptr<std::vector<UInt64>> row_ids_map_,
+        std::shared_ptr<std::vector<UInt64>> inverted_row_ids_map_,
+        std::shared_ptr<std::vector<uint8_t>> inverted_row_sources_map_,
+        bool disk_mode_,
+        bool fallback_to_flat_,
+        std::string vector_index_cache_prefix_)
+        : index(index_)
+        , total_vec(total_vec_)
+        , delete_bitmap(delete_bitmap_)
+        , des(des_)
+        , row_ids_map(row_ids_map_)
+        , inverted_row_ids_map(inverted_row_ids_map_)
+        , inverted_row_sources_map(inverted_row_sources_map_)
+        , disk_mode(disk_mode_)
+        , fallback_to_flat(fallback_to_flat_)
+        , vector_index_cache_prefix(vector_index_cache_prefix_)
+    {
+    }
 
-    void insertPoint(String name, String t) { op_point.insert(std::pair<String, String>(name, t)); }
-};
-using OperatingPointPtr = std::shared_ptr<OperatingPoint>;
-using OPsPtr = std::shared_ptr<std::vector<std::pair<float, OperatingPointPtr>>>;
+    ~IndexWithMeta()
+    {
+        if (disk_mode)
+        {
+            fs::remove_all(vector_index_cache_prefix);
+        }
+    }
 
-struct IndexWithMeta
-{
-    IndexWithMeta() = default;
-    IndexWithMeta(VectorIndexPtr & index_, uint64_t total_vec_, OPsPtr op_points_, GeneralBitMapPtr delete_bitMap_,
-            Parameters des_)
-        : index(index_), total_vec(total_vec_), op_points(op_points_), delete_bitmap(delete_bitMap_), des(des_) {};
-    
-    IndexWithMeta(VectorIndexPtr & index_, uint64_t total_vec_, OPsPtr op_points_, GeneralBitMapPtr delete_bitMap_,
-            Parameters des_, std::shared_ptr<std::vector<UInt64>> row_ids_map_, std::shared_ptr<std::vector<UInt64>> inverted_row_ids_map_,
-            std::shared_ptr<std::vector<uint8_t>> inverted_row_sources_map_)
-        : index(index_), total_vec(total_vec_), op_points(op_points_), delete_bitmap(delete_bitMap_), des(des_),
-          row_ids_map(row_ids_map_), inverted_row_ids_map(inverted_row_ids_map_), inverted_row_sources_map(inverted_row_sources_map_){};
     VectorIndexPtr index;
-    uint64_t total_vec;
-    OPsPtr op_points;
+    size_t total_vec;
+
 private:
-    GeneralBitMapPtr delete_bitmap;
+    Search::DenseBitmapPtr delete_bitmap;
     mutable std::mutex mutex_of_delete_bitmap;
+
 public:
-    Parameters des;
+    Search::Parameters des;
     std::shared_ptr<std::vector<UInt64>> row_ids_map;
     std::shared_ptr<std::vector<UInt64>> inverted_row_ids_map;
     std::shared_ptr<std::vector<uint8_t>> inverted_row_sources_map;
+    bool disk_mode;
+    bool fallback_to_flat;
+    std::string vector_index_cache_prefix;
 
-    void setDeleteBitmap(GeneralBitMapPtr delete_bitmap_)
+    void setDeleteBitmap(Search::DenseBitmapPtr delete_bitmap_)
     {
         std::lock_guard<std::mutex> lg(mutex_of_delete_bitmap);
         delete_bitmap = std::move(delete_bitmap_);
     }
 
-    GeneralBitMapPtr getDeleteBitmap() const
+    Search::DenseBitmapPtr getDeleteBitmap() const
     {
         std::lock_guard<std::mutex> lg(mutex_of_delete_bitmap);
         return delete_bitmap;
@@ -73,7 +118,15 @@ class VectorSegmentExecutor
     /// the user should not visit any index directly.
 public:
     /// Create the index but not inserting any data
-    VectorSegmentExecutor(IndexType type_, const SegmentId & segment_id_, Parameters des_, size_t dimension_ = 0);
+    VectorSegmentExecutor(
+        const SegmentId & segment_id_,
+        Search::IndexType type_,
+        Search::Metric metric_,
+        size_t dimension_,
+        size_t total_vec_,
+        Search::Parameters des_,
+        size_t min_bytes_to_build_vector_index_,
+        bool DEFAULT_DISK_MODE_);
 
     explicit VectorSegmentExecutor(const SegmentId & segment_id_);
 
@@ -86,71 +139,49 @@ public:
 
     /// A C style method that wraps VectorIndex::Search function and does some preprocessing.
     /// Distance and labels are the pointers to expected results and should be declared before calling this method with proper size.
-    Status
-    search(VectorDatasetPtr dataset, int32_t k, float *& distances, int64_t *& labels, GeneralBitMapPtr filter, Parameters parameters);
+    Status search(
+        VectorDatasetPtr dataset,
+        int32_t k,
+        float *& distances,
+        int64_t *& labels,
+        Search::DenseBitmapPtr & filter,
+        Search::Parameters & parameters);
 
-    /// buildIndex() use data to train an index, does not add data for search.
-    /// It'll call index's train(), but does not write to file io.
-    Status buildIndex(VectorDatasetPtr data_set, int64_t total_vectors_expected, bool slow_mode);
+    void buildIndex(PartReader * reader, bool slow_mode, size_t train_block_size, size_t add_block_size);
 
     /// Put the index stored in VectorSegmentExecutor into cache.
     Status cache();
 
-    /// Return index type.
-    IndexType indexType();
-
-    /// Simply add vectors into index for search.
-    Status addVectors(VectorDatasetPtr data_set);
+    Status removeByIds(size_t n, const size_t * ids);
 
-    Status removeByIds(int64_t n, int64_t * ids);
-
-    GeneralBitMapPtr getDeleteBitMap() { return this->delete_bitmap; }
+    Search::DenseBitmapPtr getDeleteBitMap() { return this->delete_bitmap; }
 
     /// Return total number of vectors.
     int64_t getRawDataSize();
 
-    /// Call to set build parameters in this VectorSegmentExecutor.
-    /// Just put the values of parameters as "parameter_name":"value"
-    /// Example: "nprobes":128
-    void setIndexParameters(Parameters parameters);
-
-    /// Automatically compute some operating points for the current index. An operating point is a
-    /// combination of all parameters of the index which corresponds to an estimated accuracy of the inedx while searching.
-    /// the accuracy is calculated by testing the base vectors against itself.
-    /// This function call only does some preprocessing and then dispatch the task to the autotuner.
-    Status dispathAutoTuneTask(VectorDatasetPtr base); /// deprecated
-
-
-    /// this function is for zili's profiler.
-    Status tune(VectorDatasetPtr base, std::vector<int64_t> & empty_ids, size_t current_round_start_row);
-
-
-    /// look into cached OPs in memory, if found nothing then look into file system and read
-    /// the OP file generated by autotuner.
-    Status getOps();
-
     /// cancel building the current vector index, free associated resources.
     Status cancelBuild();
 
     void updateCacheValueWithRowIdsMaps();
 
-    static bool compareVectorIndexParameters(IndexType t1, Parameters p1, IndexType t2, Parameters p2);
-
     static void setCacheManagerSizeInBytes(size_t size);
 
-    static void setSerializeSegmentSize(size_t size);
-
-    static std::list<std::pair<CacheKey, Parameters>> getAllCacheNames();
+    static std::list<std::pair<CacheKey, Search::Parameters>> getAllCacheNames();
 
-    static Status
-    searchWithoutIndex(VectorDatasetPtr query_data, VectorDatasetPtr bash_data, int32_t k, float *& distances, int64_t *& labels, const Metrics& metrics);
+    static Status searchWithoutIndex(
+        VectorDatasetPtr query_data,
+        VectorDatasetPtr bash_data,
+        int32_t k,
+        float *& distances,
+        int64_t *& labels,
+        const Search::Metric & metric);
 
     /// expire the related index from cache.
     static Status removeFromCache(const CacheKey & cache_key);
 
-    GeneralBitMapPtr getRealBitMap(const std::vector<UInt64>& selected_row_ids)
+    Search::DenseBitmapPtr getRealBitMap(const std::vector<UInt64> & selected_row_ids)
     {
-        GeneralBitMapPtr bits = std::make_shared<GeneralBitMap>(total_vec);
+        Search::DenseBitmapPtr bits = std::make_shared<Search::DenseBitmap>(total_vec);
         if (segment_id.fromMergedParts())
         {
             /// need to transfer merged row id to real row id of this old data part.
@@ -166,7 +197,6 @@ public:
         {
             for (auto & row_id : selected_row_ids)
             {
-                /// LOG_DEBUG(log, "[getRealBitMap] set row id: {}", row_id);
                 bits->set(row_id);
             }
         }
@@ -174,34 +204,33 @@ public:
     }
 
     /// Update SegmentId
-    void updateSegmentId(const SegmentId & new_segment_id)
-    {
-        segment_id = new_segment_id;
-    }
+    void updateSegmentId(const SegmentId & new_segment_id) { segment_id = new_segment_id; }
 
     /// Reload delete bitmap from disk.
     bool reloadDeleteBitMap() { return readBitMap(); }
 
     /// Update part's single delete bitmap after lightweight delete on disk and cache if exists.
-    void updateBitMap(const std::vector<UInt64>& deleted_row_ids);
+    void updateBitMap(const std::vector<UInt64> & deleted_row_ids);
 
     /// Update merged old part's delete bitmap after lightweight delete on disk and cache if exists.
-    void updateMergedBitMap(const std::vector<UInt64>& deleted_row_ids);
+    void updateMergedBitMap(const std::vector<UInt64> & deleted_row_ids);
 
 private:
-    Status startWrite();
-
-    Status finishWrite(int64_t binary_total_size);
+    void init();
 
     bool writeBitMap();
 
     bool readBitMap();
 
-    Status writePart(bool final, int segment_count, uint8_t * index_segment_offset, size_t index_segment_size);
-
     void handleMergedMaps();
 
-    void readTotalVec();
+    void performSearch(
+        VectorDatasetPtr dataset,
+        int32_t k,
+        float *& distances,
+        int64_t *& labels,
+        Search::DenseBitmapPtr & filter,
+        Search::Parameters & parameters);
 
     void transferToNewRowIds(int64_t *& labels, int size)
     {
@@ -219,25 +248,32 @@ private:
         }
     }
 
-    const UInt32 dimension;
-    const IndexType type;
-    IndexMode mode = IndexMode::CPU;
-    Metrics me = Metrics::L2;
-    bool auto_tune = false;
-    uint8_t cmb = static_cast<uint8_t>(DB::CompressionMethodByte::LZ4);
-    VectorIndexPtr index = nullptr; // index related to this VectorSegmentExecutor
+    std::shared_ptr<Search::DiskIOManager> getDiskIOManager();
+    void configureDiskMode();
+
+    static std::once_flag once;
+    static int max_threads;
+
+    const Poco::Logger * log = &Poco::Logger::get("VectorSegmentExecutor");
+    const bool DEFAULT_DISK_MODE;
+
     SegmentId segment_id; // this index's related segment_id and file write position.
-    static Poco::Logger * log;
-    UInt64 total_vec = 0;
-    OPsPtr op_points = nullptr; // operating points precomputed as an <accuracy, parameter> map, ordered by acc.
-    GeneralBitMapPtr delete_bitmap = nullptr; // manage deletion from database
-    Parameters des;
+    Search::IndexType type;
+    Search::Metric metric;
+    size_t dimension;
+    size_t total_vec = 0;
+    Search::Parameters des;
+    size_t min_bytes_to_build_vector_index;
+    VectorIndexPtr index = nullptr; // index related to this VectorSegmentExecutor
+    Search::DenseBitmapPtr delete_bitmap = nullptr; // manage deletion from database
     std::shared_ptr<std::vector<UInt64>> row_ids_map = std::make_shared<std::vector<UInt64>>();
     std::shared_ptr<std::vector<UInt64>> inverted_row_ids_map = std::make_shared<std::vector<UInt64>>();
     std::shared_ptr<std::vector<uint8_t>> inverted_row_sources_map = std::make_shared<std::vector<uint8_t>>();
+
+    bool fallback_to_flat = false;
+    bool disk_mode = false;
+    std::string vector_index_cache_prefix;
 };
 
 using VectorSegmentExecutorPtr = std::shared_ptr<VectorSegmentExecutor>;
-
-
 }
diff --git a/src/VectorIndex/test/CMakeLists.txt b/src/VectorIndex/test/CMakeLists.txt
deleted file mode 100644
index 9031f5596e..0000000000
--- a/src/VectorIndex/test/CMakeLists.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-add_executable(test_exe EXCLUDE_FROM_ALL testVectorSegmentExecutor.cpp)
-target_link_libraries(test_exe PUBLIC VectorIndex)
\ No newline at end of file
diff --git a/src/VectorIndex/test/testExecutionEngine.cpp b/src/VectorIndex/test/testExecutionEngine.cpp
deleted file mode 100644
index 2ee5d5fdf7..0000000000
--- a/src/VectorIndex/test/testExecutionEngine.cpp
+++ /dev/null
@@ -1,106 +0,0 @@
-#include <iostream>
-#include <random>
-#include "../VectorSegmentExecutor.h"
-
-
-using namespace VectorIndex;
-int main()
-{
-    int dimension = 64;
-    int nt = 1000;
-    int k = 20;
-    std::mt19937 rng;
-    std::uniform_real_distribution<> distrib;
-    float * train = new float[nt * dimension];
-    float * train2 = new float [nt * dimension];
-    std::cout << "I haven't started yet\n";
-    for (size_t i = 0; i < nt * dimension*2; i++)
-    {
-        if(i<nt*dimension){train[i] = distrib(rng);}
-        else{train2[i-nt*dimension] = random();}
-    }
-    std::cout << "train dataset generated\n";
-
-    VectorSegmentExecutorPtr a = std::make_shared<VectorSegmentExecutor>(dimension, IndexType(IndexType::IVFPQ), IndexMode(CPU), "test");
-    VectorSegmentExecutorPtr additional = std::make_shared<VectorSegmentExecutor>(dimension, IndexType(IndexType::IVFPQ), IndexMode(CPU), "test2");
-    std::cout << "a generated\n";
-    DatasetPtr data_set = std::make_shared<Dataset>(nt, dimension, train);
-    DatasetPtr data_set2 = std::make_shared<Dataset>(nt, dimension, train2);
-
-    a->buildIndex(data_set);
-    additional->buildIndex(data_set2);
-    std::cout << "built\n";
-    a->addVectors(data_set);
-    additional->addVectors(data_set2);
-    std::cout << "added vectors\n";
-
-    std::vector<float> pre_distance(nt * k);
-    std::vector<int64_t> pre_ids(nt * k);
-
-    std::vector<float> pre_distance2(nt * k);
-    std::vector<int64_t> pre_ids2(nt * k);
-
-    GeneralBitMapPtr bits = std::make_shared<GeneralBitMap>(nt);
-    memset(bits->bitmap, 1, (nt / 8) + 1);
-
-    a->search(data_set, k, pre_distance.data(), pre_ids.data(), bits);
-    additional->search(data_set2, k, pre_distance2.data(), pre_ids2.data(), bits);
-
-    for (int i = 0; i < k; i++)
-    {
-        std::cout << pre_ids[i] << ",";
-        std::cout<<pre_distance[i]<<";";
-    }
-    std::cout<<"\n";
-    for (int i = 0; i < k; i++)
-    {
-        std::cout << pre_ids2[i] << ",";
-        std::cout<<pre_distance2[i]<<";";
-    }
-    std::cout<<"\n";
-
-    a->cache();
-    additional->cache();
-    std::cout<<"cached\n";
-    a->serialize();
-    additional->serialize();
-    std::cout << "serilized\n";
-    VectorSegmentExecutorPtr b = std::make_shared<VectorSegmentExecutor>(dimension, IndexType(IndexType::IVFPQ), IndexMode(CPU), "test");
-    VectorSegmentExecutorPtr bdditional = std::make_shared<VectorSegmentExecutor>(dimension, IndexType(IndexType::IVFPQ), IndexMode(CPU), "test2");
-
-    std::cout << "b generated\n";
-    b->load();
-    bdditional->load();
-    std::cout << "b loaded\n";
-
-    std::vector<float> distance3(nt * k);
-    std::vector<int64_t> ids3(nt * k);
-
-    std::vector<float> distance4(nt * k);
-    std::vector<int64_t> ids4(nt * k);
-
-
-    GeneralBitMapPtr bit = std::make_shared<GeneralBitMap>(nt);
-    memset(bit->bitmap, 1, (nt / 8) + 1);
-    std::cout << "bitmap generated\n";
-    b->search(data_set, k, distance3.data(), ids3.data(), bit);
-    bdditional->search(data_set2, k, distance4.data(), ids4.data(), bit);
-    std::cout << "searched\n";
-
-    for (int i = 0; i < k; i++)
-    {
-        std::cout << ids3[i] << ",";
-        std::cout<<distance3[i]<<";";
-    }
-    std::cout<<"\n";
-
-    for (int i = 0; i < k; i++)
-    {
-        std::cout << ids4[i] << ",";
-        std::cout<<distance4[i]<<";";
-    }
-    std::cout<<"\n";
-
-    delete[] train;
-    delete[] train2;
-}
diff --git a/tests/clickhouse-test b/tests/clickhouse-test
index d57056333e..cf89ddfe39 100755
--- a/tests/clickhouse-test
+++ b/tests/clickhouse-test
@@ -326,7 +326,7 @@ class FailureReason(enum.Enum):
     SERVER_DIED = "server died"
     EXIT_CODE = "return code: "
     STDERR = "having stderror: "
-    EXCEPTION = "having having exception in stdout: "
+    EXCEPTION = "having exception in stdout: "
     RESULT_DIFF = "result differs with reference: "
     TOO_LONG = "Test runs too long (> 60s). Make it faster."
     INTERNAL_QUERY_FAIL = "Internal query (CREATE/DROP DATABASE) failed:"
diff --git a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference
index 5af98280f2..05ba402864 100644
--- a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference
+++ b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.reference
@@ -1,6 +1,6 @@
 1	[1,1,1]	0
-2	[2,2,2]	3
 0	[0,0,0]	3
+2	[2,2,2]	3
 3	[3,3,3]	12
 4	[4,4,4]	27
 5	[5,5,5]	48
diff --git a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
index 6695890837..48888c3df7 100755
--- a/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
+++ b/tests/queries/2_vector_search/00003_mqvs_distance_with_prewhere.sh
@@ -4,4 +4,4 @@
 CURDIR=$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)
 . "$CURDIR"/helpers/00000_prepare_index.sh
 
-clickhouse-client -q "SELECT id, vector, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector prewhere id < 10 or id > 60 ORDER BY d limit 20;"
+clickhouse-client -q "SELECT id, vector, distance(vector, [1.0, 1.0, 1.0]) as d FROM test_vector prewhere id < 10 or id > 60 ORDER BY (d, id) limit 20;"
diff --git a/tests/queries/2_vector_search/00005_mqvs_build_ivfflat_index.sh b/tests/queries/2_vector_search/00005_mqvs_build_ivfflat_index.sh
index f3c213d08d..ffb13de0dc 100755
--- a/tests/queries/2_vector_search/00005_mqvs_build_ivfflat_index.sh
+++ b/tests/queries/2_vector_search/00005_mqvs_build_ivfflat_index.sh
@@ -5,3 +5,4 @@ clickhouse-client -q "DROP TABLE IF EXISTS test_ivfflat"
 clickhouse-client -q "CREATE TABLE test_ivfflat(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id SETTINGS index_granularity=1024;"
 clickhouse-client -q "ALTER TABLE test_ivfflat ADD VECTOR INDEX v1 vector TYPE IVFFLAT('ncentroids = 1');"
 clickhouse-client -q "SELECT table,name,type,expr,status from system.vector_indices where table = 'test_ivfflat'"
+clickhouse-client -q "DROP TABLE test_ivfflat"
diff --git a/tests/queries/2_vector_search/00006_mqvs_build_hnswflat_index.sh b/tests/queries/2_vector_search/00006_mqvs_build_hnswflat_index.sh
index fc05c0e3d3..60b3506ab4 100755
--- a/tests/queries/2_vector_search/00006_mqvs_build_hnswflat_index.sh
+++ b/tests/queries/2_vector_search/00006_mqvs_build_hnswflat_index.sh
@@ -5,3 +5,4 @@ clickhouse-client -q "DROP TABLE IF EXISTS test_hnsw"
 clickhouse-client -q "CREATE TABLE test_hnsw(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id SETTINGS index_granularity=1024;"
 clickhouse-client -q "ALTER TABLE test_hnsw ADD VECTOR INDEX v1 vector TYPE HNSWFLAT('m = 10');"
 clickhouse-client -q "SELECT table,name,type,expr,status from system.vector_indices where table = 'test_hnsw'"
+clickhouse-client -q "DROP TABLE test_hnsw"
diff --git a/tests/queries/2_vector_search/00008_mqvs_empty_vector.reference b/tests/queries/2_vector_search/00008_mqvs_empty_vector.reference
index d619e1d15b..88e8cf2ca2 100644
--- a/tests/queries/2_vector_search/00008_mqvs_empty_vector.reference
+++ b/tests/queries/2_vector_search/00008_mqvs_empty_vector.reference
@@ -18,5 +18,5 @@
 6	[6,6,6]	588
 34	[34,34,34]	588
 5	[5,5,5]	675
-test_fail_vector	v1_fail	v1_fail vector TYPE IVFFLAT(\'ncentroids = 10\')	Error	all_1_3_1	 Part: all_1_3_1, vector column data length does not meet constraint. (INCORRECT_DATA) (version 22.3.7.5)
-test_fail_vector_2	v1_fail_2	v1_fail_2 vector TYPE IVFFLAT(\'ncentroids = 10\')	Error	all_1_3_1	 Part: all_1_3_1, vector column data length does not meet constraint. (INCORRECT_DATA) (version 22.3.7.5)
+test_fail_vector	v1_fail	v1_fail vector TYPE IVFFLAT(\'ncentroids = 10\')	Error	all_1_3_1	 Vector column data length does not meet constraint in part all_1_3_1. (INCORRECT_DATA) (version 22.3.7.5)
+test_fail_vector_2	v1_fail_2	v1_fail_2 vector TYPE IVFFLAT(\'ncentroids = 10\')	Error	all_1_3_1	 Vector column data length does not meet constraint in part all_1_3_1. (INCORRECT_DATA) (version 22.3.7.5)
diff --git a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference
index 3d8ef1afdd..012c1545f4 100644
--- a/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference
+++ b/tests/queries/2_vector_search/00013_mqvs_distance_ivfsq.reference
@@ -1,20 +1,20 @@
-0	[0,0,0]	0.00970047
-1	[1,1,1]	1.9864521
-2	[2,2,2]	11.696049
-3	[3,3,3]	24.283756
-4	[4,4,4]	48.141277
-5	[5,5,5]	71.33989
-6	[6,6,6]	109.34532
-7	[7,7,7]	143.15494
-8	[8,8,8]	181.51205
-9	[9,9,9]	239.72878
-0	[0,0,0]	0.00970047
-1	[1,1,1]	1.9864521
-2	[2,2,2]	11.696049
-3	[3,3,3]	24.283756
-4	[4,4,4]	48.141277
-5	[5,5,5]	71.33989
-6	[6,6,6]	109.34532
-7	[7,7,7]	143.15494
-8	[8,8,8]	181.51205
-9	[9,9,9]	239.72878
+0	[0,0,0]	0.05024068
+1	[1,1,1]	2.5914247
+2	[2,2,2]	11.859263
+3	[3,3,3]	27.853758
+4	[4,4,4]	42.253746
+5	[5,5,5]	69.45927
+6	[6,6,6]	103.39149
+7	[7,7,7]	144.0503
+8	[8,8,8]	191.4358
+9	[9,9,9]	245.54788
+0	[0,0,0]	0.05024068
+1	[1,1,1]	2.5914247
+2	[2,2,2]	11.859263
+3	[3,3,3]	27.853758
+4	[4,4,4]	42.253746
+5	[5,5,5]	69.45927
+6	[6,6,6]	103.39149
+7	[7,7,7]	144.0503
+8	[8,8,8]	191.4358
+9	[9,9,9]	245.54788
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.reference b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.reference
new file mode 100644
index 0000000000..710519f389
--- /dev/null
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.reference
@@ -0,0 +1,5 @@
+8	1.1920929e-7
+9	0.00008100271
+7	0.00012362003
+10	0.00027000904
+11	0.00051391125
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.sql b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.sql
new file mode 100644
index 0000000000..79d6c79982
--- /dev/null
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_bruteforce.sql
@@ -0,0 +1,10 @@
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS test_vector SYNC;
+
+CREATE TABLE test_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, vector_search_metric_type='Cosine';
+INSERT INTO test_vector SELECT number, [number, number + 3, number + 1] FROM numbers(1000);
+
+SELECT id, distance(vector, [8., 11, 9]) AS d FROM test_vector ORDER BY d LIMIT 5;
+
+DROP TABLE test_vector sync;
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.reference b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.reference
index 51adfba076..993f6adff7 100644
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.reference
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_hnsw.reference
@@ -2,9 +2,9 @@
 3	[0.33333334,0.33333334,0.33333334,0.8164966]	0.091751695
 4	[0.25,0.25,0.25,0.9013878]	0.1743061
 5	[0.2,0.2,0.2,0.9380832]	0.2309584
-6	[0.16666667,0.16666667,0.16666667,0.9574271]	0.2712865
+6	[0.16666667,0.16666667,0.16666667,0.9574271]	0.27128643
 7	[0.14285715,0.14285715,0.14285715,0.96890426]	0.30126214
 8	[0.125,0.125,0.125,0.9762812]	0.32435942
 9	[0.11111111,0.11111111,0.11111111,0.9813068]	0.34267992
 10	[0.1,0.1,0.1,0.98488575]	0.35755712
-11	[0.09090909,0.09090909,0.09090909,0.9875255]	0.36987358
+11	[0.09090909,0.09090909,0.09090909,0.9875255]	0.36987364
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.reference b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.reference
index 5bd7d66419..8da8668fd8 100644
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.reference
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfpq.reference
@@ -1,10 +1,10 @@
-2	[0.5,0.5,0.5,0.5]	-0.021656275
-3	[0.33333334,0.33333334,0.33333334,0.8164966]	0.070528865
-4	[0.25,0.25,0.25,0.9013878]	0.19552898
-8	[0.125,0.125,0.125,0.9762812]	0.2811712
-7	[0.14285715,0.14285715,0.14285715,0.96890426]	0.2811712
-5	[0.2,0.2,0.2,0.9380832]	0.29359
-6	[0.16666667,0.16666667,0.16666667,0.9574271]	0.29359
-13	[0.07692308,0.07692308,0.07692308,0.9910845]	0.36577475
-12	[0.083333336,0.083333336,0.083333336,0.98952854]	0.3665527
-11	[0.09090909,0.09090909,0.09090909,0.9875255]	0.3675542
+2	[0.5,0.5,0.5,0.5]	-0.007502675
+3	[0.33333334,0.33333334,0.33333334,0.8164966]	0.091751695
+4	[0.25,0.25,0.25,0.9013878]	0.18180883
+5	[0.2,0.2,0.2,0.9380832]	0.22634882
+6	[0.16666667,0.16666667,0.16666667,0.9574271]	0.27128863
+8	[0.125,0.125,0.125,0.9762812]	0.31281078
+7	[0.14285715,0.14285715,0.14285715,0.96890426]	0.31281078
+11	[0.09090909,0.09090909,0.09090909,0.9875255]	0.35567933
+10	[0.1,0.1,0.1,0.98488575]	0.35750002
+9	[0.11111111,0.11111111,0.11111111,0.9813068]	0.36104023
diff --git a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.reference b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.reference
index a920d4791b..65c6b20e50 100644
--- a/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.reference
+++ b/tests/queries/2_vector_search/00014_mqvs_distance_cosine_ivfsq.reference
@@ -1,10 +1,10 @@
-2	[0.5,0.5,0.5,0.5]	-0.0012428164
-3	[0.33333334,0.33333334,0.33333334,0.8164966]	0.0917362
-4	[0.25,0.25,0.25,0.9013878]	0.17300248
-5	[0.2,0.2,0.2,0.9380832]	0.22995818
-6	[0.16666667,0.16666667,0.16666667,0.9574271]	0.27147627
-7	[0.14285715,0.14285715,0.14285715,0.96890426]	0.30236912
-8	[0.125,0.125,0.125,0.9762812]	0.32391512
-9	[0.11111111,0.11111111,0.11111111,0.9813068]	0.34339523
-10	[0.1,0.1,0.1,0.98488575]	0.35741496
-11	[0.09090909,0.09090909,0.09090909,0.9875255]	0.36936855
+2	[0.5,0.5,0.5,0.5]	-0.00024676323
+3	[0.33333334,0.33333334,0.33333334,0.8164966]	0.09092176
+4	[0.25,0.25,0.25,0.9013878]	0.17403835
+5	[0.2,0.2,0.2,0.9380832]	0.23128521
+6	[0.16666667,0.16666667,0.16666667,0.9574271]	0.27123928
+7	[0.14285715,0.14285715,0.14285715,0.96890426]	0.30098808
+8	[0.125,0.125,0.125,0.9762812]	0.32428473
+9	[0.11111111,0.11111111,0.11111111,0.9813068]	0.3425076
+10	[0.1,0.1,0.1,0.98488575]	0.35789424
+11	[0.09090909,0.09090909,0.09090909,0.9875255]	0.3695426
diff --git a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
index 0684d2c936..c4e2cfac6d 100644
--- a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
+++ b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
@@ -1,7 +1,7 @@
 -- Tags: no-parallel
 
 DROP TABLE IF EXISTS test_vector;
-CREATE TABLE test_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, distable_rebuild_for_decouple=true,max_rows_for_slow_mode_single_vector_index_build = 10;
+CREATE TABLE test_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, disable_rebuild_for_decouple=true,max_rows_for_slow_mode_single_vector_index_build = 10;
 INSERT INTO test_vector SELECT number, [number, number, number] FROM numbers(100);
 ALTER TABLE test_vector ADD VECTOR INDEX v1 vector TYPE HNSWFLAT;
 
diff --git a/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql b/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql
index 5f6d7dd4c7..33e96eb131 100644
--- a/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql
+++ b/tests/queries/2_vector_search/00017_mqvs_replicated_lightweight_delete_with_decouple.sql
@@ -2,8 +2,8 @@
 
 DROP TABLE IF EXISTS test_replicated_vector SYNC;
 DROP TABLE IF EXISTS test_replicated_vector2 SYNC;
-CREATE TABLE test_replicated_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00017/vector', 'r1') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, distable_rebuild_for_decouple=true,max_rows_for_slow_mode_single_vector_index_build = 10;
-CREATE TABLE test_replicated_vector2(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00017/vector', 'r2') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, distable_rebuild_for_decouple=true,max_rows_for_slow_mode_single_vector_index_build = 10;
+CREATE TABLE test_replicated_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00017/vector', 'r1') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, disable_rebuild_for_decouple=true,max_rows_for_slow_mode_single_vector_index_build = 10;
+CREATE TABLE test_replicated_vector2(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00017/vector', 'r2') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, disable_rebuild_for_decouple=true,max_rows_for_slow_mode_single_vector_index_build = 10;
 INSERT INTO test_replicated_vector SELECT number, [number, number, number] FROM numbers(100);
 ALTER TABLE test_replicated_vector ADD VECTOR INDEX v1 vector TYPE HNSWFLAT;
 
diff --git a/tests/queries/2_vector_search/00018_mqvs_drop_index_mergetree.reference b/tests/queries/2_vector_search/00018_mqvs_drop_index_mergetree.reference
index 91d6f14d1f..3405f58b06 100644
--- a/tests/queries/2_vector_search/00018_mqvs_drop_index_mergetree.reference
+++ b/tests/queries/2_vector_search/00018_mqvs_drop_index_mergetree.reference
@@ -3,4 +3,4 @@ test_drop_index	v1	HNSWFLAT	v1 vector TYPE HNSWFLAT	Built
 -- Empty result, no vector index
 -- Create a new vector index with same name but different type
 0
-test_drop_index	v1	IVFFLAT	v1 vector TYPE IVFFlat	Built
+test_drop_index	v1	IVFFlat	v1 vector TYPE IVFFlat	Built
diff --git a/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.reference b/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.reference
index 19b0dc2173..c51386aa7c 100644
--- a/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.reference
+++ b/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.reference
@@ -1,4 +1,4 @@
 0
-test_fail_vector	v1_fail	v1_fail vector TYPE HNSWSQ(\'metric_type = cosine\', \'ef_c=256\')	Error	all_1_1_0	 [VectorIndex] unsupported metric_type COSINE. (UNSUPPORTED_PARAMETER) (version 22.3.7.5)
-test_fail_vector_2	vindex	vindex vector TYPE IVFFLAT(\'metric=IP\', \'ncentroids=5000\')	Error	all_1_1_0	 [VectorIndex] These parameters are not supported in Index type IVFFLAT : metric : IP, . (UNSUPPORTED_PARAMETER) (version 22.3.7.5)
+test_fail_vector	v1_fail	v1_fail vector TYPE HNSWSQ(\'metric_type = unknown\', \'ef_c=256\')	Error	all_1_1_0	 Unknown metric: unknown. (BAD_ARGUMENTS) (version 22.3.7.5)
+test_fail_vector_2	vindex	vindex vector TYPE IVFFLAT(\'metric=IP\', \'ncentroids=5000\')	Error	all_1_1_0	 [VectorIndex] Error(UNSUPPORTED_PARAMETER) in void Search::raiseErrorOnUnknownParams(const Search::Parameters &) at ./contrib/search-index/SearchIndex/SearchIndexCommon.h:284: Unknown parameter: metric=IP. (UNSUPPORTED_PARAMETER) (version 22.3.7.5)
 test_success_vector	v1_success	v1_success vector TYPE HNSWFLAT	Built		
diff --git a/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.sql b/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.sql
index bdefe2799b..feecd15f2f 100644
--- a/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.sql
+++ b/tests/queries/2_vector_search/00019_mqvs_add_fail_status_in_vector_indices.sql
@@ -8,8 +8,8 @@ ALTER TABLE test_success_vector ADD VECTOR INDEX v1_success vector TYPE HNSWFLAT
 DROP TABLE IF EXISTS test_fail_vector;
 CREATE TABLE test_fail_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=100;
 INSERT INTO test_fail_vector SELECT number, [number, number, number] FROM numbers(2100);
--- Unsupported parameter: metric_type = cosine
-ALTER TABLE test_fail_vector ADD VECTOR INDEX v1_fail vector TYPE HNSWSQ('metric_type = cosine', 'ef_c=256');
+-- Unsupported parameter: metric_type = unknown
+ALTER TABLE test_fail_vector ADD VECTOR INDEX v1_fail vector TYPE HNSWSQ('metric_type = unknown', 'ef_c=256');
 
 DROP TABLE IF EXISTS test_fail_vector_2;
 CREATE TABLE test_fail_vector_2(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=100;
diff --git a/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.reference b/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.reference
index d5ee6e9e53..98e0498929 100644
--- a/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.reference
+++ b/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.reference
@@ -1,6 +1,6 @@
 0
 0
 0
-test_replicated_fail_vector	v1_fail	v1_fail vector TYPE HNSWSQ(\'metric_type = cosine\', \'ef_c=256\')	Error	all_0_0_0	 [VectorIndex] unsupported metric_type COSINE. (UNSUPPORTED_PARAMETER) (version 22.3.7.5)
-test_replicated_fail_vector_2	vindex	vindex vector TYPE IVFFLAT(\'metric=IP\', \'ncentroids=5000\')	Error	all_0_0_0	 [VectorIndex] These parameters are not supported in Index type IVFFLAT : metric : IP, . (UNSUPPORTED_PARAMETER) (version 22.3.7.5)
+test_replicated_fail_vector	v1_fail	v1_fail vector TYPE HNSWSQ(\'metric_type = unknown\', \'ef_c=256\')	Error	all_0_0_0	 Unknown metric: unknown. (BAD_ARGUMENTS) (version 22.3.7.5)
+test_replicated_fail_vector_2	vindex	vindex vector TYPE IVFFLAT(\'metric=IP\', \'ncentroids=5000\')	Error	all_0_0_0	 [VectorIndex] Error(UNSUPPORTED_PARAMETER) in void Search::raiseErrorOnUnknownParams(const Search::Parameters &) at ./contrib/search-index/SearchIndex/SearchIndexCommon.h:284: Unknown parameter: metric=IP. (UNSUPPORTED_PARAMETER) (version 22.3.7.5)
 test_replicated_success_vector	v1_success	v1_success vector TYPE HNSWFLAT	Built		
diff --git a/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.sql b/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.sql
index 90191e9ec7..32ffb5e433 100644
--- a/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.sql
+++ b/tests/queries/2_vector_search/00019_mqvs_replicated_add_fail_status_in_vector_indices.sql
@@ -9,8 +9,8 @@ SELECT sleep(2);
 
 DROP TABLE IF EXISTS test_replicated_fail_vector SYNC;
 CREATE TABLE test_replicated_fail_vector(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00019/fail_vector', 'r1') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=100;
--- Unsupported parameter: metric_type = cosine
-ALTER TABLE test_replicated_fail_vector ADD VECTOR INDEX v1_fail vector TYPE HNSWSQ('metric_type = cosine', 'ef_c=256');
+-- Unsupported parameter: metric_type = unknown
+ALTER TABLE test_replicated_fail_vector ADD VECTOR INDEX v1_fail vector TYPE HNSWSQ('metric_type = unknown', 'ef_c=256');
 INSERT INTO test_replicated_fail_vector SELECT number, [number, number, number] FROM numbers(2100);
 
 SELECT sleep(2);
diff --git a/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.reference b/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.reference
index bc37d7c910..4767576b62 100644
--- a/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.reference
+++ b/tests/queries/2_vector_search/00020_mqvs_refactor_support_prewhere_where.reference
@@ -1,12 +1,12 @@
 0
 test_vector	vector_idx	IVFFLAT	Built
-1005	2022-12-29	animal	0
+1000	2022-12-29	animal	0
 1001	2022-12-29	animal	0
-1004	2022-12-29	animal	0
+1002	2022-12-29	animal	0
 1003	2022-12-29	animal	0
-1009	2022-12-29	animal	0
+1004	2022-12-29	animal	0
+1005	2022-12-29	animal	0
 1006	2022-12-29	animal	0
 1007	2022-12-29	animal	0
 1008	2022-12-29	animal	0
-1002	2022-12-29	animal	0
-1000	2022-12-29	animal	0
+1009	2022-12-29	animal	0
diff --git a/tests/queries/2_vector_search/00022_mqvs_replicated_merge_with_vector_index.sql b/tests/queries/2_vector_search/00022_mqvs_replicated_merge_with_vector_index.sql
index 7cd851c51e..5f73a12aec 100644
--- a/tests/queries/2_vector_search/00022_mqvs_replicated_merge_with_vector_index.sql
+++ b/tests/queries/2_vector_search/00022_mqvs_replicated_merge_with_vector_index.sql
@@ -1,7 +1,7 @@
 -- Tags: no-parallel
 
 DROP TABLE IF EXISTS test_replicated_vector_merge SYNC;
-CREATE TABLE test_replicated_vector_merge(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00022/vector_merge', 'r1') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, distable_rebuild_for_decouple=true;
+CREATE TABLE test_replicated_vector_merge(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 3) engine=ReplicatedMergeTree('/clickhouse/tables/{database}/mqvs_00022/vector_merge', 'r1') primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, disable_rebuild_for_decouple=true;
 ALTER TABLE test_replicated_vector_merge ADD VECTOR INDEX v1 vector TYPE HNSWFLAT;
 INSERT INTO test_replicated_vector_merge SELECT number, [number, number, number] FROM numbers(100);
 
diff --git a/tests/queries/2_vector_search/00023_mqvs_mutation_can_reuse_vector_index.sh b/tests/queries/2_vector_search/00023_mqvs_mutation_can_reuse_vector_index.sh
index d8418b1531..34203a03fc 100755
--- a/tests/queries/2_vector_search/00023_mqvs_mutation_can_reuse_vector_index.sh
+++ b/tests/queries/2_vector_search/00023_mqvs_mutation_can_reuse_vector_index.sh
@@ -16,7 +16,7 @@ time=0
 while [[ $status != "Built" && $time != 5 ]]
 do
         status=`clickhouse-client -q "select status from system.vector_indices where table = 'test_mutation' and name = 'replia_ind'"`
-        sleep 2
+        sleep 8
         ((++time))
 done
 if [ $time -eq 5 ]; then
@@ -47,7 +47,7 @@ time=0
 while [[ $status != "Built" && $time != 5 ]]
 do
         status=`clickhouse-client -q "select status from system.vector_indices where table = 'test_replica_mutation' and name = 'replia_ind'"`
-        sleep 2
+        sleep 8
         ((++time))
 done
 if [ $time -eq 5 ]; then
@@ -77,7 +77,7 @@ time=0
 while [[ $status != "Built" && $status != "Error" && $time < 5 ]]
 do
         status=`clickhouse-client -q "select status from system.vector_indices where table = 'test_replica_mutation_cancel' and name = 'replia_ind'"`
-        sleep 2
+        sleep 5
         ((++time))
 done
 
diff --git a/tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.reference b/tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.reference
new file mode 100644
index 0000000000..2c47b6133d
--- /dev/null
+++ b/tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.reference
@@ -0,0 +1,14 @@
+0
+test_mstg	v1	v1 vector TYPE MSTG(\'disk_mode=1\')	Built		
+8	0
+7	8
+9	8
+6	32
+10	32
+0
+test_mstg	v1	v1 vector TYPE MSTG(\'metric_type=Cosine\')	Built		
+8	5.9604645e-8
+9	0.000118255615
+7	0.00016528368
+10	0.00040733814
+11	0.00079762936
diff --git a/tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.sql b/tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.sql
new file mode 100644
index 0000000000..8dd5557d4d
--- /dev/null
+++ b/tests/queries/2_vector_search/00028_mqvs_index_mstg_build_search.sql
@@ -0,0 +1,22 @@
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS test_mstg SYNC;
+
+CREATE TABLE test_mstg(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 8) engine=MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1;
+INSERT INTO test_mstg SELECT number, [number, number + 7, number + 6, number + 5, number + 4, number + 3, number + 2, number + 1] FROM numbers(1000);
+OPTIMIZE TABLE test_mstg FINAL;
+
+ALTER TABLE test_mstg ADD VECTOR INDEX v1 vector TYPE MSTG('disk_mode=1');
+SELECT sleep(1);
+SELECT table, name, expr, status, latest_failed_part, latest_fail_reason FROM system.vector_indices WHERE database = currentDatabase() and table = 'test_mstg';
+
+SELECT id, distance(vector, [8., 15, 14, 13, 12, 11, 10, 9]) AS d FROM test_mstg ORDER BY d LIMIT 5;
+
+ALTER TABLE test_mstg DROP VECTOR INDEX v1;
+ALTER TABLE test_mstg ADD VECTOR INDEX v1 vector TYPE MSTG('metric_type=Cosine');
+SELECT sleep(1);
+SELECT table, name, expr, status, latest_failed_part, latest_fail_reason FROM system.vector_indices WHERE database = currentDatabase() and table = 'test_mstg';
+
+SELECT id, distance('alpha=4')(vector, [8., 15, 14, 13, 12, 11, 10, 9]) AS d FROM test_mstg ORDER BY d LIMIT 5;
+
+DROP TABLE test_mstg sync;
diff --git a/tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.reference b/tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.reference
new file mode 100644
index 0000000000..dde42cd5e5
--- /dev/null
+++ b/tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.reference
@@ -0,0 +1,12 @@
+0
+test_mstg	v1	v1 vector TYPE MSTG(\'disk_mode=1\', \'metric_type=Cosine\')	Built		
+8	0
+9	0.000118255615
+7	0.00016528368
+10	0.00040733814
+11	0.00079762936
+8	0
+9	0.000118255615
+7	0.00016528368
+10	0.00040733814
+11	0.00079762936
diff --git a/tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.sql b/tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.sql
new file mode 100644
index 0000000000..4a2690b2d2
--- /dev/null
+++ b/tests/queries/2_vector_search/00029_mqvs_fallback_to_flat.sql
@@ -0,0 +1,15 @@
+-- Tags: no-parallel
+
+DROP TABLE IF EXISTS test_mstg SYNC;
+
+CREATE TABLE test_mstg(id Float32, vector Array(Float32), CONSTRAINT vector_len CHECK length(vector) = 8) engine=MergeTree primary key id SETTINGS index_granularity=1024, min_rows_to_build_vector_index=1, min_bytes_to_build_vector_index=40000;
+INSERT INTO test_mstg SELECT number, [number, number + 7, number + 6, number + 5, number + 4, number + 3, number + 2, number + 1] FROM numbers(1000);
+OPTIMIZE TABLE test_mstg FINAL;
+ALTER TABLE test_mstg ADD VECTOR INDEX v1 vector TYPE MSTG('disk_mode=1', 'metric_type=Cosine');
+SELECT sleep(1);
+SELECT table, name, expr, status, latest_failed_part, latest_fail_reason FROM system.vector_indices WHERE database = currentDatabase() and table = 'test_mstg';
+SELECT id, distance(vector, [8., 15, 14, 13, 12, 11, 10, 9]) AS d FROM test_mstg ORDER BY d LIMIT 5;
+DETACH TABLE test_mstg;
+ATTACH TABLE test_mstg;
+SELECT id, distance(vector, [8., 15, 14, 13, 12, 11, 10, 9]) AS d FROM test_mstg ORDER BY d LIMIT 5;
+DROP TABLE test_mstg sync;
-- 
2.32.1 (Apple Git-133)

