From 2f12687be15fb81a35347fe478fd5669719bab30 Mon Sep 17 00:00:00 2001
From: Jianmei Zhang <jianmeiz@moqi.ai>
Date: Tue, 29 Nov 2022 16:07:29 +0800
Subject: [PATCH 018/150] Add lightweight delete support for decoupled part

---
 contrib/faiss                                 |   2 +-
 contrib/hnswlib                               |   2 +-
 scripts/config_on_linux.sh                    |   2 +-
 scripts/config_on_linux_debug.sh              |   1 +
 scripts/setup_build.sh                        |  20 +-
 .../PullingAsyncPipelineExecutor.cpp          |   2 -
 src/Storages/MergeTree/IMergeTreeDataPart.cpp | 224 ++++++++++++------
 src/Storages/MergeTree/IMergeTreeDataPart.h   |  69 +++++-
 .../MergeTree/MergePlainMergeTreeTask.cpp     |  20 +-
 src/Storages/MergeTree/MergeTask.cpp          |   9 +-
 .../MergeTreeBaseSelectProcessor.cpp          |  12 -
 src/Storages/MergeTree/MergeTreeData.cpp      |  34 +--
 .../MergeTreeVectorIndexBuilderUpdater.cpp    | 115 ++++++---
 .../MergeTreeVectorIndexBuilderUpdater.h      |   5 +-
 .../MergeTree/MergeTreeVectorScanManager.cpp  |  24 +-
 .../MergeTree/MutatePlainMergeTreeTask.cpp    |  22 +-
 src/Storages/MergeTree/MutateTask.cpp         |  59 ++---
 .../MergeTree/VectorIndexMergeTreeTask.h      |  26 +-
 src/Storages/StorageMergeTree.cpp             |  45 +---
 src/VectorIndex/CacheManager.cpp              |   5 +-
 src/VectorIndex/CacheManager.h                |   2 +
 src/VectorIndex/FaissIndex.cpp                |   5 +-
 src/VectorIndex/GeneralBitMap.h               |  28 +--
 src/VectorIndex/HNSWIndex.cpp                 |   4 +-
 src/VectorIndex/HNSWPQ.cpp                    |   5 +-
 src/VectorIndex/HNSWSQ.cpp                    |   9 +-
 src/VectorIndex/MergeUtils.h                  |  69 +++---
 src/VectorIndex/SegmentId.h                   |   8 +-
 src/VectorIndex/VectorSegmentExecutor.cpp     | 221 +++++++++--------
 src/VectorIndex/VectorSegmentExecutor.h       |  27 ++-
 .../00015_mqvs_create_vector_index.sql        |   4 +-
 ...x_build_after_lightweight_delete.reference |   1 +
 ...lightweight_delete_with_decouple.reference |  22 ++
 ..._mqvs_lightweight_delete_with_decouple.sql |  10 +-
 34 files changed, 634 insertions(+), 479 deletions(-)
 mode change 100644 => 100755 scripts/config_on_linux_debug.sh

diff --git a/contrib/faiss b/contrib/faiss
index de29268c79..631d7d8d46 160000
--- a/contrib/faiss
+++ b/contrib/faiss
@@ -1 +1 @@
-Subproject commit de29268c79a2c86ddf5084e4ccca4238b6b58d97
+Subproject commit 631d7d8d46f302c5a24a123fc6550ecb684a0d2a
diff --git a/contrib/hnswlib b/contrib/hnswlib
index fda1ab6320..a6ac4e52e8 160000
--- a/contrib/hnswlib
+++ b/contrib/hnswlib
@@ -1 +1 @@
-Subproject commit fda1ab6320fc3340804ba619cd28ca06f044ac27
+Subproject commit a6ac4e52e8bff990496d69638ee8e09412f3bd00
diff --git a/scripts/config_on_linux.sh b/scripts/config_on_linux.sh
index a44d206be3..fa66fc7599 100644
--- a/scripts/config_on_linux.sh
+++ b/scripts/config_on_linux.sh
@@ -8,7 +8,7 @@ mkdir -p $CURDIR/../$BUILD_FOLDER/
 cd $CURDIR/../$BUILD_FOLDER/
 export LD_LIBRARY_PATH=/usr/lib/llvm-13/lib:/opt/intel/oneapi/mkl/2021.4.0/lib/intel64/:${LD_LIBRARY_PATH}
 cmake -G Ninja .. -DCMAKE_C_COMPILER=$(command -v clang-13) \
-    -DCMAKE_CXX_COMPILER=$(command -v clang++-13) \
+    -DCMAKE_CXX_COMPILER=$(command -v clang++-13) $SANITIZER_ARGS \
     -DCMAKE_BUILD_TYPE=$BUILD_TYPE \
     -DCMAKE_EXPORT_COMPILE_COMMANDS=1 \
     -DENABLE_CLICKHOUSE_ALL=OFF \
diff --git a/scripts/config_on_linux_debug.sh b/scripts/config_on_linux_debug.sh
old mode 100644
new mode 100755
index d0f07eda34..a6827688b0
--- a/scripts/config_on_linux_debug.sh
+++ b/scripts/config_on_linux_debug.sh
@@ -13,6 +13,7 @@ cmake -G Ninja .. -DCMAKE_C_COMPILER=$(command -v clang-13) \
     -DENABLE_CLICKHOUSE_SERVER=ON \
     -DENABLE_CLICKHOUSE_CLIENT=ON \
     -DENABLE_CLICKHOUSE_FORMAT=ON \
+    -DENABLE_CLICKHOUSE_BENCHMARK=ON \
     -DENABLE_LIBRARIES=OFF \
     -DENABLE_CURL=ON \
     -DENABLE_S3=ON \
diff --git a/scripts/setup_build.sh b/scripts/setup_build.sh
index c1d28b217c..870c7c6d03 100644
--- a/scripts/setup_build.sh
+++ b/scripts/setup_build.sh
@@ -6,7 +6,7 @@ if [ $# == 0 ] || [ "$1" == "Release" ]; then
     BUILD_FOLDER="build"
     BUILD_TYPE="Release"
 elif [ "$1" == "RelWithDebInfo" ]; then
-    BUILD_FOLDER="build"
+    BUILD_FOLDER="build-reldbg"
     BUILD_TYPE="RelWithDebInfo"
 elif [ "$1" == "Debug" ]; then
     echo "Build with Debug mode"
@@ -15,4 +15,20 @@ elif [ "$1" == "Debug" ]; then
 else
     echo "Invalid build mode: $1"
     exit 1
-fi
\ No newline at end of file
+fi
+
+if [ $# -ge 2 ]; then
+    if [ "$2" == "ASAN" ]; then
+        BUILD_FOLDER="${BUILD_FOLDER}-asan"
+        SANIITIZE_ARGS="-DSANITIZE=address"
+    elif [ "$2" == "TSAN" ]; then
+        BUILD_FOLDER="${BUILD_FOLDER}-tsan"
+        SANIITIZE_ARGS="-DSANITIZE=thread"
+    elif [ "$2" == "MSAN" ]; then
+        BUILD_FOLDER="${BUILD_FOLDER}-msan"
+        SANIITIZE_ARGS="-DSANITIZE=memory"
+    else
+        echo "Invalid sanitizer mode: $2"
+        exit 1
+    fi
+fi
diff --git a/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp b/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp
index afe282c6ed..f9edb1b214 100644
--- a/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp
+++ b/src/Processors/Executors/PullingAsyncPipelineExecutor.cpp
@@ -128,9 +128,7 @@ bool PullingAsyncPipelineExecutor::pull(Chunk & chunk, uint64_t milliseconds)
 
     if (lazy_format)
     {
-        LOG_DEBUG(log, "[pull] call lazy format getChunk: time: {}", milliseconds);
         chunk = lazy_format->getChunk(milliseconds);
-        LOG_DEBUG(log, "[pull] after call lazy format getChunk");
         return true;
     }
 
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.cpp b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
index 883b88f556..5eadb2703f 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.cpp
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.cpp
@@ -1138,27 +1138,38 @@ void IMergeTreeDataPart::removeVectorIndex(const String & index_name, const Stri
 
 void IMergeTreeDataPart::loadVectorIndexMetadata() const
 {
+    if (!isStoredOnDisk())
+        return;
+
     auto metadata_snapshot = storage.getInMemoryMetadataPtr();
-    if (metadata_snapshot->getVectorIndices().empty())
-    {
-        LOG_DEBUG(storage.log, "[loadVectorIndexMetadata] no vector index declared");
+    if (metadata_snapshot->vec_indices.empty())
         return;
-    }
+
+    /// Check if single vector index is ready. If not, check decoupled many old vector indices.
+    if (volume->getDisk()->exists(getFullRelativePath() + "vector_index_ready" + VECTOR_INDEX_FILE_SUFFIX))
+        loadSimpleVectorIndexMetadata();
+    else
+        loadDecoupledVectorIndexMetadata();
+}
+
+void IMergeTreeDataPart::loadSimpleVectorIndexMetadata() const
+{
+    auto metadata_snapshot = storage.getInMemoryMetadataPtr();
 
     /// first loop through metadata, this loop we find all vector index needed to verify, and read them in one disk IO
     std::vector<String> index_name_to_verify;
     for (const auto & vec_index_desc : metadata_snapshot->vec_indices)
-    {
         index_name_to_verify.emplace_back(vec_index_desc.name + "_" + vec_index_desc.column);
-    }
 
-    String read_file_path = getFullPath() + "vector_index_ready";
-    LOG_DEBUG(storage.log, "[loadVectorIndexMetadata] ready file path :{}", read_file_path);
+    String read_file_path = getFullPath() + "vector_index_ready" + VECTOR_INDEX_FILE_SUFFIX;
 
     VectorIndex::DiskIOReader reader;
     std::unordered_map<std::string, VectorIndex::Parameters> para;
     std::unordered_map<String, int64_t> sizes = VectorIndex::readVectorIndexReadyFile(reader, read_file_path, index_name_to_verify, para);
 
+    if (sizes.empty())
+        return;
+
     for (const auto & vec_index_desc : metadata_snapshot->vec_indices)
     {
         String index_name = vec_index_desc.name + "_" + vec_index_desc.column;
@@ -1199,6 +1210,70 @@ void IMergeTreeDataPart::loadVectorIndexMetadata() const
     }
 }
 
+void IMergeTreeDataPart::loadDecoupledVectorIndexMetadata() const
+{
+    auto metadata_snapshot = storage.getInMemoryMetadataPtr();
+    if (metadata_snapshot->vec_indices.empty())
+        return;
+
+    if (!volume->getDisk()->exists(getFullRelativePath() + "merged-inverted_row_ids_map" + VECTOR_INDEX_FILE_SUFFIX))
+        return;
+
+    /// Find source part names based on vector_index_ready.
+    std::vector<MergedPartNameAndId> old_part_names;
+    String ready_file_name = toString("vector_index_ready") + VECTOR_INDEX_FILE_SUFFIX;
+
+    auto disk = volume->getDisk();
+    for (auto it = disk->iterateDirectory(getFullRelativePath()); it->isValid(); it->next())
+    {
+        String file_name = it->name();
+
+        if (!endsWith(file_name, ready_file_name))
+            continue;
+
+        /// Found merged files, merged-0-<part name>-vector_index_ready.vidx
+        Strings tokens;
+        boost::algorithm::split(tokens, file_name, boost::is_any_of("-"));
+        if (tokens.size() != 4)
+        {
+            LOG_INFO(storage.log, "merged file name {} is invalid for decoupled part {}, will remove all merged files", file_name, name);
+            removeAllRowIdsMaps(true);
+            return;
+        }
+
+        old_part_names.emplace_back(tokens[2], std::stoi(tokens[1]));
+    }
+
+    /// Initilize the decoupled metadata
+    if (!old_part_names.empty())
+    {
+        std::lock_guard lock(decouple_mutex);
+        merged_source_parts = old_part_names;
+    }
+}
+
+void IMergeTreeDataPart::removeAllRowIdsMaps(const bool force) const
+{
+    /// We force to remove all row ids maps when incompleted files found.
+    if (!containRowIdsMaps() && !force)
+        return;
+
+    auto disk = volume->getDisk();
+    String path = getFullRelativePath();
+    for (auto it = disk->iterateDirectory(getFullRelativePath()); it->isValid(); it->next())
+    {
+        String file_name = it->name();
+
+        if (!endsWith(file_name, VECTOR_INDEX_FILE_SUFFIX) || !startsWith(file_name, "merged-"))
+            continue;
+
+        disk->removeFileIfExists(path + file_name);
+    }
+
+    std::lock_guard lock(decouple_mutex);
+    merged_source_parts.clear();
+}
+
 /// Project part / part with project parts / compact part doesn't support LWD.
 bool IMergeTreeDataPart::supportLightweightDeleteMutate() const
 {
@@ -1295,109 +1370,102 @@ void IMergeTreeDataPart::onLightweightDelete() const
     if (!supportLightweightDeleteMutate() || !hasLightweightDelete())
         return;
 
-    if (!containAnyVectorIndex())
+    auto metadata_snapshot = storage.getInMemoryMetadataPtr();
+    if (metadata_snapshot->vec_indices.empty() || !containAnyVectorIndex())
         return;
 
     std::optional<ColumnPtr> row_exists_column_opt = readRowExistsColumn();
     if (!row_exists_column_opt.has_value())
     {
-        LOG_ERROR(storage.log, "[onLightweightDelete] row_exists column is empty");
+        LOG_WARNING(storage.log, "[onLightweightDelete] row_exists column is empty in part {}", name);
         return;
     }
 
-    ColumnPtr row_exists_column_ptr = row_exists_column_opt.value();
-
-    const ColumnUInt8 * col = typeid_cast<const ColumnUInt8 *>(row_exists_column_ptr.get());
-    if (col == nullptr)
+    const ColumnUInt8 * row_exists_col = typeid_cast<const ColumnUInt8 *>(row_exists_column_opt.value().get());
+    if (row_exists_col == nullptr)
     {
-        LOG_ERROR(storage.log, "[onLightweightDelete] row_exists column type error");
+        LOG_WARNING(storage.log, "[onLightweightDelete] row_exists column type is not UInt8 in part {}", name);
         return;
     }
 
-    std::vector<Int64> del_ids; // update cache bitmap
+    std::vector<UInt64> del_row_ids; /// Store deleted row ids
 
-    const ColumnUInt8::Container & vec_in = col->getData();
-    for (size_t i = 0; i < vec_in.size(); ++i)
+    const ColumnUInt8::Container & vec_res = row_exists_col->getData();
+    for (size_t pos = 0; pos < vec_res.size(); pos++)
     {
-        const UInt8 re = vec_in[i];
-        if (re == 0)
-            del_ids.push_back(static_cast<Int64>(i));
+        if (!vec_res[pos])
+            del_row_ids.push_back(static_cast<UInt64>(pos));
     }
-    if (del_ids.empty())
+
+    if (del_row_ids.empty())
     {
-        LOG_DEBUG(storage.log, "[onLightweightDelete] the value of row exists column is all 1, nothing to do");
+        LOG_DEBUG(storage.log, "[onLightweightDelete] the value of row exists column is all 1, nothing to do in part {}", name);
         return;
     }
+    /// currently only consider one vector index
+    auto vec_index_desc = metadata_snapshot->vec_indices[0];
 
-    LOG_DEBUG(storage.log, "[onLightweightDelete] Printing the first 10 deleted ids");
-    for (size_t i = 0; i < 10 && i < del_ids.size(); ++i)
-        LOG_DEBUG(storage.log, "[onLightweightDelete] del_ids[{}] = {}", i, del_ids[i]);
+    VectorIndex::SegmentId segment_id(getFullPath(), name, name, vec_index_desc.name, vec_index_desc.column, 0);
+    VectorIndex::VectorSegmentExecutor vec_executor(segment_id);
 
-    VectorIndex::CacheManager * const mgr = VectorIndex::CacheManager::getInstance();
+    /// Update vector index deleted bitmap for the part on disk and cache if exists.
+    vec_executor.updateBitMap(del_row_ids);
+}
+
+void IMergeTreeDataPart::onDecoupledLightWeightDelete() const
+{
+    if (!supportLightweightDeleteMutate() || !hasLightweightDelete())
+        return;
 
-    std::list<std::pair<VectorIndex::CacheKey, VectorIndex::Parameters>> cache_items = mgr->getAllItems();
-    std::vector<VectorIndex::CacheKey> cache_keys;
+    /// Quick return if no vector index defined or no merged old parts' index files
+    auto metadata_snapshot = storage.getInMemoryMetadataPtr();
+    if (metadata_snapshot->vec_indices.empty() || !containRowIdsMaps())
+        return;
 
-    LOG_DEBUG(storage.log, "[onLightweightDelete] Printing all cache keys");
-    for (auto it = cache_items.begin(); it != cache_items.cend(); ++it)
+    /// Load _row_exists column
+    std::optional<ColumnPtr> row_exists_column_opt = readRowExistsColumn();
+    if (!row_exists_column_opt.has_value())
     {
-        LOG_DEBUG(storage.log, "[onLightweightDelete] {}", it->first.toString());
-        cache_keys.push_back(it->first);
+        LOG_WARNING(storage.log, "[onDecoupledLightweightDelete] row_exists column is empty in part {}", name);
+        return;
     }
 
-    std::filesystem::path fs_full_path(getFullPath());
-    const String table_path = fs_full_path.parent_path().parent_path().string();
-
-    bool delete_bitmap_found_in_cache = false;
-    for (size_t i = 0; i < cache_keys.size(); ++i)
+    const ColumnUInt8 * row_exists_col = typeid_cast<const ColumnUInt8 *>(row_exists_column_opt.value().get());
+    if (row_exists_col == nullptr)
     {
-        VectorIndex::CacheKey ck = cache_keys[i];
-
-        if (ck.table_path != table_path || VectorIndex::cutMutVer(ck.part_name) != VectorIndex::cutMutVer(name))
-            continue;
-
-        LOG_DEBUG(storage.log, "[onLightweightDelete] The matched key with current data part in cache = {}", ck.toString());
+        LOG_WARNING(storage.log, "[onDecoupledLightweightDelete] row_exists column type is not UInt8 in part {}", name);
+        return;
+    }
 
-        VectorIndex::IndexWithMetaPtr index_with_meta_ptr = mgr->get(ck);
-        if (index_with_meta_ptr == nullptr)
-            continue;
+    /// Collect deleted ids. Loop through _row_exists column to find row ids (position) with value 0.
+    std::vector<UInt64> new_del_ids;
 
-        delete_bitmap_found_in_cache = true;
+    const ColumnUInt8::Container & vec_res = row_exists_col->getData();
+    for (size_t pos = 0; pos < vec_res.size(); pos++)
+    {
+        if (!vec_res[pos])
+            new_del_ids.push_back(static_cast<UInt64>(pos));
+    }
 
-        if (auto delete_bitmap = index_with_meta_ptr->getDeleteBitmap())
-        {
-            for (size_t j = 0; j < del_ids.size(); ++j)
-            {
-                delete_bitmap->unset(del_ids[j]);
-            }
+    if (new_del_ids.empty())
+    {
+        LOG_DEBUG(storage.log, "[onDecoupledLightweightDelete] the value of row exists column is all 1, nothing to do in part {}", name);
+        return;
+    }
 
-            String delete_bitmap_path = getFullPath() + VECTOR_INDEX_BITMAP + VECTOR_INDEX_FILE_SUFFIX;
-            VectorIndex::VectorIndexUtil::writeDeleteBitmap(delete_bitmap_path, delete_bitmap);
+    /// currently only consider one vector index
+    auto vec_index_desc = metadata_snapshot->vec_indices[0];
 
-            break;
-        }
-        else
-        {
-            LOG_ERROR(storage.log, "[onLightweightDelete] The cache doesn't have delete_bitmap");
-        }
-    }
+    /// In decoupled part, need to map new delete row ids to old parts' row ids and update their delete bitmaps.
+    String data_path = getFullPath();
 
-    if (!delete_bitmap_found_in_cache)
+    const auto old_parts = getMergedSourceParts();
+    for (const auto & old_part : old_parts)
     {
-        const String delete_bitmap_path = getFullPath() + VECTOR_INDEX_BITMAP + VECTOR_INDEX_FILE_SUFFIX;
-        VectorIndex::GeneralBitMapPtr delete_bitmap = VectorIndex::VectorIndexUtil::readDeleteBitmap(delete_bitmap_path, row_exists_column_ptr->size());
-        if (delete_bitmap == nullptr)
-        {
-            LOG_DEBUG(storage.log, "[onLightweightDelete] read delete bitmap from disk failed");
-        }
-        else
-        {
-            for (size_t j = 0; j < del_ids.size(); ++j)
-            {
-                delete_bitmap->unset(del_ids[j]);
-            }
-            VectorIndex::VectorIndexUtil::writeDeleteBitmap(delete_bitmap_path, delete_bitmap);
-        }
+        VectorIndex::SegmentId segment_id(data_path, name, old_part.name, vec_index_desc.name, vec_index_desc.column, old_part.id);
+        VectorIndex::VectorSegmentExecutor vec_executor(segment_id);
+        /// Update merged deleted bitmap for the old part on disk and cache if exists.
+        vec_executor.updateMergedBitMap(new_del_ids);
     }
 }
 
diff --git a/src/Storages/MergeTree/IMergeTreeDataPart.h b/src/Storages/MergeTree/IMergeTreeDataPart.h
index e00f9d7b13..751f69f820 100644
--- a/src/Storages/MergeTree/IMergeTreeDataPart.h
+++ b/src/Storages/MergeTree/IMergeTreeDataPart.h
@@ -325,6 +325,20 @@ public:
     /// TODO: move vector index related structures out of data part class
     mutable std::set<String> vector_indexed;
 
+    /// Used for decouple part
+    mutable std::mutex decouple_mutex;
+
+    struct MergedPartNameAndId
+    {
+        String name;
+        int id;
+
+        MergedPartNameAndId(const String & name_, const int & id_) : name(name_), id(id_) {}
+    };
+
+    /// Source part names which were merged to this decouple part, used to locate their vector index files.
+    mutable std::vector<MergedPartNameAndId> merged_source_parts;
+
     mutable bool vector_index_build_error = false;
 
     mutable bool vector_index_tuned = false;
@@ -333,10 +347,14 @@ public:
 
     mutable bool small_part = false;
 
-    mutable bool lightweight_delete_mask_updated = false;
+    /// Used when vector index built is finished but the active part is under mutating.
+    /// Note: this is for StorageMergeTree engine only.
+    /// Move index files to active part OR new active part after mutation to pick up.
+    /// TODO: Remove when build vector index is handled by log entry for replciated MergeTree
+    mutable std::mutex vector_index_move_and_mutate_mutex;
+    mutable bool part_is_currently_mutating = false;
 
-    /// Used for vector index building and mutation. True if original source part doesn't have vindex when mutation starts.
-    mutable bool vector_index_in_origin_part = false;
+    mutable bool lightweight_delete_mask_updated = false;
 
     bool containAnyVectorIndex() const { return !vector_indexed.empty(); }
 
@@ -353,15 +371,43 @@ public:
 
     void cancelBuild() const {vector_index_build_cancelled = true;}
 
-    bool isSmallPart(size_t min_rows_to_build_vector_index) const { return this->rows_count < min_rows_to_build_vector_index; }
+    bool isSmallPart(size_t min_rows_to_build_vector_index) const
+    {
+        return this->rows_count == 0 || this->rows_count < min_rows_to_build_vector_index;
+    }
 
     void setDeletedMaskUpdate() const { lightweight_delete_mask_updated = true; }
 
-    void setOriginPartHasVectorIndex() const { vector_index_in_origin_part = true; }
+    bool getPartIsMutating() const
+    {
+        std::lock_guard lock(vector_index_move_and_mutate_mutex);
+        return part_is_currently_mutating;
+    }
 
-    /// Read vector_index_ready file to initialize vector_indxed
+    void setPartIsMutating(const bool & new_value) const
+    {
+        std::lock_guard lock(vector_index_move_and_mutate_mutex);
+        part_is_currently_mutating = new_value;
+    }
+
+    /// Read vector_index_ready file to initialize vector_indxed if exists.
+    /// Otherwise, try to read merged vector_index_ready file if exists.
     void loadVectorIndexMetadata() const;
 
+    bool containRowIdsMaps() const
+    {
+        std::lock_guard lock(decouple_mutex);
+        return !merged_source_parts.empty();
+    }
+
+    void removeAllRowIdsMaps(const bool force = false) const;
+
+    const std::vector<MergedPartNameAndId> getMergedSourceParts() const
+    {
+        std::lock_guard lock(decouple_mutex);
+        return merged_source_parts;
+    }
+
     /// Columns with values, that all have been zeroed by expired ttl
     NameSet expired_columns;
 
@@ -484,7 +530,10 @@ public:
     std::optional<ColumnPtr> readRowExistsColumn() const;
 
     /// when lightweight delete mutation complete, this function will be called.
-    virtual void onLightweightDelete() const;
+    void onLightweightDelete() const;
+
+    /// Decoupled part support lightweight delete
+    void onDecoupledLightWeightDelete() const;
 
 protected:
 
@@ -565,6 +614,12 @@ private:
     /// any specifial compression.
     void loadDefaultCompressionCodec();
 
+    /// Load simple single vector index metadata
+    void loadSimpleVectorIndexMetadata() const;
+
+    /// Load decoulped part with many old vector indecies
+    void loadDecoupledVectorIndexMetadata() const;
+
     /// Found column without specific compression and return codec
     /// for this column with default parameters.
     CompressionCodecPtr detectDefaultCompressionCodec() const;
diff --git a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp
index 578cdbeab3..f23f19bffe 100644
--- a/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp
+++ b/src/Storages/MergeTree/MergePlainMergeTreeTask.cpp
@@ -130,13 +130,23 @@ void MergePlainMergeTreeTask::finish()
     storage.merger_mutator.renameMergedTemporaryPart(new_part, future_part->parts, nullptr);
 
     /// Check latest metadata if vector index has been dropped.
-    if (new_part->storage.getInMemoryMetadataPtr()->vec_indices.empty() && (new_part->containAnyVectorIndex() || VectorIndex::containRowIdsMaps(new_part)))
+    if (new_part->storage.getInMemoryMetadataPtr()->vec_indices.empty())
     {
-        /// Pass empty string for index_name and column name, all vector index will be removed from this part.
-        String dummy_name;
-        new_part->removeVectorIndex(dummy_name, dummy_name);
+        if (new_part->containAnyVectorIndex())
+        {
+            /// Pass empty string for index_name and column name, all vector index will be removed from this part.
+            String dummy_name;
+            new_part->removeVectorIndex(dummy_name, dummy_name);
+
+            LOG_DEBUG(storage.log, "Remove vector index from part {} due to dropped in metadata", new_part->name);
+        }
+        else if (new_part->containRowIdsMaps())
+        {
+            new_part->removeAllRowIdsMaps(true);
+            LOG_DEBUG(storage.log, "Remove old parts' vector index from decouple part {} due to dropped in metadata", new_part->name);
+        }
 
-        /// Unable to get vector index name so wait to clear by backgound removeDroppedVectorIndices()
+        /// Unable to get vector index name so wait to be removed by backgound removeDroppedVectorIndices()
     }
 
     write_part_log({});
diff --git a/src/Storages/MergeTree/MergeTask.cpp b/src/Storages/MergeTree/MergeTask.cpp
index a9045aa2c4..a25e98943e 100644
--- a/src/Storages/MergeTree/MergeTask.cpp
+++ b/src/Storages/MergeTree/MergeTask.cpp
@@ -529,9 +529,9 @@ bool MergeTask::ExecuteAndFinalizeHorizontalPart::generateRowIdsMap()
 
     if (global_ctx->chosen_merge_algorithm == MergeAlgorithm::Horizontal)
     {
-        ctx->rows_sources_file.release();
-        ctx->rows_sources_write_buf.release();
-        ctx->rows_sources_uncompressed_write_buf.release();
+        ctx->rows_sources_file.reset();
+        ctx->rows_sources_write_buf.reset();
+        ctx->rows_sources_uncompressed_write_buf.reset();
     }
 
     for (int i = 0; i < global_ctx->future_part->parts.size(); ++i)
@@ -842,6 +842,9 @@ bool MergeTask::MergeProjectionsStage::finalizeProjectionsAndWholeMerge() const
 
         String inverted_row_sources_file_path = global_ctx->new_data_part->getFullPath() + "merged-inverted_row_sources_map" + VECTOR_INDEX_FILE_SUFFIX;
         std::filesystem::rename(global_ctx->inverted_row_sources_map_file_path, inverted_row_sources_file_path);
+
+        /// Initialize the vector index metadata for the new part
+        global_ctx->new_data_part->loadVectorIndexMetadata();
     }
 
     global_ctx->promise.set_value(global_ctx->new_data_part);
diff --git a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp
index f646b856e9..db703d4ff8 100644
--- a/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp
+++ b/src/Storages/MergeTree/MergeTreeBaseSelectProcessor.cpp
@@ -622,18 +622,6 @@ MergeTreeBaseSelectProcessor::BlockAndRowCount MergeTreeBaseSelectProcessor::rea
 
     LOG_DEBUG(log, "[readFromPartImpl] read time: {}", std::chrono::duration_cast<std::chrono::milliseconds>(read_end_time - read_start_time).count());
 
-    if (part_offset)
-    {
-        LOG_DEBUG(log, "[readFromPartImpl] offset values before vector search merge result, and the part name is {}", task->data_part->name);
-        const ColumnUInt64::Container & offset_raw_value = part_offset->getData();
-        const size_t the_size = part_offset->size();
-        for (size_t i = 0; i < the_size && i < 10; ++i)
-        {
-            UInt64 v = offset_raw_value[i];
-            LOG_DEBUG(log, "[readFromPartImpl] offset values --- offset[{}] = {}", i, v);
-        }
-    }
-
     /// [MQDB] vector search
     if (task->vector_scan_manager)
     {
diff --git a/src/Storages/MergeTree/MergeTreeData.cpp b/src/Storages/MergeTree/MergeTreeData.cpp
index c11497ca4f..a62146bbb3 100644
--- a/src/Storages/MergeTree/MergeTreeData.cpp
+++ b/src/Storages/MergeTree/MergeTreeData.cpp
@@ -1668,9 +1668,7 @@ void MergeTreeData::clearCachedVectorIndex(const DataPartsVector & parts)
 {
     StorageMetadataPtr meta_snapshot = getInMemoryMetadataPtr();
     if(meta_snapshot->getVectorIndices().empty())
-    {
         return;
-    }
 
 /// TODO: how to remove old parts' caches
     for (const auto & part : parts)
@@ -1679,9 +1677,7 @@ void MergeTreeData::clearCachedVectorIndex(const DataPartsVector & parts)
         {
             auto segment_ids = VectorIndex::getAllSegmentIds(part->getFullPath(), part, vec_index_desc.name, vec_index_desc.column);
             for (auto & segment_id : segment_ids)
-            {
                 VectorIndex::VectorSegmentExecutor::removeFromCache(segment_id.getCacheKey());
-            }
         }
     }
 }
@@ -1707,7 +1703,8 @@ void MergeTreeData::regularClearCachedIndex(const DataPartsVector & parts)
 
 void MergeTreeData::clearPartsFromFilesystem(const DataPartsVector & parts_to_remove)
 {
-    clearCachedVectorIndex(parts_to_remove);
+    /// The old part's vector index is reused by new part, no need to clear cache.
+    /// clearCachedVectorIndex(parts_to_remove);
     const auto settings = getSettings();
     if (parts_to_remove.size() > 1 && settings->max_part_removal_threads > 1 && parts_to_remove.size() > settings->concurrent_part_removal_threshold)
     {
@@ -2732,33 +2729,6 @@ bool MergeTreeData::renameTempPartAndReplace(
             ++reduce_parts;
         }
 
-        /// Before modify new part to active, check for vector index.
-        /// Copy the vector index files if exists in source part.
-        if (covered_parts.size() == 1 && covered_parts[0]->containAnyVectorIndex() &&
-            !part->vector_index_in_origin_part && !part->containAnyVectorIndex())
-        {
-            auto source_part = covered_parts[0];
-            auto disk = source_part->volume->getDisk();
-
-            /// Copy vector index files in source part to new part
-            bool vector_files_found = false;
-            for (auto it = disk->iterateDirectory(source_part->getFullRelativePath()); it->isValid(); it->next())
-            {
-                String file_name = it->name();
-                if (!endsWith(file_name, VECTOR_INDEX_FILE_SUFFIX))
-                    continue;
-
-                String destination = part->getFullRelativePath() + file_name;
-                if (!disk->exists(destination))
-                    disk->moveFile(it->path(), destination);
-
-                if (!vector_files_found)
-                    vector_files_found = true;
-            }
-            if (vector_files_found)
-                part->vector_indexed = source_part->vector_indexed;
-        }
-
         modifyPartState(part_it, DataPartState::Active);
         addPartContributionToColumnAndSecondaryIndexSizes(part);
 
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
index e281f98994..a36ca14d55 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.cpp
@@ -22,6 +22,9 @@ namespace ErrorCodes
     extern const int MEMORY_LIMIT_EXCEEDED;
 }
 
+/// minimum interval (seconds) between check if need to remove dropped vector index cache.
+static const auto RECHECK_VECTOR_INDDEX_CACHE_INTERVAL_SECONDS = 600;
+
 MergeTreeVectorIndexBuilderUpdater::MergeTreeVectorIndexBuilderUpdater(MergeTreeData & data_)
     : data(data_), log(&Poco::Logger::get(data.getLogName() + " (VectorIndexUpdater)"))
 {
@@ -29,23 +32,44 @@ MergeTreeVectorIndexBuilderUpdater::MergeTreeVectorIndexBuilderUpdater(MergeTree
 
 void MergeTreeVectorIndexBuilderUpdater::removeDroppedVectorIndices(const StorageMetadataPtr & metadata_snapshot)
 {
+    auto now = time(nullptr);
+    if (last_cache_check_time == 0)
+        last_cache_check_time = now;
+
+    /// we don't want to check vector index too frequent.
+    if (now - last_cache_check_time < RECHECK_VECTOR_INDDEX_CACHE_INTERVAL_SECONDS)
+        return;
+
     ///check existing parts to see if any cached vector index need cleaning
     std::list<std::pair<VectorIndex::CacheKey, VectorIndex::Parameters>> cached_item_list
         = VectorIndex::VectorSegmentExecutor::getAllCacheNames();
 
+    /// getRelativeDataPath() contains '/' in the tail, but table_path in cache key doesn't have.
+    std::string relative_data_path = fs::path(data.getRelativeDataPath()).parent_path().string();
     for (const auto & cache_item : cached_item_list)
     {
         bool existed = false;
-        /// LOG_DEBUG(log, "relative_path: {}", data.getRelativeDataPath());
+
         /// not this table
-        if (cache_item.first.table_path.find(data.getRelativeDataPath()) == std::string::npos)
-        {
+        if (cache_item.first.table_path.find(relative_data_path) == std::string::npos)
             continue;
-        }
-        for (const auto & vec_index_desc : metadata_snapshot->vec_indices)
+
+        const auto cache_key = cache_item.first;
+
+        /// Need to check part no matter exists or not exists.
+        MergeTreeDataPartPtr part = data.getActiveContainingPart(cache_item.first.part_name_no_mutation);
+
+        /// Check vector index in cache is same as metadata
+        if (!metadata_snapshot->vec_indices.empty())
         {
+            /// Currently only one vector index is allowed.
+            const auto & vec_index_desc = metadata_snapshot->vec_indices[0];
+
             LOG_DEBUG(log, "cache: {} {}, metadata: {} {}", cache_item.first.vector_index_name, cache_item.first.column_name, vec_index_desc.name, vec_index_desc.column);
-            if (cache_item.first.vector_index_name == vec_index_desc.name && cache_item.first.column_name == vec_index_desc.column)
+
+            /// Further check the part status, decouple part or VPart with single vector index
+            if (cache_item.first.vector_index_name == vec_index_desc.name && cache_item.first.column_name == vec_index_desc.column &&
+                (part && (part->containVectorIndex(cache_item.first.vector_index_name, cache_item.first.column_name) || part->containRowIdsMaps())))
             {
                 LOG_DEBUG(log, "Find Vector Index in metadata");
                 VectorIndex::Parameters params = cache_item.second;
@@ -69,15 +93,22 @@ void MergeTreeVectorIndexBuilderUpdater::removeDroppedVectorIndices(const Storag
 
         if (!existed)
         {
-            LOG_DEBUG(log, "Find not existed cache, remove it: {}", cache_item.first.toString());
-            VectorIndex::VectorSegmentExecutor::removeFromCache(cache_item.first);
+            LOG_DEBUG(log, "Find not existed cache, remove it: {}", cache_key.toString());
+            VectorIndex::VectorSegmentExecutor::removeFromCache(cache_key);
 
             /// Clear vector files in active part
-            MergeTreeDataPartPtr part = data.getActiveContainingPart(cache_item.first.part_name);
-            if (part && part.unique())
+            if (part)
             {
-                LOG_DEBUG(log, "Remove files of dropped vector index {} for part {}", cache_item.first.vector_index_name, part->name);
-                part->removeVectorIndex(cache_item.first.vector_index_name, cache_item.first.column_name);
+                if (part->containVectorIndex(cache_key.vector_index_name, cache_key.column_name))
+                {
+                    LOG_DEBUG(log, "Remove files of dropped vector index {} for part {}", cache_key.vector_index_name, part->name);
+                    part->removeVectorIndex(cache_key.vector_index_name, cache_key.column_name);
+                }
+                else if (part->containRowIdsMaps()) /// Decouple part
+                {
+                    LOG_DEBUG(log, "Remove old parts' vector index files {} for decouple part {}", cache_key.vector_index_name, part->name);
+                    part->removeAllRowIdsMaps();
+                }
             }
         }
     }
@@ -100,11 +131,16 @@ VectorIndexEntryPtr MergeTreeVectorIndexBuilderUpdater::selectPartsToBuildVector
     for (const auto & part : data.getDataParts())
     {
         /// LOG_DEBUG(log, "[selectPartsToBuildVectorIndex] part name: {}, count: {}", part->name, currently_vector_indexing_parts.count(part->name));
+
+        /// Skip empty part
+        if (part->isEmpty())
+            continue;
+
         /// need to check currently_vector_indexing_parts.count(part) > 0
         if (data.currently_vector_indexing_parts.count(part->name) > 0 || part->vector_index_build_error || currently_merging_mutating_parts.count(part) > 0)
             continue;
 
-        if (VectorIndex::containRowIdsMaps(part) && data.getSettings()->distable_rebuild_for_decouple)
+        if (part->containRowIdsMaps() && data.getSettings()->distable_rebuild_for_decouple)
             continue;
 
         /// Since building vector index doesn't block mutation on the part, the new part need to check if any covered part is building vindex.
@@ -414,8 +450,17 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                                 }
                             }
 
-                            if (future_part)
+                            if (future_part && !future_part->getPartIsMutating())
+                            {
                                 moveVectorIndexFilesToFuturePart(metadata_snapshot, vector_tmp_relative_path, future_part);
+
+                                if (future_part->containRowIdsMaps())
+                                {
+                                    auto lock = data.lockParts();
+                                    VectorIndex::removeRowIdsMaps(future_part);
+                                }
+                            }
+                            /// else future part will pick up later at the next time when index built for it.
                         }
 
                         return BuildVectorIndexStatus::SUCCESS;
@@ -590,6 +635,19 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
             }
             LOG_INFO(log, "[buildVectorIndex] index after read vectors: read vector num: {}", vec_data->getVectorNum());
         }
+
+        if (num_rows_read == 0 && part->rows_count == 0)
+        {
+            LOG_WARNING(log, "[buildVectorIndex] part {} is empty", part->name);
+            continue;
+        }
+        else if (num_rows_read < part->rows_count)
+        {
+            LOG_ERROR(log, "[buildVectorIndex] failed to build vector index for part {}", part->name);
+            disk->removeRecursive(vector_tmp_relative_path);
+            return BuildVectorIndexStatus::BUILD_FAIL;
+        }
+
         if (!part->vector_index_build_cancelled)
         {
             if (tune)
@@ -638,15 +696,27 @@ BuildVectorIndexStatus MergeTreeVectorIndexBuilderUpdater::buildVectorIndexForOn
                     return BuildVectorIndexStatus::SUCCESS;
                 }
 
+                /// First, move index files to part and apply lightweight delete.
                 moveVectorIndexFilesToFuturePart(metadata_snapshot, vector_tmp_relative_path, future_part);
 
+                /// Second, update delete bitmap in memory in currently builder, which will be put in cache.
                 /// Update segment id with correct part name and path.
                 VectorIndex::SegmentId segment_id(future_part->getFullPath(), future_part->name, future_part->name, vec_index_desc.name, vec_index_desc.column, 0);
                 vec_index_builder->updateSegmentId(segment_id);
 
+                /// Need to reload delete bitmap from disk. The delete_bitmap in vec_index_builder doesn't contain rows deleted by lightweight.
+                if (future_part->hasLightweightDelete())
+                    vec_index_builder->reloadDeleteBitMap();
+
                 LOG_INFO(log, "[buildVectorIndex] index cache: status: {}", seri_status.getCode());
                 vec_index_builder->cache();
                 LOG_INFO(log, "[buildVectorIndex] index after cache: status: {}", seri_status.getCode());
+
+                if (future_part->containRowIdsMaps())
+                {
+                    auto lock = data.lockParts();
+                    VectorIndex::removeRowIdsMaps(future_part);
+                }
             }
         }
     }
@@ -743,23 +813,12 @@ bool MergeTreeVectorIndexBuilderUpdater::moveVectorIndexFilesToFuturePart(const
 
     LOG_INFO(log, "[buildVectorIndex] move vector index files to part {}", dest_part->name);
 
-    if (VectorIndex::containRowIdsMaps(dest_part->getFullPath()))
-    {
-        auto lock = data.lockParts();
-        LOG_INFO(log, "[buildVectorIndex] try to remove row ids maps files in {}", dest_part->getFullPath());
-        /// currently only consider one vector index
-        auto vec_index_desc = metadata_snapshot->vec_indices[0];
-        auto old_segments = VectorIndex::getAllSegmentIds(dest_part->getFullPath(), dest_part, vec_index_desc.name, vec_index_desc.column);
-        for (auto& old_segment : old_segments)
-        {
-            VectorIndex::VectorSegmentExecutor::removeFromCache(old_segment.getCacheKey());
-        }
-        VectorIndex::removeAllRowIdsMaps(dest_part->getFullPath());
-    }
-
     /// Apply lightweight delete bitmap to index's bitmap
     if (dest_part->hasLightweightDelete())
+    {
+        LOG_DEBUG(log, "[buildVectorIndex] apply lightweight delete to vector index in part {}", dest_part->name);
         dest_part->onLightweightDelete();
+    }
 
     return true;
 }
diff --git a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h
index cbe579504b..796b87312f 100644
--- a/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h
+++ b/src/Storages/MergeTree/MergeTreeVectorIndexBuilderUpdater.h
@@ -74,9 +74,12 @@ private:
 
     Poco::Logger * log;
 
+    time_t last_cache_check_time = 0;
+
     BuildVectorIndexStatus
     buildVectorIndexForOnePart(const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part, bool tune, bool slow_mode);
 
+    /// Move build vector index files from temporary directory to data part directory, and apply lightweight delete if needed.
     bool moveVectorIndexFilesToFuturePart(const StorageMetadataPtr & metadata_snapshot, const  String & vector_tmp_relative_path, const MergeTreeDataPartPtr & dest_part);
 
     void undoBuildVectorIndexForOnePart(const StorageMetadataPtr & metadata_snapshot, const MergeTreeDataPartPtr & part);
@@ -84,7 +87,7 @@ private:
     bool isSlowModePart(const MergeTreeDataPartPtr & part)
     {
         /// Smaller part built with single vector index is also treated as slow mode.
-        return VectorIndex::containRowIdsMaps(part) || part->rows_count < data.getSettings()->max_rows_for_slow_mode_single_vector_index_build;
+        return part->containRowIdsMaps() || part->rows_count < data.getSettings()->max_rows_for_slow_mode_single_vector_index_build;
     }
 };
 
diff --git a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
index ddfd9dca28..99a1d0ce5d 100644
--- a/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
+++ b/src/Storages/MergeTree/MergeTreeVectorScanManager.cpp
@@ -238,10 +238,21 @@ VectorScanResultPtr MergeTreeVectorScanManager::vectorScan(
                 find_index = true;
                 index = v_index;
 
-                VectorIndex::SegmentId segment_id(data_path, data_part->name, data_part->name, index.name, index.column, 0);
-                segment_ids.emplace_back(std::move(segment_id));
+                /// For decouple part, background index build will mark the data part's metadata before put it in cache.
+                /// Hence use the old segments first to avoid load vector index.
+                if (data_part->containRowIdsMaps())
+                {
+                    segment_ids = VectorIndex::getAllSegmentIds(data_path, data_part, v_index.name, v_index.column);
+                    LOG_DEBUG(log, "[vectorScan] index found for decouple part, use old parts' index first when both exist in metadata.");
+                }
+                else
+                {
+                    VectorIndex::SegmentId segment_id(data_path, data_part->name, data_part->name, index.name, index.column, 0);
+                    segment_ids.emplace_back(std::move(segment_id));
+
+                    LOG_DEBUG(log, "[vectorScan] index found, because current data part contains it");
+                }
 
-                LOG_DEBUG(log, "[vectorScan] index found, because current data part contains it");
                 break;
             }
             else
@@ -1227,7 +1238,12 @@ void MergeTreeVectorScanManager::searchWrapper(
             int tmp_curr_pos = 0;
             while (curr_pos < k && tmp_curr_pos < k + delete_id_num)
             {
-                if (row_exists->test(tmp_per_id[i * (k + delete_id_num) + tmp_curr_pos] + num_rows_read))
+                auto & tmp_id = tmp_per_id[i * (k + delete_id_num) + tmp_curr_pos];
+                if (tmp_id < 0)
+                {
+                    LOG_ERROR(log, "tmp_id: {}, num_rows_read: {}", tmp_id, num_rows_read);
+                }
+                else if (tmp_id >= 0 && row_exists->test(tmp_id + num_rows_read))
                 {
                     per_id[i * k + curr_pos] = tmp_per_id[i * (k + delete_id_num) + tmp_curr_pos];
                     per_distance[i * k + curr_pos] = tmp_per_distance[i * (k + delete_id_num) + tmp_curr_pos];
diff --git a/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp b/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp
index 4a22c5505d..77e1159709 100644
--- a/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp
+++ b/src/Storages/MergeTree/MutatePlainMergeTreeTask.cpp
@@ -86,24 +86,16 @@ bool MutatePlainMergeTreeTask::executeStep()
                 storage.updateMutationEntriesErrors(future_part, true, "");
                 write_part_log({});
 
+                /// Safe here, the source part status is Outdated, vector index move cannot find it.
+                future_part->parts[0]->setPartIsMutating(false);
+
                 /// Update vector index bitmap after mutations with lightweight delete.
-                if (new_part->containAnyVectorIndex())
+                if (new_part->lightweight_delete_mask_updated)
                 {
-                    if (VectorIndex::containRowIdsMaps(new_part->getFullPath()))
-                    {
-                        LOG_INFO(storage.log, "try to remove row ids maps files in {}", new_part->getFullPath());
-                        /// currently only consider one vector index
-                        auto vec_index_desc = metadata_snapshot->vec_indices[0];
-                        auto old_segments = VectorIndex::getAllSegmentIds(new_part->getFullPath(), new_part, vec_index_desc.name, vec_index_desc.column);
-                        for (auto& old_segment : old_segments)
-                        {
-                            VectorIndex::VectorSegmentExecutor::removeFromCache(old_segment.getCacheKey());
-                        }
-                        VectorIndex::removeAllRowIdsMaps(new_part->getFullPath());
-                    }
-
-                   if (new_part->lightweight_delete_mask_updated)
+                   if (new_part->containAnyVectorIndex())
                        new_part->onLightweightDelete();
+                   else if (new_part->containRowIdsMaps()) /// decoupled part with merged vector index support lightweight delete
+                       new_part->onDecoupledLightWeightDelete();
                 }
 
                 state = State::NEED_FINISH;
diff --git a/src/Storages/MergeTree/MutateTask.cpp b/src/Storages/MergeTree/MutateTask.cpp
index ad8133e820..68abea628a 100644
--- a/src/Storages/MergeTree/MutateTask.cpp
+++ b/src/Storages/MergeTree/MutateTask.cpp
@@ -473,32 +473,9 @@ void finalizeMutatedPart(
     new_data_part->calculateColumnsAndSecondaryIndicesSizesOnDisk();
     new_data_part->storage.lockSharedData(*new_data_part);
 
-    if (new_data_part->vector_index_in_origin_part)
-        new_data_part->vector_indexed = source_part->vector_indexed;
-    else if (source_part->containAnyVectorIndex()) /// origin part doesn't have vector index before create hardlink.
-    {
-        bool vector_files_found = false;
-        /// The vector index is built and copy to source part during mutation.
-        for (auto it = disk->iterateDirectory(source_part->getFullRelativePath()); it->isValid(); it->next())
-        {
-            String file_name = it->name();
-            if (!endsWith(file_name, VECTOR_INDEX_FILE_SUFFIX))
-                continue;
-
-            String destination = new_data_part->getFullRelativePath() + file_name;
-            if (!disk->exists(destination))
-                disk->createHardLink(it->path(), destination);
-
-            if (!vector_files_found)
-                vector_files_found = true;
-        }
-
-        if (vector_files_found)
-        {
-            new_data_part->vector_indexed = source_part->vector_indexed;
-            new_data_part->setOriginPartHasVectorIndex();
-        }
-    }
+    ///Origin part is decoupled with merged vector indices or has simple built vector index
+    if (source_part->containRowIdsMaps() || source_part->containAnyVectorIndex())
+        new_data_part->loadVectorIndexMetadata();
 }
 
 }
@@ -1008,8 +985,8 @@ private:
         static_pointer_cast<MergedBlockOutputStream>(ctx->out)->finalizePart(ctx->new_data_part, ctx->need_sync);
         ctx->out.reset();
 
-        /// Create hardlinks for vector index files
-        if (ctx->source_part->containAnyVectorIndex())
+        /// Create hardlinks for vector index files in simple built part or decoupled part when MutateAllPartColumns
+        if (ctx->source_part->containAnyVectorIndex() || ctx->source_part->containRowIdsMaps())
         {
             bool vector_files_found = false;
             for (auto it = ctx->disk->iterateDirectory(ctx->source_part->getFullRelativePath()); it->isValid(); it->next())
@@ -1022,11 +999,9 @@ private:
                 vector_files_found = true;
             }
 
+            /// TODO: build index marks the ector_indexed in some unsuccessful cases. If fixed, vector_files_found can be removed.
             if (vector_files_found)
-            {
-                ctx->new_data_part->vector_indexed = ctx->source_part->vector_indexed;
-                ctx->new_data_part->setOriginPartHasVectorIndex();
-            }
+                ctx->new_data_part->loadVectorIndexMetadata();
         }
     }
 
@@ -1098,9 +1073,6 @@ private:
 
         ctx->disk->createDirectories(ctx->new_part_tmp_path);
 
-        if (ctx->source_part->containAnyVectorIndex())
-            ctx->new_data_part->setOriginPartHasVectorIndex();
-
         /// Create hardlinks for unchanged files
         for (auto it = ctx->disk->iterateDirectory(ctx->source_part->getFullRelativePath()); it->isValid(); it->next())
         {
@@ -1291,6 +1263,10 @@ bool MutateTask::prepare()
 
     ctx->num_mutations = std::make_unique<CurrentMetrics::Increment>(CurrentMetrics::PartMutation);
     ctx->source_part = ctx->future_part->parts[0];
+
+    /// Used for vector index move and mutating confict
+    ctx->source_part->setPartIsMutating(true);
+
     auto storage_from_source_part = StorageFromMergeTreeDataPart::create(ctx->source_part);
 
     auto context_for_reading = Context::createCopy(ctx->context);
@@ -1373,17 +1349,14 @@ bool MutateTask::prepare()
 
     /// Check if lightweight delete mask column is updated.
     /// If true, mark lightweight delete mask updated to true. Will trigger vector index bitmap update.
+    /// Support part with simple built index and decoupled part with merged old parts' built index files
     /// TODO: Should not use vector index when any normal delete command exists.
-    if (ctx->source_part->containAnyVectorIndex())
+    for (const auto & name_type : ctx->updated_header.getNamesAndTypesList())
     {
-        ctx->new_data_part->setOriginPartHasVectorIndex();
-        for (const auto & name_type : ctx->updated_header.getNamesAndTypesList())
+        if (name_type.name == LightweightDeleteDescription::FILTER_COLUMN.name)
         {
-            if (name_type.name == LightweightDeleteDescription::FILTER_COLUMN.name)
-            {
-                ctx->new_data_part->setDeletedMaskUpdate();
-                break;
-            }
+            ctx->new_data_part->setDeletedMaskUpdate();
+            break;
         }
     }
 
diff --git a/src/Storages/MergeTree/VectorIndexMergeTreeTask.h b/src/Storages/MergeTree/VectorIndexMergeTreeTask.h
index 39b5fa7616..a3cc9bec37 100644
--- a/src/Storages/MergeTree/VectorIndexMergeTreeTask.h
+++ b/src/Storages/MergeTree/VectorIndexMergeTreeTask.h
@@ -29,30 +29,14 @@ public:
         MergeTreeVectorIndexBuilderUpdater & builder_,
         Callback && task_result_callback_, 
         bool slow_mode_)
-        : storage(storage_) // MergeTreeData's base class is IStorage.
-                            // in IStorage, 'operator=' is explicitly marked deleted.
-                            // it cannot be assigned
-        //, metadata_snapshot(std::move(metadata_snapshot_))
-        //, vector_index_entry(std::move(vector_index_entry_))
+        : storage(storage_)
+        , metadata_snapshot(std::move(metadata_snapshot_))
+        , vector_index_entry(std::move(vector_index_entry_))
         , builder(builder_)
+        , task_result_callback(std::forward<Callback>(task_result_callback_))
         , slow_mode(slow_mode_)
-        //, task_result_callback(std::forward<Callback>(task_result_callback_))
     {
-        Poco::Logger * const log = &Poco::Logger::get("VectorIndexMergeTreeTask");
-
-        LOG_INFO(log, "[VectorIndexMergeTreeTask] start to initialize VectorIndexMergeTreeTask");
-
-        if (!metadata_snapshot_)
-            LOG_INFO(log, "[VectorIndexMergeTreeTask] metadata_snapshot_ is NIL");
-        metadata_snapshot = std::move(metadata_snapshot_);
-
-        if (!vector_index_entry_)
-            LOG_INFO(log, "[VectorIndexMergeTreeTask] vector_index_entry_ is NIL");
-
-        vector_index_entry = std::move(vector_index_entry_);
-        task_result_callback = std::forward<Callback>(task_result_callback_);
-
-        LOG_INFO(log, "create VectorIndexMergeTreeTask");
+        LOG_INFO(&Poco::Logger::get("VectorIndexMergeTreeTask"), "create VectorIndexMergeTreeTask, slow mode: {}", slow_mode);
     }
 
     bool executeStep() override;
diff --git a/src/Storages/StorageMergeTree.cpp b/src/Storages/StorageMergeTree.cpp
index f417601d3b..bc7ba4ff8f 100644
--- a/src/Storages/StorageMergeTree.cpp
+++ b/src/Storages/StorageMergeTree.cpp
@@ -188,6 +188,9 @@ void StorageMergeTree::shutdown()
 
         /// Temporary directories contain incomplete results of vector index building.
         clearTemporaryIndexBuildDirectories();
+
+        /// Clear cached vector index
+        clearCachedVectorIndex(getDataPartsVector());
     }
     catch (...)
     {
@@ -799,7 +802,7 @@ std::shared_ptr<MergeMutateSelectedEntry> StorageMergeTree::selectPartsToMerge(
         return !currently_merging_mutating_parts.count(left) && !currently_merging_mutating_parts.count(right)
             && getCurrentMutationVersion(left, lock) == getCurrentMutationVersion(right, lock) && partsContainSameProjections(left, right)
             && !currently_vector_indexing_parts.count(left->name) && !currently_vector_indexing_parts.count(right->name)
-            && !VectorIndex::containRowIdsMaps(left) && !VectorIndex::containRowIdsMaps(right)
+            && !left->containRowIdsMaps() && !right->containRowIdsMaps()
             && canMergeForVectorIndex(metadata_snapshot, left, right);
     };
 
@@ -1098,8 +1101,6 @@ void StorageMergeTree::finishVectorIndexJob(const std::vector<String>& processed
 
 bool StorageMergeTree::scheduleDataProcessingJob(BackgroundJobsAssignee & assignee) //-V657
 {
-    Poco::Logger * const log = &Poco::Logger::get("StorageMergeTree");
-
     if (shutdown_called)
         return false;
 
@@ -1157,53 +1158,15 @@ bool StorageMergeTree::scheduleDataProcessingJob(BackgroundJobsAssignee & assign
     }
     if (vector_index_entry)
     {
-        /// std::unique_lock lock(currently_processing_in_background_mutex);
-        {
-            for (auto & part_name : vector_index_entry->data_part_names)
-            {
-                LOG_DEBUG(log, "[scheduleDataProcessingJob] has part name {}", part_name);
-            }
-        }
-
-        LOG_INFO(log, "[scheduleDataProcessingJob] before calling constructor of VectorIndexMergeTreeTask");
-
         std::shared_ptr<VectorIndexMergeTreeTask> task = std::make_shared<VectorIndexMergeTreeTask>(
             *this, metadata_snapshot, vector_index_entry, vec_index_builder_updater, common_assignee_trigger, false);
-        if (task)
-        {
-            LOG_DEBUG(log, "[scheduleDataProcessingJob] task has been created");
-        }
-        else
-        {
-            LOG_ERROR(log, "[scheduleDataProcessingJob] create task failed");
-            return false;
-        }
         assignee.scheduleVectorIndexTask(task);
         return true;
     }
     if (slow_mode_vector_index_entry)
     {
-        /// std::unique_lock lock(currently_processing_in_background_mutex);
-        {
-            for (auto & part_name : slow_mode_vector_index_entry->data_part_names)
-            {
-                LOG_INFO(log, "[scheduleDataProcessingJob] slow mode build task has part name {}", part_name);
-            }
-        }
-
-        LOG_INFO(log, "[scheduleDataProcessingJob] before calling constructor of VectorIndexMergeTreeTask");
-
         std::shared_ptr<VectorIndexMergeTreeTask> task = std::make_shared<VectorIndexMergeTreeTask>(
             *this, metadata_snapshot, slow_mode_vector_index_entry, vec_index_builder_updater, common_assignee_trigger, true);
-        if (task)
-        {
-            LOG_DEBUG(log, "[scheduleDataProcessingJob] task has been created");
-        }
-        else
-        {
-            LOG_ERROR(log, "[scheduleDataProcessingJob] create task failed");
-            return false;
-        }
         assignee.scheduleSlowModeVectorIndexTask(task);
         return true;
     }
diff --git a/src/VectorIndex/CacheManager.cpp b/src/VectorIndex/CacheManager.cpp
index b6e7fb0bf6..43577a5705 100644
--- a/src/VectorIndex/CacheManager.cpp
+++ b/src/VectorIndex/CacheManager.cpp
@@ -11,7 +11,7 @@ extern const int LOGICAL_ERROR;
 namespace VectorIndex
 {
 
-CacheManager::CacheManager(int)
+CacheManager::CacheManager(int): log(&Poco::Logger::get("CacheManager"))
 {
     while (!m)
     {
@@ -51,6 +51,7 @@ void CacheManager::put(const CacheKey& cache_key, IndexWithMetaPtr index)
     {
         throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "cache not allocated");
     }
+    LOG_INFO(log, "VectorIndexCache put cache_key={}", cache_key.toString());
 
     IndexAndMutexPtr iam_ptr = std::make_shared<IndexAndMutex>(index, nullptr);
 
@@ -64,6 +65,7 @@ size_t CacheManager::countItem() const
 
 void CacheManager::forceExpire(const CacheKey& cache_key)
 {
+    LOG_INFO(log, "VectorIndexCache forceExpire cache_key={}", cache_key.toString());
     return cache_->remove(cache_key);
 }
 
@@ -73,6 +75,7 @@ void CacheManager::startLoading(const CacheKey& cache_key)
     {
         throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "startLoading: cache not allocated");
     }
+    LOG_INFO(log, "VectorIndexCache startLoading cache_key={}", cache_key.toString());
     std::shared_ptr<std::mutex> new_mutex = std::make_shared<std::mutex>();
 
     std::shared_ptr<IndexAndMutex> im_ptr = std::make_shared<IndexAndMutex>(nullptr, new_mutex);
diff --git a/src/VectorIndex/CacheManager.h b/src/VectorIndex/CacheManager.h
index 922ee8f458..cb97285a9e 100644
--- a/src/VectorIndex/CacheManager.h
+++ b/src/VectorIndex/CacheManager.h
@@ -98,6 +98,8 @@ public:
 
 protected:
     mutable std::unique_ptr<VectorIndexCache> cache_;
+    Poco::Logger *log;
+
 };
 
 }
diff --git a/src/VectorIndex/FaissIndex.cpp b/src/VectorIndex/FaissIndex.cpp
index 19a4ad2dc4..63e705b384 100644
--- a/src/VectorIndex/FaissIndex.cpp
+++ b/src/VectorIndex/FaissIndex.cpp
@@ -53,10 +53,9 @@ void FaissIndex::load(BinaryPtr & bi, int64_t /*total_vec*/)
 }
 
 void * FaissIndex::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-///handle this pointer carefully! remember to deconstruct it somewhere
 {
-    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size());
-    new_map->bitmap = outerBitMap->bitmap;
+    /// handle this pointer carefully! remember to deconstruct it somewhere
+    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
     return new_map;
 }
 
diff --git a/src/VectorIndex/GeneralBitMap.h b/src/VectorIndex/GeneralBitMap.h
index 1e96f1b02a..38f64ee5da 100644
--- a/src/VectorIndex/GeneralBitMap.h
+++ b/src/VectorIndex/GeneralBitMap.h
@@ -7,16 +7,16 @@ namespace VectorIndex
 {
 class GeneralBitMap
 {
-    ///the General form of bitmap which will be used by Clickhouse,
-    ///since any user-defined index form may have its own bitmap format,
-    ///the user shall define the convertInnerBitMap
-    /// the bitmap marks available items as 1, unavailable items as 0.
+    /// The General form of bitmap which will be used by Clickhouse,
+    /// since any user-defined index form may have its own bitmap format,
+    /// the user shall define the convertInnerBitMap.
+    /// The bitmap marks available items as 1, unavailable items as 0.
 public:
     GeneralBitMap() = default;
 
-    explicit GeneralBitMap(int64_t sizeO)
+    explicit GeneralBitMap(int64_t size_)
     {
-        size = sizeO;
+        size = size_;
         int bytes_count = (size >> 3) + 1; // size/8 = bytes
         bitmap = new char[bytes_count];
         memset(bitmap, 0, bytes_count);
@@ -24,13 +24,9 @@ public:
 
     int32_t get_size() { return size; }
 
-    //    void setBitMap(char* setting){
-    //        bitmap=setting;
-    //    }
-
     bool test(int32_t id)
     {
-        //TODO should we verify id <=size ?
+        // TODO should we verify id <=size ?
         return (bitmap[id >> 3] & (0x1 << (id & 0x7)));
     }
 
@@ -38,8 +34,8 @@ public:
 
     void unset(int64_t id) { bitmap[id >> 3] &= ~(0x1 << (id & 0x7)); }
 
-    ///set bit corresponding to a region, this is much faster than set(),
-    ///but can introduce up to 14 items been wrongly set at the margins.
+    /// Set bit corresponding to a region, this is much faster than set(),
+    /// but can introduce up to 14 items been wrongly set at the margins.
     void set_range(int64_t start_id, int64_t end_id)
     {
         int64_t range = (end_id - start_id) / 8 + 1;
@@ -47,9 +43,9 @@ public:
         memset(bitmap + start_byte, 255, range);
     }
 
-    ///There are two inner bitmap in faiss and hnsw, they mimic this
-    ///structure but don't free that char* at deallocation; rather, it's freed by this
-    ///bitmap at the outer layer.
+    /// There are two inner bitmap in faiss and hnsw, they mimic this
+    /// structure but don't free that char* at deallocation; rather, it's freed by this
+    /// bitmap at the outer layer.
     ~GeneralBitMap()
     {
         if (bitmap)
diff --git a/src/VectorIndex/HNSWIndex.cpp b/src/VectorIndex/HNSWIndex.cpp
index ecfbcaff8b..ec4e42e314 100644
--- a/src/VectorIndex/HNSWIndex.cpp
+++ b/src/VectorIndex/HNSWIndex.cpp
@@ -158,8 +158,8 @@ void HNSWIndex::load(BinaryPtr & bi, int64_t total_vec)
 
 void * HNSWIndex::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
 {
-    hnswlib::bitMap * new_map = new hnswlib::bitMap(outerBitMap->get_size());
-    new_map->bitmap = outerBitMap->bitmap; //TODO possibility of mem leak
+    /// handle this pointer carefully! remember to deconstruct it somewhere
+    hnswlib::bitMap * new_map = new hnswlib::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
     return new_map;
 }
 
diff --git a/src/VectorIndex/HNSWPQ.cpp b/src/VectorIndex/HNSWPQ.cpp
index 9cc4814883..900f9934af 100644
--- a/src/VectorIndex/HNSWPQ.cpp
+++ b/src/VectorIndex/HNSWPQ.cpp
@@ -130,10 +130,9 @@ void HNSWpq::load(BinaryPtr & bi, int64_t /*total_vec*/)
 }
 
 void * HNSWpq::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-///handle this pointer carefully! remember to deconstruct it somewhere
 {
-    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size());
-    new_map->bitmap = outerBitMap->bitmap;
+    /// handle this pointer carefully! remember to deconstruct it somewhere
+    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
     return new_map;
 }
 
diff --git a/src/VectorIndex/HNSWSQ.cpp b/src/VectorIndex/HNSWSQ.cpp
index ffa0a9e261..96000e68b8 100644
--- a/src/VectorIndex/HNSWSQ.cpp
+++ b/src/VectorIndex/HNSWSQ.cpp
@@ -121,22 +121,17 @@ void HNSWsq::load(BinaryPtr & bi, int64_t /*total_vec*/)
     {
         throw IndexException(DB::ErrorCodes::EMPTY_DATA_PASSED, "load: failed with empty data");
     }
-    setRawData(bi);
     IndexReader reader;
     reader.data = bi->data;
     reader.total = bi->size;
 
     index.reset(reinterpret_cast<faiss::IndexHNSWfastSQ *>(faiss::read_index(&reader)));
-    //index->init_hnsw();
-    //reinterpret_cast might seem fishy, but when they returned from read_index they initially
-    // created a child class then cast it to Index.
 }
 
 void * HNSWsq::convertInnerBitMap(GeneralBitMapPtr outerBitMap)
-///handle this pointer carefully! remember to deconstruct it somewhere
 {
-    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size());
-    new_map->bitmap = outerBitMap->bitmap;
+    /// handle this pointer carefully! remember to deconstruct it somewhere
+    faiss::bitMap * new_map = new faiss::bitMap(outerBitMap->get_size(), outerBitMap->bitmap);
     return new_map;
 }
 
diff --git a/src/VectorIndex/MergeUtils.h b/src/VectorIndex/MergeUtils.h
index f65a9728ee..4da7901614 100644
--- a/src/VectorIndex/MergeUtils.h
+++ b/src/VectorIndex/MergeUtils.h
@@ -5,6 +5,7 @@
 #include <boost/algorithm/string.hpp>
 #include <Disks/IDisk.h>
 #include <Storages/MergeTree/MergeTreeData.h>
+#include <Storages/MergeTree/IMergeTreeDataPart.h>
 #include <VectorIndex/VectorIndexCommon.h>
 #include <VectorIndex/SegmentId.h>
 
@@ -15,7 +16,7 @@ namespace VectorIndex
 
 /// used to rename and move vector indices files of one old data part
 /// to new data part's path
-static inline void renameVectorIndexFiles(const String& part_id, const String& part_name, const String& old_path, const String& new_path)
+static inline void renameVectorIndexFiles(const String & part_id, const String & part_name, const String & old_path, const String & new_path)
 {
     /// first get all vector indices related files
     String ext(VECTOR_INDEX_FILE_SUFFIX);
@@ -36,60 +37,60 @@ static std::vector<SegmentId> getAllSegmentIds(const String & data_path, const D
     if (!data_part)
         return segment_ids;
 
+    /// TODO: Should we add a new function getAllOldSegementIds() to get list of old parts, no matter there is built vector index or not.
     /// decide whether we have merged old data parts index files
-    for (auto &p : fs::recursive_directory_iterator(data_path))
+    if (data_part->containRowIdsMaps())
     {
-        if (p.path().filename().string().find("row_ids_map") != std::string::npos 
-            && p.path().filename().string().find("inverted_row_ids_map") == std::string::npos)
-        {
-            /// found merged files
-            std::vector<String> strs;
-            boost::algorithm::split(strs, p.path().filename().string(), boost::is_any_of("-"));
+        auto log = &Poco::Logger::get("getAllSegmentIds");
+        auto old_parts = data_part->getMergedSourceParts();
 
-            LOG_DEBUG(&Poco::Logger::get("getAllSegmentIds"), "segments: {} {}", strs[0], strs[1]);
+        for (const auto & old_part : old_parts)
+        {
+            LOG_DEBUG(log, "segments: merged-{}-{}", old_part.id, old_part.name);
 
-            SegmentId segment_id(data_path, data_part->name, strs[2], index_name, index_column, std::stoi(strs[1]));
+            SegmentId segment_id(data_path, data_part->name, old_part.name, index_name, index_column, old_part.id);
             segment_ids.emplace_back(std::move(segment_id));
         }
     }
-    if (segment_ids.empty())
+
+    /// If no merged old parts' index files, decide whether we have simple built vector index.
+    if (segment_ids.empty() && data_part->containVectorIndex(index_name, index_column))
     {
         SegmentId segment_id(data_path, data_part->name, data_part->name, index_name, index_column, 0);
         segment_ids.emplace_back(std::move(segment_id));
     }
-    return segment_ids;
-}
 
-static bool containRowIdsMaps(const String& data_path)
-{
-    for (auto &p : fs::recursive_directory_iterator(data_path))
-    {
-        if (p.path().filename().string().find("inverted_row_ids_map") != std::string::npos)
-        {
-            return true;
-        }
-    }
-    return false;
+    return segment_ids;
 }
 
-static bool containRowIdsMaps(const std::shared_ptr<const DB::IMergeTreeDataPart>& part)
+static bool containRowIdsMaps(const String & data_path)
 {
-    /// Skip to check disk for in-memory part
-    if (!part->isStoredOnDisk())
-        return false;
+    fs::path path = fs::path(data_path) / (DB::toString("merged-inverted_row_ids_map") + VECTOR_INDEX_FILE_SUFFIX);
+    if (fs::exists(path))
+        return true;
     else
-       return containRowIdsMaps(part->getFullPath());
+        return false;
 }
 
-static void removeAllRowIdsMaps(const String& data_path)
+/// Remove old parts' vector index from cache manager and data part.
+static void removeRowIdsMaps(const DB::MergeTreeDataPartPtr & data_part)
 {
-    for (auto &p : fs::recursive_directory_iterator(data_path))
+    if (!data_part || !data_part->isStoredOnDisk() || !data_part->containRowIdsMaps())
+        return;
+
+    LOG_INFO(&Poco::Logger::get("removeRowIdsMaps"), "try to remove row ids maps files in {}", data_part->getFullPath());
+    /// currently only consider one vector index
+    auto metadata_snapshot = data_part->storage.getInMemoryMetadataPtr();
+    auto vec_index_desc = metadata_snapshot->vec_indices[0];
+
+    auto old_segments = getAllSegmentIds(data_part->getFullPath(), data_part, vec_index_desc.name, vec_index_desc.column);
+    for (auto & old_segment : old_segments)
     {
-        if (p.path().filename().string().starts_with("merged-"))
-        {
-            fs::remove(p.path());
-        }
+        VectorSegmentExecutor::removeFromCache(old_segment.getCacheKey());
     }
+
+    /// Remove files and erase the metadata of row ids maps from data part.
+    data_part->removeAllRowIdsMaps();
 }
 
 }
diff --git a/src/VectorIndex/SegmentId.h b/src/VectorIndex/SegmentId.h
index 07d7f994cd..b8a3da5df4 100644
--- a/src/VectorIndex/SegmentId.h
+++ b/src/VectorIndex/SegmentId.h
@@ -15,20 +15,20 @@ String cutMutVer(const String & part_name);
 struct CacheKey
 {
     String table_path;
-    String part_name;
+    String part_name_no_mutation; /// part_name doesn't include mutation version
     String vector_index_name;
     String column_name;
 
     bool operator==(const CacheKey& other) const {
         return (table_path == other.table_path)
-        && (cutMutVer(part_name) == cutMutVer(other.part_name))
+        && (part_name_no_mutation == other.part_name_no_mutation)
         && (vector_index_name == other.vector_index_name)
         && (column_name == other.column_name);
     }
 
     String toString() const
     {
-        return table_path + "/" + cutMutVer(part_name) + "/" + vector_index_name + "_" + column_name;
+        return table_path + "/" + part_name_no_mutation + "/" + vector_index_name + "_" + column_name;
     }
 };
 
@@ -80,7 +80,7 @@ struct SegmentId
         fs::path full_path(data_part_path);
         /// use parent data path, need to call parent_path() twice, 
         /// according to https://en.cppreference.com/w/cpp/filesystem/path/parent_path
-        return CacheKey{full_path.parent_path().parent_path().string(), owner_part_name, vector_index_name, column_name};
+        return CacheKey{full_path.parent_path().parent_path().string(), cutMutVer(owner_part_name), vector_index_name, column_name};
     }
 
     String getVectorReadyFilePath() const
diff --git a/src/VectorIndex/VectorSegmentExecutor.cpp b/src/VectorIndex/VectorSegmentExecutor.cpp
index 84eae58a74..c0ca9dab65 100644
--- a/src/VectorIndex/VectorSegmentExecutor.cpp
+++ b/src/VectorIndex/VectorSegmentExecutor.cpp
@@ -2,30 +2,32 @@
 #include <random>
 #include <thread>
 #include <omp.h>
+#include <boost/algorithm/string/split.hpp>
 
-#include <Common/HashTable/HashMap.h>
-#include <Common/Exception.h>
 #include <Compression/CompressedReadBuffer.h>
-#include <Compression/CompressedWriteBuffer.h>
 #include <Compression/CompressedReadBufferFromFile.h>
-#include <Interpreters/OpenTelemetrySpanLog.h>
+#include <Compression/CompressedWriteBuffer.h>
+#include <IO/BufferWithOwnMemory.h>
 #include <IO/ReadBufferFromFile.h>
 #include <IO/WriteHelpers.h>
+#include <Interpreters/OpenTelemetrySpanLog.h>
 #include <VectorIndex/BruteForceSearch.h>
 #include <VectorIndex/CacheManager.h>
 #include <VectorIndex/DiskIOReader.h>
 #include <VectorIndex/DiskIOWriter.h>
 #include <VectorIndex/IndexException.h>
-#include <VectorIndex/VectorIndexFactory.h>
-#include <VectorIndex/VectorIndexCommon.h>
 #include <VectorIndex/MergeUtils.h>
+#include <VectorIndex/VectorIndexCommon.h>
+#include <VectorIndex/VectorIndexFactory.h>
+#include <Common/Exception.h>
+#include <Common/HashTable/HashMap.h>
 
 #include <base/logger_useful.h>
 
 namespace DB::ErrorCodes
 {
-extern const int LOGICAL_ERROR;
 extern const int STD_EXCEPTION;
+extern const int CORRUPTED_DATA;
 }
 
 namespace VectorIndex
@@ -36,30 +38,16 @@ std::condition_variable_any cv;
 int num_thread_for_vector;
 std::atomic_int count;
 
-String cutMutVer(const String &part_name)
+String cutMutVer(const String & part_name)
 {
-    static const String sub("_");
-
-    int count_of_sub = 0;
-
-    size_t i = 0;
-    while (i != String::npos)
-    {
-        i = part_name.find(sub, i);
-        if (i != String::npos) {
-            count_of_sub += 1;
-            i += 1;
-        }
-    }
-
-    if (count_of_sub <= 3)
+    std::vector<String> tokens;
+    boost::split(tokens, part_name, boost::is_any_of("_"));
+    if (tokens.size() <= 4) /// without mutation version
     {
         return part_name;
     }
-
-    size_t j = part_name.rfind(sub);
-
-    return part_name.substr(0, j);
+    else
+        return tokens[0] + "_" + tokens[1] + "_" + tokens[2] + "_" + tokens[3];
 }
 
 static String dumpBitmap(GeneralBitMapPtr bit_map_ptr)
@@ -134,25 +122,14 @@ Status VectorSegmentExecutor::buildIndex(VectorDatasetPtr data_set, int64_t tota
             }
             if (para_copy.contains("compression_scheme"))
             {
-                if (this->dimension < 5)
-                {
-                    cmb = static_cast<uint8_t>(DB::CompressionMethodByte::NONE);
-                }
-                else
-                {
-                    cmb = DB::CompressionCodecFactory::instance().get(para_copy.find("compression_scheme")->second, {})->getMethodByte();
-                }
+                cmb = DB::CompressionCodecFactory::instance().get(para_copy.find("compression_scheme")->second, {})->getMethodByte();
                 para_copy.erase("compression_scheme");
             }
-            else if (this->dimension < 5)
-            {
-                cmb = static_cast<uint8_t>(DB::CompressionMethodByte::NONE);
-            }
             index = VectorIndexFactory::createIndex(type, mode, me, this->dimension, para_copy);
 
             {
                 /// slow mode
-                if (containRowIdsMaps(segment_id.data_part_path))
+                if (slow_mode)
                 {
                     int num_procs = omp_get_num_procs();
                     /// only use half cores
@@ -507,7 +484,7 @@ Status VectorSegmentExecutor::load()
             BinaryPtr index_binary = std::make_shared<Binary>();
             index_binary->size = original_binary_size;
             LOG_INFO(log, "[load] original_binary_size: {}", original_binary_size);
-            index_binary->data = new uint8_t[original_binary_size];
+            index_binary->data = new uint8_t[original_binary_size + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
 
             bool next = true;
             int part_count = 0;
@@ -538,13 +515,9 @@ Status VectorSegmentExecutor::load()
             if (des.contains("metric_type"))
             {
                 me = VectorIndexFactory::createIndexMetrics(des.at("metric_type"));
-                des.erase("metric_type");
             }
             Parameters place_holder;
             index = VectorIndexFactory::createIndex(type, mode, me, dimension, place_holder);
-            //        if(total_vec < MAX_BRUTE_FORCE_SEARCH_SIZE){
-            //            type = IndexType::FLAT;
-            //        }
             LOG_INFO(log, "[load] start loading index: total_vec: {}", total_vec);
             try
             {
@@ -614,12 +587,10 @@ Status VectorSegmentExecutor::load()
 Status VectorSegmentExecutor::readPart(bool & next, int part_count, uint8_t* index_binary, int64_t & current_loaded_size)
 {
     DiskIOReader reader;
-    if (!reader.open(segment_id.getFullPath() + "_" + ItoS(part_count) + VECTOR_INDEX_FILE_SUFFIX))
+    String path = segment_id.getFullPath() + "_" + ItoS(part_count) + VECTOR_INDEX_FILE_SUFFIX;
+    if (!reader.open(path))
     {
-        if (!reader.open(segment_id.getFullPath() + "_" + ItoS(part_count)))
-        {
-            return Status(5, "unable to open file" + segment_id.getFullPath() + "_" + ItoS(part_count));
-        }
+        return Status(5, "unable to open file " + path);
     }
     BinaryPtr index_binary_compressed = std::make_shared<Binary>();
     /// first 8 bytes is final mark, deciding if this is the last segment
@@ -651,7 +622,7 @@ Status VectorSegmentExecutor::readPart(bool & next, int part_count, uint8_t* ind
 
     /// finally we have the compressed binaries
     reader.seekg(sizeof(int64_t) * 4);
-    index_binary_compressed->data = new uint8_t[binary_length];
+    index_binary_compressed->data = new uint8_t[binary_length + COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER];
     index_binary_compressed->size = binary_length;
 
     reader.read(index_binary_compressed->data, binary_length);
@@ -941,15 +912,7 @@ uint32_t VectorSegmentExecutor::compressWithCheckSum(uint8_t * source, size_t si
 
 uint32_t VectorSegmentExecutor::validateAndDecompress(const BinaryPtr source, size_t uncompressed_size, uint8_t * des)
 {
-    uint8_t method = 0;
-    if (this->dimension < 5)
-    {
-        method = static_cast<const UInt8>(DB::CompressionMethodByte::NONE);
-    }
-    else
-    {
-        method = DB::ICompressionCodec::readMethod(reinterpret_cast<const char *>(source->data));
-    }
+    uint8_t method = DB::ICompressionCodec::readMethod(reinterpret_cast<const char *>(source->data));
     //    if(method==static_cast<const UInt8>(DB::CompressionMethodByte::NONE)){
     //        ///if no compression,don't decompress, just point des to source
     //        des.swap(source);
@@ -968,7 +931,7 @@ uint32_t VectorSegmentExecutor::validateAndDecompress(const BinaryPtr source, si
     {
         LOG_ERROR(
             log, "The binary is corrupted, decompressed size: {}, recorded decompressed sized: {}", size_decompressed, uncompressed_size);
-        throw IndexException(DB::ErrorCodes::LOGICAL_ERROR, "vector index on disk is corrupted");
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "vector index on disk is corrupted");
     }
     return size_decompressed;
 }
@@ -1033,27 +996,29 @@ bool VectorSegmentExecutor::readBitMap()
 {
     DiskIOReader bit_map_reader;
     String read_file_path = segment_id.getBitMapFilePath();
-    if (delete_bitmap == nullptr)
-    {
-        delete_bitmap = std::make_shared<GeneralBitMap>(total_vec);
-    }
 
     if (!bit_map_reader.open(read_file_path + VECTOR_INDEX_FILE_SUFFIX))
     {
         if (!bit_map_reader.open(read_file_path))
         {
-            memset(delete_bitmap->bitmap, 255, (total_vec / 8) + 1);
             return false;
         }
     }
 
     int64_t bit_map_size;
     bit_map_reader.read(&bit_map_size, sizeof(int64_t));
+    if (bit_map_size != (total_vec >> 3) + 1)
+    {
+        LOG_ERROR(log, "bitmap file {} is corrupted: bit_map_size {}, total_vec {}", read_file_path, bit_map_size, total_vec);
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "vector index bitmap on disk is corrupted");
+    }
+
+    if (delete_bitmap == nullptr)
+        delete_bitmap = std::make_shared<GeneralBitMap>(total_vec);
+
     bit_map_reader.seekg(sizeof(int64_t));
     bit_map_reader.read(delete_bitmap->bitmap, bit_map_size);
 
-    delete_bitmap->size = total_vec;
-
     return true;
 }
 
@@ -1127,56 +1092,118 @@ std::list<std::pair<CacheKey, Parameters>> VectorSegmentExecutor::getAllCacheNam
     return CacheManager::getInstance()->getAllItems();
 }
 
-GeneralBitMapPtr VectorIndexUtil::readDeleteBitmap(const String & bitmap_path, UInt64 total_vec)
+void VectorSegmentExecutor::readTotalVec()
 {
-    DiskIOReader bit_map_reader;
-    if (!bit_map_reader.open(bitmap_path))
+    DiskIOReader reader;
+    String path = segment_id.getFullPath() + "_" + ItoS(0) + VECTOR_INDEX_FILE_SUFFIX;
+    if (!reader.open(path))
     {
-        return nullptr;
+        LOG_ERROR(log, "failed to open {}", path);
+        throw IndexException(DB::ErrorCodes::CORRUPTED_DATA, "failed to open " + path);
     }
 
-    GeneralBitMapPtr delete_bitmap = std::make_shared<GeneralBitMap>(total_vec);
+    reader.seekg(sizeof(int64_t) * 3);
+    reader.read(&total_vec, sizeof(total_vec));
+    LOG_DEBUG(log, "[readTotalVec] total vectors read: {}", total_vec);
+}
 
-    int64_t bit_map_size;
-    bit_map_reader.read(&bit_map_size, sizeof(int64_t));
-    bit_map_reader.seekg(sizeof(int64_t));
-    bit_map_reader.read(delete_bitmap->bitmap, bit_map_size);
+void VectorSegmentExecutor::updateBitMap(const std::vector<UInt64>& deleted_row_ids)
+{
+    if (segment_id.fromMergedParts())
+        return;
 
-    delete_bitmap->size = total_vec;
+    readTotalVec();
 
-    return delete_bitmap;
-}
+    /// Read the delete bitmap
+    if (!readBitMap())
+    {
+        LOG_WARNING(log, "[updateBitMap] Skip to update not readable vector bitMap file part {}", segment_id.current_part_name);
+        return;
+    }
 
-bool VectorIndexUtil::writeDeleteBitmap(const String & bitmap_path, GeneralBitMapPtr delete_bitmap)
-{
-    if (!delete_bitmap)
+    /// Map new deleted row ids to row ids in old part and update delete bitmap
+    bool need_update = false;
+    for (auto & del_row_id : deleted_row_ids)
     {
-        return false;
+        if (delete_bitmap->test(del_row_id))
+        {
+            delete_bitmap->unset(del_row_id);
+
+            if (!need_update)
+                need_update = true;
+        }
     }
 
-    DiskIOWriter bit_map_writer;
-    bit_map_writer.open(bitmap_path, false);
+    if (!need_update)
+        return;
 
-    int64_t total_vec = delete_bitmap->size;
-    int64_t byte_count = (total_vec >> 3) + 1;
-    bit_map_writer.write(&byte_count, sizeof(int64_t));
+    /// Flush the updated delete bitmap to disk
+    writeBitMap();
 
-    bit_map_writer.write(delete_bitmap->bitmap, byte_count);
-    bit_map_writer.close();
+    /// Update bitmap in cache if exists
+    CacheManager * mgr = CacheManager::getInstance();
+    CacheKey cache_key = segment_id.getCacheKey();
 
-    return true;
+    IndexWithMetaPtr cache_index = mgr->get(cache_key);
+    if (cache_index)
+        cache_index->setDeleteBitmap(delete_bitmap);
 }
 
-bool VectorIndexUtil::writeDeleteBitmap(const SegmentId & segment_id, GeneralBitMapPtr delete_bitmap)
+void VectorSegmentExecutor::updateMergedBitMap(const std::vector<UInt64>& deleted_row_ids)
 {
-    if (!delete_bitmap)
+    if (!segment_id.fromMergedParts())
+        return;
+
+    readTotalVec();
+
+    /// Read the delete bitmap
+    if (!readBitMap())
     {
-        return false;
+        LOG_WARNING(log, "[updateMergedBitMap] Skip to update not readable vector bitMap file for segement: merged part {} in decouple part {}", segment_id.owner_part_name, segment_id.current_part_name);
+        return;
     }
 
-    String bitMap_path = segment_id.getBitMapFilePath() + VECTOR_INDEX_FILE_SUFFIX;
+    /// Call handleMergedMaps() to get inverted_row_ids_map and inverted_row_sources_map
+    try
+    {
+        handleMergedMaps();
+    }
+    catch(const DB::Exception & e)
+    {
+        LOG_DEBUG(log, "[updateMergedBitMap] Skip to update vector bitmap due to failure when read inverted row ids map entries, error: {}", e.what());
+        return;
+    }
+
+    /// Map new deleted row ids to row ids in old part and update delete bitmap
+    bool need_update = false;
+    for (auto & new_row_id : deleted_row_ids)
+    {
+        if (segment_id.getOwnPartId() == (*inverted_row_sources_map)[new_row_id])
+        {
+            UInt64 old_row_id = (*inverted_row_ids_map)[new_row_id];
+            if (delete_bitmap->test(old_row_id))
+            {
+                delete_bitmap->unset(old_row_id);
+
+                if (!need_update)
+                    need_update = true;
+            }
+        }
+    }
+
+    if (!need_update)
+        return;
+
+    /// Flush the updated delete bitmap to disk
+    writeBitMap();
+
+    /// Update bitmap in cache if exists
+    CacheManager * mgr = CacheManager::getInstance();
+    CacheKey cache_key = segment_id.getCacheKey();
 
-    return writeDeleteBitmap(bitMap_path, delete_bitmap);
+    IndexWithMetaPtr cache_index = mgr->get(cache_key);
+    if (cache_index)
+        cache_index->setDeleteBitmap(delete_bitmap);
 }
 
 
diff --git a/src/VectorIndex/VectorSegmentExecutor.h b/src/VectorIndex/VectorSegmentExecutor.h
index 0dc3d83d52..dc10ab85ce 100644
--- a/src/VectorIndex/VectorSegmentExecutor.h
+++ b/src/VectorIndex/VectorSegmentExecutor.h
@@ -55,7 +55,7 @@ public:
     void setDeleteBitmap(GeneralBitMapPtr delete_bitmap_)
     {
         std::lock_guard<std::mutex> lg(mutex_of_delete_bitmap);
-        delete_bitmap = delete_bitmap_;
+        delete_bitmap = std::move(delete_bitmap_);
     }
 
     GeneralBitMapPtr getDeleteBitmap() const
@@ -192,6 +192,15 @@ public:
         segment_id = new_segment_id;
     }
 
+    /// Reload delete bitmap from disk.
+    bool reloadDeleteBitMap() { return readBitMap(); }
+
+    /// Update part's single delete bitmap after lightweight delete on disk and cache if exists.
+    void updateBitMap(const std::vector<UInt64>& deleted_row_ids);
+
+    /// Update merged old part's delete bitmap after lightweight delete on disk and cache if exists.
+    void updateMergedBitMap(const std::vector<UInt64>& deleted_row_ids);
+
 private:
     Status startWrite();
 
@@ -215,6 +224,8 @@ private:
 
     void handleMergedMaps();
 
+    void readTotalVec();
+
     void transferToNewRowIds(int64_t *& labels, int size)
     {
         if (row_ids_map->empty())
@@ -226,14 +237,14 @@ private:
 
         for (int i = 0; i < size; i++)
         {
-            if (labels[i] > row_ids_map->size())
+            if (labels[i] != -1)
             {
-                LOG_DEBUG(log, "[transferToNewRowIds] overflow: label: {}", labels[i]);
+                labels[i] = (*row_ids_map)[labels[i]];
             }
-            labels[i] = (*row_ids_map)[labels[i]];
         }
     }
 
+    const static UInt32 COMPRESSION_ADDITIONAL_BYTES_AT_END_OF_BUFFER = LZ4::ADDITIONAL_BYTES_AT_END_OF_BUFFER;
     const UInt32 dimension;
     const IndexType type;
     IndexMode mode = IndexMode::CPU;
@@ -255,12 +266,4 @@ private:
 using VectorSegmentExecutorPtr = std::shared_ptr<VectorSegmentExecutor>;
 
 
-class VectorIndexUtil
-{
-public:
-    static GeneralBitMapPtr readDeleteBitmap(const String & bitmap_path, UInt64 total_vec);
-    static bool writeDeleteBitmap(const String & bitmap_path, GeneralBitMapPtr delete_bitmap);
-    static bool writeDeleteBitmap(const SegmentId & segment_id, GeneralBitMapPtr delete_bitmap);
-};
-
 }
diff --git a/tests/queries/2_vector_search/00015_mqvs_create_vector_index.sql b/tests/queries/2_vector_search/00015_mqvs_create_vector_index.sql
index f079697624..768db2a1b1 100644
--- a/tests/queries/2_vector_search/00015_mqvs_create_vector_index.sql
+++ b/tests/queries/2_vector_search/00015_mqvs_create_vector_index.sql
@@ -10,9 +10,9 @@ CREATE TABLE test_vector
 ENGINE = MergeTree PRIMARY KEY id;
 
 create vector index if not exists i_h on test_vector vector TYPE FLAT;
-SELECT table, name, type, expr, status FROM system.vector_indices WHERE table = 'test_vector' FORMAT Vertical;
+SELECT table, name, type, expr, status FROM system.vector_indices WHERE database = currentDatabase() and table = 'test_vector' FORMAT Vertical;
 drop vector index if exists i_h on test_vector;
-SELECT table, name, type, expr, status FROM system.vector_indices WHERE table = 'test_vector' FORMAT Vertical;
+SELECT table, name, type, expr, status FROM system.vector_indices WHERE database = currentDatabase() and table = 'test_vector' FORMAT Vertical;
 
 create vector index i_h on test_vector vector TYPE FLAT;
 drop vector index i_h on test_vector; 
diff --git a/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.reference b/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.reference
index b787ca8b47..40e2b75b2c 100644
--- a/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.reference
+++ b/tests/queries/2_vector_search/00016_mqvs_index_build_after_lightweight_delete.reference
@@ -8,3 +8,4 @@
 7	[7,7,7]	142.83
 8	[8,8,8]	187.23
 9	[9,9,9]	237.62997
+10	[10,10,10]	294.02997
diff --git a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.reference b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.reference
index 59be906964..4d60214a45 100644
--- a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.reference
+++ b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.reference
@@ -50,3 +50,25 @@
 14	[14,14,14]	579.63
 15	[15,15,15]	666.02997
 16	[16,16,16]	758.42993
+--- lightweight delete on decoupled part
+test_vector	v1	HNSWFLAT	1	NoVectorIndexData
+0	[0,0,0]	0.030000001
+1	[1,1,1]	2.4299998
+4	[4,4,4]	45.630005
+5	[5,5,5]	72.03
+6	[6,6,6]	104.43001
+7	[7,7,7]	142.83
+8	[8,8,8]	187.23
+9	[9,9,9]	237.62997
+11	[11,11,11]	356.42996
+12	[12,12,12]	424.82996
+6	[6,6,6]	104.43001
+7	[7,7,7]	142.83
+8	[8,8,8]	187.23
+9	[9,9,9]	237.62997
+11	[11,11,11]	356.42996
+12	[12,12,12]	424.82996
+13	[13,13,13]	499.22998
+14	[14,14,14]	579.63
+16	[16,16,16]	758.42993
+17	[17,17,17]	856.82996
diff --git a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
index 890a838f2c..66258ec2ff 100644
--- a/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
+++ b/tests/queries/2_vector_search/00017_mqvs_lightweight_delete_with_decouple.sql
@@ -23,7 +23,15 @@ SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector
 optimize table test_vector final;
 
 SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
+SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector prewhere id > 5;
+
+SELECT '--- lightweight delete on decoupled part';
+delete from test_vector where id = 3;
+delete from test_vector where id = 15;
 
+select table, name, type, total_parts, status from system.vector_indices where database = currentDatabase() and table = 'test_vector';
+
+SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector;
 SELECT id, vector, distance('topK=10')(vector, [0.1, 0.1, 0.1]) FROM test_vector prewhere id > 5;
 
-## drop table test_vector;
+drop table test_vector;
-- 
2.32.1 (Apple Git-133)

